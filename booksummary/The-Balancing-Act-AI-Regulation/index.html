<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.147.0"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel="shortcut icon" href="https://localhost:1313/favicons/favicon.ico?v=1"><link rel=apple-touch-icon href="https://localhost:1313/favicons/apple-touch-icon-180x180.png?v=1" sizes=180x180><link rel=icon type=image/png href="https://localhost:1313/favicons/favicon-16x16.png?v=1" sizes=16x16><link rel=icon type=image/png href="https://localhost:1313/favicons/favicon-32x32.png?v=1" sizes=32x32><link rel=apple-touch-icon href="https://localhost:1313/favicons/apple-touch-icon-180x180.png?v=1" sizes=180x180><title>The Balancing Act - AI Regulation | Blowfish</title><meta property="og:url" content="https://localhost:1313/booksummary/The-Balancing-Act-AI-Regulation/">
<meta property="og:site_name" content="Blowfish"><meta property="og:title" content="The Balancing Act - AI Regulation"><meta property="og:description" content="The Balancing Act - AI Regulation Questions of this Interview Below is a list of direct questions posed by the interviewer (Professor Hannah Fry) to Nicklas Lundblad (Deepmind)"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="booksummary"><meta property="article:published_time" content="2024-12-25T00:00:00+00:00"><meta property="article:modified_time" content="2024-12-25T00:00:00+00:00"><meta property="article:tag" content="Interview"><meta property="article:tag" content="Nicklas Lundblad"><meta property="article:tag" content="Philosophy"><meta itemprop=name content="The Balancing Act - AI Regulation"><meta itemprop=description content="The Balancing Act - AI Regulation Questions of this Interview Below is a list of direct questions posed by the interviewer (Professor Hannah Fry) to Nicklas Lundblad (Deepmind)"><meta itemprop=datePublished content="2024-12-25T00:00:00+00:00"><meta itemprop=dateModified content="2024-12-25T00:00:00+00:00"><meta itemprop=wordCount content="1708"><meta itemprop=keywords content="Interview Nicklas Lundblad on AI Regulation,Nicklas Lundblad,Professor Hannah Fry,Philosophy"><meta name=twitter:card content="summary"><meta name=twitter:title content="The Balancing Act - AI Regulation"><meta name=twitter:description content="The Balancing Act - AI Regulation Questions of this Interview Below is a list of direct questions posed by the interviewer (Professor Hannah Fry) to Nicklas Lundblad (Deepmind)"><link rel=preload href=https://localhost:1313/scss/main.min.8d5e9853aa86c416850fe7ccb39d048388bfe7fbefb7922f796f886c3c8084d8.css as=style integrity="sha256-jV6YU6qGxBaFD+fMs50Eg4i/5/vvt5IveW+IbDyAhNg=" crossorigin=anonymous><link href=https://localhost:1313/scss/main.min.8d5e9853aa86c416850fe7ccb39d048388bfe7fbefb7922f796f886c3c8084d8.css rel=stylesheet integrity="sha256-jV6YU6qGxBaFD+fMs50Eg4i/5/vvt5IveW+IbDyAhNg=" crossorigin=anonymous><link rel=stylesheet type=text/css href=https://localhost:1313/css/asciinema-player.css><script src=https://code.jquery.com/jquery-3.3.1.min.js integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin=anonymous></script><link rel=stylesheet href=https://localhost:1313/css/custom.css><script src=https://localhost:1313/js/lunr.js></script></head><body class=td-page><header><nav class="js-navbar-scroll navbar navbar-expand navbar-light nav-shadow flex-column flex-md-row td-navbar"><a id=agones-top class=navbar-brand href=https://localhost:1313/><svg id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><rect x="198.8952" y="225.1043" style="fill:#5b7fc0" width="122.6266" height="13.8671"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zm7.993 21.8577c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><rect x="198.8952" y="170.69" style="fill:#d95140" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><rect x="199.3456" y="279.5436" style="fill:#56a55c" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><rect x="198.8952" y="333.6497" style="fill:#f1bc42" width="122.6266" height="13.8671"/></g></g></svg> <span class="text-uppercase fw-bold">Blowfish</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://localhost:1313/template/about/><span>About</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://localhost:1313/><span>Data Science</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://localhost:1313/template/docs/><span>Documentation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://localhost:1313/template/docs/><span>Docs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://localhost:1313/community/><span>Community</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://localhost:1313/template/docs/shortcodes/><span>Short Codes</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://localhost:1313/template/blog/><span>Blog</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://github.com/nunocoracao/blowfish><span></span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href>GitHub</a></li><li class="nav-item dropdown d-none d-lg-block"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Release</a><div class=dropdown-menu aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=https://development.agones.dev>Development</a>
<a class=dropdown-item href=https://agones.dev></a><a class=dropdown-item href=https://1-47-0.agones.dev>1.47.0</a>
<a class=dropdown-item href=https://1-46-0.agones.dev>1.46.0</a>
<a class=dropdown-item href=https://1-45-0.agones.dev>1.45.0</a>
<a class=dropdown-item href=https://1-44-0.agones.dev>1.44.0</a>
<a class=dropdown-item href=https://1-43-0.agones.dev>1.43.0</a>
<a class=dropdown-item href=https://1-42-0.agones.dev>1.42.0</a>
<a class=dropdown-item href=https://1-41-0.agones.dev>1.41.0</a>
<a class=dropdown-item href=https://1-40-0.agones.dev>1.40.0</a>
<a class=dropdown-item href=https://1-39-0.agones.dev>1.39.0</a>
<a class=dropdown-item href=https://1-38-0.agones.dev>1.38.0</a>
<a class=dropdown-item href=https://1-37-0.agones.dev>1.37.0</a>
<a class=dropdown-item href=https://1-36-0.agones.dev>1.36.0</a>
<a class=dropdown-item href=https://1-35-0.agones.dev>1.35.0</a>
<a class=dropdown-item href=https://1-34-0.agones.dev>1.34.0</a>
<a class=dropdown-item href=https://1-33-0.agones.dev>1.33.0</a>
<a class=dropdown-item href=https://1-32-0.agones.dev>1.32.0</a>
<a class=dropdown-item href=https://1-31-0.agones.dev>1.31.0</a></div></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><ul class=dropdown-menu><li><a class=dropdown-item href=https://localhost:1313/it/>Italiano</a></li></ul></div></li></ul></div><div class="navbar-nav mx-lg-2 d-none d-lg-block"></div></nav></header><div class="container-fluid td-default td-outer"><main role=main class=td-main><div class=row><div class=col-md-2></div><div class=col-md-8><p><img src=https://localhost:1313/assets/images/booksummary/7544-The-Balancing-Act-AI-Regulation.jpg alt="The Balancing Act - AI Regulation"></p><h1 id=the-balancing-act---ai-regulation>The Balancing Act - AI Regulation<a class=td-heading-self-link href=#the-balancing-act---ai-regulation aria-label="Heading self-link"></a></h1><h2 id=questions-of-this-interview>Questions of this Interview<a class=td-heading-self-link href=#questions-of-this-interview aria-label="Heading self-link"></a></h2><p>Below is a list of direct questions posed by the interviewer (Professor Hannah Fry) to Nicklas Lundblad (Deepmind)</p><ol><li><p>How would you describe the current public mood, as it were, around the subject?</p></li><li><p>Do you think there’s been a shift in public mood? I mean, with the explosion of generative AI into the scenes Have you noticed a mood shift as a result?</p></li><li><p>Could you give us a brief overview of where we are at the moment in terms of the landscape of regulation on artificial intelligence?</p></li><li><p>Do you think that AI, as a distinct technology, needs regulating sort of independently of other technologies?</p></li><li><p>I’m thinking here about CRISPR or plutonium, for instance, where there are very strict rules. Doesn’t that mean sometimes we do regulate the technology itself?</p></li><li><p>If we apply that back to AI, how do you regulate the harms without regulating the technology? What does that actually look like in practice?</p></li><li><p>Does that not require you knowing in advance what the potential harms will be?</p></li><li><p>Give me an example. In what situation would it make it difficult? (Referring to setting bars for safety, false positives, etc.)</p></li><li><p>I wonder whether there’s a question here about must we do it at all? If doing so means there’s unavoidable uncertainty, then what about just not doing it?</p></li><li><p>What do you think the role should be in having private companies shape this regulation?</p></li><li><p>Is that a universal belief among the tech industry? (Reffering to building expertise and understanding of technology in the public sector and the idea that mutual dialogue between private companies and policymakers is essential.)</p></li><li><p>But there are some who think that self-regulation should be the main lever that gets used as we go forwards. What’s your take on that?</p></li><li><p>I guess one of the other big counterarguments is that this whole picture is really further colored by the pursuit of profit. So can you trust that companies are doing this for public good, or for competitive advantage?</p></li><li><p>Do you think then, with that as the background, there is a risk that we’ll end up in a future where AI is in the hands of a very small number of companies?</p></li><li><p>They’ve really gone for this risk-based approach. Do you think this is broadly a good approach? (On the EU AI Act)</p></li><li><p>Do you think then that we will see similar types of innovation? For instance, will the EU regulations force wider adoption of ideas like SynthID, and maybe even lead to a standardized system?</p></li><li><p>How about within ‘Google DeepMind,’ then? Do you have certain applications that you consider off limits here?</p></li><li><p>How do you decide at ‘Google DeepMind’ which projects you will and won’t get involved in? How does that decision process happen?</p></li><li><p>Why in a couple of years? Why not now? (Referencing Demis Hassabis’s idea of regulating frontier models in a couple of years)</p></li><li><p>Are there any emerging capabilities that you are particularly concerned about?</p></li><li><p>Do you think that we’re going to get to a point where international bodies will collaborate on AI regulation, or do you think that we’ll stay in this situation where different regions of the world approach it differently?</p></li><li><p>One place that has not yet planted its flag about regulation at all is the UK. Do you think that when it does, it will end up being closer to the EU or to the US?</p></li></ol><h2 id=themes-discussed-in-this-interview>Themes discussed in this interview<a class=td-heading-self-link href=#themes-discussed-in-this-interview aria-label="Heading self-link"></a></h2><h3 id=1-the-need-for-ai-regulation><strong>1. The Need for AI Regulation</strong><a class=td-heading-self-link href=#1-the-need-for-ai-regulation aria-label="Heading self-link"></a></h3><ul><li>There is broad consensus that regulation is essential as AI becomes integrated into society.</li><li>The challenge lies in balancing <strong>innovation</strong> with <strong>safeguarding against harm</strong>.</li><li>Regulation should aim to ensure transparency, accountability, and public trust while fostering innovation.</li></ul><hr><h3 id=2-approaches-to-ai-regulation><strong>2. Approaches to AI Regulation</strong><a class=td-heading-self-link href=#2-approaches-to-ai-regulation aria-label="Heading self-link"></a></h3><ul><li><strong>US Approach:</strong> Focuses on sectoral, industry-led regulation (e.g., healthcare, education).</li><li><strong>EU Approach:</strong> Adopts a horizontal, risk-based framework with stricter rules for high-risk systems (e.g., the AI Act).</li><li><strong>UK Approach:</strong> Still developing; likely to favor a sectoral approach but lean closer to the US model.</li><li><strong>China Approach:</strong> Focuses on power dynamics, regulating information algorithms and societal impact.</li></ul><hr><h3 id=3-regulation-of-technology-vs-regulation-of-use><strong>3. Regulation of Technology vs. Regulation of Use</strong><a class=td-heading-self-link href=#3-regulation-of-technology-vs-regulation-of-use aria-label="Heading self-link"></a></h3><ul><li>Debate on whether regulation should target the <strong>technology itself</strong> (e.g., CRISPR or plutonium) or its <strong>applications and uses</strong>.</li><li>Many regulatory decisions are based on addressing <strong>potential harm</strong> rather than blanket bans on technology.</li></ul><hr><h3 id=4-challenges-in-ai-regulation><strong>4. Challenges in AI Regulation</strong><a class=td-heading-self-link href=#4-challenges-in-ai-regulation aria-label="Heading self-link"></a></h3><ul><li><strong>Uncertainty of Harms:</strong> Difficulty in predicting all potential harms of emerging technology.</li><li><strong>Risk vs. Reward:</strong> Balancing the risks of AI with its potential for high rewards, like solving complex societal problems.</li><li><strong>Global Disparities:</strong> Differing regional regulatory approaches may lead to uneven innovation and competitive advantages.</li></ul><hr><h3 id=5-the-role-of-private-companies><strong>5. The Role of Private Companies</strong><a class=td-heading-self-link href=#5-the-role-of-private-companies aria-label="Heading self-link"></a></h3><ul><li>Companies are key players in shaping regulation, but there are concerns about the influence of profit motives.</li><li>Effective collaboration requires <strong>knowledge exchange</strong>: companies provide technical insights, while policymakers contribute democratic values and societal priorities.</li></ul><hr><h3 id=6-regulatory-models><strong>6. Regulatory Models</strong><a class=td-heading-self-link href=#6-regulatory-models aria-label="Heading self-link"></a></h3><ul><li><strong>Precautionary Principle:</strong> Emphasized in Europe; focuses on minimizing potential harms before allowing deployment.</li><li><strong>Cost-Benefit Principle:</strong> Favored in the US; balances risks against potential benefits to determine acceptability.</li></ul><hr><h3 id=7-emerging-ai-capabilities-and-risks><strong>7. Emerging AI Capabilities and Risks</strong><a class=td-heading-self-link href=#7-emerging-ai-capabilities-and-risks aria-label="Heading self-link"></a></h3><ul><li>Concerns include <strong>bias, misinformation, deception, and persuasion</strong> enabled by AI.</li><li>The importance of understanding and mitigating these risks while fostering innovation is emphasized.</li></ul><hr><h3 id=8-frontier-models-and-safety><strong>8. Frontier Models and Safety</strong><a class=td-heading-self-link href=#8-frontier-models-and-safety aria-label="Heading self-link"></a></h3><ul><li>Discussion of <strong>frontier models</strong> (cutting-edge AI systems) and their potential risks.</li><li>Frontier models are large-scale machine-learning models that exceed the capabilities currently present in the most advanced existing models.</li><li>Suggestion to gradually develop testing and regulatory frameworks as capabilities evolve, rather than prematurely imposing restrictions.</li></ul><hr><h3 id=9-self-regulation-and-public-oversight><strong>9. Self-Regulation and Public Oversight</strong><a class=td-heading-self-link href=#9-self-regulation-and-public-oversight aria-label="Heading self-link"></a></h3><ul><li>Self-regulation may be effective in some cases, but transparency and public accountability are crucial.</li><li>A hybrid model combining <strong>self-regulation</strong> with <strong>legal auditing and external review</strong> could be more effective.</li></ul><hr><h3 id=10-international-collaboration><strong>10. International Collaboration</strong><a class=td-heading-self-link href=#10-international-collaboration aria-label="Heading self-link"></a></h3><ul><li>Efforts through OECD, UN, and G7 to harmonize AI regulations globally are underway, but geopolitical tensions pose challenges.</li><li>The necessity of aligning general principles (e.g., &ldquo;AI should benefit humanity&rdquo;) and specific practices is highlighted.</li></ul><hr><h3 id=11-ethical-principles-and-prohibited-uses><strong>11. Ethical Principles and Prohibited Uses</strong><a class=td-heading-self-link href=#11-ethical-principles-and-prohibited-uses aria-label="Heading self-link"></a></h3><ul><li>Proposals for blanket bans on certain applications (e.g., real-time biometric surveillance, social credit systems).</li><li>Companies like Google DeepMind have their own <strong>AI principles</strong> to decide which projects they will and won’t engage in.</li></ul><hr><h3 id=12-innovation-driven-by-regulation><strong>12. Innovation Driven by Regulation</strong><a class=td-heading-self-link href=#12-innovation-driven-by-regulation aria-label="Heading self-link"></a></h3><ul><li>Regulation can drive innovation when clear frameworks set goals or constraints (e.g., SynthID for watermarking AI content, EV innovation spurred by emissions standards).</li></ul><hr><h3 id=13-the-importance-of-public-investment-in-science><strong>13. The Importance of Public Investment in Science</strong><a class=td-heading-self-link href=#13-the-importance-of-public-investment-in-science aria-label="Heading self-link"></a></h3><ul><li>There is a call for more <strong>public funding</strong> in AI research to balance the dominance of private-sector investment and ensure societal benefits.</li></ul><hr><h3 id=14-democratic-and-transparent-governance><strong>14. Democratic and Transparent Governance</strong><a class=td-heading-self-link href=#14-democratic-and-transparent-governance aria-label="Heading self-link"></a></h3><ul><li>The role of <strong>democratic institutions</strong> in ensuring that regulation reflects societal values and not just corporate interests.</li><li>The importance of engaging diverse stakeholders in shaping AI governance.</li></ul><hr><h3 id=15-future-directions><strong>15. Future Directions</strong><a class=td-heading-self-link href=#15-future-directions aria-label="Heading self-link"></a></h3><ul><li>Building <strong>testing institutions</strong> and <strong>benchmarking systems</strong> to evaluate AI models systematically.</li><li>Regulatory &ldquo;curiosity&rdquo; is vital for exploring where interventions can best mitigate harm while enabling progress.</li></ul><hr><h3 id=16-regulation-vs-legislation><strong>16. Regulation vs Legislation</strong><a class=td-heading-self-link href=#16-regulation-vs-legislation aria-label="Heading self-link"></a></h3><ul><li>Regulation: Refers to a broader framework for controlling or guiding the use of technology. It can involve a combination of tools such as norms, market forces, architectural design (how the technology is built), and laws.</li><li>Legislation: Refers specifically to laws enacted by governments or legislative bodies. Legislation is a subset of regulation and focuses on formal, legal rules and requirements.</li></ul><hr><h2 id=books-and-documents-discused-in-this-interview>Books and Documents Discused in this Interview<a class=td-heading-self-link href=#books-and-documents-discused-in-this-interview aria-label="Heading self-link"></a></h2><p>The transcript mentions the following books:</p><h3 id=1><strong>1. <em>Code and Other Laws of Cyberspace</em> by Lawrence Lessig</strong><a class=td-heading-self-link href=#1 aria-label="Heading self-link"></a></h3><p>This book is referenced by Nicklas Lundblad to explain the broader concept of regulation, emphasizing that regulation is not just about laws (legislation) but also includes architecture (technical design), markets (economic forces), and norms (societal expectations). This book presents a framework for understanding how technology can be regulated through multiple forces and highlights the interplay between technology and societal governance.</p><h3 id=2><strong>2. <em>The Library of Babel</em> by Jorge Luis Borges</strong><a class=td-heading-self-link href=#2 aria-label="Heading self-link"></a></h3><p>Nicklas Lundblad during the discussion on the hype cycle of technologies, he refers to Borges&rsquo; fictional library containing all possible books as a metaphor for the initial euphoria and subsequent disillusionment that often accompany technological breakthroughs. This explores the infinite nature of information and the despair that comes with its overwhelming abundance, which parallels the excitement and challenges of technological advancements like AI.</p><h3 id=3><strong>3. <em>The Imperative of Responsibility</em> by Hans Jonas</strong><a class=td-heading-self-link href=#3 aria-label="Heading self-link"></a></h3><p>Lundblad discusses the sociotechnical aspect of regulation. He mentions Jonas&rsquo; philosophical idea that all use of technology is an exercise of power. This book argues for an ethical framework of responsibility in using technology, particularly in light of humanity&rsquo;s increasing capacity to affect the future through technological innovation.</p><h3 id=4><strong>4. <em>A Declaration of the Independence of Cyberspace</em> by John Perry Barlow</strong><a class=td-heading-self-link href=#4 aria-label="Heading self-link"></a></h3><p>(not a book but an essay/document)<br>Libertarian ethos of early internet regulation debates contrasts this with the current, more cautious and regulation-friendly approach to AI. It argues for minimal interference by governments in the digital realm, reflecting a libertarian vision of freedom on the internet.</p><hr><h2 id=key-hypothesis-by-nicklas-lundblad>Key Hypothesis by Nicklas Lundblad<a class=td-heading-self-link href=#key-hypothesis-by-nicklas-lundblad aria-label="Heading self-link"></a></h2><p>While responding to these question Nicklas Lundblad had following hypothesis:</p><ul><li>Different global approaches to AI regulation (e.g., EU&rsquo;s risk-based model, US&rsquo;s sectoral model, China&rsquo;s focus on societal control) are effectively &ldquo;experiments,&rdquo; and we will learn from their successes and failures over time.</li><li>Regulation should be oriented around mitigating harm rather than directly targeting the technology itself.</li><li>Effective regulation requires considering both the risks and the potential rewards of AI applications, particularly in high-impact areas such as healthcare or climate change.</li><li>A well-defined regulatory frameworks can spur innovation by providing certainty and goals for companies to meet.</li><li>Democracies are more capable of balancing public interests, technical knowledge, and ethical considerations when regulating AI compared to authoritarian systems.</li><li>Immediate, restrictive regulation of cutting-edge AI (frontier models) might stifle innovation. A better approach is to build evaluation frameworks, test models, and incrementally develop regulatory standards.</li><li>Self-regulation by AI companies can be effective if paired with transparency, external audits, and government oversight.</li><li>The effectiveness of AI regulation can be partially measured by how quickly the technology diffuses through society and the economy, unlocking benefits and welfare.</li><li>While there is value in global collaboration on AI regulation (e.g., through the UN, OECD), geopolitical tensions and national competitiveness will likely limit the scope of such efforts.</li></ul><p><a href="https://www.youtube.com/watch?v=eWuumlduTRg">Full Interview : The Balancing Act: AI & Regulation with Nicklas Lundblad</a></p><div class=td-tags><h4 class=td-tags__title>Tags:</h4><div class=category-badges><a href=https://localhost:1313/tags/interview class=category-badge>Interview</a><a href=https://localhost:1313/tags/nicklas-lundblad class=category-badge>Nicklas Lundblad</a><a href=https://localhost:1313/tags/philosophy class=category-badge>Philosophy</a></div></div><div class=td-author-box><div class=td-author-box__info><h4 class=td-author-box__name>Blowfish</h4><p class=td-author-box__bio>A powerful, lightweight theme for Hugo.</p><div class=td-author-box__links><a href target=_blank rel=noopener aria-label></a><a href target=_blank rel=noopener aria-label></a></div></div></div><div class=td-social-share><h4 class=td-social-share__title>Share this article:</h4><ul class=td-social-share__list><div class=social-share><a href="https://twitter.com/intent/tweet?text=The%20Balancing%20Act%20-%20AI%20Regulation&url=https%3a%2f%2flocalhost%3a1313%2fbooksummary%2fThe-Balancing-Act-AI-Regulation%2f" target=_blank rel=noopener aria-label="Share on Twitter"><i class="fab fa-twitter"></i>
</a><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2flocalhost%3a1313%2fbooksummary%2fThe-Balancing-Act-AI-Regulation%2f" target=_blank rel=noopener aria-label="Share on Facebook"><i class="fab fa-facebook"></i>
</a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2flocalhost%3a1313%2fbooksummary%2fThe-Balancing-Act-AI-Regulation%2f&title=The%20Balancing%20Act%20-%20AI%20Regulation" target=_blank rel=noopener aria-label="Share on LinkedIn"><i class="fab fa-linkedin"></i>
</a><a href="https://www.reddit.com/submit?url=https%3a%2f%2flocalhost%3a1313%2fbooksummary%2fThe-Balancing-Act-AI-Regulation%2f&title=The%20Balancing%20Act%20-%20AI%20Regulation" target=_blank rel=noopener aria-label="Share on Reddit"><i class="fab fa-reddit"></i>
</a><a href="mailto:?subject=The%20Balancing%20Act%20-%20AI%20Regulation&body=https%3a%2f%2flocalhost%3a1313%2fbooksummary%2fThe-Balancing-Act-AI-Regulation%2f" aria-label="Share via Email"><i class="fas fa-envelope"></i></a></div></ul></div><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><a class="td-pager__link td-pager__link--prev" href=https://localhost:1313/booksummary/Interview-Yuval-Noah-Harari-with-BeerBiceps/ aria-label="Previous page"><div class=td-pager__meta><i class="fa-solid fa-angle-left"></i>
<span class=td-pager__meta-label><b>Previous:</b></span>
<span class=td-pager__meta-title>Interview: Yuval Noah Harari with BeerBiceps</span></div></a><a class="td-pager__link td-pager__link--next" href=https://localhost:1313/booksummary/Geff-Hilton-Talk-Will-Digital-Intelligence-Replace-Biological-Intelligence/ aria-label="Next page"><div class=td-pager__meta><span class=td-pager__meta-label><b>Next:</b></span>
<span class=td-pager__meta-title>Geff Hilton Talk: Will Digital Intelligence Replace Biological Intelligence?</span>
<i class="fa-solid fa-angle-right"></i></div></a></ul></div><div class=col-md-2></div></div></main><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class=col-2><a href=https://dasarpai.com target=_blank rel=noopener><img src=https://localhost:1313/assets/images/site-logo.png alt=dasarpAI width=100 style=border-radius:12px></a></div><div class=col-8><div class=row></div><div class=row></div></div><div class=col-2></div><div class="td-footer__left col-6 col-sm-4 order-sm-1"></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"></div></div></div></footer></div><script src=https://localhost:1313/js/main.min.7c31f98e62c36b0c9c834ce3f8260a0e21895dd6aa0773e81a64b104eae3b2e8.js integrity="sha256-fDH5jmLDawycg0zj+CYKDiGJXdaqB3PoGmSxBOrjsug=" crossorigin=anonymous></script><script defer src=https://localhost:1313/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=https://localhost:1313/js/tabpane-persist.js></script><script src=https://localhost:1313/js/asciinema-player.js></script><script>(function(){var e=document.querySelector("#td-section-nav");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></body></html>