<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI Research on Blowfish</title><link>https://localhost:1313/tags/ai-research/</link><description>Recent content in AI Research on Blowfish</description><generator>Hugo</generator><language>en</language><managingEditor>nuno@n9o.xyz (Blowfish)</managingEditor><webMaster>nuno@n9o.xyz (Blowfish)</webMaster><lastBuildDate>Wed, 08 Nov 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://localhost:1313/tags/ai-research/index.xml" rel="self" type="application/rss+xml"/><item><title>My Journey from Master to PhD in Data Science and AI</title><link>https://localhost:1313/dsblog/journey-from-master-to-phd/</link><pubDate>Wed, 08 Nov 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/journey-from-master-to-phd/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6100-Journey-from-MS-to-Phd.jpg" alt="My Journey from Master to PhD in Data Science and AI">&lt;/p>
&lt;h1 id="my-journey-from-master-to-phd-in-data-science-and-ai">My Journey from Master to PhD in Data Science and AI&lt;a class="td-heading-self-link" href="#my-journey-from-master-to-phd-in-data-science-and-ai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>I have been in software development between 1993 to 2009. Some of these years were in senior leadership roles in delivery management, project management, CMMI, ISO, ISMS, PMO, etc. In 2010 I moved into project management training and consulting. In 2018, I was considering going back to technology but this time I wanted to pick up a completely new stack of technology. I decided I would move into Data Science and AI. I knew AI as much as any typical software development person in senior management knew about this. It means I was highly confident that I could pick this up quickly. On top of that lots of content is available on the internet, many YouTube channels, and many courses are available. I thought it should be a cakewalk for me. I started learning this technology in my own way in my committed free time. Within 5-6 months after lots of study I started realizing this was the way to get the knowledge but it could not help me get confident to solve the problem. The more I learned, the more I felt that I did not know how much I needed to learn or how far I needed to go.&lt;/p></description></item><item><title>Important AI Paper List</title><link>https://localhost:1313/dsblog/select-ai-papers/</link><pubDate>Tue, 22 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/select-ai-papers/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6090-rps-Important-AI-Paper-List.jpg" alt="Important AI Paper List">&lt;/p>
&lt;h1 id="important-ai-paper-list">Important AI Paper List&lt;a class="td-heading-self-link" href="#important-ai-paper-list" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduciton">Introduciton&lt;a class="td-heading-self-link" href="#introduciton" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>In almost all citations it becomes very difficult to read the title of research papers. Why? Because the contributors&amp;rsquo; information is first and most of the time, it is difficult to read the name other than native people. For example, if an Indian find a native name like &amp;ldquo;Vivek Ramaswami, Kartikeyan Karunanidhi&amp;rdquo; it is easy for them to read the name but the same name becomes difficult to read for non-Indian people, and vice-versa. Giving respect to the creator is very important but more than we need to know what have they done. I know from my experience, for almost every researcher, it becomes very difficult to track good AI research papers. For me, it is more difficult because I need to maintain this blog and I want to give references to the work across different webpages. Therefore I am creating a citation key, which includes the Last name of the first researcher + year of presenting that paper. Along with this, I am describing the title of the paper and where it was presented. If you find a particular title interesting for your work you can search that paper on &amp;ldquo;google scholar&amp;rdquo;, Mendeley, sci-hub or other places with which you are familiar and comfortable. Post that you can download and read that paper at your leisure. Hope you find this list of some use for your work.&lt;/p></description></item><item><title>Paper-Summary- A Survey Paper# Pretrained Language Models for Text Generation</title><link>https://localhost:1313/dsblog/rps-Pretrained-Language-Models-for-Text-Generation/</link><pubDate>Fri, 18 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/rps-Pretrained-Language-Models-for-Text-Generation/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6088-rps-Pretrained-Language-Models-for-Text-Generation.jpg" alt="Pretrained Language Models for Text Generation">&lt;/p>
&lt;p>&lt;strong>Paper Name :- Pretrained Language Models for Text Generation: A Survey&lt;/strong>&lt;br>
Typer of Paper:- Survey Paper &lt;br>
&lt;a href="https://arxiv.org/abs/2105.10311">Paper URL&lt;/a>&lt;br>
Paper title of the citations mentioned can be found at &lt;a href="https://localhost:1313/dsblog/aip">AI Papers with Heading&lt;/a>. Use citation code to locate.&lt;/p></description></item><item><title>Major LLM Developers Shaping the AI Landscape</title><link>https://localhost:1313/dsblog/Major-LLM-Developers-Reshaping-NLP-Advancements/</link><pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/Major-LLM-Developers-Reshaping-NLP-Advancements/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6075-Major-LLM-Developers-Reshaping-NLP-Advancements.jpg" alt="Major LLM Developers Shaping the AI Landscape">&lt;/p>
&lt;h1 id="major-llm-developers-shaping-the-ai-landscape">Major LLM Developers Shaping the AI Landscape&lt;a class="td-heading-self-link" href="#major-llm-developers-shaping-the-ai-landscape" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;strong>From Text to Intelligence: Major LLM Developers Shaping the AI Landscape&lt;/strong>&lt;/p>
&lt;h2 id="introduction">Introduction:&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>The world of Artificial Intelligence (AI) has experienced an exponential growth, fueled by groundbreaking research and the efforts of innovative developers. Among the key players, Large Language Model (LLM) developers have taken center stage, creating powerful language models that have revolutionized natural language processing and understanding. In this article, we delve into the major LLM developers, their key contributions.&lt;/p></description></item><item><title>God Fathers of AI</title><link>https://localhost:1313/dsblog/God-Fathers-of-AI/</link><pubDate>Fri, 05 May 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/God-Fathers-of-AI/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6058-God-Fathers-of-AI.jpg" alt="God Fathers of AI">&lt;/p>
&lt;h1 id="god-fathers-of-ai">God Fathers of AI&lt;a class="td-heading-self-link" href="#god-fathers-of-ai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>In other fields of studies or in religion, there is only one god or only one godfather. But in the field of AI, that is not the case. There are many pioneers or Godfathers who have done significant work in this field. Recently, the resignation of Dr. Geoffrey Hinton from Google raised eyebrows in the business world and in Governments the world over. Technology is good or bad, it depends upon whose hand it is. Geoffrey raised that concern and for that, he wants better controls in place. What will happen, we need to follow the progress and raise our voices around. In this article, I am mentioning some godfathers of AI, their workplaces, and their contributions. I am sure this will inspire many young minds.&lt;/p></description></item><item><title>What Are Transformers in AI</title><link>https://localhost:1313/dsblog/What-Are-Transformers-in-AI/</link><pubDate>Tue, 03 Aug 2021 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/What-Are-Transformers-in-AI/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6031-What-are-Transformers-in-AI.jpg" alt="What-are-Transformers-in-AI">&lt;/p>
&lt;h1 id="what-are-transformers-in-ai">What Are Transformers in AI&lt;a class="td-heading-self-link" href="#what-are-transformers-in-ai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="transformer-architecture">Transformer Architecture&lt;a class="td-heading-self-link" href="#transformer-architecture" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/transformer/transformer-arch.jpg" alt="Transformer">&lt;/p>
&lt;h2 id="background">Background&lt;a class="td-heading-self-link" href="#background" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Whether GPT, ChatGPT, DALL-E, Whisper, Satablity AI or whatever significant you see in the AI worlds nowdays it is because of Transformer Architecture. Transformers are a type of neural network architecture that have several properties that make them effective for modeling data with long-range dependencies. They generally feature a combination of multi-headed attention mechanisms, residual connections, layer normalization, feedforward connections, and positional embeddings.&lt;/p></description></item></channel></rss>