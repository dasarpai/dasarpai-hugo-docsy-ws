<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AI Technology on Blowfish</title><link>https://localhost:1313/tags/ai-technology/</link><description>Recent content in AI Technology on Blowfish</description><generator>Hugo</generator><language>en</language><managingEditor>nuno@n9o.xyz (Blowfish)</managingEditor><webMaster>nuno@n9o.xyz (Blowfish)</webMaster><lastBuildDate>Thu, 24 Oct 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://localhost:1313/tags/ai-technology/index.xml" rel="self" type="application/rss+xml"/><item><title>Types of Large Language Models (LLM)</title><link>https://localhost:1313/dsblog/Types-of-LLM/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/Types-of-LLM/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6171-Types-of-LLM.jpg" alt="">&lt;/p>
&lt;h2 id="introduction">&lt;strong>Introduction:&lt;/strong>&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>The world of Generative AI (GenAI) is expanding at an astonishing rate, with new models emerging almost daily, each sporting unique names, capabilities, versions, and sizes. For AI professionals, keeping track of these models can feel like a full-time job. But for business users, IT professionals, and software developers trying to make the right choice, understanding the model’s name and what it represents can seem overwhelming. Wouldn’t it be helpful if we could decode the meaning behind these names to know if a model fits our needs and is worth the investment? In this article, we’ll break down how the names of GenAI models can reveal clues about their functionality and suitability for specific tasks, helping you make informed decisions with confidence.&lt;/p></description></item><item><title>GPT Usecases</title><link>https://localhost:1313/dsblog/gpt-usecases/</link><pubDate>Thu, 05 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/gpt-usecases/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6020-GPT-Usecases.jpg" alt="GPT Usecases">&lt;/p>
&lt;h1 id="what-is-gpt">What is GPT?&lt;a class="td-heading-self-link" href="#what-is-gpt" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>GPT is a transformer. Don&amp;rsquo;t confuse it with your electricity transformer! In Artificial Intelligence there are different kinds of neural network architectures to perform various tasks like classification, translation, segmentation, regression, etc. One of those architectures is transformer architecture. The Foundation of this architecture is based on another two architectures called encoder architecture and decoder architecture. There are lots of other technical complexity but for the business readers I am hiding that for that the time being, we will discuss that at some other place. In nutshell, GPT is a Transformer technology developed by OpenAI and it can perform several NLP tasks. NLP stands for natural language preprocessing. NLP tasks mean tasks like sentiment analysis of the text, text classification, topic modeling, translation, named entity recognition, and dozens of other tasks.&lt;/p></description></item></channel></rss>