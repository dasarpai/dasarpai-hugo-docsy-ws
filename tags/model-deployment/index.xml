<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Model Deployment on Blowfish</title><link>https://dasarpai.github.io/tags/model-deployment/</link><description>Recent content in Model Deployment on Blowfish</description><generator>Hugo</generator><language>en</language><managingEditor>nuno@n9o.xyz (Blowfish)</managingEditor><webMaster>nuno@n9o.xyz (Blowfish)</webMaster><lastBuildDate>Thu, 14 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://dasarpai.github.io/tags/model-deployment/index.xml" rel="self" type="application/rss+xml"/><item><title>Navigating the LLM Infrastructure Landscape</title><link>https://dasarpai.github.io/dsblog/navigating-llm-infrastructure-landscape/</link><pubDate>Thu, 14 Nov 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/navigating-llm-infrastructure-landscape/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6181-llm-infrastructure.jpg" alt="Navigating the LLM Infrastructure Landscape">&lt;/p>
&lt;h1 id="navigating-the-llm-infrastructure-landscape-from-cloud-giants-to-specialized-providers">Navigating the LLM Infrastructure Landscape: From Cloud Giants to Specialized Providers&lt;a class="td-heading-self-link" href="#navigating-the-llm-infrastructure-landscape-from-cloud-giants-to-specialized-providers" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="1-introduction">&lt;strong>1. Introduction&lt;/strong>&lt;a class="td-heading-self-link" href="#1-introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>The rapid advancement of Large Language Models (LLMs) has revolutionized a wide range of industries, from customer support to content creation and beyond. As LLMs like GPT-4, T5, and BERT become integral to AI-driven applications, the need for specialized infrastructure to support their deployment, training, and scaling has grown significantly. Traditional cloud services, while effective for general-purpose computing, often fall short in addressing the unique challenges posed by these models, such as handling vast amounts of data, providing low-latency responses, and managing the immense computational load. As a result, businesses and developers are increasingly turning to platforms specifically optimized for LLMs.&lt;/p></description></item><item><title>MLOps Tools</title><link>https://dasarpai.github.io/dsblog/MLOps-Tools/</link><pubDate>Tue, 13 Aug 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/MLOps-Tools/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6137-MLOps-Tools.jpg" alt="MLOps-Tools">&lt;/p>
&lt;h1 id="mlops-tools">MLOps Tools&lt;a class="td-heading-self-link" href="#mlops-tools" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>MLOps (Machine Learning Operations) is a set of practices and tools designed to streamline and automate the deployment, monitoring, and management of machine learning models in production environments. It combines principles from both DevOps (Development Operations) and machine learning to ensure that ML models are deployed efficiently, managed effectively, and maintained reliably throughout their lifecycle.&lt;/p></description></item><item><title>Open Source vs Closed Source AI</title><link>https://dasarpai.github.io/dsblog/Open-Source-vs-Closed-Source-AI/</link><pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Open-Source-vs-Closed-Source-AI/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6134-Open-Source-vs-Closed-Source-AI.jpg" alt="Open-Source-vs-Closed-Source-AI">&lt;/p>
&lt;h1 id="open-source-ai-vs-closed-source-ai">Open Source AI vs Closed Source AI&lt;a class="td-heading-self-link" href="#open-source-ai-vs-closed-source-ai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Major players in the AI industry, such as Google, Microsoft, IBM, Salesforce, etc each have their own proprietary models and infrastructure to host these models. They offer AI services that companies use to develop AI products for either their end customers or internal use. Training or developing AI models requires expensive hardware and highly skilled personnel, making it a costly process. However, the deployment and inference stages are even more expensive, as they involve ongoing costs for hardware and monitoring.&lt;/p></description></item><item><title>ML Model Respository from Pinto0309</title><link>https://dasarpai.github.io/dsblog/ML-Model-Repository-from-Pinto0309/</link><pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/ML-Model-Repository-from-Pinto0309/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6095-ML-Model-Repository-from-Pinto0309.jpg" alt="ML Model Respository from Pinto0309">&lt;/p>
&lt;h1 id="ml-model-repository-from-pinto0309">ML Model Repository from Pinto0309&lt;a class="td-heading-self-link" href="#ml-model-repository-from-pinto0309" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Using AI we can solve many kinds of tasks for this input can be text, structured data, image, video, audio, time-series, etc. To solve these problems we need to train model. These models may be computer vision, NLP, or traditional machine learning kind. There are hundreds of architectures and algorithms to solve business problems and create models. There a hundreds of different datasets that can be along with a particular architecture or algorithm to solve the problem. If you have any of these tasks then you can explore using these pre-trained models to solve your problem. There is a GitHub user &amp;ldquo;Katsuya Hyodo&amp;rdquo; with GitHub account &amp;ldquo;PINTO0309&amp;rdquo;. He has trained hundreds of models and created these pre-trained models for the community. You can scan and explore them from there. From there you can download the pre-trained models.&lt;/p></description></item><item><title>Introduction to ML Model Deployment</title><link>https://dasarpai.github.io/dsblog/Introduction-to-ML-Model-deployment/</link><pubDate>Wed, 19 Jul 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Introduction-to-ML-Model-deployment/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6077-Introduction-to-ML-Model-deployment.jpg" alt="Introduction to AI Model Deployement">&lt;/p>
&lt;h1 id="introduction-to-ai-model-deployment">Introduction to AI Model deployment&lt;a class="td-heading-self-link" href="#introduction-to-ai-model-deployment" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="big-players">Big Players&lt;a class="td-heading-self-link" href="#big-players" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>Amazon
&lt;ul>
&lt;li>Amazon has many products and one of their product is &lt;strong>AWS Cloud&lt;/strong>. Under this product they sell IT infrastructure (storage, memory, network, VM, webhosting etc.)&lt;/li>
&lt;li>&lt;strong>Amazon SageMaker&lt;/strong> is Cloud based Machine Learning Platform, and this is one of the product under AWS Cloud.&lt;/li>
&lt;li>Amazon SageMaker can be used to train AI model, host AI model, monitor the model and hosts many other services which any Data Science project need from data gathering to model serving.&lt;/li>
&lt;li>AWS is oldest cloud service provider in the market.&lt;/li>
&lt;li>AWS Sagemaker was launched in Nov'17.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Google
&lt;ul>
&lt;li>Google has hundreds of products like gmail, youtube, google drive etc. One of their product is called &lt;strong>Google Cloud&lt;/strong>. Under this product they sell IT infrastrcture like Amazon sells under AWS.&lt;/li>
&lt;li>&lt;strong>VertexAI&lt;/strong> is Cloud based Machine Learning platform of Google. VertexAI is part of Google Cloud.&lt;/li>
&lt;li>VertexAI can be used to train AI Model,host AI model, monitor the model etc.&lt;/li>
&lt;li>VertexAI was launched in Jun'21&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Microsoft
&lt;ul>
&lt;li>Like Amazon&amp;rsquo;s cloud platform which is called AWS Cloud, Microsoft&amp;rsquo;s cloud plateform is called &lt;strong>Azure&lt;/strong>.&lt;/li>
&lt;li>Microsoft&amp;rsquo;s AI product is called &lt;strong>Azure Machine Learning&lt;/strong>.&lt;/li>
&lt;li>Today (Jul'23) Azure Machine Learning has has most of the capabilites than any other player&amp;rsquo;s AI product.&lt;/li>
&lt;li>Azure Machine Learning was launched Feb'14&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="what-is-genai">What is GenAI?&lt;a class="td-heading-self-link" href="#what-is-genai" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>There are many kinds of AI models like classifier models, regressor models, clustering models, reinforcement models, etc. An AI model which has the ability to generate text, images, video, and music is called GenAI. They all take inspiration from the human brain, therefore they all have neural network (NN) architecture. There are dozens (if not hundreds) types of NN architecture that can be used to create different kinds of AI models. The type of NN architecture depends upon the data which is used for developing the model and the problem which we want to solve using AI model. Researchers in universities or big corporations like Google, Facebook, Amazon, and Microsoft keep developing new architecture, and using these architectures they develop the foundational models. Once foundational models are developed, they release a research paper. In this, they inform the world what architecture they used, what data they used, what parameters (weights &amp;amp; biases) the model has learned, what are the results of their product and compare that with other existing models. They can develop these foundational models with one set of hyperparameters, and they can release these foundational models of different sizes (it depends upon the number of parameters used). AI product builders pick up these foundational models and fine-tune these based on the exact business problem in their hands. Which foundational model do they choose, it also depends upon the size of the model, the kind of data it has used to create those foundational models, and what was the performance of the model on a similar task which the product developer want to solve.&lt;/p></description></item></channel></rss>