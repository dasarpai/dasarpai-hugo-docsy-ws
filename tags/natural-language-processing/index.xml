<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Natural Language Processing on Blowfish</title><link>https://localhost:1313/tags/natural-language-processing/</link><description>Recent content in Natural Language Processing on Blowfish</description><generator>Hugo</generator><language>en</language><managingEditor>nuno@n9o.xyz (Blowfish)</managingEditor><webMaster>nuno@n9o.xyz (Blowfish)</webMaster><lastBuildDate>Mon, 11 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://localhost:1313/tags/natural-language-processing/index.xml" rel="self" type="application/rss+xml"/><item><title>Exploring AnythingLLM</title><link>https://localhost:1313/dsblog/exploring-anythingllm/</link><pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/exploring-anythingllm/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6179-exploring-anythingllm.jpg" alt="Exploring AnythingLLM ">&lt;/p>
&lt;h1 id="exploring-anythingllm">Exploring AnythingLLM&lt;a class="td-heading-self-link" href="#exploring-anythingllm" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-is-anythingllm">What is AnythingLLM?&lt;a class="td-heading-self-link" href="#what-is-anythingllm" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>AnythingLLM is an open-source project developed by Mintplex Labs that offers a highly flexible platform for creating personalized language models and knowledge databases. It operates using Retrieval-Augmented Generation (RAG), which combines language models with data from custom document collections. AnythingLLM supports embedding models (e.g., BERT), language models, and vector databases to index and query data, allowing users to fine-tune or deploy various models tailored to their needs, from local deployments to cloud integrations with OpenAI or Azure OpenAI.&lt;/p></description></item><item><title>Exploring All Dimensions of Application Development</title><link>https://localhost:1313/dsblog/Exploring-All-Dimensions-of-Application-Development/</link><pubDate>Mon, 28 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/Exploring-All-Dimensions-of-Application-Development/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6175-Exploring-All-Dimensions-of-Application-Development.jpg" alt="">&lt;/p>
&lt;h1 id="exploring-all-dimensions-of-application-development">Exploring All Dimensions of Application Development&lt;a class="td-heading-self-link" href="#exploring-all-dimensions-of-application-development" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>These aspects highlight the diverse areas involved in application development beyond just frontend, backend, or mobile/desktop apps. Each plays a critical role in building, deploying, and maintaining robust, scalable, and user-friendly applications.&lt;/p></description></item><item><title>Exploring LLM Application Development</title><link>https://localhost:1313/dsblog/Exploring-LLM-App-Development/</link><pubDate>Sun, 27 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/Exploring-LLM-App-Development/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6174-Exploring-LLM-App-Development.jpg" alt="Exploring LLM Application Development">&lt;/p>
&lt;h1 id="exploring-llm-application-development">Exploring LLM Application Development&lt;a class="td-heading-self-link" href="#exploring-llm-application-development" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-is-llm-application-development">What is LLM Application Development?&lt;a class="td-heading-self-link" href="#what-is-llm-application-development" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Large Language Model (LLM) application development involves creating applications that leverage pretrained large language models, like GPT (like GPT3.5, GPT4.o), Sonnet, DALLE, SORA, BERT, T5, Gemma, RoBERTa, DINO, Turning-NLG, Phi, Llama, Stable Diffusion, Flang, Einstine, Megatron, StyleGAN, BART, Granite, or others, to perform natural language processing tasks. Unlike classical applications, which operate on explicit programming logic, LLM-based applications rely on trained models to process human language, make predictions, and respond dynamically based on vast amounts of text data.&lt;/p></description></item><item><title>AI Benchmarks Explained</title><link>https://localhost:1313/dsblog/AI-Benchmarks-Explained/</link><pubDate>Sat, 26 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/AI-Benchmarks-Explained/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6173-AI-Benchmarks-Explained.jpg" alt="AI-Benchmarks-Explained">&lt;/p>
&lt;h1 id="ai-benchmarks-explained-essential-components-and-leading-llm-evaluation-techniques">AI Benchmarks Explained: Essential Components and Leading LLM Evaluation Techniques&lt;a class="td-heading-self-link" href="#ai-benchmarks-explained-essential-components-and-leading-llm-evaluation-techniques" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-is-a-benchmark-in-ai">What is a Benchmark in AI?&lt;a class="td-heading-self-link" href="#what-is-a-benchmark-in-ai" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>A &lt;strong>benchmark&lt;/strong> in AI is like a standard measurement tool that helps researchers and developers assess how well their artificial intelligence models perform. Just like athletes are judged based on their performance against specific standards, AI models are evaluated against predefined tasks and metrics.&lt;/p></description></item><item><title>Transfer Learning Key AI Techniques Explained</title><link>https://localhost:1313/dsblog/Transfer-Learning-Key-AI-Techniques-Explained/</link><pubDate>Fri, 25 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/Transfer-Learning-Key-AI-Techniques-Explained/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6172-Transfer-Learning-Key-AI-Techniques-Explained.jpg" alt="Transfer Learning Key AI Techniques Explained">&lt;/p>
&lt;h1 id="transfer-learning-key-ai-techniques-explained">Transfer Learning Key AI Techniques Explained&lt;a class="td-heading-self-link" href="#transfer-learning-key-ai-techniques-explained" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>In this article we will understand some important concepts used within machine learning.&lt;/p>
&lt;ul>
&lt;li>What is in-context Learning?&lt;/li>
&lt;li>What is Prompt-Engineering?&lt;/li>
&lt;li>What is the relationship between Prompt Engineering and In-Context Learning?&lt;/li>
&lt;li>What is Zero-shot learning?&lt;/li>
&lt;li>How Zero-shot learning is different from In-context Learning?&lt;/li>
&lt;li>What is Meta-Learning?&lt;/li>
&lt;li>What is Few-shot learning?&lt;/li>
&lt;li>Do we need foundational models for Meta-learning and Few-shot learning?&lt;/li>
&lt;li>What is transfer learning?&lt;/li>
&lt;li>How do we do transfer learning from existing model?&lt;/li>
&lt;li>What is finetuning?&lt;/li>
&lt;li>Which layers to update, what weight to update during finetuning?&lt;/li>
&lt;/ul>
&lt;h2 id="prompt-engineering-in-context-learning-and-zero-shot-learning">Prompt Engineering, In Context Learning and Zero-shot Learning&lt;a class="td-heading-self-link" href="#prompt-engineering-in-context-learning-and-zero-shot-learning" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="what-is-in-context-learning">What is in-context Learning?&lt;a class="td-heading-self-link" href="#what-is-in-context-learning" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>In-Context Learning refers to a model&amp;rsquo;s ability to adapt its responses based on the context provided in the input prompt without updating its parameters or undergoing explicit training. The model uses the examples, instructions, or context given in the input to influence its behavior during inference.&lt;/p></description></item><item><title>Types of Large Language Models (LLM)</title><link>https://localhost:1313/dsblog/Types-of-LLM/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/Types-of-LLM/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6171-Types-of-LLM.jpg" alt="">&lt;/p>
&lt;h2 id="introduction">&lt;strong>Introduction:&lt;/strong>&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>The world of Generative AI (GenAI) is expanding at an astonishing rate, with new models emerging almost daily, each sporting unique names, capabilities, versions, and sizes. For AI professionals, keeping track of these models can feel like a full-time job. But for business users, IT professionals, and software developers trying to make the right choice, understanding the model’s name and what it represents can seem overwhelming. Wouldn’t it be helpful if we could decode the meaning behind these names to know if a model fits our needs and is worth the investment? In this article, we’ll break down how the names of GenAI models can reveal clues about their functionality and suitability for specific tasks, helping you make informed decisions with confidence.&lt;/p></description></item><item><title>Navigating the JavaScript Ecosystem</title><link>https://localhost:1313/dsblog/Navigating-the-JavaScript-Ecosystem/</link><pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/Navigating-the-JavaScript-Ecosystem/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6170-Navigating-the-JavaScript-Ecosystem.jpg" alt="Navigating the JavaScript Ecosystem">&lt;/p>
&lt;h1 id="navigating-the-javascript-ecosystem-npm-yarn-unpkg-and-more">Navigating the JavaScript Ecosystem: npm, Yarn, unpkg, and More&lt;a class="td-heading-self-link" href="#navigating-the-javascript-ecosystem-npm-yarn-unpkg-and-more" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>This article is trying to answer following questions.&lt;/p>
&lt;ol>
&lt;li>Evoluation of Javascript and Relationship with Java.&lt;/li>
&lt;li>What are popular javascript libraries?&lt;/li>
&lt;li>What is Node and Node.js?&lt;/li>
&lt;li>Key Features of Node.js.&lt;/li>
&lt;li>How are Node and Node.js Related?&lt;/li>
&lt;li>What are the Central Repositories of Javascript Packages?&lt;/li>
&lt;li>What is the difference between npm and npx?&lt;/li>
&lt;li>What are important npx commands?&lt;/li>
&lt;li>What is the &amp;rsquo;export&amp;rsquo; keyword in javascript?&lt;/li>
&lt;li>How to Use the Exported Function?&lt;/li>
&lt;li>What is the meaning of workspace in Yarn pacakge manager?&lt;/li>
&lt;li>Key Features of Yarn Workspaces.&lt;/li>
&lt;li>How to Set Up Yarn Workspaces?&lt;/li>
&lt;li>Can I use multiple package managers in my Javascript project?&lt;/li>
&lt;li>What are other Important Languages and their primary purpose?&lt;/li>
&lt;/ol>
&lt;h2 id="evoluation-of-javascript-and-relationship-with-java">Evoluation of Javascript and Relationship with Java.&lt;a class="td-heading-self-link" href="#evoluation-of-javascript-and-relationship-with-java" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>There is no relationship between Java and JavaScript.&lt;/p></description></item><item><title>Applications of GenAI</title><link>https://localhost:1313/dsblog/Applications-of-GenAI/</link><pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/Applications-of-GenAI/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6169-Applications-of-GenAI.jpg" alt="Applications of GenAI">&lt;/p>
&lt;h1 id="application-of-generative-ai-genai">Application of Generative AI (GenAI)&lt;a class="td-heading-self-link" href="#application-of-generative-ai-genai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Generative AI (GenAI) is transforming how we interact with technology by producing human-like text, images, audio, and even code. Leveraging advanced models, especially large language models (LLMs), GenAI offers a wide range of applications across industries and data types. Let&amp;rsquo;s explore some of the key use cases and how different sectors are benefiting from this technology.&lt;/p></description></item><item><title>Variations of Language Model in Huggingface</title><link>https://localhost:1313/dsblog/Variations-of-Language-Model-in-Huggingface/</link><pubDate>Thu, 22 Aug 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/Variations-of-Language-Model-in-Huggingface/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6138-Variations-of-Language-Model-in-Huggingface.jpg" alt="Variations-of-LanguageModel">&lt;/p>
&lt;h1 id="variations-of-language-model-in-huggingface">Variations of Language Model in Huggingface&lt;a class="td-heading-self-link" href="#variations-of-language-model-in-huggingface" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-the-model-variable-in-huggingface">What the Model variable in Huggingface?&lt;a class="td-heading-self-link" href="#what-the-model-variable-in-huggingface" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>We know base moels like BERT, T5, GPT2, GPT3 etc are developed by researchers working with different companies. But when we look into huggingface model repository we see other models like GPT2LMHeadModel, GPT2ForSequenceClassification, etc what are these?&lt;/p></description></item><item><title>Transformers Demystified A Step-by-Step Guide</title><link>https://localhost:1313/dsblog/transformers-demystified-a-step-by-step-guide/</link><pubDate>Thu, 25 Jul 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/transformers-demystified-a-step-by-step-guide/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6113-transformers-demystified-a-step-by-step-guide.jpg" alt="Transformers Demystified A Step-by-Step Guide">&lt;/p>
&lt;h1 id="transformers-demystified-a-step-by-step-guide">Transformers Demystified A Step-by-Step Guide&lt;a class="td-heading-self-link" href="#transformers-demystified-a-step-by-step-guide" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>All modern Transformers are based on a paper &amp;ldquo;Attention is all you need&amp;rdquo;&lt;/p>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>This was the mother paper of all the transformer architectures we see today around NLP, Multimodal, Deep Learning. It was presented by Ashish Vaswani et al from Deep Learning / Google in 2017. We will discuss following and anything whatever question/observation/idea I have.&lt;/p></description></item><item><title>NLP BenchMarks</title><link>https://localhost:1313/dsblog/NLP-BenchMarks1/</link><pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/NLP-BenchMarks1/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6120-NLP-BenchMarks.jpg" alt="NLP-BenchMarks">&lt;/p>
&lt;h1 id="nlp-benchmarks">NLP BenchMarks&lt;a class="td-heading-self-link" href="#nlp-benchmarks" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-is-language-model">What is Language Model?&lt;a class="td-heading-self-link" href="#what-is-language-model" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>A &lt;strong>language model&lt;/strong> is a computational model that understands and generates human language. It learns the patterns and structure of a language by analyzing large amounts of text data, allowing it to predict the next word in a sequence or generate coherent text. Language models are used in applications like text generation, translation, speech recognition, chatbots, and sentiment analysis.&lt;/p></description></item><item><title>Empowering Language with AI NLP Capabilities</title><link>https://localhost:1313/dsblog/empowering-language-with-ainlp-capabilities/</link><pubDate>Sat, 18 Nov 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/empowering-language-with-ainlp-capabilities/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6106-Empowering-Language-with-AI-NLP-Capabilities.jpg" alt="Empowering-Language-with-AI-NLP-Capabilities">&lt;/p>
&lt;h1 id="empowering-language-with-ai-nlp-capabilities">Empowering-Language-with-AI-NLP-Capabilities&lt;a class="td-heading-self-link" href="#empowering-language-with-ai-nlp-capabilities" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>When envisioning artificial intelligence (AI), the initial images that often come to mind are humanoid robots. However, this perception oversimplifies the vast realm of AI, which is fundamentally distinct from natural intelligence—the inherent cognitive capacity found in living organisms shaped by Mother Nature. Life, in all its forms, from microscopic bacteria to complex human beings, possesses an innate intelligence derived from hydrocarbon-based living cells.&lt;/p></description></item><item><title>Topic Modeling with BERT</title><link>https://localhost:1313/dsblog/topic-modeling-with-bert/</link><pubDate>Mon, 13 Nov 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/topic-modeling-with-bert/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6105-Topic-Modeling-with-BERT.jpg" alt="Topic Modeling with BERT">&lt;/p>
&lt;h1 id="topic-modeling-with-bert">Topic Modeling with BERT&lt;a class="td-heading-self-link" href="#topic-modeling-with-bert" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Key steps in BERTopic modelling are as following.&lt;/p>
&lt;ul>
&lt;li>Use &amp;ldquo;Sentence Embedding&amp;rdquo; models to embed the sentences of the article&lt;/li>
&lt;li>Reduce the dimensionality of embedding using UMAP&lt;/li>
&lt;li>Cluster these documents (reduced dimensions) using HDBSAN&lt;/li>
&lt;li>Use c-TF-IDF extract keywords, their frequency and IDF for each cluster.&lt;/li>
&lt;li>MMR: Maximize Candidate Relevance. How many words in a topic can represent the topic?&lt;/li>
&lt;li>Intertopic Distance Map&lt;/li>
&lt;li>Use similarity matrix (heatmap), dandogram (hierarchical map), to visualize the topics and key_words.&lt;/li>
&lt;li>Traction of topic over time period. Some may be irrelevant and for other traction may be increasing or decreasing.&lt;/li>
&lt;/ul>
&lt;h1 id="installation">Installation&lt;a class="td-heading-self-link" href="#installation" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Installation, with sentence-transformers, can be done using pypi:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">pip&lt;/span> &lt;span class="n">install&lt;/span> &lt;span class="n">bertopic&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># If you want to install BERTopic with other embedding models, you can choose one of the following:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Choose an embedding backend&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">pip&lt;/span> &lt;span class="n">install&lt;/span> &lt;span class="n">bertopic&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">flair&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">gensim&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">spacy&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">use&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Topic modeling with images&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">pip&lt;/span> &lt;span class="n">install&lt;/span> &lt;span class="n">bertopic&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">vision&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="supported-topic-modelling-techniques">Supported Topic Modelling Techniques&lt;a class="td-heading-self-link" href="#supported-topic-modelling-techniques" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>BERTopic supports all kinds of topic modeling techniques as below.&lt;/p></description></item><item><title>What is LLM</title><link>https://localhost:1313/dsblog/what-is-llm/</link><pubDate>Fri, 18 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/what-is-llm/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6087-What-is-LLM.jpg" alt="What is LLM">&lt;/p>
&lt;h1 id="what-is-large-language-model">What is Large Language Model&lt;a class="td-heading-self-link" href="#what-is-large-language-model" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>LLM stands for &lt;strong>Large Language Model&lt;/strong>. It is a type of artificial intelligence (AI) model that is trained on a massive dataset of text and code. This allows LLMs to learn the statistical relationships between words and phrases, and to generate text that is similar to the text that they were trained on.&lt;/p></description></item><item><title>NLP Tasks</title><link>https://localhost:1313/dsblog/nlp-tasks/</link><pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/nlp-tasks/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6085-NLP-Tasks.jpg" alt="NLP Tasks">&lt;/p>
&lt;h1 id="nlp-tasks">NLP Tasks&lt;a class="td-heading-self-link" href="#nlp-tasks" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Processing words of any language and driving some meaning from these is as old as the human language. Recently, AI momentum is taking on many of these language-processing tasks. Here is the summary of these NLP tasks, this list is continuously growing. Researchers keep creating a dataset for these tasks in different languages. Other researchers keep devising new ways to solve these tasks with better performance. They come up with a new architecture, a new set of hyperparameters, a new pipeline, etc. In summary, as of today, there are around 55 tasks. Hundreds of datasets and research papers exist around these. You can check on &lt;a href="https://paperswithcode.com/">PaperWithCode&lt;/a> or &lt;a href="https://huggingface.co/">Hggingface&lt;/a>&lt;/p></description></item><item><title>Introduction to Prompt Engineering</title><link>https://localhost:1313/dsblog/Introduction-to-Prompt-Engineering/</link><pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/Introduction-to-Prompt-Engineering/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6080-Introduction-to-Prompt-Engineering.jpg" alt="Introduction to Prompt Engineering">&lt;/p>
&lt;h1 id="introduction-to-prompt-best-engineering">Introduction to Prompt Best Engineering&lt;a class="td-heading-self-link" href="#introduction-to-prompt-best-engineering" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Prompts can contain questions, instructions, contextual information, examples, and partial input for the model to complete or continue. After the model receives a prompt, depending on the type of model being used, it can generate text, embeddings, code, images, videos, music, and more. Below are &lt;strong>14 examples of good prompts&lt;/strong>.&lt;/p></description></item><item><title/><link>https://localhost:1313/dsblog/%23Prompt-Engineering-for-GPT4/</link><pubDate>Fri, 06 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/%23Prompt-Engineering-for-GPT4/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6117-#Prompt-Engineering-for-GPT4.jpg" alt="#Prompt-Engineering-for-GPT4">&lt;/p>
&lt;h1 id="prompt-engineering-for-gpt4">#Prompt Engineering for GPT4&lt;a class="td-heading-self-link" href="#prompt-engineering-for-gpt4" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="prompt-engineering-for-gpt4-1">#Prompt Engineering for GPT4&lt;a class="td-heading-self-link" href="#prompt-engineering-for-gpt4-1" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="prompt-engineering-for-gpt4-2">#Prompt Engineering for GPT4&lt;a class="td-heading-self-link" href="#prompt-engineering-for-gpt4-2" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="prompt-engineering-for-gpt4-3">#Prompt Engineering for GPT4&lt;a class="td-heading-self-link" href="#prompt-engineering-for-gpt4-3" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>##Prompt Engineering for GPT4&lt;/p>
&lt;h1 id="what-is-prompting">What is Prompting?&lt;a class="td-heading-self-link" href="#what-is-prompting" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="trading">Trading&lt;a class="td-heading-self-link" href="#trading" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="generate-code-for-indicator">Generate Code for Indicator&lt;a class="td-heading-self-link" href="#generate-code-for-indicator" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Generate a pine script code to create a simple moving average of the closing price with a period of 14 days which is compatable with v5 of pine script and uses &amp;lsquo;color&amp;rsquo; dot before any color argument and &amp;rsquo;ta&amp;rsquo; before any sma argument&lt;/p></description></item><item><title/><link>https://localhost:1313/dsblog/%23ChatGPT-Business-Ideas/</link><pubDate>Fri, 06 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/%23ChatGPT-Business-Ideas/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6118-#ChatGPT-Business-Ideas.jpg" alt="#ChatGPT-Business-Ideas">&lt;/p>
&lt;h1 id="chatgpt-business-ideas">#ChatGPT Business Ideas&lt;a class="td-heading-self-link" href="#chatgpt-business-ideas" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="chatgpt-business-ideas-1">#ChatGPT Business Ideas&lt;a class="td-heading-self-link" href="#chatgpt-business-ideas-1" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="chatgpt-business-ideas-2">#ChatGPT Business Ideas&lt;a class="td-heading-self-link" href="#chatgpt-business-ideas-2" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="chatgpt-business-ideas-3">#ChatGPT Business Ideas&lt;a class="td-heading-self-link" href="#chatgpt-business-ideas-3" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>##ChatGPT Business Ideas&lt;/p>
&lt;h1 id="chatgpt-business-ideas-4">ChatGPT Business Ideas&lt;a class="td-heading-self-link" href="#chatgpt-business-ideas-4" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>ChatGPT Business Ideas&lt;/p></description></item><item><title>GPT Usecases</title><link>https://localhost:1313/dsblog/gpt-usecases/</link><pubDate>Thu, 05 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/gpt-usecases/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6020-GPT-Usecases.jpg" alt="GPT Usecases">&lt;/p>
&lt;h1 id="what-is-gpt">What is GPT?&lt;a class="td-heading-self-link" href="#what-is-gpt" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>GPT is a transformer. Don&amp;rsquo;t confuse it with your electricity transformer! In Artificial Intelligence there are different kinds of neural network architectures to perform various tasks like classification, translation, segmentation, regression, etc. One of those architectures is transformer architecture. The Foundation of this architecture is based on another two architectures called encoder architecture and decoder architecture. There are lots of other technical complexity but for the business readers I am hiding that for that the time being, we will discuss that at some other place. In nutshell, GPT is a Transformer technology developed by OpenAI and it can perform several NLP tasks. NLP stands for natural language preprocessing. NLP tasks mean tasks like sentiment analysis of the text, text classification, topic modeling, translation, named entity recognition, and dozens of other tasks.&lt;/p></description></item><item><title>ChatGPT Usecases</title><link>https://localhost:1313/dsblog/chatgpt-usecases/</link><pubDate>Wed, 04 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/chatgpt-usecases/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6019-ChatGPT-Usecases.jpg" alt="ChatGPT Usecases">&lt;/p>
&lt;h1 id="what-is-chatgpt">What is ChatGPT?&lt;a class="td-heading-self-link" href="#what-is-chatgpt" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>ChatGPT is &lt;strong>general purpose&lt;/strong> - &amp;ldquo;chat model&amp;rdquo; from OpenAI. It is a &lt;strong>language model&lt;/strong>, which means if you type some text then it can understand and respond to you appropriately. At this point in time, it is not accepting voice commands, neither able to process images or videos. A &lt;strong>general-purpose model&lt;/strong> means it can understand the question coming from any domain of life. A domain may be vertical or horizontal. A vertical domain means where a vendor is supplying a product or service for a specific type of customer. A horizontal domain is where a vendor supplies products or services for all types of customer. Healthcare, banking, logistic, insurance, agriculture, philosophy, history, and economics are one kind of verticals whereas
BPO, Quality Management, Software Development, Taxation, HR, IT Security, Accounting, Office Administration, Catering, and Entertainment are other kind of domains. A &lt;strong>general-purpose model&lt;/strong> can understand the questions from all aspects of life whether business vertical or horizontal or normal daily family or conflicts with other group members, family members, etc.&lt;/p></description></item><item><title>What is NLP?</title><link>https://localhost:1313/dsblog/what-is-nlp/</link><pubDate>Mon, 19 Dec 2022 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/what-is-nlp/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6016-What-is-NLP.jpg" alt="What is NLP?">&lt;/p>
&lt;h2 id="what-is-nlp">What is NLP?&lt;a class="td-heading-self-link" href="#what-is-nlp" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Humans interact with their surroundings using different kinds of inputs. Eyes deal with inputs of color, shape, and size. Ear deals with inputs of sound, voice, and noise. Similarly, the other 3 senses also deal with other kinds of inputs. When you write something you may be drawing some art or you may be drawing letters of some language. Language is what we use to speak, for example, English, Hindi, Kannada, Tamil, and French are languages. The script is a tool to write what we speak. There are many kinds of scripts and you can use those scripts to write words of the languages. Some scripts are good for some languages. You cannot write all the words of all the languages of the world using one script (without modifying the original letters of the script). The Roman script is good to write English languages but when you want to write any Indian language using Roman then you will make many mistakes when reading the scripts. Because you won&amp;rsquo;t be able to produce the same sound as the original language was producing.&lt;/p></description></item><item><title>What Are Transformers in AI</title><link>https://localhost:1313/dsblog/What-Are-Transformers-in-AI/</link><pubDate>Tue, 03 Aug 2021 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/What-Are-Transformers-in-AI/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6031-What-are-Transformers-in-AI.jpg" alt="What-are-Transformers-in-AI">&lt;/p>
&lt;h1 id="what-are-transformers-in-ai">What Are Transformers in AI&lt;a class="td-heading-self-link" href="#what-are-transformers-in-ai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="transformer-architecture">Transformer Architecture&lt;a class="td-heading-self-link" href="#transformer-architecture" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/transformer/transformer-arch.jpg" alt="Transformer">&lt;/p>
&lt;h2 id="background">Background&lt;a class="td-heading-self-link" href="#background" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Whether GPT, ChatGPT, DALL-E, Whisper, Satablity AI or whatever significant you see in the AI worlds nowdays it is because of Transformer Architecture. Transformers are a type of neural network architecture that have several properties that make them effective for modeling data with long-range dependencies. They generally feature a combination of multi-headed attention mechanisms, residual connections, layer normalization, feedforward connections, and positional embeddings.&lt;/p></description></item><item><title>Important AI Research Papers</title><link>https://localhost:1313/dsblog/important-ai-research-papers/</link><pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/important-ai-research-papers/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dsresources/dsr105-Important-AI-Research-Papers.jpg" alt="Important AI Research Papers">&lt;/p>
&lt;h1 id="important-ai-research-papers">Important AI Research Papers&lt;a class="td-heading-self-link" href="#important-ai-research-papers" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Content from this page is migrated to &lt;a href="https://dasarpai.com/dsblog/select-ai-papers">Link&lt;/a>&lt;/p></description></item></channel></rss>