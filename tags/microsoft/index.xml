<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Microsoft on Blowfish</title><link>https://localhost:1313/tags/microsoft/</link><description>Recent content in Microsoft on Blowfish</description><generator>Hugo</generator><language>en</language><managingEditor>nuno@n9o.xyz (Blowfish)</managingEditor><webMaster>nuno@n9o.xyz (Blowfish)</webMaster><lastBuildDate>Mon, 23 Dec 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://localhost:1313/tags/microsoft/index.xml" rel="self" type="application/rss+xml"/><item><title>Interview: Satya Nadella with BG2 - Dec-2024</title><link>https://localhost:1313/booksummary/Interview-Satya-Nadella-with--BG2-Dec-2024/</link><pubDate>Mon, 23 Dec 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/booksummary/Interview-Satya-Nadella-with--BG2-Dec-2024/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/booksummary/7542-Interview-Satya-Nadella-with--BG2-Dec-2024.jpg" alt="Interview: Satya Nadella with BG, 2 Dec 2024">&lt;/p>
&lt;h1 id="interview-satya-nadella-with-bg2---dec-2024">Interview: Satya Nadella with BG2 - Dec-2024&lt;a class="td-heading-self-link" href="#interview-satya-nadella-with-bg2---dec-2024" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>If you want to hear from top technology leader around any of these questions then this interview is for you.&lt;/p></description></item><item><title>Serverless LLM Deployment Platform</title><link>https://localhost:1313/dsblog/serverless-llm-deployment/</link><pubDate>Sun, 08 Dec 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://localhost:1313/dsblog/serverless-llm-deployment/</guid><description>&lt;p>&lt;img src="https://localhost:1313/assets/images/dspost/dsp6185-Serverless-LLM-Deployment.jpg" alt="Serverless-LLM-Deployment">&lt;/p>
&lt;h1 id="serverless-llm-deployment-platform">Serverless LLM Deployment Platform&lt;a class="td-heading-self-link" href="#serverless-llm-deployment-platform" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="microsoft">&lt;strong>Microsoft&amp;rsquo;s Serverless LLM Deployment Platform&lt;/strong>&lt;a class="td-heading-self-link" href="#microsoft" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="azure-openai-service">&lt;strong>Azure OpenAI Service&lt;/strong>&lt;a class="td-heading-self-link" href="#azure-openai-service" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>&lt;strong>Azure OpenAI Service&lt;/strong> is Microsoft&amp;rsquo;s answer to serverless LLM deployment. It provides access to powerful language models, including OpenAI&amp;rsquo;s GPT-4, GPT-3.5, Codex, and DALL-E, within the Azure ecosystem. It simplifies the process of integrating and deploying LLMs in a serverless manner.&lt;/p></description></item></channel></rss>