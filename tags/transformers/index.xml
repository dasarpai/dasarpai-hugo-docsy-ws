<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Transformers on </title>
    <link>https://dasarpai.com/tags/transformers/</link>
    <description>Recent content in Transformers on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>hari@dasarpai.com (Hari Thapliyaal)</managingEditor>
    <webMaster>hari@dasarpai.com (Hari Thapliyaal)</webMaster>
    <copyright>Â© 2025 Hari Thapliyaal</copyright>
    <lastBuildDate>Fri, 28 Feb 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://dasarpai.com/tags/transformers/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>AI News - February 2025</title>
      <link>https://dasarpai.com/news/AI-News-Feb-2025/</link>
      <pubDate>Fri, 28 Feb 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/news/AI-News-Feb-2025/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/news/8005-AI-News-Feb-2025.jpg&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AI News - February 2025 
    &lt;div id=&#34;ai-news---february-2025&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ai-news---february-2025&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;1. &lt;strong&gt;Elon Musk Announces Grok 3&lt;/strong&gt; 
    &lt;div id=&#34;1-elon-musk-announces-grok-3&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#1-elon-musk-announces-grok-3&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Elon Musk revealed plans to release Grok 3, a new AI chatbot from his startup xAI, which he claims outperforms existing AI chatbots like OpenAI&amp;rsquo;s ChatGPT[1].&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Understanding Contextual Embedding in Transformers</title>
      <link>https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/</link>
      <pubDate>Thu, 30 Jan 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6214-Understanding-Contextual-Embedding-in-Transformer.jpg&#34; alt=&#34;Understanding Contextual Embedding in Transformers&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Embedding can be confusing for many people, and contextual embedding performed by transformers can be even more perplexing. Even after gaining an understanding, many questions remain. In this article, we aim to address the following questions.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AI Imperialism: Western Dominance and the Future of Global Technology </title>
      <link>https://dasarpai.com/dsblog/AI-Imperialism/</link>
      <pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/AI-Imperialism/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6191-AI-Imperialism.jpg&#34; alt=&#34;AI Imperialism&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AI Imperialism: Western Dominance and the Future of Global Technology 
    &lt;div id=&#34;ai-imperialism-western-dominance-and-the-future-of-global-technology&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ai-imperialism-western-dominance-and-the-future-of-global-technology&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;In the rapidly evolving landscape of artificial intelligence (AI), the emergence of transformer models has marked a significant milestone. Among these, OpenAI&amp;rsquo;s GPT-3 stands out as a groundbreaking achievement, yet its dominance raises critical questions about the concentration of power, legal ambiguities, and global technological equity. This article delves into the phenomenon of AI imperialism, exploring how Western dominance shapes the future of global technology and the implications for developing nations.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Visualizing Transformers and Attention</title>
      <link>https://dasarpai.com/dsblog/Visualizing-transformers-and-attention/</link>
      <pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Visualizing-transformers-and-attention/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6189-Visualizing-transformers-and-attention.jpg&#34; alt=&#34;Visualizing transformers and attention&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Visualizing Transformers and Attention 
    &lt;div id=&#34;visualizing-transformers-and-attention&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#visualizing-transformers-and-attention&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;This is the summary note from Grant Sanderson&amp;rsquo;s talk at TNG Big Tech 2024. My earlir article on transformers can be found &lt;a href=&#34;https://dasarpai.com/dsblog/transformers-demystified-a-step-by-step-guide&#34;&gt;here&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Understanding LLM GAN and Transformers</title>
      <link>https://dasarpai.com/dsblog/Understanding-LLM-GAN-and-Transformers/</link>
      <pubDate>Fri, 26 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Understanding-LLM-GAN-and-Transformers/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6127-Understanding-LLM-GAN-and-Transformers.jpg&#34; alt=&#34;Understanding-LLM-GAN-Transformers&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Understanding LLM, GAN and Transformers 
    &lt;div id=&#34;understanding-llm-gan-and-transformers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#understanding-llm-gan-and-transformers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;LLM Layers 
    &lt;div id=&#34;llm-layers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#llm-layers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Large Language Models (LLMs) are typically based on Transformer architectures, which consist of several types of layers that work together to process and generate text. Here are the primary kinds of layers found in an LLM:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Transformers Demystified A Step-by-Step Guide</title>
      <link>https://dasarpai.com/dsblog/transformers-demystified-a-step-by-step-guide/</link>
      <pubDate>Thu, 25 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/transformers-demystified-a-step-by-step-guide/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6113-transformers-demystified-a-step-by-step-guide.jpg&#34; alt=&#34;Transformers Demystified A Step-by-Step Guide&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Transformers Demystified A Step-by-Step Guide 
    &lt;div id=&#34;transformers-demystified-a-step-by-step-guide&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#transformers-demystified-a-step-by-step-guide&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;All modern Transformers are based on a paper &amp;ldquo;Attention is all you need&amp;rdquo;&lt;/p&gt;</description>
      
    </item>
    
  </channel>
</rss>
