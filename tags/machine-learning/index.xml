<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning on </title>
    <link>https://dasarpai.com/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>hari@dasarpai.com (Hari Thapliyaal)</managingEditor>
    <webMaster>hari@dasarpai.com (Hari Thapliyaal)</webMaster>
    <copyright>© 2025 Hari Thapliyaal</copyright>
    <lastBuildDate>Fri, 28 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://dasarpai.com/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Audio Video Processing Concepts</title>
      <link>https://dasarpai.com/dsblog/audio-video-processing-concepts/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/audio-video-processing-concepts/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6252-audio-video-processing-concepts.jpg&#34; alt=&#34;Audio Video Processing Concepts&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Foundational Concepts of Audio and Video Processing 
    &lt;div id=&#34;foundational-concepts-of-audio-and-video-processing&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#foundational-concepts-of-audio-and-video-processing&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Whether you are multimedia professional or deep learning Engineer, if you are dealing with audio and video processing, you will need to understand the core concepts of audio and video processing. My this guide is focussed on some of the key concepts of Audio Video processing.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Quantum Physics with Deeper Questions with ChatGPT</title>
      <link>https://dasarpai.com/dsblog/quantum-physics-with-deeper-questions/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/quantum-physics-with-deeper-questions/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6253-quantum-physics-with-deeper-questions.jpg&#34; alt=&#34;Quantum Physics with Deeper Questions&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Quantum Physics with Deeper Questions with ChatGPT 
    &lt;div id=&#34;quantum-physics-with-deeper-questions-with-chatgpt&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#quantum-physics-with-deeper-questions-with-chatgpt&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;I was a physics student during my college years, and I’ve always loved the subject—even today. However, Quantum Physics, despite all my reading and learning, remains a mystery to me. At this stage, who can teach me Quantum Physics effectively? Finding an able professor, aligning my availability with theirs, and hoping they’d be willing to teach me for free seems impossible. So, I turned to a Large Language Model (LLM) for help. I could have explored other LLMs like Grok, Claude, DeepSeek, and many more. I’m not saying the others are bad, nor am I claiming that ChatGPT is the best at providing plausible answers. Whether an answer is correct or plausible also depends on the learner’s ability.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring GGUF and Other Model Formats</title>
      <link>https://dasarpai.com/dsblog/exploring-gguf-and-other-model-formats/</link>
      <pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/exploring-gguf-and-other-model-formats/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6180-exploring-gguf.jpg&#34; alt=&#34;Understanding GGUF and Other Model Formats in Machine Learning&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;&lt;strong&gt;Understanding GGUF and Other Model Formats in Machine Learning&lt;/strong&gt; 
    &lt;div id=&#34;understanding-gguf-and-other-model-formats-in-machine-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#understanding-gguf-and-other-model-formats-in-machine-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;As machine learning models continue to grow in complexity, the need for efficient, flexible, and versatile model formats becomes more pronounced. While formats like ONNX, TensorFlow’s SavedModel, and PyTorch’s native format have been around for some time, newer formats like GGUF are gaining attention for their unique benefits. This article explores these formats, their use cases, and how they support various aspects of machine learning, including deployment, compatibility, and optimization.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Exploring AnythingLLM</title>
      <link>https://dasarpai.com/dsblog/exploring-anythingllm/</link>
      <pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/exploring-anythingllm/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6179-exploring-anythingllm.jpg&#34; alt=&#34;Exploring AnythingLLM &#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Exploring AnythingLLM 
    &lt;div id=&#34;exploring-anythingllm&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#exploring-anythingllm&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is AnythingLLM? 
    &lt;div id=&#34;what-is-anythingllm&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-anythingllm&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;AnythingLLM is an open-source project developed by Mintplex Labs that offers a highly flexible platform for creating personalized language models and knowledge databases. It operates using Retrieval-Augmented Generation (RAG), which combines language models with data from custom document collections. AnythingLLM supports embedding models (e.g., BERT), language models, and vector databases to index and query data, allowing users to fine-tune or deploy various models tailored to their needs, from local deployments to cloud integrations with OpenAI or Azure OpenAI.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Train Tensorflow Lite Models for Android</title>
      <link>https://dasarpai.com/dscourses/Building-and-Deploying-Generative-AI-with-Amazon-Bedrock/</link>
      <pubDate>Fri, 25 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/Building-and-Deploying-Generative-AI-with-Amazon-Bedrock/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc322-Building-and-Deploying-Generative-AI-with-Amazon-Bedrock.jpg&#34; alt=&#34;Building and Deploying Generative AI with Amazon Bedrock&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Building and Deploying Generative AI with Amazon Bedrock 
    &lt;div id=&#34;building-and-deploying-generative-ai-with-amazon-bedrock&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#building-and-deploying-generative-ai-with-amazon-bedrock&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Course Objective&lt;/strong&gt; 
    &lt;div id=&#34;course-objective&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#course-objective&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;This hands-on Amazon Bedrock workshop is designed to equip participants with in-depth knowledge and practical skills to harness the power of Amazon Bedrock for generative AI applications. Over the course of 2-3 days, participants will gain a foundational understanding of Bedrock&amp;rsquo;s services, learn to configure and integrate its APIs, and customize models to meet specific use cases. By the end of the workshop, participants will be able to build, deploy, and scale generative AI models, applying best practices for performance and cost-efficiency in real-world scenarios.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Types of Large Language Models (LLM)</title>
      <link>https://dasarpai.com/dsblog/Types-of-LLM/</link>
      <pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Types-of-LLM/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6171-Types-of-LLM.jpg&#34; alt=&#34;&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Introduction:&lt;/strong&gt; 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;The world of Generative AI (GenAI) is expanding at an astonishing rate, with new models emerging almost daily, each sporting unique names, capabilities, versions, and sizes. For AI professionals, keeping track of these models can feel like a full-time job. But for business users, IT professionals, and software developers trying to make the right choice, understanding the model’s name and what it represents can seem overwhelming. Wouldn’t it be helpful if we could decode the meaning behind these names to know if a model fits our needs and is worth the investment? In this article, we’ll break down how the names of GenAI models can reveal clues about their functionality and suitability for specific tasks, helping you make informed decisions with confidence.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Design for Cloud Computing with GCP</title>
      <link>https://dasarpai.com/dscourses/Design-for-Cloud-Computing-with-GCP/</link>
      <pubDate>Sun, 20 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/Design-for-Cloud-Computing-with-GCP/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc320-Design-for-Cloud-Computing-with-GCP.jpg&#34; alt=&#34;Design for Cloud Computing with GCP&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Design for Cloud Computing with GCP 
    &lt;div id=&#34;design-for-cloud-computing-with-gcp&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#design-for-cloud-computing-with-gcp&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Duration: 4 weeks : - 20 Days&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Train Tensorflow Lite Models for Android</title>
      <link>https://dasarpai.com/dscourses/Train-Tensorflow-Lite-Models-for-Android/</link>
      <pubDate>Sun, 20 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/Train-Tensorflow-Lite-Models-for-Android/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc321-Train-Tensorflow-Lite-Models-for-Android.jpg&#34; alt=&#34;Train Tensorflow Lite Models for Android&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Train Tensorflow Lite Models for Android 
    &lt;div id=&#34;train-tensorflow-lite-models-for-android&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#train-tensorflow-lite-models-for-android&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;strong&gt;Course Overview:&lt;/strong&gt; 
    &lt;div id=&#34;course-overview&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#course-overview&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;We&amp;rsquo;ll begin by exploring the basics of Machine Learning and its various types, and then dive into the world of deep learning and artificial neural networks, which will serve as the foundation for training our machine learning models for Android.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AI/ML with Oracle Cloud</title>
      <link>https://dasarpai.com/dsblog/AI-ML-With-Oracle-Cloud/</link>
      <pubDate>Sat, 19 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/AI-ML-With-Oracle-Cloud/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6166-AI-ML-With-Oracle-Cloud.jpg&#34; alt=&#34;AI/ML with Oracle Cloud&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AI/ML with Oracle Cloud 
    &lt;div id=&#34;aiml-with-oracle-cloud&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#aiml-with-oracle-cloud&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/services.htm&#34; target=&#34;_blank&#34;&gt;Oracle Infrastructure Services&lt;/a&gt; 
    &lt;div id=&#34;oracle-infrastructure-services&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#oracle-infrastructure-services&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Register for &lt;a href=&#34;https://www.oracle.com/cloud/free/?source=:ow:o:h:po:OHPPanel1nav0625&amp;amp;intcmp=:ow:o:h:po:OHPPanel1nav0625&#34; target=&#34;_blank&#34;&gt;Oracle Cloud Free Tier&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Machine Learning Key Concepts</title>
      <link>https://dasarpai.com/dsblog/Machine-Learning-Key-Concepts/</link>
      <pubDate>Thu, 03 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Machine-Learning-Key-Concepts/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6152-Machine-Learning-Key-Concepts.jpg&#34; alt=&#34;Exploring Docker and VS Code Integration&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Machine Learning Key Concepts 
    &lt;div id=&#34;machine-learning-key-concepts&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#machine-learning-key-concepts&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;In this article Essential Machine Learning Techniques/Concepts are Explained, some of them are are Cross-Validation, Hyperparameter Optimization, Machine learning types and much More.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Automated Machine Learning</title>
      <link>https://dasarpai.com/dsblog/AutoML-Tools/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/AutoML-Tools/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6150-AutoML-Tools.jpg&#34; alt=&#34;What is AutoML&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Automated Machine Learning 
    &lt;div id=&#34;automated-machine-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#automated-machine-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Is this article for me? 
    &lt;div id=&#34;is-this-article-for-me&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#is-this-article-for-me&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;This is article is for you, if you know&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Everything About Developer Console</title>
      <link>https://dasarpai.com/dsblog/Everything-About-Developer-Console/</link>
      <pubDate>Sun, 29 Sep 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Everything-About-Developer-Console/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6148-Everything-About-Developer-Console.jpg&#34; alt=&#34;Everything About Developer Console&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Console Types Every Programmer Should Know 
    &lt;div id=&#34;console-types-every-programmer-should-know&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#console-types-every-programmer-should-know&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Is this article for me? 
    &lt;div id=&#34;is-this-article-for-me&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#is-this-article-for-me&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;If you are you confused about a term &amp;ldquo;console&amp;rdquo; which you heard at many places and in many context, and you want to know the following answers, then continue reading.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Navigating Google Cloud Security: Key Components, Roles, and Best Practices</title>
      <link>https://dasarpai.com/dsblog/Google-Cloud-Security-Components/</link>
      <pubDate>Sat, 28 Sep 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Google-Cloud-Security-Components/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6147-Google-Cloud-Security-Components.jpg&#34; alt=&#34;Navigating Google Cloud Security&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Navigating Google Cloud Security 
    &lt;div id=&#34;navigating-google-cloud-security&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#navigating-google-cloud-security&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Is this article for me? 
    &lt;div id=&#34;is-this-article-for-me&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#is-this-article-for-me&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;If you are looking answers of these questions then continue reading.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Variations of Language Model in Huggingface</title>
      <link>https://dasarpai.com/dsblog/Variations-of-Language-Model-in-Huggingface/</link>
      <pubDate>Thu, 22 Aug 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Variations-of-Language-Model-in-Huggingface/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6138-Variations-of-Language-Model-in-Huggingface.jpg&#34; alt=&#34;Variations-of-LanguageModel&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Variations of Language Model in Huggingface 
    &lt;div id=&#34;variations-of-language-model-in-huggingface&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#variations-of-language-model-in-huggingface&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What the Model variable in Huggingface? 
    &lt;div id=&#34;what-the-model-variable-in-huggingface&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-the-model-variable-in-huggingface&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;We know base moels like BERT, T5, GPT2, GPT3 etc are developed by researchers working with different companies. But when we look into huggingface model repository we see other models like GPT2LMHeadModel, GPT2ForSequenceClassification, etc what are these?&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>MLOps Tools</title>
      <link>https://dasarpai.com/dsblog/MLOps-Tools/</link>
      <pubDate>Tue, 13 Aug 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/MLOps-Tools/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6137-MLOps-Tools.jpg&#34; alt=&#34;MLOps-Tools&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;MLOps Tools 
    &lt;div id=&#34;mlops-tools&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#mlops-tools&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;MLOps (Machine Learning Operations) is a set of practices and tools designed to streamline and automate the deployment, monitoring, and management of machine learning models in production environments. It combines principles from both DevOps (Development Operations) and machine learning to ensure that ML models are deployed efficiently, managed effectively, and maintained reliably throughout their lifecycle.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AI Usecases in Cybersecurity</title>
      <link>https://dasarpai.com/dsblog/AI-Usecases-in-Cybersecurity/</link>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/AI-Usecases-in-Cybersecurity/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6135-AI-Usecases-in-Cybersecurity.jpg&#34; alt=&#34;AI-Usecases-in-Cybersecurity&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AI Usecases in Cybersecurity 
    &lt;div id=&#34;ai-usecases-in-cybersecurity&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ai-usecases-in-cybersecurity&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AI in Cyber Security, Ethics Related Challenges and Usecases 
    &lt;div id=&#34;ai-in-cyber-security-ethics-related-challenges-and-usecases&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ai-in-cyber-security-ethics-related-challenges-and-usecases&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;AI Usecases in Cyber Security 
    &lt;div id=&#34;ai-usecases-in-cyber-security&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ai-usecases-in-cyber-security&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Threat Detection and Response
AI can enhance the detection and response to cybersecurity threats by:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Open Source vs Closed Source AI</title>
      <link>https://dasarpai.com/dsblog/Open-Source-vs-Closed-Source-AI/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Open-Source-vs-Closed-Source-AI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6134-Open-Source-vs-Closed-Source-AI.jpg&#34; alt=&#34;Open-Source-vs-Closed-Source-AI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Open Source AI vs Closed Source AI 
    &lt;div id=&#34;open-source-ai-vs-closed-source-ai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#open-source-ai-vs-closed-source-ai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Major players in the AI industry, such as Google, Microsoft, IBM, Salesforce, etc each have their own proprietary models and infrastructure to host these models. They offer AI services that companies use to develop AI products for either their end customers or internal use. Training or developing AI models requires expensive hardware and highly skilled personnel, making it a costly process. However, the deployment and inference stages are even more expensive, as they involve ongoing costs for hardware and monitoring.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>LLM Architecture and Training</title>
      <link>https://dasarpai.com/dsblog/LLM-Architecture-and-Training/</link>
      <pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/LLM-Architecture-and-Training/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6129-LLM-Architecture-and-Training.jpg&#34; alt=&#34;LLM-Architecture-and-Training&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;&lt;strong&gt;Understanding LLM Architectures and Model Training&lt;/strong&gt; 
    &lt;div id=&#34;understanding-llm-architectures-and-model-training&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#understanding-llm-architectures-and-model-training&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Large Language Models (LLMs) are transforming the field of artificial intelligence by enabling machines to understand and generate human language with unprecedented accuracy. This article delves into the architecture, training methods, and practical applications of LLMs. We’ll explore the core components that make these models so powerful and explain how they are trained and fine-tuned for real-world use cases.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Why to Finetune LLM?</title>
      <link>https://dasarpai.com/dsblog/why-to-finetune-llm/</link>
      <pubDate>Sun, 28 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/why-to-finetune-llm/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6115-why-to-finetune-llm.jpg&#34; alt=&#34;Why to Finetune LLM?&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Finetuning, Fewshot Learning, Why and How? 
    &lt;div id=&#34;finetuning-fewshot-learning-why-and-how&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#finetuning-fewshot-learning-why-and-how&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Why to finetune a LLM? 
    &lt;div id=&#34;why-to-finetune-a-llm&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#why-to-finetune-a-llm&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Fine-tuning a large language model (LLM) can provide several benefits, depending on your specific needs and objectives. Here are some key reasons to consider fine-tuning an LLM:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Stanford Alpaca</title>
      <link>https://dasarpai.com/dsblog/Stanford-Alpaca/</link>
      <pubDate>Sat, 27 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Stanford-Alpaca/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6116-Stanford-Alpaca.jpg&#34; alt=&#34;Stanford-Alpaca&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Stanford Alpaca 
    &lt;div id=&#34;stanford-alpaca&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#stanford-alpaca&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34; target=&#34;_blank&#34;&gt;Stanford Alpaca Github Report&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Understanding LLM GAN and Transformers</title>
      <link>https://dasarpai.com/dsblog/Understanding-LLM-GAN-and-Transformers/</link>
      <pubDate>Fri, 26 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Understanding-LLM-GAN-and-Transformers/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6127-Understanding-LLM-GAN-and-Transformers.jpg&#34; alt=&#34;Understanding-LLM-GAN-Transformers&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Understanding LLM, GAN and Transformers 
    &lt;div id=&#34;understanding-llm-gan-and-transformers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#understanding-llm-gan-and-transformers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;LLM Layers 
    &lt;div id=&#34;llm-layers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#llm-layers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Large Language Models (LLMs) are typically based on Transformer architectures, which consist of several types of layers that work together to process and generate text. Here are the primary kinds of layers found in an LLM:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Transformers Demystified A Step-by-Step Guide</title>
      <link>https://dasarpai.com/dsblog/transformers-demystified-a-step-by-step-guide/</link>
      <pubDate>Thu, 25 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/transformers-demystified-a-step-by-step-guide/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6113-transformers-demystified-a-step-by-step-guide.jpg&#34; alt=&#34;Transformers Demystified A Step-by-Step Guide&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Transformers Demystified A Step-by-Step Guide 
    &lt;div id=&#34;transformers-demystified-a-step-by-step-guide&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#transformers-demystified-a-step-by-step-guide&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;All modern Transformers are based on a paper &amp;ldquo;Attention is all you need&amp;rdquo;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Dimensionality Reduction and Visualization</title>
      <link>https://dasarpai.com/dsblog/Dimensionality-Reduction-and-Visualization/</link>
      <pubDate>Wed, 24 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Dimensionality-Reduction-and-Visualization/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6126-Dimensionality-Reduction-and-Visualization.jpg&#34; alt=&#34;Dimensionality-Reduction-and-Visualization&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Dimensionality Reduction and Visualization 
    &lt;div id=&#34;dimensionality-reduction-and-visualization&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#dimensionality-reduction-and-visualization&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What are the popular methods of dimensionality reduction? 
    &lt;div id=&#34;what-are-the-popular-methods-of-dimensionality-reduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-are-the-popular-methods-of-dimensionality-reduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Dimensionality reduction is a crucial step in data preprocessing, particularly when dealing with high-dimensional datasets. It helps in reducing the number of features while retaining the essential information, improving computational efficiency, and facilitating data visualization. Here are some popular methods of dimensionality reduction:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>NLP BenchMarks</title>
      <link>https://dasarpai.com/dsblog/NLP-BenchMarks1/</link>
      <pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/NLP-BenchMarks1/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6120-NLP-BenchMarks.jpg&#34; alt=&#34;NLP-BenchMarks&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;NLP BenchMarks 
    &lt;div id=&#34;nlp-benchmarks&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#nlp-benchmarks&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is Language Model? 
    &lt;div id=&#34;what-is-language-model&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-language-model&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;A &lt;strong&gt;language model&lt;/strong&gt; is a computational model that understands and generates human language. It learns the patterns and structure of a language by analyzing large amounts of text data, allowing it to predict the next word in a sequence or generate coherent text. Language models are used in applications like text generation, translation, speech recognition, chatbots, and sentiment analysis.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Empowering Language with AI NLP Capabilities</title>
      <link>https://dasarpai.com/dsblog/empowering-language-with-ainlp-capabilities/</link>
      <pubDate>Sat, 18 Nov 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/empowering-language-with-ainlp-capabilities/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6106-Empowering-Language-with-AI-NLP-Capabilities.jpg&#34; alt=&#34;Empowering-Language-with-AI-NLP-Capabilities&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Empowering-Language-with-AI-NLP-Capabilities 
    &lt;div id=&#34;empowering-language-with-ai-nlp-capabilities&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#empowering-language-with-ai-nlp-capabilities&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;When envisioning artificial intelligence (AI), the initial images that often come to mind are humanoid robots. However, this perception oversimplifies the vast realm of AI, which is fundamentally distinct from natural intelligence—the inherent cognitive capacity found in living organisms shaped by Mother Nature. Life, in all its forms, from microscopic bacteria to complex human beings, possesses an innate intelligence derived from hydrocarbon-based living cells.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Topic Modeling with BERT</title>
      <link>https://dasarpai.com/dsblog/topic-modeling-with-bert/</link>
      <pubDate>Mon, 13 Nov 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/topic-modeling-with-bert/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6105-Topic-Modeling-with-BERT.jpg&#34; alt=&#34;Topic Modeling with BERT&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Topic Modeling with BERT 
    &lt;div id=&#34;topic-modeling-with-bert&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#topic-modeling-with-bert&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Key steps in BERTopic modelling are as following.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Basics of Word Embedding</title>
      <link>https://dasarpai.com/dsblog/basics-of-word-embedding/</link>
      <pubDate>Sat, 11 Nov 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/basics-of-word-embedding/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6101-Basics-of-Word-Embedding.jpg&#34; alt=&#34;Basics of Word Embedding&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Basics of Word Embedding 
    &lt;div id=&#34;basics-of-word-embedding&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#basics-of-word-embedding&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is Context, target and window? 
    &lt;div id=&#34;what-is-context-target-and-window&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-context-target-and-window&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The &amp;ldquo;context&amp;rdquo; word is the surrounding word.&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;target&amp;rdquo; word is the middle word.&lt;/li&gt;
&lt;li&gt;The &amp;ldquo;window distance&amp;rdquo; is number of words (including) between context words and target word. Window distance 1 means, one word surronding the target, one left side context word, one right context word. Two window distance means 2 words left and 2 words right.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let&amp;rsquo;s take a sentence&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Graph of Thoughts</title>
      <link>https://dasarpai.com/dsblog/graph-of-thoughts/</link>
      <pubDate>Sat, 11 Nov 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/graph-of-thoughts/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6103-Graph-of-Thoughts.jpg&#34; alt=&#34;Graph of Thoughts&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Graph of Thoughts 
    &lt;div id=&#34;graph-of-thoughts&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#graph-of-thoughts&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;This is a valuable resource for learning Graph of Thoughts (GoT) concepts. The YouTube video is from code_your_own_AI. I&amp;rsquo;m utilizing the comments made by @wesleychang2005 on the video, which provide an excellent summary of GoT. If you&amp;rsquo;re interested in this topic and find the summary below intriguing, I recommend watching the entire 41-minute video.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What is Pinecone</title>
      <link>https://dasarpai.com/dsblog/What-is-Pinecone/</link>
      <pubDate>Sun, 03 Sep 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/What-is-Pinecone/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6097-What-is-Pinecone.jpg&#34; alt=&#34;What is Pinecone&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is pinecone? 
    &lt;div id=&#34;what-is-pinecone&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-pinecone&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Pinecone is a managed vector database that provides vector search (or “similarity search”) for developers with a straightforward API and usage-based pricing. It’s free to try. &lt;a href=&#34;https://www.pinecone.io/learn/vector-search-basics/&#34; target=&#34;_blank&#34;&gt;Introduction to Vector Search for Developers&lt;/a&gt;.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Distances in Machine Learning</title>
      <link>https://dasarpai.com/dsblog/Distances-in-Machine-Learning/</link>
      <pubDate>Sun, 27 Aug 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Distances-in-Machine-Learning/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6093-Distances-in-Machine-Learning.jpg&#34; alt=&#34;Distances in Machine Learning&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Distances in Machine Learning 
    &lt;div id=&#34;distances-in-machine-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#distances-in-machine-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Every sample, record, word, sentence, object, image etc in the Machine learning language is called vector. If we want to measure the similarity or dissimilarity between two data points then we need distance function.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Important AI Paper List</title>
      <link>https://dasarpai.com/dsblog/select-ai-papers/</link>
      <pubDate>Tue, 22 Aug 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/select-ai-papers/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6090-rps-Important-AI-Paper-List.jpg&#34; alt=&#34;Important AI Paper List&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Important AI Paper List 
    &lt;div id=&#34;important-ai-paper-list&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#important-ai-paper-list&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduciton 
    &lt;div id=&#34;introduciton&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduciton&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;In almost all citations it becomes very difficult to read the title of research papers. Why? Because the contributors&amp;rsquo; information is first and most of the time, it is difficult to read the name other than native people. For example, if an Indian find a native name like &amp;ldquo;Vivek Ramaswami, Kartikeyan Karunanidhi&amp;rdquo; it is easy for them to read the name but the same name becomes difficult to read for non-Indian people, and vice-versa. Giving respect to the creator is very important but more than we need to know what have they done. I know from my experience, for almost every researcher, it becomes very difficult to track good AI research papers. For me, it is more difficult because I need to maintain this blog and I want to give references to the work across different webpages. Therefore I am creating a citation key, which includes the Last name of the first researcher + year of presenting that paper. Along with this, I am describing the title of the paper and where it was presented. If you find a particular title interesting for your work you can search that paper on &amp;ldquo;google scholar&amp;rdquo;, Mendeley, sci-hub or other places with which you are familiar and comfortable. Post that you can download and read that paper at your leisure. Hope you find this list of some use for your work.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Paper with Code Resources</title>
      <link>https://dasarpai.com/dsblog/paperwithcode-resources/</link>
      <pubDate>Tue, 22 Aug 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/paperwithcode-resources/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6091-rps-Paperwithcode-Resources.jpg&#34; alt=&#34;Paper with Code Resources&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Paper with Code Resources 
    &lt;div id=&#34;paper-with-code-resources&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#paper-with-code-resources&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Trending Papers of 2021 
    &lt;div id=&#34;trending-papers-of-2021&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#trending-papers-of-2021&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;ADOP: Approximate Differentiable One-Pixel Point Rendering — Rückert et al — &lt;a href=&#34;https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The Bayesian Learning Rule —Khan et al &lt;a href=&#34;https://paperswithcode.com/paper/the-bayesian-learning-rule&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/paper/the-bayesian-learning-rule&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Program Synthesis with Large Language Models — Austin et al &lt;a href=&#34;https://paperswithcode.com/paper/program-synthesis-with-large-language-models&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/paper/program-synthesis-with-large-language-models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Masked Autoencoders Are Scalable Vision Learners — He et al &lt;a href=&#34;https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;8-bit Optimizers via Block-wise Quantization — Dettmers et al &lt;a href=&#34;https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Revisiting ResNets: Improved Training and Scaling Strategies — Bello et al &lt;a href=&#34;https://paperswithcode.com/paper/revisiting-resnets-improved-training-and&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/paper/revisiting-resnets-improved-training-and&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Image Super-Resolution via Iterative Refinement — Saharia et al &lt;a href=&#34;https://paperswithcode.com/paper/image-super-resolution-via-iterative&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/paper/image-super-resolution-via-iterative&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Perceiver IO: A General Architecture for Structured Inputs &amp;amp; Outputs — Jaegle et al &lt;a href=&#34;https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Do Vision Transformers See Like Convolutional Neural Networks? — Raghu et al &lt;a href=&#34;https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions — Niepert et al &lt;a href=&#34;https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Trending Libaries of 2021 
    &lt;div id=&#34;trending-libaries-of-2021&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#trending-libaries-of-2021&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;PyTorch Image Models — Ross Wightman — &lt;a href=&#34;https://github.com/rwightman/pytorch-image-models&#34; target=&#34;_blank&#34;&gt;https://github.com/rwightman/pytorch-image-models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Transformers — Hugging Face — &lt;a href=&#34;https://github.com/huggingface/transformers&#34; target=&#34;_blank&#34;&gt;https://github.com/huggingface/transformers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PyTorch-GAN — Erik Linder-Norén — &lt;a href=&#34;https://github.com/eriklindernoren/PyTorch-GAN&#34; target=&#34;_blank&#34;&gt;https://github.com/eriklindernoren/PyTorch-GAN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MMDetection — OpenMMLab — &lt;a href=&#34;https://github.com/open-mmlab/mmdetection&#34; target=&#34;_blank&#34;&gt;https://github.com/open-mmlab/mmdetection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Darknet — AlexeyAB — &lt;a href=&#34;https://github.com/AlexeyAB/darknet&#34; target=&#34;_blank&#34;&gt;https://github.com/AlexeyAB/darknet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vision Transformer PyTorch — lucidrains — &lt;a href=&#34;https://github.com/lucidrains/vit-pytorch&#34; target=&#34;_blank&#34;&gt;https://github.com/lucidrains/vit-pytorch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;InsightFace — DeepInsight — &lt;a href=&#34;https://github.com/deepinsight/insightface&#34; target=&#34;_blank&#34;&gt;https://github.com/deepinsight/insightface&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Detectron2 — Meta AI — &lt;a href=&#34;https://github.com/facebookresearch/detectron2&#34; target=&#34;_blank&#34;&gt;https://github.com/facebookresearch/detectron2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PaddleOCR — PaddlePaddle — &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR&#34; target=&#34;_blank&#34;&gt;https://github.com/PaddlePaddle/PaddleOCR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;FairSeq — Meta AI — &lt;a href=&#34;https://github.com/pytorch/fairseq&#34; target=&#34;_blank&#34;&gt;https://github.com/pytorch/fairseq&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Top Dataset - 2021 
    &lt;div id=&#34;top-dataset---2021&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#top-dataset---2021&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;MATH — Hendrycks et al &lt;a href=&#34;https://paperswithcode.com/dataset/math&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/dataset/math&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;UAV-Human — Li et al &lt;a href=&#34;https://paperswithcode.com/dataset/uav-human&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/dataset/uav-human&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;UPFD (User Preference-aware Fake News Detection) — Dou et al &lt;a href=&#34;https://paperswithcode.com/dataset/upfd&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/dataset/upfd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OGB-LSC (OGB Large-Scale Challenge) — Hu et al &lt;a href=&#34;https://paperswithcode.com/dataset/ogb-lsc&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/dataset/ogb-lsc&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CodeXGLUE —Lu et al &lt;a href=&#34;https://paperswithcode.com/dataset/codexglue&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/dataset/codexglue&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;AGORA — Patel et al &lt;a href=&#34;https://paperswithcode.com/dataset/agora&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/dataset/agora&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;BEIR (Benchmarking IR) — Thakur et al &lt;a href=&#34;https://paperswithcode.com/dataset/beir&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/dataset/beir&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;WikiGraphs — Wang et al &lt;a href=&#34;https://paperswithcode.com/dataset/wikigraphs&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/dataset/wikigraphs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Few-NERD — Ding et al &lt;a href=&#34;https://paperswithcode.com/dataset/few-nerd&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/dataset/few-nerd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PASS (Pictures without humAns for Self-Supervision) —Asano et al &lt;a href=&#34;https://paperswithcode.com/dataset/pass&#34; target=&#34;_blank&#34;&gt;https://paperswithcode.com/dataset/pass&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Papers of 2022 
    &lt;div id=&#34;papers-of-2022&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#papers-of-2022&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Controllable Animation of Fluid Elements in Still Images&lt;/li&gt;
&lt;li&gt;F-SfT: Shape-From-Template With A Physics-Based Deformation Model&lt;/li&gt;
&lt;li&gt;TWIST: Two-Way Inter-Label Self-Training for Semi-Supervised 3D Instance Segmentation&lt;/li&gt;
&lt;li&gt;Do Learned Representations Respect Causal Relationships?&lt;/li&gt;
&lt;li&gt;ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic&lt;/li&gt;
&lt;li&gt;3D Moments From Near-Duplicate Photos&lt;/li&gt;
&lt;li&gt;Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization&lt;/li&gt;
&lt;li&gt;Blind2Unblind: Self-Supervised Image Denoising With Visible Blind Spots&lt;/li&gt;
&lt;li&gt;Balanced and Hierarchical Relation Learning for One-Shot Object Detection&lt;/li&gt;
&lt;li&gt;NICE-SLAM: Neural Implicit Scalable Encoding for SLAM&lt;/li&gt;
&lt;li&gt;Stochastic Trajectory Prediction Via Motion Indeterminacy Diffusion&lt;/li&gt;
&lt;li&gt;CLRNet: Cross Layer Refinement Network for Lane Detection&lt;/li&gt;
&lt;li&gt;Motion-Aware Contrastive Video Representation Learning Via Foreground-Background Merging&lt;/li&gt;
&lt;li&gt;DINE: Domain Adaptation From Single and Multiple Black-Box Predictors&lt;/li&gt;
&lt;li&gt;FaceFormer: Speech-Driven 3D Facial Animation With Transformers&lt;/li&gt;
&lt;li&gt;Rotationally Equivariant 3D Object Detection&lt;/li&gt;
&lt;li&gt;Accelerating DETR Convergence Via Semantic-Aligned Matching&lt;/li&gt;
&lt;li&gt;Cloning Outfits From Real-World Images to 3D Characters for Generalizable Person Re-Identification&lt;/li&gt;
&lt;li&gt;GeoNeRF: Generalizing NeRF With Geometry Priors&lt;/li&gt;
&lt;li&gt;ABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo&lt;/li&gt;
&lt;li&gt;Expanding Low-Density Latent Regions for Open-Set Object Detection&lt;/li&gt;
&lt;li&gt;Uformer: A General U-Shaped Transformer for Image Restoration&lt;/li&gt;
&lt;li&gt;Exploring Dual-Task Correlation for Pose Guided Person Image Generation&lt;/li&gt;
&lt;li&gt;Portrait Eyeglasses and Shadow Removal By Leveraging 3D Synthetic Data&lt;/li&gt;
&lt;li&gt;Modeling 3D Layout for Group Re-Identification&lt;/li&gt;
&lt;li&gt;Toward Fast, Flexible, and Robust Low-Light Image Enhancement&lt;/li&gt;
&lt;li&gt;Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos&lt;/li&gt;
&lt;li&gt;HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network&lt;/li&gt;
&lt;li&gt;Modular Action Concept Grounding in Semantic Video Prediction&lt;/li&gt;
&lt;li&gt;StyleSwin: Transformer-Based GAN for High-Resolution Image Generation&lt;/li&gt;
&lt;li&gt;Discrete Cosine Transform Network for Guided Depth Map Super-Resolution&lt;/li&gt;
&lt;li&gt;Cerberus Transformer: Joint Semantic, Affordance and Attribute Parsing&lt;/li&gt;
&lt;li&gt;TransGeo: Transformer Is All You Need for Cross-View Image Geo-Localization&lt;/li&gt;
&lt;li&gt;Contrastive Boundary Learning for Point Cloud Segmentation&lt;/li&gt;
&lt;li&gt;Details or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution&lt;/li&gt;
&lt;li&gt;CVNet: Contour Vibration Network for Building Extraction&lt;/li&gt;
&lt;li&gt;Swin Transformer V2: Scaling Up Capacity and Resolution&lt;/li&gt;
&lt;li&gt;Projective Manifold Gradient Layer for Deep Rotation Regression&lt;/li&gt;
&lt;li&gt;HCSC: Hierarchical Contrastive Selective Coding&lt;/li&gt;
&lt;li&gt;TransRank: Self-Supervised Video Representation Learning Via Ranking-Based Transformation Recognition&lt;/li&gt;
&lt;li&gt;DiSparse: Disentangled Sparsification for Multitask Model Compression&lt;/li&gt;
&lt;li&gt;Pushing The Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make A Difference&lt;/li&gt;
&lt;li&gt;Towards Efficient and Scalable Sharpness-Aware Minimization&lt;/li&gt;
&lt;li&gt;OSSO: Obtaining Skeletal Shape From Outside&lt;/li&gt;
&lt;li&gt;A Study on The Distribution of Social Biases in Self-Supervised Learning Visual Models&lt;/li&gt;
&lt;li&gt;Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes&lt;/li&gt;
&lt;li&gt;Comparing Correspondences: Video Prediction With Correspondence-Wise Losses&lt;/li&gt;
&lt;li&gt;Towards Fewer Annotations: Active Learning Via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation&lt;/li&gt;
&lt;li&gt;CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding&lt;/li&gt;
&lt;li&gt;Few Shot Generative Model Adaption Via Relaxed Spatial Structural Alignment&lt;/li&gt;
&lt;li&gt;Enhancing Adversarial Training With Second-Order Statistics of Weights&lt;/li&gt;
&lt;li&gt;Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo&lt;/li&gt;
&lt;li&gt;Moving Window Regression: A Novel Approach to Ordinal Regression&lt;/li&gt;
&lt;li&gt;Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection&lt;/li&gt;
&lt;li&gt;Robust Optimization As Data Augmentation for Large-Scale Graphs&lt;/li&gt;
&lt;li&gt;Robust Structured Declarative Classifiers for 3D Point Clouds: Defending Adversarial Attacks With Implicit Gradients&lt;/li&gt;
&lt;li&gt;Improving The Transferability of Targeted Adversarial Examples Through Object-Based Diverse Input&lt;/li&gt;
&lt;li&gt;ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer&lt;/li&gt;
&lt;li&gt;360MonoDepth: High-Resolution 360deg Monocular Depth Estimation&lt;/li&gt;
&lt;li&gt;POCO: Point Convolution for Surface Reconstruction&lt;/li&gt;
&lt;li&gt;Neural Texture Extraction and Distribution for Controllable Person Image Synthesis&lt;/li&gt;
&lt;li&gt;Classification-Then-Grounding: Reformulating Video Scene Graphs As Temporal Bipartite Graphs&lt;/li&gt;
&lt;li&gt;DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis&lt;/li&gt;
&lt;li&gt;ZeroWaste Dataset: Towards Deformable Object Segmentation in Cluttered Scenes&lt;/li&gt;
&lt;li&gt;UNIST: Unpaired Neural Implicit Shape Translation Network&lt;/li&gt;
&lt;li&gt;APES: Articulated Part Extraction From Sprite Sheets&lt;/li&gt;
&lt;li&gt;SPAct: Self-Supervised Privacy Preservation for Action Recognition&lt;/li&gt;
&lt;li&gt;De-Rendering 3D Objects in The Wild&lt;/li&gt;
&lt;li&gt;Global Sensing and Measurements Reuse for Image Compressed Sensing&lt;/li&gt;
&lt;li&gt;Practical Evaluation of Adversarial Robustness Via Adaptive Auto Attack&lt;/li&gt;
&lt;li&gt;Cross-View Transformers for Real-Time Map-View Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Controllable Dynamic Multi-Task Architectures&lt;/li&gt;
&lt;li&gt;FastDOG: Fast Discrete Optimization on GPU&lt;/li&gt;
&lt;li&gt;Focal and Global Knowledge Distillation for Detectors&lt;/li&gt;
&lt;li&gt;Learning To Prompt for Continual Learning&lt;/li&gt;
&lt;li&gt;Human Mesh Recovery From Multiple Shots&lt;/li&gt;
&lt;li&gt;Convolution of Convolution: Let Kernels Spatially Collaborate&lt;/li&gt;
&lt;li&gt;Make It Move: Controllable Image-to-Video Generation With Text Descriptions&lt;/li&gt;
&lt;li&gt;Neural Points: Point Cloud Representation With Neural Fields for Arbitrary Upsampling&lt;/li&gt;
&lt;li&gt;Video-Text Representation Learning Via Differentiable Weak Temporal Alignment&lt;/li&gt;
&lt;li&gt;Bi-Directional Object-Context Prioritization Learning for Saliency Ranking&lt;/li&gt;
&lt;li&gt;Vehicle Trajectory Prediction Works, But Not Everywhere&lt;/li&gt;
&lt;li&gt;MonoDTR: Monocular 3D Object Detection With Depth-Aware Transformer&lt;/li&gt;
&lt;li&gt;Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-Shot Learning&lt;/li&gt;
&lt;li&gt;Generalized Category Discovery&lt;/li&gt;
&lt;li&gt;Contour-Hugging Heatmaps for Landmark Detection&lt;/li&gt;
&lt;li&gt;Voxel Field Fusion for 3D Object Detection&lt;/li&gt;
&lt;li&gt;DisARM: Displacement Aware Relation Module for 3D Detection&lt;/li&gt;
&lt;li&gt;MixFormer: Mixing Features Across Windows and Dimensions&lt;/li&gt;
&lt;li&gt;FineDiving: A Fine-Grained Dataset for Procedure-Aware Action Quality Assessment&lt;/li&gt;
&lt;li&gt;HEAT: Holistic Edge Attention Transformer for Structured Reconstruction&lt;/li&gt;
&lt;li&gt;Mobile-Former: Bridging MobileNet and Transformer&lt;/li&gt;
&lt;li&gt;CycleMix: A Holistic Strategy for Medical Image Segmentation From Scribble Supervision&lt;/li&gt;
&lt;li&gt;VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution&lt;/li&gt;
&lt;li&gt;Towards End-to-End Unified Scene Text Detection and Layout Analysis&lt;/li&gt;
&lt;li&gt;AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation&lt;/li&gt;
&lt;li&gt;ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior&lt;/li&gt;
&lt;li&gt;End-to-End Referring Video Object Segmentation With Multimodal Transformers&lt;/li&gt;
&lt;li&gt;IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo&lt;/li&gt;
&lt;li&gt;Not All Points Are Equal: Learning Highly Efficient Point-Based Detectors for 3D LiDAR Point Clouds&lt;/li&gt;
&lt;li&gt;Detecting Camouflaged Object in Frequency Domain&lt;/li&gt;
&lt;li&gt;SelfRecon: Self Reconstruction Your Digital Avatar From Monocular Video&lt;/li&gt;
&lt;li&gt;Equivariant Point Cloud Analysis Via Learning Orientations for Message Passing&lt;/li&gt;
&lt;li&gt;Node Representation Learning in Graph Via Node-to-Neighbourhood Mutual Information Maximization&lt;/li&gt;
&lt;li&gt;Semi-Supervised Video Semantic Segmentation With Inter-Frame Feature Reconstruction&lt;/li&gt;
&lt;li&gt;Amodal Segmentation Through Out-of-Task and Out-of-Distribution Generalization With A Bayesian Model&lt;/li&gt;
&lt;li&gt;How Well Do Sparse ImageNet Models Transfer?&lt;/li&gt;
&lt;li&gt;REX: Reasoning-Aware and Grounded Explanation&lt;/li&gt;
&lt;li&gt;Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes&lt;/li&gt;
&lt;li&gt;Object-Aware Video-Language Pre-Training for Retrieval&lt;/li&gt;
&lt;li&gt;MAT: Mask-Aware Transformer for Large Hole Image Inpainting&lt;/li&gt;
&lt;li&gt;Align and Prompt: Video-and-Language Pre-Training With Entity Prompts&lt;/li&gt;
&lt;li&gt;MSG-Transformer: Exchanging Local Spatial Information By Manipulating Messenger Tokens&lt;/li&gt;
&lt;li&gt;Cross Modal Retrieval With Querybank Normalisation&lt;/li&gt;
&lt;li&gt;Ray3D: Ray-Based 3D Human Pose Estimation for Monocular Absolute 3D Localization&lt;/li&gt;
&lt;li&gt;ASM-Loc: Action-Aware Segment Modeling for Weakly-Supervised Temporal Action Localization&lt;/li&gt;
&lt;li&gt;Scaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs&lt;/li&gt;
&lt;li&gt;End-to-End Multi-Person Pose Estimation With Transformers&lt;/li&gt;
&lt;li&gt;REGTR: End-to-End Point Cloud Correspondences With Transformers&lt;/li&gt;
&lt;li&gt;Neural 3D Scene Reconstruction With The Manhattan-World Assumption&lt;/li&gt;
&lt;li&gt;V2C: Visual Voice Cloning&lt;/li&gt;
&lt;li&gt;Revisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection&lt;/li&gt;
&lt;li&gt;MAD: A Scalable Dataset for Language Grounding in Videos From Movie Audio Descriptions&lt;/li&gt;
&lt;li&gt;Gait Recognition in The Wild With Dense 3D Representations and A Benchmark&lt;/li&gt;
&lt;li&gt;ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation Via Online Exploration and Synthesis&lt;/li&gt;
&lt;li&gt;QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection&lt;/li&gt;
&lt;li&gt;IDEA-Net: Dynamic 3D Point Cloud Interpolation Via Deep Embedding Alignment&lt;/li&gt;
&lt;li&gt;BEHAVE: Dataset and Method for Tracking Human Object Interactions&lt;/li&gt;
&lt;li&gt;Revisiting Random Channel Pruning for Neural Network Compression&lt;/li&gt;
&lt;li&gt;Generating Diverse and Natural 3D Human Motions From Text&lt;/li&gt;
&lt;li&gt;E-CIR: Event-Enhanced Continuous Intensity Recovery&lt;/li&gt;
&lt;li&gt;Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond&lt;/li&gt;
&lt;li&gt;Symmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose Estimation&lt;/li&gt;
&lt;li&gt;AziNorm: Exploiting The Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception&lt;/li&gt;
&lt;li&gt;Weakly Supervised Rotation-Invariant Aerial Object Detection Network&lt;/li&gt;
&lt;li&gt;Surface Reconstruction From Point Clouds By Learning Predictive Context Priors&lt;/li&gt;
&lt;li&gt;IRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes&lt;/li&gt;
&lt;li&gt;DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation&lt;/li&gt;
&lt;li&gt;Weakly Supervised Temporal Action Localization Via Representative Snippet Knowledge Propagation&lt;/li&gt;
&lt;li&gt;E2EC: An End-to-End Contour-Based Method for High-Quality High-Speed Instance Segmentation&lt;/li&gt;
&lt;li&gt;BatchFormer: Learning To Explore Sample Relationships for Robust Representation Learning&lt;/li&gt;
&lt;li&gt;Self-Supervised Image-Specific Prototype Exploration for Weakly Supervised Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Learning Multi-View Aggregation in The Wild for Large-Scale 3D Semantic Segmentation&lt;/li&gt;
&lt;li&gt;PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition&lt;/li&gt;
&lt;li&gt;Clothes-Changing Person Re-Identification With RGB Modality Only&lt;/li&gt;
&lt;li&gt;Robust Image Forgery Detection Over Online Social Network Shared Images&lt;/li&gt;
&lt;li&gt;Representation Compensation Networks for Continual Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Tracking People By Predicting 3D Appearance, Location and Pose&lt;/li&gt;
&lt;li&gt;Text2Mesh: Text-Driven Neural Stylization for Meshes&lt;/li&gt;
&lt;li&gt;C-CAM: Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image&lt;/li&gt;
&lt;li&gt;Forward Compatible Few-Shot Class-Incremental Learning&lt;/li&gt;
&lt;li&gt;Weakly Supervised Object Localization As Domain Adaption&lt;/li&gt;
&lt;li&gt;Tencent-MVSE: A Large-Scale Benchmark Dataset for Multi-Modal Video Similarity Evaluation&lt;/li&gt;
&lt;li&gt;Deep Orientation-Aware Functional Maps: Tackling Symmetry Issues in Shape Matching&lt;/li&gt;
&lt;li&gt;Tree Energy Loss: Towards Sparsely Annotated Semantic Segmentation&lt;/li&gt;
&lt;li&gt;MatteFormer: Transformer-Based Image Matting Via Prior-Tokens&lt;/li&gt;
&lt;li&gt;Video Shadow Detection Via Spatio-Temporal Interpolation Consistency Training&lt;/li&gt;
&lt;li&gt;Robust and Accurate Superquadric Recovery: A Probabilistic Approach&lt;/li&gt;
&lt;li&gt;Grounding Answers for Visual Questions Asked By Visually Impaired People&lt;/li&gt;
&lt;li&gt;Sparse Instance Activation for Real-Time Instance Segmentation&lt;/li&gt;
&lt;li&gt;VisualGPT: Data-Efficient Adaptation of Pretrained Language Models for Image Captioning&lt;/li&gt;
&lt;li&gt;MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation&lt;/li&gt;
&lt;li&gt;Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis&lt;/li&gt;
&lt;li&gt;Towards Implicit Text-Guided 3D Shape Generation&lt;/li&gt;
&lt;li&gt;SoftCollage: A Differentiable Probabilistic Tree Generator for Image Collage&lt;/li&gt;
&lt;li&gt;Query and Attention Augmentation for Knowledge-Based Explainable Reasoning&lt;/li&gt;
&lt;li&gt;Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality&lt;/li&gt;
&lt;li&gt;Progressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection&lt;/li&gt;
&lt;li&gt;Fine-Grained Object Classification Via Self-Supervised Pose Alignment&lt;/li&gt;
&lt;li&gt;Animal Kingdom: A Large and Diverse Dataset for Animal Behavior Understanding&lt;/li&gt;
&lt;li&gt;Fine-Grained Temporal Contrastive Learning for Weakly-Supervised Temporal Action Localization&lt;/li&gt;
&lt;li&gt;Relieving Long-Tailed Instance Segmentation Via Pairwise Class Balance&lt;/li&gt;
&lt;li&gt;Online Convolutional Re-Parameterization&lt;/li&gt;
&lt;li&gt;Mimicking The Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning&lt;/li&gt;
&lt;li&gt;RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition&lt;/li&gt;
&lt;li&gt;Personalized Image Aesthetics Assessment With Rich Attributes&lt;/li&gt;
&lt;li&gt;Part-Based Pseudo Label Refinement for Unsupervised Person Re-Identification&lt;/li&gt;
&lt;li&gt;HDNet: High-Resolution Dual-Domain Learning for Spectral Compressive Imaging&lt;/li&gt;
&lt;li&gt;OW-DETR: Open-World Detection Transformer&lt;/li&gt;
&lt;li&gt;Learning Deep Implicit Functions for 3D Shapes With Dynamic Code Clouds&lt;/li&gt;
&lt;li&gt;Reversible Vision Transformers&lt;/li&gt;
&lt;li&gt;Amodal Panoptic Segmentation&lt;/li&gt;
&lt;li&gt;Correlation Verification for Image Retrieval&lt;/li&gt;
&lt;li&gt;Temporal Feature Alignment and Mutual Information Maximization for Video-Based Human Pose Estimation&lt;/li&gt;
&lt;li&gt;Self-Supervised Transformers for Unsupervised Object Discovery Using Normalized Cut&lt;/li&gt;
&lt;li&gt;Exploring Structure-Aware Transformer Over Interaction Proposals for Human-Object Interaction Detection&lt;/li&gt;
&lt;li&gt;Decoupled Multi-Task Learning With Cyclical Self-Regulation for Face Parsing&lt;/li&gt;
&lt;li&gt;Glass: Geometric Latent Augmentation for Shape Spaces&lt;/li&gt;
&lt;li&gt;DPICT: Deep Progressive Image Compression Using Trit-Planes&lt;/li&gt;
&lt;li&gt;Text to Image Generation With Semantic-Spatial Aware GAN&lt;/li&gt;
&lt;li&gt;Generalizable Cross-Modality Medical Image Segmentation Via Style Augmentation and Dual Normalization&lt;/li&gt;
&lt;li&gt;Learning To Prompt for Open-Vocabulary Object Detection With Vision-Language Model&lt;/li&gt;
&lt;li&gt;Interactive Segmentation and Visualization for Tiny Objects in Multi-Megapixel Images&lt;/li&gt;
&lt;li&gt;Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture&lt;/li&gt;
&lt;li&gt;Surface Representation for Point Clouds&lt;/li&gt;
&lt;li&gt;Implicit Motion Handling for Video Camouflaged Object Detection&lt;/li&gt;
&lt;li&gt;DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides&lt;/li&gt;
&lt;li&gt;Learning With Twin Noisy Labels for Visible-Infrared Person Re-Identification&lt;/li&gt;
&lt;li&gt;Optical Flow Estimation for Spiking Camera&lt;/li&gt;
&lt;li&gt;GradViT: Gradient Inversion of Vision Transformers&lt;/li&gt;
&lt;li&gt;Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution Via Cycle-Projected Mutual Learning&lt;/li&gt;
&lt;li&gt;Joint Global and Local Hierarchical Priors for Learned Image Compression&lt;/li&gt;
&lt;li&gt;Knowledge Distillation Via The Target-Aware Transformer&lt;/li&gt;
&lt;li&gt;Subspace Adversarial Training&lt;/li&gt;
&lt;li&gt;3D-VField: Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection&lt;/li&gt;
&lt;li&gt;Image Segmentation Using Text and Image Prompts&lt;/li&gt;
&lt;li&gt;AutoMine: An Unmanned Mine Dataset&lt;/li&gt;
&lt;li&gt;Background Activation Suppression for Weakly Supervised Object Localization&lt;/li&gt;
&lt;li&gt;Synthetic Generation of Face Videos With Plethysmograph Physiology&lt;/li&gt;
&lt;li&gt;Hallucinated Neural Radiance Fields in The Wild&lt;/li&gt;
&lt;li&gt;Global Tracking Transformers&lt;/li&gt;
&lt;li&gt;Backdoor Attacks on Self-Supervised Learning&lt;/li&gt;
&lt;li&gt;GMFlow: Learning Optical Flow Via Global Matching&lt;/li&gt;
&lt;li&gt;Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation&lt;/li&gt;
&lt;li&gt;Explore Spatio-Temporal Aggregation for Insubstantial Object Detection: Benchmark Dataset and Baseline&lt;/li&gt;
&lt;li&gt;Graph-Based Spatial Transformer With Memory Replay for Multi-Future Pedestrian Trajectory Prediction&lt;/li&gt;
&lt;li&gt;Scanline Homographies for Rolling-Shutter Plane Absolute Pose&lt;/li&gt;
&lt;li&gt;AdaInt: Learning Adaptive Intervals for 3D Lookup Tables on Real-Time Image Enhancement&lt;/li&gt;
&lt;li&gt;Recurrent Glimpse-Based Decoder for Detection With Transformer&lt;/li&gt;
&lt;li&gt;SimMIM: A Simple Framework for Masked Image Modeling&lt;/li&gt;
&lt;li&gt;Label Matching Semi-Supervised Object Detection&lt;/li&gt;
&lt;li&gt;RegionCLIP: Region-Based Language-Image Pretraining&lt;/li&gt;
&lt;li&gt;Video Frame Interpolation Transformer&lt;/li&gt;
&lt;li&gt;BCOT: A Markerless High-Precision 3D Object Tracking Benchmark&lt;/li&gt;
&lt;li&gt;Omni-DETR: Omni-Supervised Object Detection With Transformers&lt;/li&gt;
&lt;li&gt;Transferable Sparse Adversarial Attack&lt;/li&gt;
&lt;li&gt;CREAM: Weakly Supervised Object Localization Via Class RE-Activation Mapping&lt;/li&gt;
&lt;li&gt;VALHALLA: Visual Hallucination for Machine Translation&lt;/li&gt;
&lt;li&gt;HINT: Hierarchical Neuron Concept Explainer&lt;/li&gt;
&lt;li&gt;Neural Face Identification in A 2D Wireframe Projection of A Manifold Object&lt;/li&gt;
&lt;li&gt;Nonuniform-to-Uniform Quantization: Towards Accurate Quantization Via Generalized Straight-Through Estimation&lt;/li&gt;
&lt;li&gt;An Empirical Study of End-to-End Temporal Action Detection&lt;/li&gt;
&lt;li&gt;Object Localization Under Single Coarse Point Supervision&lt;/li&gt;
&lt;li&gt;Unsupervised Learning of Accurate Siamese Tracking&lt;/li&gt;
&lt;li&gt;Non-Parametric Depth Distribution Modelling Based Depth Inference for Multi-View Stereo&lt;/li&gt;
&lt;li&gt;Equalized Focal Loss for Dense Long-Tailed Object Detection&lt;/li&gt;
&lt;li&gt;DeepDPM: Deep Clustering With An Unknown Number of Clusters&lt;/li&gt;
&lt;li&gt;ISDNet: Integrating Shallow and Deep Networks for Efficient Ultra-High Resolution Segmentation&lt;/li&gt;
&lt;li&gt;Unsupervised Domain Adaptation for Nighttime Aerial Tracking&lt;/li&gt;
&lt;li&gt;RestoreFormer: High-Quality Blind Face Restoration From Undegraded Key-Value Pairs&lt;/li&gt;
&lt;li&gt;Mask-Guided Spectral-Wise Transformer for Efficient Hyperspectral Image Reconstruction&lt;/li&gt;
&lt;li&gt;A Variational Bayesian Method for Similarity Learning in Non-Rigid Image Registration&lt;/li&gt;
&lt;li&gt;Not Just Selection, But Exploration: Online Class-Incremental Continual Learning Via Dual View Consistency&lt;/li&gt;
&lt;li&gt;Coupling Vision and Proprioception for Navigation of Legged Robots&lt;/li&gt;
&lt;li&gt;Exploiting Rigidity Constraints for LiDAR Scene Flow Estimation&lt;/li&gt;
&lt;li&gt;EMOCA: Emotion Driven Monocular Face Capture and Animation&lt;/li&gt;
&lt;li&gt;Quarantine: Sparsity Can Uncover The Trojan Attack Trigger for Free&lt;/li&gt;
&lt;li&gt;AlignQ: Alignment Quantization With ADMM-Based Correlation Preservation&lt;/li&gt;
&lt;li&gt;Interactive Multi-Class Tiny-Object Detection&lt;/li&gt;
&lt;li&gt;Learning From Pixel-Level Noisy Label: A New Perspective for Light Field Saliency Detection&lt;/li&gt;
&lt;li&gt;Multi-View Depth Estimation By Fusing Single-View Depth Probability With Multi-View Geometry&lt;/li&gt;
&lt;li&gt;Slimmable Domain Adaptation&lt;/li&gt;
&lt;li&gt;High-Resolution Image Harmonization Via Collaborative Dual Transformations&lt;/li&gt;
&lt;li&gt;MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Self-Supervised Neural Articulated Shape and Appearance Models&lt;/li&gt;
&lt;li&gt;Topology Preserving Local Road Network Estimation From Single Onboard Camera Image&lt;/li&gt;
&lt;li&gt;Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes&lt;/li&gt;
&lt;li&gt;SwinTextSpotter: Scene Text Spotting Via Better Synergy Between Text Detection and Text Recognition&lt;/li&gt;
&lt;li&gt;Deblur-NeRF: Neural Radiance Fields From Blurry Images&lt;/li&gt;
&lt;li&gt;Whose Track Is It Anyway? Improving Robustness to Tracking Errors With Affinity-Based Trajectory Prediction&lt;/li&gt;
&lt;li&gt;Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation&lt;/li&gt;
&lt;li&gt;Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning&lt;/li&gt;
&lt;li&gt;Blind Image Super-Resolution With Elaborate Degradation Modeling on Noise and Kernel&lt;/li&gt;
&lt;li&gt;Faithful Extreme Rescaling Via Generative Prior Reciprocated Invertible Representations&lt;/li&gt;
&lt;li&gt;Proto2Proto: Can You Recognize The Car, The Way I Do?&lt;/li&gt;
&lt;li&gt;TVConv: Efficient Translation Variant Convolution for Layout-Aware Visual Processing&lt;/li&gt;
&lt;li&gt;Dual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution&lt;/li&gt;
&lt;li&gt;Habitat-Web: Learning Embodied Object-Search Strategies From Human Demonstrations at Scale&lt;/li&gt;
&lt;li&gt;Simple But Effective: CLIP Embeddings for Embodied AI&lt;/li&gt;
&lt;li&gt;NomMer: Nominate Synergistic Context in Vision Transformer for Visual Recognition&lt;/li&gt;
&lt;li&gt;Collaborative Transformers for Grounded Situation Recognition&lt;/li&gt;
&lt;li&gt;CPPF: Towards Robust Category-Level 9D Pose Estimation in The Wild&lt;/li&gt;
&lt;li&gt;Continual Test-Time Domain Adaptation&lt;/li&gt;
&lt;li&gt;Dynamic MLP for Fine-Grained Image Classification By Leveraging Geographical and Temporal Information&lt;/li&gt;
&lt;li&gt;MuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-Based Visual Question Answering&lt;/li&gt;
&lt;li&gt;Fair Contrastive Learning for Facial Attribute Classification&lt;/li&gt;
&lt;li&gt;Directional Self-Supervised Learning for Heavy Image Augmentations&lt;/li&gt;
&lt;li&gt;No-Reference Point Cloud Quality Assessment Via Domain Adaptation&lt;/li&gt;
&lt;li&gt;Comprehending and Ordering Semantics for Image Captioning&lt;/li&gt;
&lt;li&gt;A Large-Scale Comprehensive Dataset and Copy-Overlap Aware Evaluation Protocol for Segment-Level Video Copy Detection&lt;/li&gt;
&lt;li&gt;Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification&lt;/li&gt;
&lt;li&gt;HeadNeRF: A Real-Time NeRF-Based Parametric Head Model&lt;/li&gt;
&lt;li&gt;Occlusion-Robust Face Alignment Using A Viewpoint-Invariant Hierarchical Network Architecture&lt;/li&gt;
&lt;li&gt;IDR: Self-Supervised Image Denoising Via Iterative Data Refinement&lt;/li&gt;
&lt;li&gt;MogFace: Towards A Deeper Appreciation on Face Detection&lt;/li&gt;
&lt;li&gt;Learning Affinity From Attention: End-to-End Weakly-Supervised Semantic Segmentation With Transformers&lt;/li&gt;
&lt;li&gt;CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation&lt;/li&gt;
&lt;li&gt;FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos&lt;/li&gt;
&lt;li&gt;Learning To Detect Mobile Objects From LiDAR Scans Without Labels&lt;/li&gt;
&lt;li&gt;WildNet: Learning Domain Generalized Semantic Segmentation From The Wild&lt;/li&gt;
&lt;li&gt;DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection&lt;/li&gt;
&lt;li&gt;Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Generating Diverse 3D Reconstructions From A Single Occluded Face Image&lt;/li&gt;
&lt;li&gt;Stand-Alone Inter-Frame Attention in Video Models&lt;/li&gt;
&lt;li&gt;Large-Scale Pre-Training for Person Re-Identification With Noisy Labels&lt;/li&gt;
&lt;li&gt;Semantic Segmentation By Early Region Proxy&lt;/li&gt;
&lt;li&gt;LD-ConGR: A Large RGB-D Video Dataset for Long-Distance Continuous Gesture Recognition&lt;/li&gt;
&lt;li&gt;HVH: Learning A Hybrid Neural Volumetric Representation for Dynamic Hair Performance Capture&lt;/li&gt;
&lt;li&gt;Rethinking Visual Geo-Localization for Large-Scale Applications&lt;/li&gt;
&lt;li&gt;The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy&lt;/li&gt;
&lt;li&gt;ViM: Out-of-Distribution With Virtual-Logit Matching&lt;/li&gt;
&lt;li&gt;Class-Aware Contrastive Semi-Supervised Learning&lt;/li&gt;
&lt;li&gt;Ditto: Building Digital Twins of Articulated Objects From Interaction&lt;/li&gt;
&lt;li&gt;Adaptive Early-Learning Correction for Segmentation From Noisy Annotations&lt;/li&gt;
&lt;li&gt;Cross-Domain Correlation Distillation for Unsupervised Domain Adaptation in Nighttime Semantic Segmentation&lt;/li&gt;
&lt;li&gt;RSTT: Real-Time Spatial Temporal Transformer for Space-Time Video Super-Resolution&lt;/li&gt;
&lt;li&gt;Partial Class Activation Attention for Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Multi-Scale Memory-Based Video Deblurring&lt;/li&gt;
&lt;li&gt;A Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching&lt;/li&gt;
&lt;li&gt;Geometric Structure Preserving Warp for Natural Image Stitching&lt;/li&gt;
&lt;li&gt;GOAL: Generating 4D Whole-Body Motion for Hand-Object Grasping&lt;/li&gt;
&lt;li&gt;Conditional Prompt Learning for Vision-Language Models&lt;/li&gt;
&lt;li&gt;Graph Sampling Based Deep Metric Learning for Generalizable Person Re-Identification&lt;/li&gt;
&lt;li&gt;Undoing The Damage of Label Shift for Cross-Domain Semantic Segmentation&lt;/li&gt;
&lt;li&gt;FisherMatch: Semi-Supervised Rotation Regression Via Entropy-Based Filtering&lt;/li&gt;
&lt;li&gt;Affine Medical Image Registration With Coarse-To-Fine Vision Transformer&lt;/li&gt;
&lt;li&gt;A Differentiable Two-Stage Alignment Scheme for Burst Image Reconstruction With Large Shift&lt;/li&gt;
&lt;li&gt;Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes&lt;/li&gt;
&lt;li&gt;Restormer: Efficient Transformer for High-Resolution Image Restoration&lt;/li&gt;
&lt;li&gt;IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation&lt;/li&gt;
&lt;li&gt;Large Loss Matters in Weakly Supervised Multi-Label Classification&lt;/li&gt;
&lt;li&gt;Neural Inertial Localization&lt;/li&gt;
&lt;li&gt;GraftNet: Towards Domain Generalized Stereo Matching With A Broad-Spectrum and Task-Oriented Feature&lt;/li&gt;
&lt;li&gt;VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning&lt;/li&gt;
&lt;li&gt;Catching Both Gray and Black Swans: Open-Set Supervised Anomaly Detection&lt;/li&gt;
&lt;li&gt;MLSLT: Towards Multilingual Sign Language Translation&lt;/li&gt;
&lt;li&gt;Towards An End-to-End Framework for Flow-Guided Video Inpainting&lt;/li&gt;
&lt;li&gt;Contrastive Test-Time Adaptation&lt;/li&gt;
&lt;li&gt;MotionAug: Augmentation With Physical Correction for Human Motion Prediction&lt;/li&gt;
&lt;li&gt;Modeling Indirect Illumination for Inverse Rendering&lt;/li&gt;
&lt;li&gt;TransWeather: Transformer-Based Restoration of Images Degraded By Adverse Weather Conditions&lt;/li&gt;
&lt;li&gt;H2FA R-CNN: Holistic and Hierarchical Feature Alignment for Cross-Domain Weakly Supervised Object Detection&lt;/li&gt;
&lt;li&gt;P3Depth: Monocular Depth Estimation With A Piecewise Planarity Prior&lt;/li&gt;
&lt;li&gt;GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection&lt;/li&gt;
&lt;li&gt;Simple Multi-Dataset Detection&lt;/li&gt;
&lt;li&gt;Proactive Image Manipulation Detection&lt;/li&gt;
&lt;li&gt;StyTr2: Image Style Transfer With Transformers&lt;/li&gt;
&lt;li&gt;Global Matching With Overlapping Attention for Optical Flow Estimation&lt;/li&gt;
&lt;li&gt;Language As Queries for Referring Video Object Segmentation&lt;/li&gt;
&lt;li&gt;MViTv2: Improved Multiscale Vision Transformers for Classification and Detection&lt;/li&gt;
&lt;li&gt;Audio-Visual Generalised Zero-Shot Learning With Cross-Modal Attention and Language&lt;/li&gt;
&lt;li&gt;Rethinking Efficient Lane Detection Via Curve Modeling&lt;/li&gt;
&lt;li&gt;Self-Supervised Arbitrary-Scale Point Clouds Upsampling Via Implicit Neural Representation&lt;/li&gt;
&lt;li&gt;Co-Advise: Cross Inductive Bias Distillation&lt;/li&gt;
&lt;li&gt;AdaMixer: A Fast-Converging Query-Based Object Detector&lt;/li&gt;
&lt;li&gt;DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification&lt;/li&gt;
&lt;li&gt;BEVT: BERT Pretraining of Video Transformers&lt;/li&gt;
&lt;li&gt;Deep Generalized Unfolding Networks for Image Restoration&lt;/li&gt;
&lt;li&gt;VISOLO: Grid-Based Space-Time Aggregation for Efficient Online Video Instance Segmentation&lt;/li&gt;
&lt;li&gt;Deep Unlearning Via Randomized Conditionally Independent Hessians&lt;/li&gt;
&lt;li&gt;Revisiting Skeleton-Based Action Recognition&lt;/li&gt;
&lt;li&gt;Stereo Depth From Events Cameras: Concentrate and Focus on The Future&lt;/li&gt;
&lt;li&gt;A Simple Data Mixing Prior for Improving Self-Supervised Learning&lt;/li&gt;
&lt;li&gt;Knowledge Distillation As Efficient Pre-Training: Faster Convergence, Higher Data-Efficiency, and Better Transferability&lt;/li&gt;
&lt;li&gt;BigDL 2.0: Seamless Scaling of AI Pipelines From Laptops to Distributed Cluster&lt;/li&gt;
&lt;li&gt;Attentive Fine-Grained Structured Sparsity for Image Restoration&lt;/li&gt;
&lt;li&gt;Learning Fair Classifiers With Partially Annotated Group Labels&lt;/li&gt;
&lt;li&gt;NightLab: A Dual-Level Architecture With Hardness Detection for Segmentation at Night&lt;/li&gt;
&lt;li&gt;Constrained Few-Shot Class-Incremental Learning&lt;/li&gt;
&lt;li&gt;Threshold Matters in WSSS: Manipulating The Activation for The Robust and Accurate Segmentation Model Against Thresholds&lt;/li&gt;
&lt;li&gt;TransMVSNet: Global Context-Aware Multi-View Stereo Network With Transformers&lt;/li&gt;
&lt;li&gt;DPGEN: Differentially Private Generative Energy-Guided Network for Natural Image Synthesis&lt;/li&gt;
&lt;li&gt;The Majority Can Help The Minority: Context-Rich Minority Oversampling for Long-Tailed Classification&lt;/li&gt;
&lt;li&gt;IntentVizor: Towards Generic Query Guided Interactive Video Summarization&lt;/li&gt;
&lt;li&gt;Shape-Invariant 3D Adversarial Point Clouds&lt;/li&gt;
&lt;li&gt;Bootstrapping ViTs: Towards Liberating Vision Transformers From Pre-Training&lt;/li&gt;
&lt;li&gt;PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents&lt;/li&gt;
&lt;li&gt;Meta-Attention for ViT-Backed Continual Learning&lt;/li&gt;
&lt;li&gt;DST: Dynamic Substitute Training for Data-Free Black-Box Attack&lt;/li&gt;
&lt;li&gt;Unified Contrastive Learning in Image-Text-Label Space&lt;/li&gt;
&lt;li&gt;Unsupervised Pre-Training for Temporal Action Localization Tasks&lt;/li&gt;
&lt;li&gt;Look Outside The Room: Synthesizing A Consistent Long-Term 3D Scene Video From A Single Image&lt;/li&gt;
&lt;li&gt;High-Fidelity Human Avatars From A Single RGB Camera&lt;/li&gt;
&lt;li&gt;Multiview Transformers for Video Recognition&lt;/li&gt;
&lt;li&gt;How Good Is Aesthetic Ability of A Fashion Model?&lt;/li&gt;
&lt;li&gt;Deformation and Correspondence Aware Unsupervised Synthetic-to-Real Scene Flow Estimation for Point Clouds&lt;/li&gt;
&lt;li&gt;Sequential Voting With Relational Box Fields for Active Object Detection&lt;/li&gt;
&lt;li&gt;Semantic-Aware Auto-Encoders for Self-Supervised Representation Learning&lt;/li&gt;
&lt;li&gt;Consistency Learning Via Decoding Path Augmentation for Transformers in Human Object Interaction Detection&lt;/li&gt;
&lt;li&gt;Consistent Explanations By Contrastive Learning&lt;/li&gt;
&lt;li&gt;Hierarchical Modular Network for Video Captioning&lt;/li&gt;
&lt;li&gt;Depth Estimation By Combining Binocular Stereo and Monocular Structured-Light&lt;/li&gt;
&lt;li&gt;Salient-to-Broad Transition for Video Person Re-Identification&lt;/li&gt;
&lt;li&gt;DeeCap: Dynamic Early Exiting for Efficient Image Captioning&lt;/li&gt;
&lt;li&gt;RepMLPNet: Hierarchical Vision MLP With Re-Parameterized Locality&lt;/li&gt;
&lt;li&gt;DR.VIC: Decomposition and Reasoning for Video Individual Counting&lt;/li&gt;
&lt;li&gt;ARCS: Accurate Rotation and Correspondence Search&lt;/li&gt;
&lt;li&gt;Learning To Anticipate Future With Dynamic Context Removal&lt;/li&gt;
&lt;li&gt;GCFSR: A Generative and Controllable Face Super Resolution Method Without Facial and GAN Priors&lt;/li&gt;
&lt;li&gt;On The Integration of Self-Attention and Convolution&lt;/li&gt;
&lt;li&gt;Domain Adaptation on Point Clouds Via Geometry-Aware Implicits&lt;/li&gt;
&lt;li&gt;GroupViT: Semantic Segmentation Emerges From Text Supervision&lt;/li&gt;
&lt;li&gt;DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation&lt;/li&gt;
&lt;li&gt;BppAttack: Stealthy and Efficient Trojan Attacks Against Deep Neural Networks Via Image Quantization and Contrastive Adversarial Learning&lt;/li&gt;
&lt;li&gt;Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation&lt;/li&gt;
&lt;li&gt;Towards Better Plasticity-Stability Trade-Off in Incremental Learning: A Simple Linear Connector&lt;/li&gt;
&lt;li&gt;Topology-Preserving Shape Reconstruction and Registration Via Neural Diffeomorphic Flow&lt;/li&gt;
&lt;li&gt;Segment and Complete: Defending Object Detectors Against Adversarial Patch Attacks With Robust Patch Detection&lt;/li&gt;
&lt;li&gt;MAXIM: Multi-Axis MLP for Image Processing&lt;/li&gt;
&lt;li&gt;Learning Part Segmentation Through Unsupervised Domain Adaptation From Synthetic Vehicles&lt;/li&gt;
&lt;li&gt;PSTR: End-to-End One-Step Person Search With Transformers&lt;/li&gt;
&lt;li&gt;NFormer: Robust Person Re-Identification With Neighbor Transformer&lt;/li&gt;
&lt;li&gt;Bridging Global Context Interactions for High-Fidelity Image Completion&lt;/li&gt;
&lt;li&gt;SwinBERT: End-to-End Transformers With Sparse Attention for Video Captioning&lt;/li&gt;
&lt;li&gt;Not All Tokens Are Equal: Human-Centric Visual Analysis Via Token Clustering Transformer&lt;/li&gt;
&lt;li&gt;Temporally Efficient Vision Transformer for Video Instance Segmentation&lt;/li&gt;
&lt;li&gt;The Devil Is in The Margin: Margin-Based Label Smoothing for Network Calibration&lt;/li&gt;
&lt;li&gt;NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks&lt;/li&gt;
&lt;li&gt;WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation&lt;/li&gt;
&lt;li&gt;Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding&lt;/li&gt;
&lt;li&gt;E2(GO)MOTION: Motion Augmented Event Stream for Egocentric Action Recognition&lt;/li&gt;
&lt;li&gt;OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization&lt;/li&gt;
&lt;li&gt;OnePose: One-Shot Object Pose Estimation Without CAD Models&lt;/li&gt;
&lt;li&gt;Rethinking Minimal Sufficient Representation in Contrastive Learning&lt;/li&gt;
&lt;li&gt;Scalable Penalized Regression for Noise Detection in Learning With Noisy Labels&lt;/li&gt;
&lt;li&gt;Federated Class-Incremental Learning&lt;/li&gt;
&lt;li&gt;Show, Deconfound and Tell: Image Captioning With Causal Inference&lt;/li&gt;
&lt;li&gt;MobRecon: Mobile-Friendly Hand Mesh Reconstruction From Monocular Image&lt;/li&gt;
&lt;li&gt;Parameter-Free Online Test-Time Adaptation&lt;/li&gt;
&lt;li&gt;SIGMA: Semantic-Complete Graph Matching for Domain Adaptive Object Detection&lt;/li&gt;
&lt;li&gt;No Pain, Big Gain: Classify Dynamic Point Cloud Sequences With Static Models By Fitting Feature-Level Space-Time Surfaces&lt;/li&gt;
&lt;li&gt;HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for Snapshot Compressive Imaging&lt;/li&gt;
&lt;li&gt;Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space&lt;/li&gt;
&lt;li&gt;Learning To Estimate Robust 3D Human Mesh From In-the-Wild Crowded Scenes&lt;/li&gt;
&lt;li&gt;Detecting Deepfakes With Self-Blended Images&lt;/li&gt;
&lt;li&gt;Implicit Sample Extension for Unsupervised Person Re-Identification&lt;/li&gt;
&lt;li&gt;Energy-Based Latent Aligner for Incremental Learning&lt;/li&gt;
&lt;li&gt;Towards Semi-Supervised Deep Facial Expression Recognition With An Adaptive Confidence Margin&lt;/li&gt;
&lt;li&gt;Group R-CNN for Weakly Semi-Supervised Object Detection With Points&lt;/li&gt;
&lt;li&gt;Weakly-Supervised Action Transition Learning for Stochastic Human Motion Prediction&lt;/li&gt;
&lt;li&gt;Hybrid Relation Guided Set Matching for Few-Shot Action Recognition&lt;/li&gt;
&lt;li&gt;Cross-Patch Dense Contrastive Learning for Semi-Supervised Segmentation of Cellular Nuclei in Histopathologic Images&lt;/li&gt;
&lt;li&gt;Generalized Binary Search Network for Highly-Efficient Multi-View Stereo&lt;/li&gt;
&lt;li&gt;SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation&lt;/li&gt;
&lt;li&gt;FlexIT: Towards Flexible Semantic Image Translation&lt;/li&gt;
&lt;li&gt;CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow&lt;/li&gt;
&lt;li&gt;BoxeR: Box-Attention for 2D and 3D Transformers&lt;/li&gt;
&lt;li&gt;Neural Architecture Search With Representation Mutual Information&lt;/li&gt;
&lt;li&gt;Can Neural Nets Learn The Same Model Twice? Investigating Reproducibility and Double Descent From The Decision Boundary Perspective&lt;/li&gt;
&lt;li&gt;Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction&lt;/li&gt;
&lt;li&gt;Multi-View Transformer for 3D Visual Grounding&lt;/li&gt;
&lt;li&gt;Structured Sparse R-CNN for Direct Scene Graph Generation&lt;/li&gt;
&lt;li&gt;BARC: Learning To Regress 3D Dog Shape From Images By Exploiting Breed Information&lt;/li&gt;
&lt;li&gt;PCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models&lt;/li&gt;
&lt;li&gt;Towards Understanding Adversarial Robustness of Optical Flow Networks&lt;/li&gt;
&lt;li&gt;Lifelong Graph Learning&lt;/li&gt;
&lt;li&gt;Hypergraph-Induced Semantic Tuplet Loss for Deep Metric Learning&lt;/li&gt;
&lt;li&gt;Computing Wasserstein-p Distance Between Images With Linear Cost&lt;/li&gt;
&lt;li&gt;Unsupervised Representation Learning for Binary Networks By Joint Classifier Learning&lt;/li&gt;
&lt;li&gt;Large-Scale Video Panoptic Segmentation in The Wild: A Benchmark&lt;/li&gt;
&lt;li&gt;GrainSpace: A Large-Scale Dataset for Fine-Grained and Domain-Adaptive Recognition of Cereal Grains&lt;/li&gt;
&lt;li&gt;Learning Modal-Invariant and Temporal-Memory for Video-Based Visible-Infrared Person Re-Identification&lt;/li&gt;
&lt;li&gt;MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning&lt;/li&gt;
&lt;li&gt;Oriented RepPoints for Aerial Object Detection&lt;/li&gt;
&lt;li&gt;Weakly Supervised Temporal Sentence Grounding With Gaussian-Based Contrastive Proposal Learning&lt;/li&gt;
&lt;li&gt;Low-Resource Adaptation for Personalized Co-Speech Gesture Generation&lt;/li&gt;
&lt;li&gt;Task-Specific Inconsistency Alignment for Domain Adaptive Object Detection&lt;/li&gt;
&lt;li&gt;MS2DG-Net: Progressive Correspondence Learning Via Multiple Sparse Semantics Dynamic Graph&lt;/li&gt;
&lt;li&gt;Learning To Listen: Modeling Non-Deterministic Dyadic Facial Motion&lt;/li&gt;
&lt;li&gt;Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation From Monocular Video&lt;/li&gt;
&lt;li&gt;MixFormer: End-to-End Tracking With Iterative Mixed Attention&lt;/li&gt;
&lt;li&gt;Plenoxels: Radiance Fields Without Neural Networks&lt;/li&gt;
&lt;li&gt;Selective-Supervised Contrastive Learning With Noisy Labels&lt;/li&gt;
&lt;li&gt;SimT: Handling Open-Set Noise for Domain Adaptive Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Frequency-Driven Imperceptible Adversarial Attack on Semantic Similarity&lt;/li&gt;
&lt;li&gt;Video Demoireing With Relation-Based Temporal Consistency&lt;/li&gt;
&lt;li&gt;Industrial Style Transfer With Large-Scale Geometric Warping and Content Preservation&lt;/li&gt;
&lt;li&gt;Modeling Image Composition for Complex Scene Generation&lt;/li&gt;
&lt;li&gt;Decoupling Zero-Shot Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions&lt;/li&gt;
&lt;li&gt;Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting The Adversarial Transferability&lt;/li&gt;
&lt;li&gt;IFOR: Iterative Flow Minimization for Robotic Object Rearrangement&lt;/li&gt;
&lt;li&gt;Zero Experience Required: Plug &amp;amp; Play Modular Transfer Learning for Semantic Visual Navigation&lt;/li&gt;
&lt;li&gt;TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation&lt;/li&gt;
&lt;li&gt;The Wanderings of Odysseus in 3D Scenes&lt;/li&gt;
&lt;li&gt;All-in-One Image Restoration for Unknown Corruption&lt;/li&gt;
&lt;li&gt;PUMP: Pyramidal and Uniqueness Matching Priors for Unsupervised Learning of Local Descriptors&lt;/li&gt;
&lt;li&gt;MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video&lt;/li&gt;
&lt;li&gt;RCP: Recurrent Closest Point for Point Cloud&lt;/li&gt;
&lt;li&gt;A Dual Weighting Label Assignment Scheme for Object Detection&lt;/li&gt;
&lt;li&gt;Hyperbolic Vision Transformers: Combining Improvements in Metric Learning&lt;/li&gt;
&lt;li&gt;Instance-Aware Dynamic Neural Network Quantization&lt;/li&gt;
&lt;li&gt;Exploring Effective Data for Surrogate Training Towards Black-Box Attack&lt;/li&gt;
&lt;li&gt;JRDB-Act: A Large-Scale Dataset for Spatio-Temporal Action, Social Group and Activity Detection&lt;/li&gt;
&lt;li&gt;Investigating Top-k White-Box and Transferable Black-Box Attack&lt;/li&gt;
&lt;li&gt;Decoupling and Recoupling Spatiotemporal Representation for RGB-D-Based Motion Recognition&lt;/li&gt;
&lt;li&gt;A Self-Supervised Descriptor for Image Copy Detection&lt;/li&gt;
&lt;li&gt;Negative-Aware Attention Framework for Image-Text Matching&lt;/li&gt;
&lt;li&gt;An Image Patch Is A Wave: Phase-Aware Vision MLP&lt;/li&gt;
&lt;li&gt;Shunted Self-Attention Via Multi-Scale Token Aggregation&lt;/li&gt;
&lt;li&gt;Unified Multivariate Gaussian Mixture for Efficient Neural Image Compression&lt;/li&gt;
&lt;li&gt;Recurrent Variational Network: A Deep Learning Inverse Problem Solver Applied to The Task of Accelerated MRI Reconstruction&lt;/li&gt;
&lt;li&gt;Surpassing The Human Accuracy: Detecting Gallbladder Cancer From USG Images With Curriculum Learning&lt;/li&gt;
&lt;li&gt;Appearance and Structure Aware Robust Deep Visual Graph Matching: Attack, Defense and Beyond&lt;/li&gt;
&lt;li&gt;TrackFormer: Multi-Object Tracking With Transformers&lt;/li&gt;
&lt;li&gt;3D Shape Reconstruction From 2D Images With Disentangled Attribute Flow&lt;/li&gt;
&lt;li&gt;Feature Statistics Mixing Regularization for Generative Adversarial Networks&lt;/li&gt;
&lt;li&gt;OpenTAL: Towards Open Set Temporal Action Localization&lt;/li&gt;
&lt;li&gt;Self-Supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection&lt;/li&gt;
&lt;li&gt;Ego4D: Around The World in 3,000 Hours of Egocentric Video&lt;/li&gt;
&lt;li&gt;Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis&lt;/li&gt;
&lt;li&gt;Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data&lt;/li&gt;
&lt;li&gt;DAD-3DHeads: A Large-Scale Dense, Accurate and Diverse Dataset for 3D Head Alignment From A Single Image&lt;/li&gt;
&lt;li&gt;Reconstructing Surfaces for Sparse Point Clouds With On-Surface Priors&lt;/li&gt;
&lt;li&gt;VCLIMB: A Novel Video Class Incremental Learning Benchmark&lt;/li&gt;
&lt;li&gt;Robust Equivariant Imaging: A Fully Unsupervised Framework for Learning To Image From Noisy and Partial Measurements&lt;/li&gt;
&lt;li&gt;ST++: Make Self-Training Work Better for Semi-Supervised Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Interacting Attention Graph for Single Image Two-Hand Reconstruction&lt;/li&gt;
&lt;li&gt;Rope3D: The Roadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task&lt;/li&gt;
&lt;li&gt;Cross-Image Relational Knowledge Distillation for Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Towards Layer-Wise Image Vectorization&lt;/li&gt;
&lt;li&gt;Scenic: A JAX Library for Computer Vision Research and Beyond&lt;/li&gt;
&lt;li&gt;Real-Time Object Detection for Streaming Perception&lt;/li&gt;
&lt;li&gt;VisualHow: Multimodal Problem Solving&lt;/li&gt;
&lt;li&gt;Spatial Commonsense Graph for Object Localisation in Partial Scenes&lt;/li&gt;
&lt;li&gt;OSSGAN: Open-Set Semi-Supervised Image Generation&lt;/li&gt;
&lt;li&gt;Bi-Level Alignment for Cross-Domain Crowd Counting&lt;/li&gt;
&lt;li&gt;ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation&lt;/li&gt;
&lt;li&gt;Efficient Multi-View Stereo By Iterative Dynamic Cost Volume&lt;/li&gt;
&lt;li&gt;TransEditor: Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing&lt;/li&gt;
&lt;li&gt;Use All The Labels: A Hierarchical Multi-Label Contrastive Learning Framework&lt;/li&gt;
&lt;li&gt;SGTR: End-to-End Scene Graph Generation With Transformer&lt;/li&gt;
&lt;li&gt;Decoupled Knowledge Distillation&lt;/li&gt;
&lt;li&gt;DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection&lt;/li&gt;
&lt;li&gt;Reusing The Task-Specific Classifier As A Discriminator: Discriminator-Free Adversarial Domain Adaptation&lt;/li&gt;
&lt;li&gt;Show Me What and Tell Me How: Video Synthesis Via Multimodal Conditioning&lt;/li&gt;
&lt;li&gt;SIMBAR: Single Image-Based Scene Relighting for Effective Data Augmentation for Automated Driving Vision Tasks&lt;/li&gt;
&lt;li&gt;Multi-Label Classification With Partial Annotations Using Class-Aware Selective Loss&lt;/li&gt;
&lt;li&gt;CADTransformer: Panoptic Symbol Spotting Transformer for CAD Drawings&lt;/li&gt;
&lt;li&gt;IntraQ: Learning Synthetic Images With Intra-Class Heterogeneity for Zero-Shot Network Quantization&lt;/li&gt;
&lt;li&gt;I M Avatar: Implicit Morphable Head Avatars From Videos&lt;/li&gt;
&lt;li&gt;Weakly-Supervised Metric Learning With Cross-Module Communications for The Classification of Anterior Chamber Angle Images&lt;/li&gt;
&lt;li&gt;A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-Resolution&lt;/li&gt;
&lt;li&gt;Multi-Modal Dynamic Graph Transformer for Visual Grounding&lt;/li&gt;
&lt;li&gt;Geometric Transformer for Fast and Robust Point Cloud Registration&lt;/li&gt;
&lt;li&gt;UMT: Unified Multi-Modal Transformers for Joint Video Moment Retrieval and Highlight Detection&lt;/li&gt;
&lt;li&gt;Demystifying The Neural Tangent Kernel From A Practical Perspective: Can It Be Trusted for Neural Architecture Search Without Training?&lt;/li&gt;
&lt;li&gt;The Devil Is in The Details: Window-Based Attention for Image Compression&lt;/li&gt;
&lt;li&gt;DiLiGenT102: A Photometric Stereo Benchmark Dataset With Controlled Shape and Material Variation&lt;/li&gt;
&lt;li&gt;PolyWorld: Polygonal Building Extraction With Graph Neural Networks in Satellite Images&lt;/li&gt;
&lt;li&gt;Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation&lt;/li&gt;
&lt;li&gt;Spatio-Temporal Relation Modeling for Few-Shot Action Recognition&lt;/li&gt;
&lt;li&gt;Multi-Person Extreme Motion Prediction&lt;/li&gt;
&lt;li&gt;B-DARTS: Beta-Decay Regularization for Differentiable Architecture Search&lt;/li&gt;
&lt;li&gt;CMT: Convolutional Neural Networks Meet Vision Transformers&lt;/li&gt;
&lt;li&gt;KNN Local Attention for Image Restoration&lt;/li&gt;
&lt;li&gt;Predict, Prevent, and Evaluate: Disentangled Text-Driven Image Manipulation Empowered By Pre-Trained Vision-Language Model&lt;/li&gt;
&lt;li&gt;TransMix: Attend To Mix for Vision Transformers&lt;/li&gt;
&lt;li&gt;Inertia-Guided Flow Completion and Style Fusion for Video Inpainting&lt;/li&gt;
&lt;li&gt;Long-Tailed Visual Recognition Via Gaussian Clouded Logit Adjustment&lt;/li&gt;
&lt;li&gt;Image Animation With Perturbed Masks&lt;/li&gt;
&lt;li&gt;Domain Generalization Via Shuffled Style Assembly for Face Anti-Spoofing&lt;/li&gt;
&lt;li&gt;OcclusionFusion: Occlusion-Aware Motion Estimation for Real-Time Dynamic 3D Reconstruction&lt;/li&gt;
&lt;li&gt;MonoScene: Monocular 3D Semantic Scene Completion&lt;/li&gt;
&lt;li&gt;AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition&lt;/li&gt;
&lt;li&gt;Continuous Scene Representations for Embodied AI&lt;/li&gt;
&lt;li&gt;Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds&lt;/li&gt;
&lt;li&gt;Non-Probability Sampling Network for Stochastic Human Trajectory Prediction&lt;/li&gt;
&lt;li&gt;ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning&lt;/li&gt;
&lt;li&gt;Human-Aware Object Placement for Visual Environment Reconstruction&lt;/li&gt;
&lt;li&gt;X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval&lt;/li&gt;
&lt;li&gt;RAMA: A Rapid Multicut Algorithm on GPU&lt;/li&gt;
&lt;li&gt;Adversarial Parametric Pose Prior&lt;/li&gt;
&lt;li&gt;Mask Transfiner for High-Quality Instance Segmentation&lt;/li&gt;
&lt;li&gt;It Is Okay To Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning By Contrastive Data Collection&lt;/li&gt;
&lt;li&gt;DiRA: Discriminative, Restorative, and Adversarial Learning for Self-Supervised Medical Image Analysis&lt;/li&gt;
&lt;li&gt;Event-Based Video Reconstruction Via Potential-Assisted Spiking Neural Network&lt;/li&gt;
&lt;li&gt;YouMVOS: An Actor-Centric Multi-Shot Video Object Segmentation Dataset&lt;/li&gt;
&lt;li&gt;DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification&lt;/li&gt;
&lt;li&gt;Self-Supervised Video Transformer&lt;/li&gt;
&lt;li&gt;AutoRF: Learning 3D Object Radiance Fields From Single View Observations&lt;/li&gt;
&lt;li&gt;Coopernaut: End-to-End Driving With Cooperative Perception for Networked Vehicles&lt;/li&gt;
&lt;li&gt;TubeR: Tubelet Transformer for Video Action Detection&lt;/li&gt;
&lt;li&gt;MUM: Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection&lt;/li&gt;
&lt;li&gt;Learning Non-Target Knowledge for Few-Shot Semantic Segmentation&lt;/li&gt;
&lt;li&gt;UKPGAN: A General Self-Supervised Keypoint Detector&lt;/li&gt;
&lt;li&gt;Raw High-Definition Radar for Multi-Task Learning&lt;/li&gt;
&lt;li&gt;Coarse-To-Fine Feature Mining for Video Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Compressing Models With Few Samples: Mimicking Then Replacing&lt;/li&gt;
&lt;li&gt;PokeBNN: A Binary Pursuit of Lightweight Accuracy&lt;/li&gt;
&lt;li&gt;Zoom in and Out: A Mixed-Scale Triplet Network for Camouflaged Object Detection&lt;/li&gt;
&lt;li&gt;SOMSI: Spherical Novel View Synthesis With Soft Occlusion Multi-Sphere Images&lt;/li&gt;
&lt;li&gt;EMScore: Evaluating Video Captioning Via Coarse-Grained and Fine-Grained Embedding Matching&lt;/li&gt;
&lt;li&gt;PoseTriplet: Co-Evolving 3D Human Pose Estimation, Imitation, and Hallucination Under Self-Supervision&lt;/li&gt;
&lt;li&gt;Group Contextualization for Video Recognition&lt;/li&gt;
&lt;li&gt;Single-Domain Generalized Object Detection in Urban Scene Via Cyclic-Disentangled Self-Distillation&lt;/li&gt;
&lt;li&gt;L2G: A Simple Local-to-Global Knowledge Transfer Framework for Weakly Supervised Semantic Segmentation&lt;/li&gt;
&lt;li&gt;Self-Augmented Unpaired Image Dehazing Via Density and Depth Decomposition&lt;/li&gt;
&lt;li&gt;Neural 3D Video Synthesis From Multi-View Video&lt;/li&gt;
&lt;li&gt;SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation&lt;/li&gt;
&lt;li&gt;Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search&lt;/li&gt;
&lt;li&gt;HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening&lt;/li&gt;
&lt;li&gt;Structure-Aware Flow Generation for Human Body Reshaping&lt;/li&gt;
&lt;li&gt;Learning To Answer Questions in Dynamic Audio-Visual Scenarios&lt;/li&gt;
&lt;li&gt;Synthetic Aperture Imaging With Events and Frames&lt;/li&gt;
&lt;li&gt;MonoGround: Detecting Monocular 3D Objects From The Ground&lt;/li&gt;
&lt;li&gt;Deep Visual Geo-Localization Benchmark&lt;/li&gt;
&lt;li&gt;StyleGAN-V: A Continuous Video Generator With The Price, Image Quality and Perks of StyleGAN2&lt;/li&gt;
&lt;li&gt;LISA: Learning Implicit Shape and Appearance of Hands&lt;/li&gt;
&lt;li&gt;Iterative Deep Homography Estimation&lt;/li&gt;
&lt;li&gt;Learned Queries for Efficient Local Attention&lt;/li&gt;
&lt;li&gt;Colar: Effective and Efficient Online Action Detection By Consulting Exemplars&lt;/li&gt;
&lt;li&gt;SoftGroup for 3D Instance Segmentation on Point Clouds&lt;/li&gt;
&lt;li&gt;MVS2D: Efficient Multi-View Stereo Via Attention-Driven 2D Convolutions&lt;/li&gt;
&lt;li&gt;Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance Segmentation Via Semantic Knowledge Transfer and Self-Refinement&lt;/li&gt;
&lt;li&gt;Deep Constrained Least Squares for Blind Image Super-Resolution&lt;/li&gt;
&lt;li&gt;EDTER: Edge Detection With Transformer&lt;/li&gt;
&lt;li&gt;AirObject: A Temporally Evolving Graph Embedding for Object Identification&lt;/li&gt;
&lt;li&gt;From Representation to Reasoning: Towards Both Evidence and Commonsense Reasoning for Video Question-Answering&lt;/li&gt;
&lt;li&gt;Semantic-Aware Domain Generalized Segmentation&lt;/li&gt;
&lt;li&gt;DanceTrack: Multi-Object Tracking in Uniform Appearance and Diverse Motion&lt;/li&gt;
&lt;li&gt;UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection&lt;/li&gt;
&lt;li&gt;AKB-48: A Real-World Articulated Object Knowledge Base&lt;/li&gt;
&lt;li&gt;Stratified Transformer for 3D Point Cloud Segmentation&lt;/li&gt;
&lt;li&gt;Aug-NeRF: Training Stronger Neural Radiance Fields With Triple-Level Physically-Grounded Augmentations&lt;/li&gt;
&lt;li&gt;Semantic-Shape Adaptive Feature Modulation for Semantic Image Synthesis&lt;/li&gt;
&lt;li&gt;Day-to-Night Image Synthesis for Training Nighttime Neural ISPs Literature ~Highlight: To address this problem, we propose a method that synthesizes nighttime images from daytime images.&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;References 
    &lt;div id=&#34;references&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#references&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/&#34; target=&#34;_blank&#34;&gt;https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Author&lt;/strong&gt;&lt;br&gt;
Dr Hari Thapliyaal&lt;br&gt;
dasarpai.com &lt;br&gt;
linkedin.com/in/harithapliyal&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Comprehensive Glossary of LLM, Deep Learning, NLP, and CV Terminology</title>
      <link>https://dasarpai.com/dsblog/Comprehensive-Glossary-of-LLM/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Comprehensive-Glossary-of-LLM/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6089-Comprehensive-Glossary-of-LLM.jpg&#34; alt=&#34;Comprehensive Glossary of LLM&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Comprehensive Glossary of LLM 
    &lt;div id=&#34;comprehensive-glossary-of-llm&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#comprehensive-glossary-of-llm&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;I am developing this Glossary slowly at my own pace. Content on this page keep changing. Better definition, better explaination are part of my learing, my evolution and advancement in the field of Deep Learning and Machine Learning. As of Aug&#39;23 the terms are not in any order therefore if you are look for any specific term you can search on the page. When I will have 50+ terms on this page then I will try to sort them on some attribute of these terms.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Machine Learning Metrics</title>
      <link>https://dasarpai.com/dsblog/Machine-Learning-Metrics/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Machine-Learning-Metrics/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6092-Machine-Learning-Metrics.jpg&#34; alt=&#34;Comprehensive Glossary of LLM&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Machine Learning Metrics 
    &lt;div id=&#34;machine-learning-metrics&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#machine-learning-metrics&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;In Machine Learning projects whether classical machine learning, deep learning, computer vision, speech processing, NLP, or any other ML project we keep building different models with different datasets. But how to know that for a particular problem model X is the best one? For that, we need to evaluate these models against certain metrics. What metrics we pick, depends upon the problem statement, data imbalance, type of data, etc. In this article, we will explore an exhaustive list of ML Metrics.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Paper-Summary- A Survey Paper# Pretrained Language Models for Text Generation</title>
      <link>https://dasarpai.com/dsblog/rps-Pretrained-Language-Models-for-Text-Generation/</link>
      <pubDate>Fri, 18 Aug 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/rps-Pretrained-Language-Models-for-Text-Generation/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6088-rps-Pretrained-Language-Models-for-Text-Generation.jpg&#34; alt=&#34;Pretrained Language Models for Text Generation&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Paper Name :- Pretrained Language Models for Text Generation: A Survey&lt;/strong&gt;&lt;br&gt;
Typer of Paper:- Survey Paper  &lt;br&gt;
&lt;a href=&#34;https://arxiv.org/abs/2105.10311&#34; target=&#34;_blank&#34;&gt;Paper URL&lt;/a&gt;&lt;br&gt;
Paper title of the citations mentioned can be found at &lt;a href=&#34;https://dasarpai.com/dsblog/aip&#34;&gt;AI Papers with Heading&lt;/a&gt;. Use citation code to locate.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What is LLM</title>
      <link>https://dasarpai.com/dsblog/what-is-llm/</link>
      <pubDate>Fri, 18 Aug 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/what-is-llm/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6087-What-is-LLM.jpg&#34; alt=&#34;What is LLM&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;What is Large Language Model 
    &lt;div id=&#34;what-is-large-language-model&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-large-language-model&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;LLM stands for &lt;strong&gt;Large Language Model&lt;/strong&gt;. It is a type of artificial intelligence (AI) model that is trained on a massive dataset of text and code. This allows LLMs to learn the statistical relationships between words and phrases, and to generate text that is similar to the text that they were trained on.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>NLP Tasks</title>
      <link>https://dasarpai.com/dsblog/nlp-tasks/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/nlp-tasks/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6085-NLP-Tasks.jpg&#34; alt=&#34;NLP Tasks&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;NLP Tasks 
    &lt;div id=&#34;nlp-tasks&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#nlp-tasks&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Processing words of any language and driving some meaning from these is as old as the human language. Recently, AI momentum is taking on many of these language-processing tasks. Here is the summary of these NLP tasks, this list is continuously growing. Researchers keep creating a dataset for these tasks in different languages. Other researchers keep devising new ways to solve these tasks with better performance. They come up with a new architecture, a new set of hyperparameters, a new pipeline, etc. In summary, as of today, there are around 55 tasks. Hundreds of datasets and research papers exist around these. You can check on &lt;a href=&#34;https://paperswithcode.com/&#34; target=&#34;_blank&#34;&gt;PaperWithCode&lt;/a&gt; or &lt;a href=&#34;https://huggingface.co/&#34; target=&#34;_blank&#34;&gt;Hggingface&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Model Tuning with VertexAI</title>
      <link>https://dasarpai.com/dsblog/Model-Tuning-with-VertexAI/</link>
      <pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Model-Tuning-with-VertexAI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6081-Model-Tuning-with-VertexAI.jpg&#34; alt=&#34;Model Tuning with VertexAI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Tuning Large Language Model with VertexAI 
    &lt;div id=&#34;tuning-large-language-model-with-vertexai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#tuning-large-language-model-with-vertexai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Why Model Tuning? 
    &lt;div id=&#34;why-model-tuning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#why-model-tuning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Tuning is required when you want the model to learn something niche or specific that deviates from general language patterns.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AI Product and Services from Google, Azure and AWS</title>
      <link>https://dasarpai.com/dsblog/AI-Product-and-Services-from-Google-Azure-and-AWS/</link>
      <pubDate>Thu, 20 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/AI-Product-and-Services-from-Google-Azure-and-AWS/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6078-AI-Product-and-Services-from-Google-Azure-and-AWS.jpg&#34; alt=&#34;AI Product and Services from Google, Azure and AWS&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AI Product and Services from Google, Azure and AWS 
    &lt;div id=&#34;ai-product-and-services-from-google-azure-and-aws&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ai-product-and-services-from-google-azure-and-aws&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Sno&lt;/th&gt;
          &lt;th&gt;Azure&lt;/th&gt;
          &lt;th&gt;Google&lt;/th&gt;
          &lt;th&gt;AWS&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;1.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/anomaly-detector/&#34; target=&#34;_blank&#34;&gt;Anomaly Detector:&lt;/a&gt; Easily add anomaly detection capabilities to your apps.&lt;/td&gt;
          &lt;td&gt;AutoML: Custom low-code models &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/training/training&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/a2i/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Augmented AI&lt;/a&gt; : Easily implement human review of machine learning predictions&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/bot-services/&#34; target=&#34;_blank&#34;&gt;Azure Bot Service:&lt;/a&gt; Build conversational AI experiences for your customers&lt;/td&gt;
          &lt;td&gt;Cloud TPU: Hardware acceleration for ML &lt;a href=&#34;https://cloud.google.com/tpu/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/tpu/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Bedrock&lt;/a&gt; : The easiest way to build and scale generative AI applications with foundation models (FMs).&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;3.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/search/&#34; target=&#34;_blank&#34;&gt;Azure Cognitive Search:&lt;/a&gt; Enterprise scale search for app development&lt;/td&gt;
          &lt;td&gt;Cloud Translation: Language detection and translation &lt;a href=&#34;https://cloud.google.com/translate/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/translate/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/codeguru/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon CodeGuru&lt;/a&gt; : Intelligent recommendations for building and running modern applications&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;4.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/databricks/&#34; target=&#34;_blank&#34;&gt;Azure Databricks:&lt;/a&gt; Design AI with Apache Spark™-based analytics&lt;/td&gt;
          &lt;td&gt;Cloud Vision: Image recognition and classification &lt;a href=&#34;https://cloud.google.com/vision/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vision/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/comprehendmedical/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Comprehend Medical&lt;/a&gt; : Amazon Comprehend Medical uses machine learning to extract insights and relationships from medical text.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;5.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/machine-learning/&#34; target=&#34;_blank&#34;&gt;Azure Machine Learning:&lt;/a&gt; Enterprise-grade machine learning service to build and deploy models faster&lt;/td&gt;
          &lt;td&gt;Contact Center AI: AI in your contact center &lt;a href=&#34;https://cloud.google.com/solutions/contact-center/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/solutions/contact-center/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/comprehend/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Comprehend&lt;/a&gt; : Analyze Unstructured Text&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;6.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/services/open-datasets/&#34; target=&#34;_blank&#34;&gt;Azure Open Datasets:&lt;/a&gt; Cloud platform to host and share curated open datasets to accelerate development of machine learning models&lt;/td&gt;
          &lt;td&gt;Deep Learning Containers: Preconfigured containers for deep learning &lt;a href=&#34;https://cloud.google.com/ai-platform/deep-learning-containers/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/ai-platform/deep-learning-containers/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/deepcomposer/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;AWS DeepComposer&lt;/a&gt; : AWS DeepComposer allows developers of all skill levels to get started with Generative AI.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;7.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/&#34; target=&#34;_blank&#34;&gt;Azure Cognitive Services:&lt;/a&gt; Deploy high-quality AI models as APIs&lt;/td&gt;
          &lt;td&gt;Deep Learning VM Images: Preconfigured VMs for deep learning &lt;a href=&#34;https://cloud.google.com/deep-learning-vm/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/deep-learning-vm/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/deeplens/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;AWS DeepLens&lt;/a&gt; : Deep Learning Enabled Video Camera&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;8.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/services/video-indexer/&#34; target=&#34;_blank&#34;&gt;Azure Video Analyzer for Media:&lt;/a&gt; Unlock video insights&lt;/td&gt;
          &lt;td&gt;Dialogflow: Create conversational interfaces &lt;a href=&#34;https://cloud.google.com/dialogflow-enterprise/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/dialogflow-enterprise/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/deepracer/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;AWS DeepRacer&lt;/a&gt; : Fully autonomous 1/18th scale race car, driven by machine learning&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;9.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/content-safety/&#34; target=&#34;_blank&#34;&gt;Content Moderator GA:&lt;/a&gt; Automated image, text and video moderation&lt;/td&gt;
          &lt;td&gt;Document AI: Analyze, classify, search documents &lt;a href=&#34;https://cloud.google.com/solutions/document-understanding/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/document-understanding/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/devops-guru/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon DevOps Guru&lt;/a&gt; : ML-powered cloud operations service to improve application availability.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;10.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/custom-vision-service/&#34; target=&#34;_blank&#34;&gt;Custom Vision:&lt;/a&gt; Easily customise your own state-of-the-art computer vision models for your unique use case&lt;/td&gt;
          &lt;td&gt;Recommendations AI: Create custom recommendations &lt;a href=&#34;https://cloud.google.com/recommendations/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/recommendations-ai/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/forecast/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Forecast&lt;/a&gt; : Amazon Forecast is a fully-managed service for accurate time-series forecasting&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;11.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/virtual-machines/data-science-virtual-machines/&#34; target=&#34;_blank&#34;&gt;Data Science Virtual Machines:&lt;/a&gt; Rich pre-configured environment for AI development&lt;/td&gt;
          &lt;td&gt;Speech-To-Text: Convert audio to text &lt;a href=&#34;https://cloud.google.com/speech/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/speech/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/frauddetector/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Fraud Detector&lt;/a&gt; : Detect more online fraud faster using machine learning&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;12.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/form-recognizer/&#34; target=&#34;_blank&#34;&gt;Azure Form Recogniser:&lt;/a&gt; Accelerate information extraction from documents&lt;/td&gt;
          &lt;td&gt;Talent Solutions: Job search with ML &lt;a href=&#34;https://cloud.google.com/job-discovery/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/job-discovery/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/healthlake/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon HealthLake&lt;/a&gt; : Making sense of health data&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;13.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/immersive-reader/&#34; target=&#34;_blank&#34;&gt;Azure Immersive Reader:&lt;/a&gt; Empower users of all ages and abilities to read and comprehend text&lt;/td&gt;
          &lt;td&gt;Text-To-Speech: Convert text to audio &lt;a href=&#34;https://cloud.google.com/text-to-speech/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/text-to-speech/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/kendra/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Kendra&lt;/a&gt; : Highly accurate enterprise search service powered by machine learning&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;14.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/kinect-dk/&#34; target=&#34;_blank&#34;&gt;Kinect DK:&lt;/a&gt; Build computer vision and speech models using a developer kit with advanced AI sensors&lt;/td&gt;
          &lt;td&gt;Vertex AI Data Labeling: Data labeling by humans &lt;a href=&#34;https://cloud.google.com/data-labeling/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/lexv2/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Lex&lt;/a&gt; : Build Voice and Text Chatbots&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;15.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/conversational-language-understanding/&#34; target=&#34;_blank&#34;&gt;Language Understanding:&lt;/a&gt; Teach your apps to understand commands from your users&lt;/td&gt;
          &lt;td&gt;Vertex AI Edge Manager: Deploy monitor edge inferences &lt;a href=&#34;https://https://cloud.google.com/vertex-ai/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/lookoutequipment/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Lookout for Equipment&lt;/a&gt; : Detect abnormal equipment behavior by analyzing sensor data&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;16.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/genomics/&#34; target=&#34;_blank&#34;&gt;Microsoft Genomics:&lt;/a&gt; Power genome sequencing and research insights&lt;/td&gt;
          &lt;td&gt;Vertex AI Feature Store: Managed ML feature repository &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/featurestore&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/featurestore/overview&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/lookoutmetrics/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Lookout for Metrics&lt;/a&gt; : Accurately detect anomalies in your business metrics and quickly understand why&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;17.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/personalizer/&#34; target=&#34;_blank&#34;&gt;Personaliser:&lt;/a&gt; An AI service that delivers a personalised user experience&lt;/td&gt;
          &lt;td&gt;Vertex AI Matching Engine: Vector similarity searches &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/matching-engine&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/matching-engine&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/lookoutvision/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Lookout for Vision&lt;/a&gt; : Identify defects using computer vision to automate quality inspection.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;18.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/services/project-bonsai/&#34; target=&#34;_blank&#34;&gt;Project Bonsai:&lt;/a&gt; Create intelligent industrial control systems using simulations&lt;/td&gt;
          &lt;td&gt;Vertex AI Model Monitoring: Monitor models for skew/drift &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/model-monitoring&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/model-monitoring/overview&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/monitron/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Monitron&lt;/a&gt; : End-to-end system for equipment monitoring&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;19.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://docs.microsoft.com/en-in/azure/cognitive-services/QnAMaker/Overview/overview&#34; target=&#34;_blank&#34;&gt;QnA Maker:&lt;/a&gt; Distill information into conversational, easy-to-navigate answers&lt;/td&gt;
          &lt;td&gt;Vertex AI Pipelines: Hosted ML workflows &lt;a href=&#34;https://cloud.google.com/ai-platform/pipelines/&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/omics/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Omics&lt;/a&gt; : Transform omics data into insights.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;20.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/speaker-recognition/&#34; target=&#34;_blank&#34;&gt;Speaker Recognition:&lt;/a&gt; A Speech service feature that verifies and identifies speakers&lt;/td&gt;
          &lt;td&gt;Vertex AI Predictions: Autoscaled model serving &lt;a href=&#34;https://cloud.google.com/ai-platform/prediction/docs/overview&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/panorama/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;AWS Panorama&lt;/a&gt; : Enabling computer vision applications at the edge&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;21.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/speech-to-text/&#34; target=&#34;_blank&#34;&gt;Speech to Text:&lt;/a&gt; A Speech service feature that accurately converts spoken audio to text&lt;/td&gt;
          &lt;td&gt;Vertex AI Tensorboard: Managed TensorBoard for ML-experiment Visualization &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/experiments&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/personalize/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Personalize&lt;/a&gt; : Amazon Personalize helps you easily add real-time recommendations to your apps&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;22.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/speech-translation/&#34; target=&#34;_blank&#34;&gt;Speech Translation:&lt;/a&gt; Easily integrate real-time speech translation to your app&lt;/td&gt;
          &lt;td&gt;Vertex AI Training: Distributed AI training &lt;a href=&#34;https://cloud.google.com/ai-platform/training/docs/overview&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/polly/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Polly&lt;/a&gt; : Turn Text into Lifelike Speech&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;23.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/language-service/&#34; target=&#34;_blank&#34;&gt;Cognitive Service for Language:&lt;/a&gt; Add natural language capabilities with a single API call&lt;/td&gt;
          &lt;td&gt;Vertex AI Vizier: black-box hyperparameter tuning &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/vizier/overview&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/vizier&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/rekognition/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Rekognition&lt;/a&gt; : Search and Analyze Images&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;24.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/services/cognitive-services/text-to-speech/&#34; target=&#34;_blank&#34;&gt;Text to Speech:&lt;/a&gt; A Speech service feature that converts text to lifelike speech&lt;/td&gt;
          &lt;td&gt;Vertex AI Workbench:Jupyter-based environment for Data Science &lt;a href=&#34;https://cloud.google.com/vertex-ai-workbench&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/workbench&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon SageMaker&lt;/a&gt; : Build, Train, and Deploy Machine Learning Models&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;25.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/services/cognitive-services/translator/&#34; target=&#34;_blank&#34;&gt;Translator:&lt;/a&gt; Easily conduct machine translation with a simple REST API call&lt;/td&gt;
          &lt;td&gt;Vertex Explainable AI: Understand ML model predictions &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/explainable-ai/overview&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/explainable-ai&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/textract/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Textract&lt;/a&gt; : Easily extract text and data from virtually any document&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;26.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/metrics-advisor/&#34; target=&#34;_blank&#34;&gt;Azure Metrics Advisor:&lt;/a&gt; An AI service that monitors metrics and diagnoses issues&lt;/td&gt;
          &lt;td&gt;Vertex ML Metadata: Artifact, lineage, and execution tracking &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/ml-metadata&#34; target=&#34;_blank&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/ml-metadata/introduction&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/transcribe/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Transcribe&lt;/a&gt; : Powerful Speech Recognition&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;27.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/bot-services/health-bot/&#34; target=&#34;_blank&#34;&gt;Health Bot:&lt;/a&gt; A managed service purpose-built for development of virtual healthcare assistants&lt;/td&gt;
          &lt;td&gt;Vision Product Search: Visual search for products &lt;a href=&#34;https://cloud.google.com/vision/product-search/docs/&#34; target=&#34;_blank&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/translate/home?region=us-east-1&#34; target=&#34;_blank&#34;&gt;Amazon Translate&lt;/a&gt; : Powerful Neural Machine Translation&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;28.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://aka.ms/ScalerHomepage&#34; target=&#34;_blank&#34;&gt;Azure Applied AI Services:&lt;/a&gt; Specialised services that enable organisations to accelerate time to value in applying AI to solve common scenarios&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;29.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/openai-service/&#34; target=&#34;_blank&#34;&gt;Azure OpenAI Service:&lt;/a&gt; Apply advanced coding and language models to a variety of use cases&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;30.&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/vision-services/&#34; target=&#34;_blank&#34;&gt;Azure Cognitive Services for Vision:&lt;/a&gt; Unlock insights from image and video content with AI&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
          &lt;td&gt;&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;Author&lt;/strong&gt;&lt;br&gt;
Dr Hari Thapliyaal&lt;br&gt;
dasarpai.com &lt;br&gt;
linkedin.com/in/harithapliyal&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Introduction to ML Model Deployment</title>
      <link>https://dasarpai.com/dsblog/Introduction-to-ML-Model-deployment/</link>
      <pubDate>Wed, 19 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Introduction-to-ML-Model-deployment/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6077-Introduction-to-ML-Model-deployment.jpg&#34; alt=&#34;Introduction to AI Model Deployement&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Introduction to AI Model deployment 
    &lt;div id=&#34;introduction-to-ai-model-deployment&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction-to-ai-model-deployment&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Big Players 
    &lt;div id=&#34;big-players&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#big-players&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Amazon
&lt;ul&gt;
&lt;li&gt;Amazon has many products and one of their product is &lt;strong&gt;AWS Cloud&lt;/strong&gt;. Under this product they sell IT infrastructure (storage, memory, network, VM, webhosting etc.)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Amazon SageMaker&lt;/strong&gt; is Cloud based Machine Learning Platform, and this is one of the product under AWS Cloud.&lt;/li&gt;
&lt;li&gt;Amazon SageMaker can be used to train AI model, host AI model, monitor the model and hosts many other services which any Data Science project need from data gathering to model serving.&lt;/li&gt;
&lt;li&gt;AWS is oldest cloud service provider in the market.&lt;/li&gt;
&lt;li&gt;AWS Sagemaker was launched in Nov&#39;17.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Google
&lt;ul&gt;
&lt;li&gt;Google has hundreds of products like gmail, youtube, google drive etc. One of their product is called &lt;strong&gt;Google Cloud&lt;/strong&gt;. Under this product they sell IT infrastrcture like Amazon sells under AWS.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;VertexAI&lt;/strong&gt; is Cloud based Machine Learning platform of Google. VertexAI is part of Google Cloud.&lt;/li&gt;
&lt;li&gt;VertexAI can be used to train AI Model,host AI model, monitor the model etc.&lt;/li&gt;
&lt;li&gt;VertexAI was launched in Jun&#39;21&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Microsoft
&lt;ul&gt;
&lt;li&gt;Like Amazon&amp;rsquo;s cloud platform which is called AWS Cloud, Microsoft&amp;rsquo;s cloud plateform is called &lt;strong&gt;Azure&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Microsoft&amp;rsquo;s AI product is called &lt;strong&gt;Azure Machine Learning&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Today (Jul&#39;23) Azure Machine Learning has has most of the capabilites than any other player&amp;rsquo;s AI product.&lt;/li&gt;
&lt;li&gt;Azure Machine Learning was launched Feb&#39;14&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is GenAI? 
    &lt;div id=&#34;what-is-genai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-genai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;There are many kinds of AI models like classifier models, regressor models, clustering models, reinforcement models, etc. An AI model which has the ability to generate text, images, video, and music is called GenAI. They all take inspiration from the human brain, therefore they all have neural network (NN) architecture. There are dozens (if not hundreds) types of NN architecture that can be used to create different kinds of AI models. The type of NN architecture depends upon the data which is used for developing the model and the problem which we want to solve using AI model. Researchers in universities or big corporations like Google, Facebook, Amazon, and Microsoft keep developing new architecture, and using these architectures they develop the foundational models. Once foundational models are developed, they release a research paper. In this, they inform the world what architecture they used, what data they used, what parameters (weights &amp;amp; biases) the model has learned, what are the results of their product and compare that with other existing models. They can develop these foundational models with one set of hyperparameters, and they can release these foundational models of different sizes (it depends upon the number of parameters used). AI product builders pick up these foundational models and fine-tune these based on the exact business problem in their hands. Which foundational model do they choose, it also depends upon the size of the model, the kind of data it has used to create those foundational models, and what was the performance of the model on a similar task which the product developer want to solve.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Embedding with FastText</title>
      <link>https://dasarpai.com/dsblog/Embedding-with-FastText/</link>
      <pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Embedding-with-FastText/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6073-Embedding-with-FastText.jpg&#34; alt=&#34;Embedding with FastText&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Embedding with FastText 
    &lt;div id=&#34;embedding-with-fasttext&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#embedding-with-fasttext&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://dasarpai.com/dsblog/what-is-nlp#what-is-embedding&#34;&gt;What is Embedding?&lt;/a&gt; &lt;br&gt;
&lt;a href=&#34;https://dasarpai.com/dsblog/what-is-nlp#what-are-different-embedding-types&#34;&gt;What are Different Types of Embedding&lt;/a&gt;&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is FastText? 
    &lt;div id=&#34;what-is-fasttext&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-fasttext&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;FastText is an open-source library for efficient learning of word representations and sentence classification developed by Facebook AI Research. It is designed to handle large-scale text data and provides tools for &lt;strong&gt;training&lt;/strong&gt; and &lt;strong&gt;using word embeddings&lt;/strong&gt;.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Major LLM Developers Shaping the AI Landscape</title>
      <link>https://dasarpai.com/dsblog/Major-LLM-Developers-Reshaping-NLP-Advancements/</link>
      <pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Major-LLM-Developers-Reshaping-NLP-Advancements/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6075-Major-LLM-Developers-Reshaping-NLP-Advancements.jpg&#34; alt=&#34;Major LLM Developers Shaping the AI Landscape&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Major LLM Developers Shaping the AI Landscape 
    &lt;div id=&#34;major-llm-developers-shaping-the-ai-landscape&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#major-llm-developers-shaping-the-ai-landscape&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;From Text to Intelligence: Major LLM Developers Shaping the AI Landscape&lt;/strong&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What is GAN Architecture?</title>
      <link>https://dasarpai.com/dsblog/What-is-GAN-Architecture/</link>
      <pubDate>Mon, 03 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/What-is-GAN-Architecture/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6069-What-is-GAN-Architecture.jpg&#34; alt=&#34;What is GAN Architecture?&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;What is GAN Architecture? 
    &lt;div id=&#34;what-is-gan-architecture&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-gan-architecture&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Generative Adversarial Networks (GANs) are a powerful class of neural networks that are used for unsupervised learning. It was developed and introduced by Ian J. Goodfellow in 2014. It is a type of artificial intelligence (AI) model that consists of two neural networks: a generator and a discriminator. GANs are used for generative tasks, such as creating realistic images, videos, or even audio.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Capabilities of AI Transformers</title>
      <link>https://dasarpai.com/dsblog/Capabilities-of-AI-Transformers/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Capabilities-of-AI-Transformers/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6067-Capabilities-of-AI-Transformers.jpg&#34; alt=&#34;Capabilities of AI Transformers&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Capabilities of AI Transformers 
    &lt;div id=&#34;capabilities-of-ai-transformers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#capabilities-of-ai-transformers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Background 
    &lt;div id=&#34;background&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#background&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Whether GPT, ChatGPT, DALL-E, Whisper, Satablity AI or whatever significant you see in the AI worlds nowdays it is because of Transformer Architecture. Transformers are a type of neural network architecture that have several properties that make them effective for modeling data with long-range dependencies. They generally feature a combination of multi-headed attention mechanisms, residual connections, layer normalization, feedforward connections, and positional embeddings.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Model Garden of VertexAI</title>
      <link>https://dasarpai.com/dsblog/Model-Garden-of-VertexAI/</link>
      <pubDate>Wed, 21 Jun 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Model-Garden-of-VertexAI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6065-Model-Garden-of-VertexAI.jpg&#34; alt=&#34;All Resources to Learn Data Science&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Model Garden of VertexAI: 
    &lt;div id=&#34;model-garden-of-vertexai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#model-garden-of-vertexai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Unlocking the Power of Google&amp;rsquo;s VertexAI: Exploring the World of Pre-Built Models for AI Tasks 
    &lt;div id=&#34;unlocking-the-power-of-googles-vertexai-exploring-the-world-of-pre-built-models-for-ai-tasks&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#unlocking-the-power-of-googles-vertexai-exploring-the-world-of-pre-built-models-for-ai-tasks&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction: 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Artificial Intelligence (AI) has transformed numerous industries, from healthcare and finance to e-commerce, logistic, eduction and entertainment. But the complexity of developing machine learning models often poses a challenge. As the demand for AI-powered solutions continues to rise, data scientists seek efficient ways to leverage pre-trained models or build custom models to address specific tasks. In this regard, Google&amp;rsquo;s VertexAI emerges as a robust platform that offers an extensive selection of pre-built models for a wide range of AI tasks. VertexAI platform has revolutionized the landscape by seamlessly leveraging LLM (Large Language Models) and Prompt Engineering techniques to perform complex machine learning tasks effortlessly. With VertexAI, data scientists can harness the power of state-of-the-art language models, such as LLM, to accelerate their ML development process. Additionally, the innovative concept of Prompt Engineering enables users to effectively communicate with the models, guiding them to deliver precise and accurate results. From computer vision and natural language processing to speech processing and structured tabular data analysis, Vertex AI&amp;rsquo;s repertoire includes over 100 models catering to diverse application domains. This article explores how Vertex AI, through its integration of LLM and Prompt Engineering, empowers users to effortlessly tackle intricate machine learning tasks across diverse domains, revolutionizing the AI development experience.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>All Resources to Learn Data Science</title>
      <link>https://dasarpai.com/dsblog/all-resources-to-learn-data-science/</link>
      <pubDate>Thu, 08 Jun 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/all-resources-to-learn-data-science/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6064-Resources-to-Learn-Everything-About-AI.jpg&#34; alt=&#34;All Resources to Learn Data Science&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;All Resources to Learn Data Science 
    &lt;div id=&#34;all-resources-to-learn-data-science&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#all-resources-to-learn-data-science&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Welcome to the AI ML Resources category page, where you&amp;rsquo;ll find a wealth of knowledge on various topics related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), Natural Language Processing (NLP), Mathematics and statistics required to learn Data Science. Each of the pages mentioned below brings together a wide range of articles, tutorials, and guides that delve into the fascinating world of AI and ML. Whether you&amp;rsquo;re a beginner seeking foundational knowledge or an experienced practitioner looking to expand your skills, these resources offer valuable insights and practical guidance. You need to go through these links one at time. As a master page you can book mark this page.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Demystifying DevOps, MLOps, and DataOps</title>
      <link>https://dasarpai.com/dsblog/Demystifying-DevOps-MLOps-and-DataOps/</link>
      <pubDate>Thu, 08 Jun 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Demystifying-DevOps-MLOps-and-DataOps/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6066-Demystifying-DevOps-MLOps-and-DataOps.jpg&#34; alt=&#34;All Resources to Learn Data Science&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Demystifying DevOps, MLOps, and DataOps: 
    &lt;div id=&#34;demystifying-devops-mlops-and-dataops&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#demystifying-devops-mlops-and-dataops&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;Bridging the Gap between Software Development, Machine Learning, and Data Managemen&lt;/strong&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>God Fathers of AI</title>
      <link>https://dasarpai.com/dsblog/God-Fathers-of-AI/</link>
      <pubDate>Fri, 05 May 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/God-Fathers-of-AI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6058-God-Fathers-of-AI.jpg&#34; alt=&#34;God Fathers of AI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;God Fathers of AI 
    &lt;div id=&#34;god-fathers-of-ai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#god-fathers-of-ai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;In other fields of studies or in religion, there is only one god or only one godfather. But in the field of AI, that is not the case. There are many pioneers or Godfathers who have done significant work in this field. Recently, the resignation of Dr. Geoffrey Hinton from Google raised eyebrows in the business world and in Governments the world over. Technology is good or bad, it depends upon whose hand it is. Geoffrey raised that concern and for that, he wants better controls in place. What will happen, we need to follow the progress and raise our voices around. In this article, I am mentioning some godfathers of AI, their workplaces, and their contributions. I am sure this will inspire many young minds.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Types of Machine Learning</title>
      <link>https://dasarpai.com/dsblog/Types-of-Machine-Learning/</link>
      <pubDate>Thu, 27 Apr 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Types-of-Machine-Learning/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6056-Types-of-Machine-Learning.jpg&#34; alt=&#34;Types of Machine Learning&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Types of Machine Learning 
    &lt;div id=&#34;types-of-machine-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#types-of-machine-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Machine learning is a field of artificial intelligence that focuses on developing algorithms that can learn from data and make predictions or decisions. There are several types of machine learning techniques, each with its strengths and weaknesses. In this post, we will explore some of the most commonly used machine learning techniques, including supervised learning, unsupervised learning, reinforcement learning, and more. This post is not about deep diving into these topics but to give you a oneliner understanding and the difference between these different techniques.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Cost Functions and Optimizers in Machine Learning</title>
      <link>https://dasarpai.com/dsblog/Cost-Functions-and-Optimizers-in-Machine-Learning/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Cost-Functions-and-Optimizers-in-Machine-Learning/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6045-Cost-Functions-and-Optimizers-in-Machine-Learning.jpg&#34; alt=&#34;Cost-Functions-and-Optimizers-in-Machine-Learning&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Cost-Functions-and-Optimizers-in-Machine-Learning 
    &lt;div id=&#34;cost-functions-and-optimizers-in-machine-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#cost-functions-and-optimizers-in-machine-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is machine learning? 
    &lt;div id=&#34;what-is-machine-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-machine-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Machine learning is a subfield of artificial intelligence that focuses on the &lt;strong&gt;development of algorithms and statistical models&lt;/strong&gt; that enable computers to improve their performance on a specific task through experience.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>GPU for Data Science Work</title>
      <link>https://dasarpai.com/dsblog/GPU-for-Data-Science-Work/</link>
      <pubDate>Thu, 26 Jan 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/GPU-for-Data-Science-Work/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6042-GPU-for-Data-Science-Work.jpg&#34; alt=&#34;GPU for Data Science Work&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;GPU for Data Science Work 
    &lt;div id=&#34;gpu-for-data-science-work&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#gpu-for-data-science-work&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is the difference between microprocessor (CPU) and GPU? 
    &lt;div id=&#34;what-is-the-difference-between-microprocessor-cpu-and-gpu&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-the-difference-between-microprocessor-cpu-and-gpu&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;A microprocessor and a GPU (graphics processing unit) are both types of processors, but they are designed for different purposes and have different architectures.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AI Usecases in Agriculture Industry</title>
      <link>https://dasarpai.com/dsblog/AI-usecases-in-Agriculture-Industry/</link>
      <pubDate>Mon, 23 Jan 2023 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/AI-usecases-in-Agriculture-Industry/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6037-AI-usecases-in-Agriculture-Industry.jpg&#34; alt=&#34;AI Usecases in Agriculture Industry&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AI Usecases in Agriculture Industry 
    &lt;div id=&#34;ai-usecases-in-agriculture-industry&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ai-usecases-in-agriculture-industry&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;In the today world where energy saving, climate change, cost and process optimization, effectiveness is the philosophy of all business activities. With ever-increasing demand of food, the agriculture industry is looking for ways to improve crop yields and optimize farming practices. The use of Artificial Intelligence (AI) in agriculture is proving to be a game-changer, providing farmers with new and innovative tools to improve efficiency and productivity. From precision farming to autonomous tractors, AI is revolutionizing the way we think about farming and agriculture.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>AI Use Cases in Food Processing</title>
      <link>https://dasarpai.com/dsblog/AI-Use-Cases-in-Food-Processing/</link>
      <pubDate>Sun, 22 Jan 2023 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/AI-Use-Cases-in-Food-Processing/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6036-AI-Use-Cases-in-Food-Processing.jpg&#34; alt=&#34;&amp;ldquo;AI Use Cases in Food Processing&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;AI Use Cases in Food Processing 
    &lt;div id=&#34;ai-use-cases-in-food-processing&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ai-use-cases-in-food-processing&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;The food processing industry is a vital sector in the global economy, responsible for providing safe and nutritious food to millions of people around the world. Artificial intelligence (AI) is being increasingly used in the food processing industry to improve efficiency, reduce costs, and enhance the quality and safety of food products. From automated sorting and grading of fruits and vegetables to intelligent vending machines, AI is being used in a wide range of applications across the food processing industry.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Introduction to Neural Network</title>
      <link>https://dasarpai.com/dsblog/Introduction-to-Neural-Network/</link>
      <pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Introduction-to-Neural-Network/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6034-Introduction-to-Neural-Network.jpg&#34; alt=&#34;Introduction to Neural Network&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Introduction to Neural Network 
    &lt;div id=&#34;introduction-to-neural-network&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction-to-neural-network&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction to a Perceptron 
    &lt;div id=&#34;introduction-to-a-perceptron&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction-to-a-perceptron&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;A perceptron is a type of artificial neural network that can be used for binary classification. It is a simple model that consists of a single layer of artificial neurons and is used to classify input data into one of two categories. The perceptron algorithm learns the weights of the artificial neurons by adjusting them based on the input data and the desired output. The perceptron is considered a basic building block for more complex neural networks.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What is GAN?</title>
      <link>https://dasarpai.com/dsblog/What-is-GAN/</link>
      <pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/What-is-GAN/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6043-gan.jpg&#34; alt=&#34;Partial Dependence Plots&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;What is GAN? 
    &lt;div id=&#34;what-is-gan&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-gan&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is GAN (Generative Adversarial Network)? 
    &lt;div id=&#34;what-is-gan-generative-adversarial-network&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-gan-generative-adversarial-network&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Generative adversarial networks (GANs) are besing used to generate images, videos, text, audio and music. GAN is a class of machine-learning models introduced by Ian Goodfellow and his colleagues in 2014. The GANs became popular among researchers quickly because of their property to generate new data with the same statistics as the input training set. It can be applied to images, videos, textual data, tabular data and more, proving useful for semi-supervised, fully supervised, and reinforcement learning.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Timeseries Interview Questions</title>
      <link>https://dasarpai.com/dsblog/Timeseries-Interview-Questions/</link>
      <pubDate>Sun, 08 Jan 2023 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Timeseries-Interview-Questions/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6023-Timeseries-Interview-Questions.jpg&#34; alt=&#34;Timeseries Interview Questions&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Timeseries Interview Questions 
    &lt;div id=&#34;timeseries-interview-questions&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#timeseries-interview-questions&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What are the characterstics of  time series data? 
    &lt;div id=&#34;what-are-the-characterstics-of--time-series-data&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-are-the-characterstics-of--time-series-data&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Time series data is a series of data points collected over time. Some characteristics of time series data include:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Linear Regression Interview Questions</title>
      <link>https://dasarpai.com/dsblog/Linear-Regression-Interview-Questions/</link>
      <pubDate>Sat, 07 Jan 2023 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Linear-Regression-Interview-Questions/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6022-Linear-Regression-Interview-Questions.jpg&#34; alt=&#34;Prompt Engineering for GPT4&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Linear Regression Interview Questions and Answers 
    &lt;div id=&#34;linear-regression-interview-questions-and-answers&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#linear-regression-interview-questions-and-answers&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;In this question-answer article, I will try that the start of every answer from example rather than theory (some unavoidable variation may be possible). I firmly believe if examples are clear, human mind is smart enough in generlization and creating theories.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>GPT Usecases</title>
      <link>https://dasarpai.com/dsblog/gpt-usecases/</link>
      <pubDate>Thu, 05 Jan 2023 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/gpt-usecases/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6020-GPT-Usecases.jpg&#34; alt=&#34;GPT Usecases&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;What is GPT? 
    &lt;div id=&#34;what-is-gpt&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-gpt&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;GPT is a transformer. Don&amp;rsquo;t confuse it with your electricity transformer! In Artificial Intelligence there are different kinds of neural network architectures to perform various tasks like classification, translation, segmentation, regression, etc. One of those architectures is transformer architecture. The Foundation of this architecture is based on another two architectures called encoder architecture and decoder architecture. There are lots of other technical complexity but for the business readers I am hiding that for that the time being, we will discuss that at some other place. In nutshell, GPT is a Transformer technology developed by OpenAI and it can perform several NLP tasks. NLP stands for natural language preprocessing. NLP tasks mean tasks like sentiment analysis of the text, text classification, topic modeling, translation, named entity recognition, and dozens of other tasks.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>ChatGPT Usecases</title>
      <link>https://dasarpai.com/dsblog/chatgpt-usecases/</link>
      <pubDate>Wed, 04 Jan 2023 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/chatgpt-usecases/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6019-ChatGPT-Usecases.jpg&#34; alt=&#34;ChatGPT Usecases&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;What is ChatGPT? 
    &lt;div id=&#34;what-is-chatgpt&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-chatgpt&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;ChatGPT is &lt;strong&gt;general purpose&lt;/strong&gt; - &amp;ldquo;chat model&amp;rdquo; from OpenAI. It is a &lt;strong&gt;language model&lt;/strong&gt;, which means if you type some text then it can understand and respond to you appropriately. At this point in time, it is not accepting voice commands, neither able to process images or videos. A &lt;strong&gt;general-purpose model&lt;/strong&gt; means it can understand the question coming from any domain of life. A domain may be vertical or horizontal. A vertical domain means where a vendor is supplying a product or service for a specific type of customer. A horizontal domain is where a vendor supplies products or services for all types of customer.  Healthcare, banking, logistic, insurance, agriculture, philosophy, history, and economics are one kind of verticals whereas
BPO, Quality Management, Software Development, Taxation, HR, IT Security, Accounting, Office Administration, Catering, and Entertainment are other kind of domains. A &lt;strong&gt;general-purpose model&lt;/strong&gt; can understand the questions from all aspects of life whether business vertical or horizontal or normal daily family or conflicts with other group members, family members, etc.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What is Computer Vision</title>
      <link>https://dasarpai.com/dsblog/what-is-computer-vision/</link>
      <pubDate>Wed, 28 Dec 2022 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/what-is-computer-vision/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6018-What-is-Computer-Vision.jpg&#34; alt=&#34;What is Computer Vision&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;What is Computer vision? 
    &lt;div id=&#34;what-is-computer-vision&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-computer-vision&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Background 
    &lt;div id=&#34;background&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#background&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;In the digital world, scientists are working hard to create machines and robots that can interact with humans the way humans interact with each other. You cannot interact with another human being around if you are not aware of the objects and background around you. There are many ways to know the things around us. We can know them through smell; without looking anything around we can tell, here is a rose flower or samosa or sugar factory around. Without looking we can tell whether a train is coming or going, a person is going or coming, this is a song sung by Lata Mangeshkar. Without looking I can tell this is smooth or rough, hard or soft, cold or hot. In all these cases we could identify the objects and things around us without using our eyes.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What is NLP?</title>
      <link>https://dasarpai.com/dsblog/what-is-nlp/</link>
      <pubDate>Mon, 19 Dec 2022 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/what-is-nlp/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6016-What-is-NLP.jpg&#34; alt=&#34;What is NLP?&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is NLP? 
    &lt;div id=&#34;what-is-nlp&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-nlp&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Humans interact with their surroundings using different kinds of inputs. Eyes deal with inputs of color, shape, and size. Ear deals with inputs of sound, voice, and noise. Similarly, the other 3 senses also deal with other kinds of inputs. When you write something you may be drawing some art or you may be drawing letters of some language. Language is what we use to speak, for example, English, Hindi, Kannada, Tamil, and French are languages. The script is a tool to write what we speak. There are many kinds of scripts and you can use those scripts to write words of the languages. Some scripts are good for some languages. You cannot write all the words of all the languages of the world using one script (without modifying the original letters of the script). The Roman script is good to write English languages but when you want to write any Indian language using Roman then you will make many mistakes when reading the scripts. Because you won&amp;rsquo;t be able to produce the same sound as the original language was producing.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Domain Knowledge in Machine Learning</title>
      <link>https://dasarpai.com/dsblog/Domain-Knowledge-in-Machine-Learning/</link>
      <pubDate>Sat, 15 Oct 2022 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/Domain-Knowledge-in-Machine-Learning/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6015-domain-knowledge-in-machine-learning.jpg&#34; alt=&#34;Domain Knowledge in Machine Learning&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Domain Knowledge in Machine Learning 
    &lt;div id=&#34;domain-knowledge-in-machine-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#domain-knowledge-in-machine-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Let’s say the domain is a restaurant kitchen. A dataset with 3 variables. Two predictors and one predicted. Predictor variables are flour in kilograms and water in liters.  A predicted variable is the number of roti/ bread. You know the model will be something like this.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Data Science, AI, ML, eBooks, PDF Books</title>
      <link>https://dasarpai.com/dsblog/ds-ai-ml-books/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/ds-ai-ml-books/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dsresources/dsr120-Data-Science-AI-ML-eBooks-PDF-Books.jpg&#34; alt=&#34;DS, AI, ML, Books Available&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Online Data Science, AI, ML Content 
    &lt;div id=&#34;online-data-science-ai-ml-content&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#online-data-science-ai-ml-content&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;Data Science, AI, Machine Learning, Books/ Guide/ Reports/ Presentations / Jupyter Notebook Available.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>RDBMS</title>
      <link>https://dasarpai.com/dscourses/rdbms/</link>
      <pubDate>Thu, 30 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/rdbms/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc316-RDBMS.jpg&#34; alt=&#34;RDBMS&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Relational Database Management Systems (RDBMS) 
    &lt;div id=&#34;relational-database-management-systems-rdbms&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#relational-database-management-systems-rdbms&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;A brief summary of the topics covered in this course is as below. This is 60 hours course, it is suggested to complete this course in 1 month.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Big Data</title>
      <link>https://dasarpai.com/dscourses/big-data/</link>
      <pubDate>Wed, 29 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/big-data/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc315-Big-Data.jpg&#34; alt=&#34;Big Data&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Big Data Analytics 
    &lt;div id=&#34;big-data-analytics&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#big-data-analytics&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Big Data Systems 
    &lt;div id=&#34;big-data-systems&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#big-data-systems&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;What is Big Data&lt;/li&gt;
&lt;li&gt;Data Warehouse, Data Lakes&lt;/li&gt;
&lt;li&gt;Hadoop – Components&lt;/li&gt;
&lt;li&gt;Storage – HDFS, Hbase&lt;/li&gt;
&lt;li&gt;Resource Manager (MapReduce, YARN)&lt;/li&gt;
&lt;li&gt;Types of data formats (JSON, ORC, Parquet, AVRO)&lt;/li&gt;
&lt;li&gt;Scripting  (Hive, Pig)&lt;/li&gt;
&lt;li&gt;Stream Processing&lt;/li&gt;
&lt;li&gt;Massive Parallel Processing (Spark, Imapala, Mahout)&lt;/li&gt;
&lt;li&gt;RDDs in Spark&lt;/li&gt;
&lt;li&gt;Data Migration (Scoop/ Flume)&lt;/li&gt;
&lt;li&gt;Schedular (Oozie)&lt;/li&gt;
&lt;li&gt;Resource Negotiator (Zookeeper)&lt;/li&gt;
&lt;li&gt;RDBMS Database&lt;/li&gt;
&lt;li&gt;Columnar Database&lt;/li&gt;
&lt;li&gt;Multimodel Database&lt;/li&gt;
&lt;li&gt;NoSQL (HBase, Cassandra, MongoDB, DynamoDB)&lt;/li&gt;
&lt;li&gt;RDBMS (MySQL, PostgreSQL)&lt;/li&gt;
&lt;li&gt;CosmoDB&lt;/li&gt;
&lt;li&gt;In memory database (Redis)&lt;/li&gt;
&lt;li&gt;Spark SQL&lt;/li&gt;
&lt;li&gt;Case Study&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Stream Processing &amp;amp; Analytics 
    &lt;div id=&#34;stream-processing--analytics&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#stream-processing--analytics&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Real Time Streaming Architecture&lt;/li&gt;
&lt;li&gt;Service Configuration and Coordination&lt;/li&gt;
&lt;li&gt;Data Flow Management, Storing and Processing Streaming Data&lt;/li&gt;
&lt;li&gt;Visualization Techniques for Real Time Streaming Data&lt;/li&gt;
&lt;li&gt;Aggregation (Timed Counting, Multi Resolution Time Series Aggregation)&lt;/li&gt;
&lt;li&gt;Statistical Approximation&lt;/li&gt;
&lt;li&gt;Approximating with sketches&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;PySpark 
    &lt;div id=&#34;pyspark&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#pyspark&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Overview &amp;amp; Installation.&lt;/li&gt;
&lt;li&gt;RDD&lt;/li&gt;
&lt;li&gt;Dataframe.&lt;/li&gt;
&lt;li&gt;Architecture.&lt;/li&gt;
&lt;li&gt;MLLib&lt;/li&gt;
&lt;li&gt;NLP&lt;/li&gt;
&lt;li&gt;Linear regression&lt;/li&gt;
&lt;li&gt;Logistic regression&lt;/li&gt;
&lt;li&gt;Decision tree&lt;/li&gt;
&lt;li&gt;Naive Bayes&lt;/li&gt;
&lt;li&gt;XGBoost&lt;/li&gt;
&lt;li&gt;Timeseries&lt;/li&gt;
&lt;li&gt;Spark Job automation with Scheduler&lt;/li&gt;
&lt;li&gt;NYC Parking Case Study: Apache Spark&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>Tableau</title>
      <link>https://dasarpai.com/dscourses/tableau/</link>
      <pubDate>Tue, 28 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/tableau/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc314-Tableau.jpg&#34; alt=&#34;Tableau&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Tableau Course 
    &lt;div id=&#34;tableau-course&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#tableau-course&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;A brief summary of the topics covered in this Tableau course is as below. This is 16 hours course, it is suggested to complete this course in 1 week.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Power BI</title>
      <link>https://dasarpai.com/dscourses/power-bi/</link>
      <pubDate>Mon, 27 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/power-bi/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc313-Power-BI.jpg&#34; alt=&#34;Power BI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Microsoft Power BI Course 
    &lt;div id=&#34;microsoft-power-bi-course&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#microsoft-power-bi-course&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;A brief summary of the topics covered in this Power BI course is as below. This is 16 hours course, it is suggested to complete this course within 1 week.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Reinforcement Learning</title>
      <link>https://dasarpai.com/dscourses/reinforcement-learning/</link>
      <pubDate>Sun, 26 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/reinforcement-learning/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc312-Reinforcement-Learning.jpg&#34; alt=&#34;Reinforcement Learning&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Reinforcement Learning 
    &lt;div id=&#34;reinforcement-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#reinforcement-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Classical Reinforcement Learning 
    &lt;div id=&#34;classical-reinforcement-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#classical-reinforcement-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Markov Decision Process 
    &lt;div id=&#34;markov-decision-process&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#markov-decision-process&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Introduction&lt;/li&gt;
&lt;li&gt;What is Reinforcement Learning?&lt;/li&gt;
&lt;li&gt;Agent-Environment Interaction&lt;/li&gt;
&lt;li&gt;State Vectors&lt;/li&gt;
&lt;li&gt;Objective of RL Agent&lt;/li&gt;
&lt;li&gt;Actions &amp;amp; Policy&lt;/li&gt;
&lt;li&gt;Exploration vs Exploitation&lt;/li&gt;
&lt;li&gt;Markov State&lt;/li&gt;
&lt;li&gt;Markov Decision Process (MDP)&lt;/li&gt;
&lt;li&gt;Value Function&lt;/li&gt;
&lt;li&gt;Optimal Policy&lt;/li&gt;
&lt;li&gt;Model of the Environment&lt;/li&gt;
&lt;li&gt;RL vs Supervised Learning&lt;/li&gt;
&lt;li&gt;Inventory Management (MDP)&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Fundamental Equations in RL 
    &lt;div id=&#34;fundamental-equations-in-rl&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#fundamental-equations-in-rl&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Introduction&lt;/li&gt;
&lt;li&gt;RL Equations – State Value Function&lt;/li&gt;
&lt;li&gt;RL Equations – Action Value Function&lt;/li&gt;
&lt;li&gt;Understanding the RL Equations&lt;/li&gt;
&lt;li&gt;Bellman Equations of Optimality&lt;/li&gt;
&lt;li&gt;Policy Improvement&lt;/li&gt;
&lt;li&gt;Introduction&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Model-Based Method – Dynamic Programming 
    &lt;div id=&#34;model-based-method--dynamic-programming&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#model-based-method--dynamic-programming&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Dynamic Programming&lt;/li&gt;
&lt;li&gt;Policy Iteration – Algorithm&lt;/li&gt;
&lt;li&gt;Policy Evaluation – Prediction&lt;/li&gt;
&lt;li&gt;Policy Improvement – Control&lt;/li&gt;
&lt;li&gt;Policy Iteration – GridWorld&lt;/li&gt;
&lt;li&gt;Value Iteration&lt;/li&gt;
&lt;li&gt;Generalised Policy Iteration (GPI)&lt;/li&gt;
&lt;li&gt;Ad Placement Optimization (Demo)&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Model-Free Methods 
    &lt;div id=&#34;model-free-methods&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#model-free-methods&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Introduction&lt;/li&gt;
&lt;li&gt;Intuition behind Monte-Carlo Methods&lt;/li&gt;
&lt;li&gt;Monte-Carlo Prediction &amp;amp; Demo&lt;/li&gt;
&lt;li&gt;Monte-Carlo Control&lt;/li&gt;
&lt;li&gt;Off Policy&lt;/li&gt;
&lt;li&gt;Temporal Difference&lt;/li&gt;
&lt;li&gt;Q-Learning with Pseudocode&lt;/li&gt;
&lt;li&gt;Cliff Walking Demo&lt;/li&gt;
&lt;li&gt;Ad Placement Optimization Demo -Q Learning&lt;/li&gt;
&lt;li&gt;OpenAI Gym -Taxi v2&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Inventory Management Demo 
    &lt;div id=&#34;inventory-management-demo&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#inventory-management-demo&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Introduction&lt;/li&gt;
&lt;li&gt;Problem Statement&lt;/li&gt;
&lt;li&gt;MDP code&lt;/li&gt;
&lt;li&gt;Q-Learning code&lt;/li&gt;
&lt;li&gt;Results&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Assignment -Classical Reinforcement Learning 
    &lt;div id=&#34;assignment--classical-reinforcement-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#assignment--classical-reinforcement-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Assignment – Tic-Tac-Toe 
    &lt;div id=&#34;assignment--tic-tac-toe&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#assignment--tic-tac-toe&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Deep Reinforcement Learning 
    &lt;div id=&#34;deep-reinforcement-learning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#deep-reinforcement-learning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Introduction 
    &lt;div id=&#34;introduction&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;p&gt;Want to build your own Atari Game? Learn the Q-function or policy using the various Deep Reinforcement Learning algorithms: Deep Q Learning, Policy Gradient Methods, Actor-Critic method.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Explainable AI</title>
      <link>https://dasarpai.com/dscourses/explainable-ai/</link>
      <pubDate>Sat, 25 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/explainable-ai/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc311-Explainable-AI.jpg&#34; alt=&#34;Explainable AI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Explainable AI - XAI 
    &lt;div id=&#34;explainable-ai---xai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#explainable-ai---xai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Please contant me via &lt;a href=&#34;mailto:hari@dasarpai.com&#34;&gt;hari@dasarpai.com&lt;/a&gt; or whatsapp +91 9 5 3 5 9 9 9 3 3 6 
    &lt;div id=&#34;please-contant-me-via--or-whatsapp-91-9-5-3-5-9-9-9-3-3-6&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#please-contant-me-via--or-whatsapp-91-9-5-3-5-9-9-9-3-3-6&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;</description>
      
    </item>
    
    <item>
      <title>Microsoft Excel</title>
      <link>https://dasarpai.com/dscourses/microsoft-excel/</link>
      <pubDate>Fri, 24 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/microsoft-excel/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc310-Microsoft-Excel.jpg&#34; alt=&#34;Microsoft Excel&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Microsoft Excel 
    &lt;div id=&#34;microsoft-excel&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#microsoft-excel&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Introduction to Excel 
    &lt;div id=&#34;introduction-to-excel&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#introduction-to-excel&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Basic 
    &lt;div id=&#34;basic&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#basic&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Microsoft Excel Fundamentals&lt;/li&gt;
&lt;li&gt;Introduction to Interface&lt;/li&gt;
&lt;li&gt;Discovering Shortcuts&lt;/li&gt;
&lt;li&gt;Entering and Editing Text and Formulas&lt;/li&gt;
&lt;li&gt;Excel Data Validation&lt;/li&gt;
&lt;li&gt;Excel List Functions&lt;/li&gt;
&lt;li&gt;Slicing and Dicing Data – Sort and Filter&lt;/li&gt;
&lt;li&gt;Cell Referencing and Text Functions&lt;/li&gt;
&lt;li&gt;Passwords and Naming Files&lt;/li&gt;
&lt;li&gt;Inserting Images and Shapes into an Excel Worksheet&lt;/li&gt;
&lt;li&gt;Modifying an Excel Worksheet&lt;/li&gt;
&lt;li&gt;Protecting Excel Worksheets and Workbooks&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Working with Cells 
    &lt;div id=&#34;working-with-cells&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#working-with-cells&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Cell Referencing and Text Functions&lt;/li&gt;
&lt;li&gt;Common Errors in Excel&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Working with Formulae 
    &lt;div id=&#34;working-with-formulae&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#working-with-formulae&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Introduction to Formulae&lt;/li&gt;
&lt;li&gt;Logical Formulae&lt;/li&gt;
&lt;li&gt;Lookup Functions&lt;/li&gt;
&lt;li&gt;Text Based Functions&lt;/li&gt;
&lt;li&gt;Complex Functions&lt;/li&gt;
&lt;li&gt;Conditional Functions&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Working with Files 
    &lt;div id=&#34;working-with-files&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#working-with-files&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Importing and Exporting Data&lt;/li&gt;
&lt;li&gt;Importing Data from Text Files&lt;/li&gt;
&lt;li&gt;Delimited Files&lt;/li&gt;
&lt;li&gt;Auditing an Excel Worksheet&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Printing &amp;amp; Formatting 
    &lt;div id=&#34;printing--formatting&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#printing--formatting&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Formatting Data in an Excel Worksheet&lt;/li&gt;
&lt;li&gt;Preparing Weekly Report&lt;/li&gt;
&lt;li&gt;Printing an Excel Worksheet&lt;/li&gt;
&lt;li&gt;Printing and Page Layout&lt;/li&gt;
&lt;li&gt;Report Making II: Conditional Formatting&lt;/li&gt;
&lt;li&gt;Report Making III: Advanced Formatting&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Advance Excel 
    &lt;div id=&#34;advance-excel&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#advance-excel&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Charts 
    &lt;div id=&#34;charts&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#charts&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Types of Charts&lt;/li&gt;
&lt;li&gt;Charts&lt;/li&gt;
&lt;li&gt;Creating Basic Charts in Excel&lt;/li&gt;
&lt;li&gt;Creating and Formatting Charts&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Pivot 
    &lt;div id=&#34;pivot&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#pivot&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Creating a Pivot Table&lt;/li&gt;
&lt;li&gt;Analyzing Data in a Pivot Table&lt;/li&gt;
&lt;li&gt;Filtering Data in a Pivot Table&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Automation 
    &lt;div id=&#34;automation&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#automation&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;VBA&lt;/li&gt;
&lt;li&gt;Automating Repetitive Tasks in Excel with Macros&lt;/li&gt;
&lt;li&gt;Preparing and Cleaning Up Data with VBA&lt;/li&gt;
&lt;/ul&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Analysis 
    &lt;div id=&#34;analysis&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#analysis&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Mastering Excel “What If?” Tools&lt;/li&gt;
&lt;li&gt;Working with Large Sets of Excel Data&lt;/li&gt;
&lt;li&gt;VLOOKUP-Linking Data from Multiple Files &amp;amp; Tables&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Visualization and EDA in Excel 
    &lt;div id=&#34;visualization-and-eda-in-excel&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#visualization-and-eda-in-excel&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Limitations of Excel 
    &lt;div id=&#34;limitations-of-excel&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#limitations-of-excel&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;</description>
      
    </item>
    
    <item>
      <title>Data Engineering</title>
      <link>https://dasarpai.com/dscourses/Data-Engineering/</link>
      <pubDate>Thu, 23 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/Data-Engineering/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc309-Data-Engineering.jpg&#34; alt=&#34;Data Engineering&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Data Engineering 
    &lt;div id=&#34;data-engineering&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#data-engineering&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Exploratory Data Analysis (EDA) 
    &lt;div id=&#34;exploratory-data-analysis-eda&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#exploratory-data-analysis-eda&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Data sourcing – public and private data&lt;/li&gt;
&lt;li&gt;Data cleaning – handling missing values, handling invalid data, filtering data, standardization, etc.&lt;/li&gt;
&lt;li&gt;Univariate analysis – unordered vs ordered categorical variables, quantitative variables &amp;amp; measures of central tendency&lt;/li&gt;
&lt;li&gt;Segmented univariate analysis – basis of segmentation, comparison of averages and other metrics&lt;/li&gt;
&lt;li&gt;Bivariate analysis – bivariate on quantitative and categorical variables, correlation&lt;/li&gt;
&lt;li&gt;Derived metrics – introduction, type-driven metrics, business-driven metrics, data-driven metrics&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Examples&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Feature engineering and selection.&lt;/li&gt;
&lt;li&gt;Analyzing bike sharing trends.&lt;/li&gt;
&lt;li&gt;Analyzing movie reviews sentiment.&lt;/li&gt;
&lt;li&gt;Customer segmentation and effective cross-selling.&lt;/li&gt;
&lt;li&gt;Analyzing wine types and quality.&lt;/li&gt;
&lt;li&gt;Analyzing music trends and recommendations.&lt;/li&gt;
&lt;li&gt;Forecasting stock and commodity prices&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Data Mining 
    &lt;div id=&#34;data-mining&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#data-mining&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Introduction: Definitions, Activities, Process, Key challenges&lt;/li&gt;
&lt;li&gt;Understanding Data:  Data Types/ Attribute Types,  Statistical Descriptions of Data&lt;/li&gt;
&lt;li&gt;Measuring Data Similarity and Dissimilarity&lt;/li&gt;
&lt;li&gt;Data Pre-processing – Overview&lt;/li&gt;
&lt;li&gt;Association Rule Mining&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Data Modelling 
    &lt;div id=&#34;data-modelling&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#data-modelling&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Data Cleaning 
    &lt;div id=&#34;data-cleaning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#data-cleaning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Data Visualization &amp;amp; Interpretation 
    &lt;div id=&#34;data-visualization--interpretation&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#data-visualization--interpretation&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Information overload and issues in decision making&lt;/li&gt;
&lt;li&gt;Design of visual encoding schemes to improve comprehension of data and their use in decision making&lt;/li&gt;
&lt;li&gt;Presentation and visualization of data for effective communication&lt;/li&gt;
&lt;li&gt;Elementary graphics programming, charts, graphs, animations, user interactivity, hierarchical layouts, and techniques for visualization of high dimensional data &amp;amp; discovered patterns&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;EDA Tools 
    &lt;div id=&#34;eda-tools&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#eda-tools&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Pandas Profiling&lt;/li&gt;
&lt;li&gt;Lux&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>Python For Data Science</title>
      <link>https://dasarpai.com/dscourses/python-for-data-science/</link>
      <pubDate>Wed, 22 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/python-for-data-science/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc308-Python-For-Data-Science.jpg&#34; alt=&#34;Python For Data Science&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Python for Data Science 
    &lt;div id=&#34;python-for-data-science&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#python-for-data-science&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;A brief summary of the topics covered in this course is as below. This is 30 hours course, it is suggested to complete this course in 3 weeks. After the completion of this course, you will have a solid foundation in Python programming. Following that, you need to practice it consistently for a minimum of 6 months.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Pandas for Data Science</title>
      <link>https://dasarpai.com/dscourses/pandas-for-data-science/</link>
      <pubDate>Tue, 21 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/pandas-for-data-science/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc307-Pandas-for-Data-Science.jpg&#34; alt=&#34;Pandas for Data Science&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Pandas for Data Science 
    &lt;div id=&#34;pandas-for-data-science&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#pandas-for-data-science&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;A brief summary of the topics covered in this course is as below. This is 30 hours course, it is suggested to complete this course in 3 weeks. If you already know python enough, then you can skip the first 3 modules of this course. It will save you one week.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Statistics For Data Science</title>
      <link>https://dasarpai.com/dscourses/Statistics-For-Data-Science/</link>
      <pubDate>Mon, 20 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/Statistics-For-Data-Science/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc306-Statistics-For-Data-Science.jpg&#34; alt=&#34;Statistics For Data Science&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Statistics for Data Science 
    &lt;div id=&#34;statistics-for-data-science&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#statistics-for-data-science&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;A brief summary of the topics covered in this course is as below. This is 25 hours course, it is suggested to complete this course in 3 weeks.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Mathematics for Data Scientist</title>
      <link>https://dasarpai.com/dscourses/Mathematics-for-Data-Scientist/</link>
      <pubDate>Sun, 19 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/Mathematics-for-Data-Scientist/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc305-Mathematics-for-Data-Scientist.jpg&#34; alt=&#34;Mathematics for Data Scientist&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Mathematical for Data Scientist 
    &lt;div id=&#34;mathematical-for-data-scientist&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#mathematical-for-data-scientist&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;To excel in the field of data science, especially as a data scientist, I would recommend you have good command over the topics mentioned below. There are many YouTube channels that you can use for this purpose. Because this is 10+2 level mathematics, and it is just a matter of revision. So I am not offering any course unless there is a specific need for some group, organization.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Deep Learning for Computer Vision</title>
      <link>https://dasarpai.com/dscourses/Deep-Learning-for-Computer-Vision/</link>
      <pubDate>Sat, 18 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/Deep-Learning-for-Computer-Vision/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc304-Deep-Learning-for-Computer-Vision.jpg&#34; alt=&#34;Deep Learning for Computer Vision&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Deep Learning – Computer Vision 
    &lt;div id=&#34;deep-learning--computer-vision&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#deep-learning--computer-vision&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Foundation of Computer Vision 
    &lt;div id=&#34;foundation-of-computer-vision&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#foundation-of-computer-vision&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Common Architectural Principles of Deep Networks&lt;/li&gt;
&lt;li&gt;Building Blocks of Deep Networks&lt;/li&gt;
&lt;li&gt;Convolutional Neural Networks (CNNs)&lt;/li&gt;
&lt;li&gt;Recurrent Neural Networks&lt;/li&gt;
&lt;li&gt;Recursive Neural Networks; Applications to Sequence Data&lt;/li&gt;
&lt;li&gt;Anomaly Detection&lt;/li&gt;
&lt;li&gt;Tuning Deep Networks&lt;/li&gt;
&lt;li&gt;Vectorization&lt;/li&gt;
&lt;li&gt;Data Mining (Pre-requisites)&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;CNN overview 
    &lt;div id=&#34;cnn-overview&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#cnn-overview&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;CNN Definition&lt;/li&gt;
&lt;li&gt;CNN based Architectures&lt;/li&gt;
&lt;li&gt;End to end CNN network&lt;/li&gt;
&lt;li&gt;Training CNN&lt;/li&gt;
&lt;li&gt;Deployment in Azure Cloud&lt;/li&gt;
&lt;li&gt;Performance tuning of CNN network&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Advance Computer Vision – Part 1 
    &lt;div id=&#34;advance-computer-vision--part-1&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#advance-computer-vision--part-1&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;CNN Architectures with research paper and mathematics&lt;/li&gt;
&lt;li&gt;Resnet-5 variants with research paper and practical&lt;/li&gt;
&lt;li&gt;AlexNet variants with research paper and practical&lt;/li&gt;
&lt;li&gt;GoogleNet variants with research paper and practical&lt;/li&gt;
&lt;li&gt;Transfer learning&lt;/li&gt;
&lt;li&gt;VGGNet variants with research paper and practical&lt;/li&gt;
&lt;li&gt;Inception net variants with research paper and practical&lt;/li&gt;
&lt;li&gt;Darknet variants with research paper and practical&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Advance Computer Vision – Part 2 
    &lt;div id=&#34;advance-computer-vision--part-2&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#advance-computer-vision--part-2&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Object detection in-depth&lt;/li&gt;
&lt;li&gt;Transfer learning&lt;/li&gt;
&lt;li&gt;RCNN with research paper and practical&lt;/li&gt;
&lt;li&gt;Fast RCNN with research paper and practical&lt;/li&gt;
&lt;li&gt;Faster RCNN with research paper and practical&lt;/li&gt;
&lt;li&gt;SSD with research paper and practical&lt;/li&gt;
&lt;li&gt;SSD lite with research paper and practical&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Training of Custom Object Detection 
    &lt;div id=&#34;training-of-custom-object-detection&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#training-of-custom-object-detection&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;TFOD introduction&lt;/li&gt;
&lt;li&gt;Environment setup wtih TFOD&lt;/li&gt;
&lt;li&gt;GPU vs TPU vs CPU&lt;/li&gt;
&lt;li&gt;GPU Comparison&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Advance Computer Vision – Part 3 
    &lt;div id=&#34;advance-computer-vision--part-3&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#advance-computer-vision--part-3&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Yolo v1 with research paper and practical&lt;/li&gt;
&lt;li&gt;Retina net&lt;/li&gt;
&lt;li&gt;Face net&lt;/li&gt;
&lt;li&gt;Detectron2 with practical and live testing&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Object segmentation 
    &lt;div id=&#34;object-segmentation&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#object-segmentation&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Semantic segmentation&lt;/li&gt;
&lt;li&gt;Panoptic segmentation&lt;/li&gt;
&lt;li&gt;Masked RCNN&lt;/li&gt;
&lt;li&gt;Practical with Detectron&lt;/li&gt;
&lt;li&gt;Practical with TFOD&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Object tracking 
    &lt;div id=&#34;object-tracking&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#object-tracking&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Detail of object tracking&lt;/li&gt;
&lt;li&gt;Kalman filtering&lt;/li&gt;
&lt;li&gt;Sort&lt;/li&gt;
&lt;li&gt;Deep sort&lt;/li&gt;
&lt;li&gt;Object tracking live project with live camera testing&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;OCR 
    &lt;div id=&#34;ocr&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ocr&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Introduction to OCR&lt;/li&gt;
&lt;li&gt;Various framework and API for OCR&lt;/li&gt;
&lt;li&gt;Practical implementation of OCR&lt;/li&gt;
&lt;li&gt;Live project deployment for bill parsing&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Image captioning 
    &lt;div id=&#34;image-captioning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#image-captioning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Image captioning overview&lt;/li&gt;
&lt;li&gt;Image captioning project with deployment&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>Natural Language Processing</title>
      <link>https://dasarpai.com/dscourses/Natural-Language-Processing/</link>
      <pubDate>Fri, 17 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/Natural-Language-Processing/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc303-Natural-Language-Processing.jpg&#34; alt=&#34;Natural Language Processing&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Natural Language Processing (NLP) 
    &lt;div id=&#34;natural-language-processing-nlp&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#natural-language-processing-nlp&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Foundation of Natural Language Processing 
    &lt;div id=&#34;foundation-of-natural-language-processing&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#foundation-of-natural-language-processing&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Overview computational linguistic.&lt;/li&gt;
&lt;li&gt;History of NLP&lt;/li&gt;
&lt;li&gt;Why NLP&lt;/li&gt;
&lt;li&gt;Use of NLP&lt;/li&gt;
&lt;li&gt;Language modelling with N-gram&lt;/li&gt;
&lt;li&gt;Spelling correction&lt;/li&gt;
&lt;li&gt;Neural networks and neural language models&lt;/li&gt;
&lt;li&gt;Parts-of-Speech tagging&lt;/li&gt;
&lt;li&gt;Syntactic parsing&lt;/li&gt;
&lt;li&gt;Language semantics&lt;/li&gt;
&lt;li&gt;Computational semantics&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Text Analytics, Processing, and Predictive Modelling 
    &lt;div id=&#34;text-analytics-processing-and-predictive-modelling&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#text-analytics-processing-and-predictive-modelling&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Introduction to text analytics (text encoding, regular expressions*, word frequencies &amp;amp; stop words, tokenization, bag-of-words representation, stemming &amp;amp; lemmatization, TF-IDF)&lt;/li&gt;
&lt;li&gt;The Naive Bayes algorithm (Bayes’ theorem and its building blocks, Naive Bayes for text classification)&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Text Processing Importing text. 
    &lt;div id=&#34;text-processing-importing-text&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#text-processing-importing-text&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Web scrapping.&lt;/li&gt;
&lt;li&gt;Text processing&lt;/li&gt;
&lt;li&gt;Understanding regex.&lt;/li&gt;
&lt;li&gt;Text normalization&lt;/li&gt;
&lt;li&gt;Word count.&lt;/li&gt;
&lt;li&gt;Frequency distribution.&lt;/li&gt;
&lt;li&gt;Text annotation.&lt;/li&gt;
&lt;li&gt;Use of annotator.&lt;/li&gt;
&lt;li&gt;String tokenization&lt;/li&gt;
&lt;li&gt;Annotator creation.&lt;/li&gt;
&lt;li&gt;Sentence processing.&lt;/li&gt;
&lt;li&gt;Lemmatization in text processing&lt;/li&gt;
&lt;li&gt;POS.&lt;/li&gt;
&lt;li&gt;Named entity recognition&lt;/li&gt;
&lt;li&gt;Dependency parsing in text.&lt;/li&gt;
&lt;li&gt;Sentimental analysis&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Word embedding 
    &lt;div id=&#34;word-embedding&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#word-embedding&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Word embedding&lt;/li&gt;
&lt;li&gt;Co-occurrence vectors&lt;/li&gt;
&lt;li&gt;Word2vec&lt;/li&gt;
&lt;li&gt;Doc2vec&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;RNN for NLP 
    &lt;div id=&#34;rnn-for-nlp&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#rnn-for-nlp&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Recurrent neural networks.&lt;/li&gt;
&lt;li&gt;Long short term memory (LSTM)&lt;/li&gt;
&lt;li&gt;Bi LSTM.&lt;/li&gt;
&lt;li&gt;Stacked LSTM&lt;/li&gt;
&lt;li&gt;GRU implementation.&lt;/li&gt;
&lt;li&gt;Building a story writer using character level RNN.&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Attention based model 
    &lt;div id=&#34;attention-based-model&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#attention-based-model&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Seq2Seq.&lt;/li&gt;
&lt;li&gt;Encoders and decoders.&lt;/li&gt;
&lt;li&gt;Attention mechanism.&lt;/li&gt;
&lt;li&gt;Attention neural networks&lt;/li&gt;
&lt;li&gt;Self-attention&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Transfer learning in NLP 
    &lt;div id=&#34;transfer-learning-in-nlp&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#transfer-learning-in-nlp&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Introduction to transformers.&lt;/li&gt;
&lt;li&gt;Bert model.&lt;/li&gt;
&lt;li&gt;Elmo model.&lt;/li&gt;
&lt;li&gt;GPT2 model&lt;/li&gt;
&lt;li&gt;GPT3 model.&lt;/li&gt;
&lt;li&gt;Albert model.&lt;/li&gt;
&lt;li&gt;Distilbert model&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Transformers for NLP 
    &lt;div id=&#34;transformers-for-nlp&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#transformers-for-nlp&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;GPT3&lt;/li&gt;
&lt;li&gt;BERT&lt;/li&gt;
&lt;/ul&gt;


&lt;h2 class=&#34;relative group&#34;&gt;NLP Libraries 
    &lt;div id=&#34;nlp-libraries&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#nlp-libraries&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;


&lt;h3 class=&#34;relative group&#34;&gt;Spacy 
    &lt;div id=&#34;spacy&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#spacy&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Spacy overview&lt;/li&gt;
&lt;li&gt;Spacy function&lt;/li&gt;
&lt;li&gt;Spacy function implementation in text processing.&lt;/li&gt;
&lt;li&gt;Pos tagging, challenges and accuracy.&lt;/li&gt;
&lt;li&gt;Entities and named entry recognition&lt;/li&gt;
&lt;li&gt;Interpolation, language models&lt;/li&gt;
&lt;li&gt;NLTK&lt;/li&gt;
&lt;li&gt;Text blob&lt;/li&gt;
&lt;li&gt;Stanford NLP&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>Machine Learning for Timeseries</title>
      <link>https://dasarpai.com/dscourses/Machine-Learning-for-Timeseries/</link>
      <pubDate>Thu, 16 Sep 2021 15:46:43 -0400</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/Machine-Learning-for-Timeseries/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc302-Machine-Learning-for-Timeseries.jpg&#34; alt=&#34;Machine Learning for Timeseries&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Machine Learning for Timeseries 
    &lt;div id=&#34;machine-learning-for-timeseries&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#machine-learning-for-timeseries&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;A brief summary of the topics covered in this course is as below. This is 24 hours course, it is suggested to complete this course in 3 weeks. Apart from my classroom course, you will be given exercises, and it will take another 100 hours in the course duration to complete these exercises.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>What Are Transformers in AI</title>
      <link>https://dasarpai.com/dsblog/What-Are-Transformers-in-AI/</link>
      <pubDate>Tue, 03 Aug 2021 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/What-Are-Transformers-in-AI/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6031-What-are-Transformers-in-AI.jpg&#34; alt=&#34;What-are-Transformers-in-AI&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;What Are Transformers in AI 
    &lt;div id=&#34;what-are-transformers-in-ai&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-are-transformers-in-ai&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Transformer Architecture 
    &lt;div id=&#34;transformer-architecture&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#transformer-architecture&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/transformer/transformer-arch.jpg&#34; alt=&#34;Transformer&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Machine Learning Course</title>
      <link>https://dasarpai.com/dscourses/machine-learning/</link>
      <pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dscourses/machine-learning/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dscourses/dsc301-Machine-Learning.jpg&#34; alt=&#34;Machine Learning Course&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Machine Learning Courses 
    &lt;div id=&#34;machine-learning-courses&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#machine-learning-courses&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;p&gt;A brief summary of the topics covered in this course is as below. This is 150 hours course, it is suggested to complete this course in 2 Months. Apart from my classroom course, you will be given exercises, and it will take another 100 hours in the course duration to complete these exercises.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>How Naive Bayes Classifier Works</title>
      <link>https://dasarpai.com/dsblog/How-Naive-Bayes-Classifier-Works/</link>
      <pubDate>Wed, 31 Mar 2021 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/How-Naive-Bayes-Classifier-Works/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6005-How-Naive-Bayes-Work-for-Recommendation.jpg&#34; alt=&#34;Naive Bayes&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;How Naive Bayes Classifier Works? 
    &lt;div id=&#34;how-naive-bayes-classifier-works&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#how-naive-bayes-classifier-works&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Naive Bayes classifier example 
    &lt;div id=&#34;naive-bayes-classifier-example&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#naive-bayes-classifier-example&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;In this presentation, I am not going into the depth of the Naive Bayes algorithm. I am assuming you have heard this term many times but are not able to visualize it mentally or struggling to comprehend this. If that is the case, then you are on the right page.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>EDA &amp; Feature Engineering 101</title>
      <link>https://dasarpai.com/dsblog/EDA-Feature-Engineering-101/</link>
      <pubDate>Mon, 24 Aug 2020 15:50:00 +0530</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/EDA-Feature-Engineering-101/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dspost/dsp6008-EDA101.jpg&#34; alt=&#34;EDA &amp;amp; Feature Engineering&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h2 class=&#34;relative group&#34;&gt;What is EDA? 
    &lt;div id=&#34;what-is-eda&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#what-is-eda&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;EDA means Exploratory Data Analysis. The purpose of data analysis is to explore. Exploration means try to understand what kind of data I have in my hand. Using EDA we try to get the answer to the following questions.&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>DS, AI, ML Online Course, Tutorial, Videos</title>
      <link>https://dasarpai.com/dsblog/data-science-tutorial-video-resources/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/data-science-tutorial-video-resources/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dsresources/dsr119-DS-AI-ML-Online-Course-Tutorial-Videos.jpg&#34; alt=&#34;DS, AI, ML Online Course, Tutorial, Videos&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;DS, AI, ML Online Course, Tutorial, Videos 
    &lt;div id=&#34;ds-ai-ml-online-course-tutorial-videos&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#ds-ai-ml-online-course-tutorial-videos&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Courses 
    &lt;div id=&#34;courses&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#courses&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://class.coursera.org/ml-005&#34; target=&#34;_blank&#34;&gt;Machine Learning – Stanford&lt;/a&gt; by Andrew Ng in Coursera (2010-2014)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://work.caltech.edu/lectures.html&#34; target=&#34;_blank&#34;&gt;Machine Learning – Caltech&lt;/a&gt; by Yaser Abu-Mostafa (2012-2014)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml&#34; target=&#34;_blank&#34;&gt;Machine Learning – Carnegie Mellon&lt;/a&gt; by Tom Mitchell (Spring 2011)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://class.coursera.org/neuralnets-2012-001&#34; target=&#34;_blank&#34;&gt;Neural Networks for Machine Learning&lt;/a&gt; by Geoffrey Hinton in Coursera (2012)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&#34; target=&#34;_blank&#34;&gt;Neural networks class&lt;/a&gt; by Hugo Larochelle from Université de Sherbrooke (2013)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cilvr.cs.nyu.edu/doku.php?id=deeplearning:slides:start&#34; target=&#34;_blank&#34;&gt;Deep Learning Course&lt;/a&gt; by CILVR lab @ NYU (2014)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://courses.edx.org/courses/BerkeleyX/CS188x_1/1T2013/courseware/&#34; target=&#34;_blank&#34;&gt;A.I – Berkeley&lt;/a&gt; by Dan Klein and Pieter Abbeel (2013)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/&#34; target=&#34;_blank&#34;&gt;A.I – MIT&lt;/a&gt; by Patrick Henry Winston (2010)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://web.mit.edu/course/other/i2course/www/vision_and_learning_fall_2013.html&#34; target=&#34;_blank&#34;&gt;Vision and learning – computers and brains&lt;/a&gt; by Shimon Ullman, Tomaso Poggio, Ethan Meyers @ MIT (2013)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vision.stanford.edu/teaching/cs231n/syllabus.html&#34; target=&#34;_blank&#34;&gt;Convolutional Neural Networks for Visual Recognition – Stanford&lt;/a&gt; by Fei-Fei Li, Andrej Karpathy (2017)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cs224d.stanford.edu/&#34; target=&#34;_blank&#34;&gt;Deep Learning for Natural Language Processing – Stanford&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://info.usherbrooke.ca/hlarochelle/neural_networks/content.html&#34; target=&#34;_blank&#34;&gt;Neural Networks – usherbrooke&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/&#34; target=&#34;_blank&#34;&gt;Machine Learning – Oxford&lt;/a&gt; (2014-2015)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/deep-learning-courses&#34; target=&#34;_blank&#34;&gt;Deep Learning – Nvidia&lt;/a&gt; (2015)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLHyI3Fbmv0SdzMHAy0aN59oYnLy5vyyTA&#34; target=&#34;_blank&#34;&gt;Graduate Summer School: Deep Learning, Feature Learning&lt;/a&gt; by Geoffrey Hinton, Yoshua Bengio, Yann LeCun, Andrew Ng, Nando de Freitas and several others @ IPAM, UCLA (2012)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/deep-learning--ud730&#34; target=&#34;_blank&#34;&gt;Deep Learning – Udacity/Google&lt;/a&gt; by Vincent Vanhoucke and Arpan Chakraborty (2016)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLehuLRPyt1Hyi78UOkMPWCGRxGcA9NVOE&#34; target=&#34;_blank&#34;&gt;Deep Learning – UWaterloo&lt;/a&gt; by Prof. Ali Ghodsi at University of Waterloo (2015)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=azaLcvuql_g&amp;amp;list=PLjbUi5mgii6BWEUZf7He6nowWvGne_Y8r&#34; target=&#34;_blank&#34;&gt;Statistical Machine Learning – CMU&lt;/a&gt; by Prof. Larry Wasserman&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.college-de-france.fr/site/en-yann-lecun/course-2015-2016.htm&#34; target=&#34;_blank&#34;&gt;Deep Learning Course&lt;/a&gt; by Yann LeCun (2016)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLkFD6_40KJIxopmdJF_CLNqG3QuDFHQUm&#34; target=&#34;_blank&#34;&gt;Designing, Visualizing and Understanding Deep Neural Networks-UC Berkeley&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://uvadlc.github.io/&#34; target=&#34;_blank&#34;&gt;UVA Deep Learning Course&lt;/a&gt; MSc in Artificial Intelligence for the University of Amsterdam.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://selfdrivingcars.mit.edu/&#34; target=&#34;_blank&#34;&gt;MIT 6.S094: Deep Learning for Self-Driving Cars&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://introtodeeplearning.com/&#34; target=&#34;_blank&#34;&gt;MIT 6.S191: Introduction to Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rll.berkeley.edu/deeprlcourse/&#34; target=&#34;_blank&#34;&gt;Berkeley CS 294: Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/keras-in-motion&#34; target=&#34;_blank&#34;&gt;Keras in Motion video course&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://course.fast.ai/&#34; target=&#34;_blank&#34;&gt;Practical Deep Learning For Coders&lt;/a&gt; by Jeremy Howard – Fast.ai&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://deeplearning.cs.cmu.edu/&#34; target=&#34;_blank&#34;&gt;Introduction to Deep Learning&lt;/a&gt; by Prof. Bhiksha Raj (2017)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.deeplearning.ai/ai-for-everyone/&#34; target=&#34;_blank&#34;&gt;AI for Everyone&lt;/a&gt; by Andrew Ng (2019)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://introtodeeplearning.com/&#34; target=&#34;_blank&#34;&gt;MIT Intro to Deep Learning 7 day bootcamp&lt;/a&gt; – A seven day bootcamp designed in MIT to introduce deep learning methods and applications (2019)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mithi.github.io/deep-blueberry&#34; target=&#34;_blank&#34;&gt;Deep Blueberry: Deep Learning&lt;/a&gt; – A free five-weekend plan to self-learners to learn the basics of deep-learning architectures like CNNs, LSTMs, RNNs, VAEs, GANs, DQN, A3C and more (2019)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://spinningup.openai.com/&#34; target=&#34;_blank&#34;&gt;Spinning Up in Deep Reinforcement Learning&lt;/a&gt; – A free deep reinforcement learning course by OpenAI (2019)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/specializations/deep-learning&#34; target=&#34;_blank&#34;&gt;Deep Learning Specialization – Coursera&lt;/a&gt; – Breaking into AI with the best course from Andrew NG.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLZSO_6-bSqHQHBCoGaObUljoXAyyqhpFW&#34; target=&#34;_blank&#34;&gt;Deep Learning – UC Berkeley STAT-157&lt;/a&gt; by Alex Smola and Mu Li (2019)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/machine-learning-for-mere-mortals&#34; target=&#34;_blank&#34;&gt;Machine Learning for Mere Mortals video course&lt;/a&gt; by Nick Chase&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developers.google.com/machine-learning/crash-course/&#34; target=&#34;_blank&#34;&gt;Machine Learning Crash Course with TensorFlow APIs&lt;/a&gt; -Google AI&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://course.fast.ai/part2&#34; target=&#34;_blank&#34;&gt;Deep Learning from the Foundations&lt;/a&gt; Jeremy Howard – Fast.ai&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893&#34; target=&#34;_blank&#34;&gt;Deep Reinforcement Learning (nanodegree) – Udacity&lt;/a&gt; a 3-6 month Udacity nanodegree, spanning multiple courses (2018)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/grokking-deep-learning-in-motion&#34; target=&#34;_blank&#34;&gt;Grokking Deep Learning in Motion&lt;/a&gt; by Beau Carnes (2018)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/share/1000gAA0QdcV9aQng=/&#34; target=&#34;_blank&#34;&gt;Face Detection with Computer Vision and Deep Learning&lt;/a&gt; by Hakan Cebeci&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/slides?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-CmOo_hUqOR9Oj8ApcOw0Kg&amp;amp;siteID=SAyYsTvLiGQ-CmOo_hUqOR9Oj8ApcOw0Kg&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ&#34; target=&#34;_blank&#34;&gt;Presentation skills: Designing Presentation Slides - Coursera&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/multivariate-calculus-machine-learning?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-heqdps0Uveezr1XmtoOPDQ&amp;amp;siteID=SAyYsTvLiGQ-heqdps0Uveezr1XmtoOPDQ&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ&#34; target=&#34;_blank&#34;&gt;Mathematics for Machine Learning: Multivariate Calculus - Coursera&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/machine-learning/home/welcome&#34; target=&#34;_blank&#34;&gt;Machine Learning – Home Coursera&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/multivariate-calculus-machine-learning?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-P3iVNag0daUW2nModtd2GA&amp;amp;siteID=SAyYsTvLiGQ-P3iVNag0daUW2nModtd2GA&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ&#34; target=&#34;_blank&#34;&gt;Mathematics for Machine Learning: Multivariate Calculus - Coursera&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/browse/data-science&#34; target=&#34;_blank&#34;&gt;Data Science Certificates - Coursera&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://learning.edureka.co/mycourses&#34; target=&#34;_blank&#34;&gt;Edureka&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bdlabs.edureka.co:50001/cmf/services/18/status&#34; target=&#34;_blank&#34;&gt;Edureka-Cloudera Manager&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/&#34; target=&#34;_blank&#34;&gt;Udemy Courses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://onlinereikicourse.com/&#34; target=&#34;_blank&#34;&gt;Courses – Online Reiki Course&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.datacamp.com/courses&#34; target=&#34;_blank&#34;&gt;DataCamp Courses&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://learn.byjus.com/video/chapter-videos/44724&#34; target=&#34;_blank&#34;&gt;Byju&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229&#34; target=&#34;_blank&#34;&gt;udacity&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://intellipaat.com/blog/what-is-apache-spark/&#34; target=&#34;_blank&#34;&gt;What is Spark – A Comparison Between Spark vs. Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://studio.azureml.net/Home/ViewWorkspaceCached/086ca408664942138b618398589b02ff#Workspace/Settings/Name&#34; target=&#34;_blank&#34;&gt;Microsoft Azure Machine Learning Studio (classic)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.apache.org/&#34; target=&#34;_blank&#34;&gt;Welcome to The Apache Software Foundation!&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://makingindiaemployable.com/&#34; target=&#34;_blank&#34;&gt;Making India Employable - Vivid Vision 10  10  10&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ideone.com/&#34; target=&#34;_blank&#34;&gt;GpI8H5 – Online Python3 Interpreter &amp;amp; Debugging Tool – Ideone.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLOU2XLYxmsILVTiOlMJdo7RQS55jYhsMi&#34; target=&#34;_blank&#34;&gt;Google I/O 2019 – All Sessions – YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLQY2H8rRoyvy2_vtWvCpQWM9GJXNTa5rV&#34; target=&#34;_blank&#34;&gt;TensorFlow at Google I/O 2019 – YouTube&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://bsc.hcverma.in/course/quantum&#34; target=&#34;_blank&#34;&gt;Quantum Mechanics - BSc Lectures by Prof. H C Verma and Team&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openpathshala.com/&#34; target=&#34;_blank&#34;&gt;Open Pathshala - Your Best Source to Learn Sanskrit&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.classcentral.com/&#34; target=&#34;_blank&#34;&gt;Class Central #1 Search Engine for Free Online Courses &amp;amp; MOOCs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.class-central.com/course/coursera-mathematics-for-machine-learning-multivariate-calculus-10452&#34; target=&#34;_blank&#34;&gt;Free Online Course: Mathematics for Machine Learning: Multivariate Calculus from Coursera - Class Central&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://byjus.com/&#34; target=&#34;_blank&#34;&gt;e Learning for Basic Science and Maths&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.skillshare.com/&#34; target=&#34;_blank&#34;&gt;Online Classes by Skillshare - Start for Free Today&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://learndigital.withgoogle.com/digitalgarage&#34; target=&#34;_blank&#34;&gt;Learn online marketing with free courses – Google Digital Garage&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://moz.com/blog&#34; target=&#34;_blank&#34;&gt;Moz Blog – SEO and Inbound Marketing Blog – Moz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://onlinecourses.nptel.ac.in/m#/lesson/noc19_hs53/8/15&#34; target=&#34;_blank&#34;&gt;NPTEL Online Courses Mobile&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/learn/overview&#34; target=&#34;_blank&#34;&gt;Learn Python, Data Viz, Pandas &amp;amp; More - Tutorials - Kaggle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.superdatascience.com/training/&#34; target=&#34;_blank&#34;&gt;Data Science Training&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Tutorials 
    &lt;div id=&#34;tutorials&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#tutorials&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial&#34; target=&#34;_blank&#34;&gt;UFLDL Tutorial 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ufldl.stanford.edu/tutorial/supervised/LinearRegression/&#34; target=&#34;_blank&#34;&gt;UFLDL Tutorial 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.socher.org/index.php/DeepLearningTutorial/DeepLearningTutorial&#34; target=&#34;_blank&#34;&gt;Deep Learning for NLP (without Magic)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks&#34; target=&#34;_blank&#34;&gt;A Deep Learning Tutorial: From Perceptrons to Deep Networks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.metacademy.org/roadmaps/rgrosse/deep_learning&#34; target=&#34;_blank&#34;&gt;Deep Learning from the Bottom up&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://deeplearning.net/tutorial/deeplearning.pdf&#34; target=&#34;_blank&#34;&gt;Theano Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://uk.mathworks.com/help/pdf_doc/nnet/nnet_ug.pdf&#34; target=&#34;_blank&#34;&gt;Neural Networks for Matlab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/&#34; target=&#34;_blank&#34;&gt;Using convolutional neural nets to detect facial keypoints tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/clementfarabet/ipam-tutorials/tree/master/th_tutorials&#34; target=&#34;_blank&#34;&gt;Torch7 Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/josephmisiti/machine-learning-module&#34; target=&#34;_blank&#34;&gt;The Best Machine Learning Tutorials On The Web&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.robots.ox.ac.uk/~vgg/practicals/cnn/index.html&#34; target=&#34;_blank&#34;&gt;VGG Convolutional Neural Networks Practical&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/nlintz/TensorFlow-Tutorials&#34; target=&#34;_blank&#34;&gt;TensorFlow tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pkmital/tensorflow_tutorials&#34; target=&#34;_blank&#34;&gt;More TensorFlow tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/aymericdamien/TensorFlow-Examples&#34; target=&#34;_blank&#34;&gt;TensorFlow Python Notebooks&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Vict0rSch/deep_learning&#34; target=&#34;_blank&#34;&gt;Keras and Lasagne Deep Learning Tutorials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition&#34; target=&#34;_blank&#34;&gt;Classification on raw time series in TensorFlow with a LSTM RNN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/&#34; target=&#34;_blank&#34;&gt;Using convolutional neural nets to detect facial keypoints tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/astorfi/TensorFlow-World&#34; target=&#34;_blank&#34;&gt;TensorFlow-World&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/deep-learning-with-python&#34; target=&#34;_blank&#34;&gt;Deep Learning with Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/grokking-deep-learning&#34; target=&#34;_blank&#34;&gt;Grokking Deep Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/deep-learning-for-search&#34; target=&#34;_blank&#34;&gt;Deep Learning for Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.sicara.com/keras-tutorial-content-based-image-retrieval-convolutional-denoising-autoencoder-dc91450cc511&#34; target=&#34;_blank&#34;&gt;Keras Tutorial: Content Based Image Retrieval Using a Convolutional Denoising Autoencoder&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/yunjey/pytorch-tutorial&#34; target=&#34;_blank&#34;&gt;Pytorch Tutorial by Yunjey Choi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html&#34; target=&#34;_blank&#34;&gt;Understanding deep Convolutional Neural Networks with a practical use-case in Tensorflow and Keras&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ahmedbesbes.com/overview-and-benchmark-of-traditional-and-deep-learning-models-in-text-classification.html&#34; target=&#34;_blank&#34;&gt;Overview and benchmark of traditional and deep learning models in text classification&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/MelAbgrall/HardwareforAI&#34; target=&#34;_blank&#34;&gt;Hardware for AI: Understanding computer hardware &amp;amp; build your own computer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hackr.io/tutorials/learn-artificial-intelligence-ai&#34; target=&#34;_blank&#34;&gt;Programming Community Curated Resources&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://amitness.com/2020/02/illustrated-self-supervised-learning/&#34; target=&#34;_blank&#34;&gt;The Illustrated Self-Supervised Learning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://amitness.com/2020/02/albert-visual-summary/&#34; target=&#34;_blank&#34;&gt;Visual Paper Summary: ALBERT (A Lite BERT)&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Videos and Lectures 
    &lt;div id=&#34;videos-and-lectures&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#videos-and-lectures&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=RIkxVci-R4k&#34; target=&#34;_blank&#34;&gt;How To Create A Mind&lt;/a&gt; By Ray Kurzweil&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=n1ViNeWhC24&#34; target=&#34;_blank&#34;&gt;Deep Learning, Self-Taught Learning and Unsupervised Feature Learning&lt;/a&gt; By Andrew Ng&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=vShMxxqtDDs&amp;amp;index=3&amp;amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT&#34; target=&#34;_blank&#34;&gt;Recent Developments in Deep Learning&lt;/a&gt; By Geoff Hinton&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=sc-KbuZqGkI&#34; target=&#34;_blank&#34;&gt;The Unreasonable Effectiveness of Deep Learning&lt;/a&gt; by Yann LeCun&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4xsVFLnHC_0&#34; target=&#34;_blank&#34;&gt;Deep Learning of Representations&lt;/a&gt; by Yoshua bengio&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=6ufPpZDmPKA&#34; target=&#34;_blank&#34;&gt;Principles of Hierarchical Temporal Memory&lt;/a&gt; by Jeff Hawkins&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2QJi0ArLq7s&amp;amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT&#34; target=&#34;_blank&#34;&gt;Machine Learning Discussion Group – Deep Learning w/ Stanford AI Lab&lt;/a&gt; by Adam Coates&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://vimeo.com/80821560&#34; target=&#34;_blank&#34;&gt;Making Sense of the World with Deep Learning&lt;/a&gt; By Adam Coates&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=wZfVBwOO0-k&#34; target=&#34;_blank&#34;&gt;Demystifying Unsupervised Feature Learning&lt;/a&gt; By Adam Coates&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=3boKlkPBckA&#34; target=&#34;_blank&#34;&gt;Visual Perception with Deep Learning&lt;/a&gt; By Yann LeCun&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=AyzOUbkUf3M&#34; target=&#34;_blank&#34;&gt;The Next Generation of Neural Networks&lt;/a&gt; By Geoffrey Hinton at GoogleTechTalks&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn&#34; target=&#34;_blank&#34;&gt;The wonderful and terrifying implications of computers that can learn&lt;/a&gt; By Jeremy Howard at TEDxBrussels&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://web.stanford.edu/class/cs294a/handouts.html&#34; target=&#34;_blank&#34;&gt;Unsupervised Deep Learning – Stanford&lt;/a&gt; by Andrew Ng in Stanford (2011)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://web.stanford.edu/class/cs224n/handouts/&#34; target=&#34;_blank&#34;&gt;Natural Language Processing&lt;/a&gt; By Chris Manning in Stanford&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://googleresearch.blogspot.com/2015/09/a-beginners-guide-to-deep-neural.html&#34; target=&#34;_blank&#34;&gt;A beginners Guide to Deep Neural Networks&lt;/a&gt; By Natalie Hammel and Lorraine Yurshansky&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=czLI3oLDe8M&#34; target=&#34;_blank&#34;&gt;Deep Learning: Intelligence from Big Data&lt;/a&gt; by Steve Jurvetson (and panel) at VLAB in Stanford.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=FoO8qDB8gUU&#34; target=&#34;_blank&#34;&gt;Introduction to Artificial Neural Networks and Deep Learning&lt;/a&gt; by Leo Isikdogan at Motorola Mobility HQ&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule&#34; target=&#34;_blank&#34;&gt;NIPS 2016 lecture and workshop videos&lt;/a&gt; – NIPS 2016&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=oS5fz_mHVz0&amp;amp;list=PLWKotBjTDoLj3rXBL-nEIPRN9V3a9Cx07&#34; target=&#34;_blank&#34;&gt;Deep Learning Crash Course&lt;/a&gt;: a series of mini-lectures by Leo Isikdogan on YouTube (2018)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/deep-learning-crash-course&#34; target=&#34;_blank&#34;&gt;Deep Learning Crash Course&lt;/a&gt; By Oliver Zeigermann&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/deep-learning-with-r-in-motion&#34; target=&#34;_blank&#34;&gt;Deep Learning with R in Motion&lt;/a&gt;: a live video course that teaches how to apply deep learning to text and images using the powerful Keras library and its R language interface.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lnkd.in/f5vUg6i&#34; target=&#34;_blank&#34;&gt;8 Essential Tips for People starting a Career in Data Science&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fMEhi4D&#34; target=&#34;_blank&#34;&gt;Cheatsheet: How to become a data scientist&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fruY2AC&#34; target=&#34;_blank&#34;&gt;The Art of Learning Data Science&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fxReDab&#34; target=&#34;_blank&#34;&gt;The Periodic Table of Data Science&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fXSE-us&#34; target=&#34;_blank&#34;&gt;Aspiring Data Scientists! Start to learn Statistics with these 6 books&lt;/a&gt;!&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lnkd.in/f8S3Ygd&#34; target=&#34;_blank&#34;&gt;8 Skills You Need to Be a Data Scientist&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fKugicE&#34; target=&#34;_blank&#34;&gt;Top 10 Essential Books for the Data Enthusiast&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fTGDkju&#34; target=&#34;_blank&#34;&gt;Aspiring data scientist? Master these fundamentals&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://lnkd.in/f_Zhpzf&#34; target=&#34;_blank&#34;&gt;How to Become a Data Scientist – On your own.&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;


&lt;h2 class=&#34;relative group&#34;&gt;GRETL – Great Statistical software for Beginners 
    &lt;div id=&#34;gretl--great-statistical-software-for-beginners&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#gretl--great-statistical-software-for-beginners&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Simple Linear Regression &lt;a href=&#34;https://lnkd.in/ecfsV9c&#34; target=&#34;_blank&#34;&gt;https://lnkd.in/ecfsV9c&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Coding Dummy Variables &lt;a href=&#34;https://lnkd.in/ef7Yd7f&#34; target=&#34;_blank&#34;&gt;https://lnkd.in/ef7Yd7f&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Forecasting New Observations &lt;a href=&#34;https://lnkd.in/eNKbxbU&#34; target=&#34;_blank&#34;&gt;https://lnkd.in/eNKbxbU&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Forecasting a Large Number of Observations &lt;a href=&#34;https://lnkd.in/eHmibGs&#34; target=&#34;_blank&#34;&gt;https://lnkd.in/eHmibGs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Logistic Regression &lt;a href=&#34;https://lnkd.in/eRfhQ87&#34; target=&#34;_blank&#34;&gt;https://lnkd.in/eRfhQ87&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Forecasting and Confusion Matrix &lt;a href=&#34;https://lnkd.in/eaqrFJr&#34; target=&#34;_blank&#34;&gt;https://lnkd.in/eaqrFJr&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Modeling and Forecasting Time Series Data &lt;a href=&#34;https://lnkd.in/e6fqKpF&#34; target=&#34;_blank&#34;&gt;https://lnkd.in/e6fqKpF&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Comparing Time Series Trend Models &lt;a href=&#34;https://lnkd.in/eKjEUAE&#34; target=&#34;_blank&#34;&gt;https://lnkd.in/eKjEUAE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Khan Academy is the best online free resource to learn Math for Data Science. ( &lt;a href=&#34;https://www.khanacademy.org/math/&#34; target=&#34;_blank&#34;&gt;https://www.khanacademy.org/math/&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Krista King has also done a great job in creating an exceptionally good introductory course. She is too good at designing the course. ( &lt;a href=&#34;https://www.udemy.com/user/kristaking/&#34; target=&#34;_blank&#34;&gt;https://www.udemy.com/user/kristaking/&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;3Blue1Brown ( &lt;a href=&#34;https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/playlists&#34; target=&#34;_blank&#34;&gt;https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/playlists&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Every Intro to Data Science Course on the Internet, Ranked. (&lt;a href=&#34;https://lnkd.in/fQDMiNX&#34; target=&#34;_blank&#34;&gt;https://lnkd.in/fQDMiNX&lt;/a&gt; )&lt;/li&gt;
&lt;li&gt;What would be useful for aspiring data scientists to know? (&lt;a href=&#34;https://lnkd.in/fmcFyN7&#34; target=&#34;_blank&#34;&gt;https://lnkd.in/fmcFyN7&lt;/a&gt;)&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>Reinforcement Learning Git Repositories</title>
      <link>https://dasarpai.com/dsblog/rl-git-repo/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://dasarpai.com/dsblog/rl-git-repo/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://dasarpai.com/assets/images/dsresources/dsr101-Reinforcement-Learning-Git-Repositories.jpg&#34; alt=&#34;Reinforcement Learning Git Repositories&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;Reinforcement Learning Git Repositories 
    &lt;div id=&#34;reinforcement-learning-git-repositories&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#reinforcement-learning-git-repositories&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th&gt;Sno.&lt;/th&gt;
          &lt;th&gt;URL&lt;/th&gt;
          &lt;th&gt;Description&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td&gt;1&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/baselines&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/baselines&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;OpenAI Baselines: high-quality implementations of reinforcement learning algorithms&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;2&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/hill-a/stable-baselines&#34; target=&#34;_blank&#34;&gt;https://github.com/hill-a/stable-baselines&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A fork of OpenAI Baselines, implementations of reinforcement learning algorithms&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;3&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/spinningup&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/spinningup&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;An educational resource to help anyone learn deep reinforcement learning.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;4&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/google/dopamine&#34; target=&#34;_blank&#34;&gt;https://github.com/google/dopamine&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Dopamine is a research framework for fast prototyping of reinforcement learning algorithms.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;5&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/agents&#34; target=&#34;_blank&#34;&gt;https://github.com/tensorflow/agents&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;TF-Agents is a library for Reinforcement Learning in TensorFlow&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;6&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/trfl&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/trfl&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;TensorFlow Reinforcement Learning&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;7&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/Horizon&#34; target=&#34;_blank&#34;&gt;https://github.com/facebookresearch/Horizon&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A platform for Applied Reinforcement Learning (Applied RL)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;8&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/ELF&#34; target=&#34;_blank&#34;&gt;https://github.com/facebookresearch/ELF&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;An End-To-End, Lightweight and Flexible Platform for Game Research&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;9&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/NervanaSystems/coach&#34; target=&#34;_blank&#34;&gt;https://github.com/NervanaSystems/coach&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Reinforcement Learning Coach by Intel AI Lab enables easy experimentation with state of the art Reinforcement Learning algorithms&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;10&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/ray-project/ray/tree/master/python/ray/rllib&#34; target=&#34;_blank&#34;&gt;https://github.com/ray-project/ray/tree/master/python/ray/rllib&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A fast and simple framework for building and running distributed applications.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;11&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/keras-rl/keras-rl&#34; target=&#34;_blank&#34;&gt;https://github.com/keras-rl/keras-rl&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Deep Reinforcement Learning for Keras.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;12&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&#34; target=&#34;_blank&#34;&gt;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch implementation of Advantage Actor Critic (A2C), Proximal Policy Optimization (PPO), Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation (ACKTR) and Generative Adversarial Imitation Learning (GAIL).&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;13&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Kaixhin/Rainbow&#34; target=&#34;_blank&#34;&gt;https://github.com/Kaixhin/Rainbow&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Rainbow: Combining Improvements in Deep Reinforcement Learning&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;14&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/MillionIntegrals/vel&#34; target=&#34;_blank&#34;&gt;https://github.com/MillionIntegrals/vel&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Velocity in deep-learning research&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;15&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorforce/tensorforce&#34; target=&#34;_blank&#34;&gt;https://github.com/tensorforce/tensorforce&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorforce: A TensorFlow library for applied reinforcement learning&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;16&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/kengz/SLM-Lab&#34; target=&#34;_blank&#34;&gt;https://github.com/kengz/SLM-Lab&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Modular Deep Reinforcement Learning framework in PyTorch.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;17&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/rlworkgroup/garage&#34; target=&#34;_blank&#34;&gt;https://github.com/rlworkgroup/garage&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A framework for reproducible reinforcement learning research&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;18&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/catalyst-team/catalyst&#34; target=&#34;_blank&#34;&gt;https://github.com/catalyst-team/catalyst&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Reproducible and fast DL &amp;amp; RL.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;19&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/higgsfield/RL-Adventure&#34; target=&#34;_blank&#34;&gt;https://github.com/higgsfield/RL-Adventure&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Pytorch Implementation of DQN / DDQN / Prioritized replay/ noisy networks/ distributional values/ Rainbow/ hierarchical RL&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;20&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/qfettes/DeepRL-Tutorials&#34; target=&#34;_blank&#34;&gt;https://github.com/qfettes/DeepRL-Tutorials&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Contains high quality implementations of Deep Reinforcement Learning algorithms written in PyTorch&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;21&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/gym&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/gym&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A toolkit for developing and comparing reinforcement learning algorithms.&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;22&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/lab&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/lab&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;A customisable 3D platform for agent-based AI research&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;23&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Microsoft/malmo&#34; target=&#34;_blank&#34;&gt;https://github.com/Microsoft/malmo&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Project Malmo is a platform for Artificial Intelligence experimentation and research built on top of Minecraft. We aim to inspire a new generation of research into challenging new problems presented by this unique environment. — For installation instruct&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;24&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/retro&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/retro&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Retro Games in Gym&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;25&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/dm_control&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/dm_control&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;The DeepMind Control Suite and Package&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;26&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/neural-mmo&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/neural-mmo&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Neural MMO – A Massively Multiagent Game Environment&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;27&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/gym&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/gym&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Gym @ OpenAI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;28&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/lab&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/lab&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Lab @ DeepMind&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;29&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Microsoft/malmo&#34; target=&#34;_blank&#34;&gt;https://github.com/Microsoft/malmo&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Project Malmo @ Microsoft&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;30&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/retro&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/retro&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Retro @ OpenAI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;31&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/dm_control&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/dm_control&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Control Suite @ DeepMind&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;32&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/neural-mmo&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/neural-mmo&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Neural MMO @ OpenAI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;33&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/baselines&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/baselines&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by OpenAI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;34&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/hill-a/stable-baselines&#34; target=&#34;_blank&#34;&gt;https://github.com/hill-a/stable-baselines&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Antonin Raffin, Ashley Hill&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;35&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/catalyst-team/catalyst&#34; target=&#34;_blank&#34;&gt;https://github.com/catalyst-team/catalyst&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Sergey Kolesnikov&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;36&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/ray-project/ray/tree/master/python/ray/rllib&#34; target=&#34;_blank&#34;&gt;https://github.com/ray-project/ray/tree/master/python/ray/rllib&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Ray Team&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;37&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/agents&#34; target=&#34;_blank&#34;&gt;https://github.com/tensorflow/agents&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Google&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;38&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/Horizon&#34; target=&#34;_blank&#34;&gt;https://github.com/facebookresearch/Horizon&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Facebook&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;39&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/NervanaSystems/coach&#34; target=&#34;_blank&#34;&gt;https://github.com/NervanaSystems/coach&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Intel&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;40&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/rlworkgroup/garage&#34; target=&#34;_blank&#34;&gt;https://github.com/rlworkgroup/garage&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by community&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;41&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/kengz/SLM-Lab&#34; target=&#34;_blank&#34;&gt;https://github.com/kengz/SLM-Lab&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Wah Loon Keng, Laura Graesser&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;42&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/google/dopamine&#34; target=&#34;_blank&#34;&gt;https://github.com/google/dopamine&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Google&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;43&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/spinningup&#34; target=&#34;_blank&#34;&gt;https://github.com/openai/spinningup&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by OpenAI&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;44&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/trfl&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/trfl&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by DeepMind&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;45&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/scalable_agent&#34; target=&#34;_blank&#34;&gt;https://github.com/deepmind/scalable_agent&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by DeepMind&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;46&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/ELF&#34; target=&#34;_blank&#34;&gt;https://github.com/facebookresearch/ELF&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Facebook&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;47&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/keras-rl/keras-rl&#34; target=&#34;_blank&#34;&gt;https://github.com/keras-rl/keras-rl&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow Maintained by Matthias Plappert&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;48&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&#34; target=&#34;_blank&#34;&gt;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Ilya Kostrikov&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;49&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Kaixhin/Rainbow&#34; target=&#34;_blank&#34;&gt;https://github.com/Kaixhin/Rainbow&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Kai Arulkumaran&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;50&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/MillionIntegrals/vel&#34; target=&#34;_blank&#34;&gt;https://github.com/MillionIntegrals/vel&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch Maintained by Jerry (?)&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;51&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Khrylx/PyTorch-RL&#34; target=&#34;_blank&#34;&gt;https://github.com/Khrylx/PyTorch-RL&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;52&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorforce/tensorforce&#34; target=&#34;_blank&#34;&gt;https://github.com/tensorforce/tensorforce&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;53&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/higgsfield/RL-Adventure&#34; target=&#34;_blank&#34;&gt;https://github.com/higgsfield/RL-Adventure&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;54&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/qfettes/DeepRL-Tutorials&#34; target=&#34;_blank&#34;&gt;https://github.com/qfettes/DeepRL-Tutorials&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;55&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/SurrealAI/surreal&#34; target=&#34;_blank&#34;&gt;https://github.com/SurrealAI/surreal&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;TorchX&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;56&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/zuoxingdong/lagom&#34; target=&#34;_blank&#34;&gt;https://github.com/zuoxingdong/lagom&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;57&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/dennybritz/reinforcement-learning&#34; target=&#34;_blank&#34;&gt;https://github.com/dennybritz/reinforcement-learning&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;58&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/unixpickle/anyrl-py&#34; target=&#34;_blank&#34;&gt;https://github.com/unixpickle/anyrl-py&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;59&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/Scitator/rl-course-experiments&#34; target=&#34;_blank&#34;&gt;https://github.com/Scitator/rl-course-experiments&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;Tensorflow&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td&gt;60&lt;/td&gt;
          &lt;td&gt;&lt;a href=&#34;https://github.com/oxwhirl/pymarl&#34; target=&#34;_blank&#34;&gt;https://github.com/oxwhirl/pymarl&lt;/a&gt;&lt;/td&gt;
          &lt;td&gt;PyTorch&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</description>
      
    </item>
    
  </channel>
</rss>
