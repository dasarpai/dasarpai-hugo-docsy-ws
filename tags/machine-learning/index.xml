<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Machine Learning on Blowfish</title><link>https://dasarpai.github.io/tags/machine-learning/</link><description>Recent content in Machine Learning on Blowfish</description><generator>Hugo</generator><language>en</language><managingEditor>nuno@n9o.xyz (Blowfish)</managingEditor><webMaster>nuno@n9o.xyz (Blowfish)</webMaster><lastBuildDate>Fri, 28 Mar 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://dasarpai.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml"/><item><title>Audio Video Processing Concepts</title><link>https://dasarpai.github.io/dsblog/audio-video-processing-concepts/</link><pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/audio-video-processing-concepts/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6252-audio-video-processing-concepts.jpg" alt="Audio Video Processing Concepts">&lt;/p>
&lt;h1 id="foundational-concepts-of-audio-and-video-processing">Foundational Concepts of Audio and Video Processing&lt;a class="td-heading-self-link" href="#foundational-concepts-of-audio-and-video-processing" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Whether you are multimedia professional or deep learning Engineer, if you are dealing with audio and video processing, you will need to understand the core concepts of audio and video processing. My this guide is focussed on some of the key concepts of Audio Video processing.&lt;/p></description></item><item><title>Quantum Physics with Deeper Questions with ChatGPT</title><link>https://dasarpai.github.io/dsblog/quantum-physics-with-deeper-questions/</link><pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/quantum-physics-with-deeper-questions/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6253-quantum-physics-with-deeper-questions.jpg" alt="Quantum Physics with Deeper Questions">&lt;/p>
&lt;h1 id="quantum-physics-with-deeper-questions-with-chatgpt">Quantum Physics with Deeper Questions with ChatGPT&lt;a class="td-heading-self-link" href="#quantum-physics-with-deeper-questions-with-chatgpt" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>I was a physics student during my college years, and I’ve always loved the subject—even today. However, Quantum Physics, despite all my reading and learning, remains a mystery to me. At this stage, who can teach me Quantum Physics effectively? Finding an able professor, aligning my availability with theirs, and hoping they’d be willing to teach me for free seems impossible. So, I turned to a Large Language Model (LLM) for help. I could have explored other LLMs like Grok, Claude, DeepSeek, and many more. I’m not saying the others are bad, nor am I claiming that ChatGPT is the best at providing plausible answers. Whether an answer is correct or plausible also depends on the learner’s ability.&lt;/p></description></item><item><title>Exploring GGUF and Other Model Formats</title><link>https://dasarpai.github.io/dsblog/exploring-gguf-and-other-model-formats/</link><pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/exploring-gguf-and-other-model-formats/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6180-exploring-gguf.jpg" alt="Understanding GGUF and Other Model Formats in Machine Learning">&lt;/p>
&lt;h1 id="understanding-gguf-and-other-model-formats-in-machine-learning">&lt;strong>Understanding GGUF and Other Model Formats in Machine Learning&lt;/strong>&lt;a class="td-heading-self-link" href="#understanding-gguf-and-other-model-formats-in-machine-learning" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>As machine learning models continue to grow in complexity, the need for efficient, flexible, and versatile model formats becomes more pronounced. While formats like ONNX, TensorFlow’s SavedModel, and PyTorch’s native format have been around for some time, newer formats like GGUF are gaining attention for their unique benefits. This article explores these formats, their use cases, and how they support various aspects of machine learning, including deployment, compatibility, and optimization.&lt;/p></description></item><item><title>Exploring AnythingLLM</title><link>https://dasarpai.github.io/dsblog/exploring-anythingllm/</link><pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/exploring-anythingllm/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6179-exploring-anythingllm.jpg" alt="Exploring AnythingLLM ">&lt;/p>
&lt;h1 id="exploring-anythingllm">Exploring AnythingLLM&lt;a class="td-heading-self-link" href="#exploring-anythingllm" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-is-anythingllm">What is AnythingLLM?&lt;a class="td-heading-self-link" href="#what-is-anythingllm" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>AnythingLLM is an open-source project developed by Mintplex Labs that offers a highly flexible platform for creating personalized language models and knowledge databases. It operates using Retrieval-Augmented Generation (RAG), which combines language models with data from custom document collections. AnythingLLM supports embedding models (e.g., BERT), language models, and vector databases to index and query data, allowing users to fine-tune or deploy various models tailored to their needs, from local deployments to cloud integrations with OpenAI or Azure OpenAI.&lt;/p></description></item><item><title>Train Tensorflow Lite Models for Android</title><link>https://dasarpai.github.io/dscourses/Building-and-Deploying-Generative-AI-with-Amazon-Bedrock/</link><pubDate>Fri, 25 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/Building-and-Deploying-Generative-AI-with-Amazon-Bedrock/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc322-Building-and-Deploying-Generative-AI-with-Amazon-Bedrock.jpg" alt="Building and Deploying Generative AI with Amazon Bedrock">&lt;/p>
&lt;h1 id="building-and-deploying-generative-ai-with-amazon-bedrock">Building and Deploying Generative AI with Amazon Bedrock&lt;a class="td-heading-self-link" href="#building-and-deploying-generative-ai-with-amazon-bedrock" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="course-objective">&lt;strong>Course Objective&lt;/strong>&lt;a class="td-heading-self-link" href="#course-objective" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>This hands-on Amazon Bedrock workshop is designed to equip participants with in-depth knowledge and practical skills to harness the power of Amazon Bedrock for generative AI applications. Over the course of 2-3 days, participants will gain a foundational understanding of Bedrock&amp;rsquo;s services, learn to configure and integrate its APIs, and customize models to meet specific use cases. By the end of the workshop, participants will be able to build, deploy, and scale generative AI models, applying best practices for performance and cost-efficiency in real-world scenarios.&lt;/p></description></item><item><title>Types of Large Language Models (LLM)</title><link>https://dasarpai.github.io/dsblog/Types-of-LLM/</link><pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Types-of-LLM/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6171-Types-of-LLM.jpg" alt="">&lt;/p>
&lt;h2 id="introduction">&lt;strong>Introduction:&lt;/strong>&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>The world of Generative AI (GenAI) is expanding at an astonishing rate, with new models emerging almost daily, each sporting unique names, capabilities, versions, and sizes. For AI professionals, keeping track of these models can feel like a full-time job. But for business users, IT professionals, and software developers trying to make the right choice, understanding the model’s name and what it represents can seem overwhelming. Wouldn’t it be helpful if we could decode the meaning behind these names to know if a model fits our needs and is worth the investment? In this article, we’ll break down how the names of GenAI models can reveal clues about their functionality and suitability for specific tasks, helping you make informed decisions with confidence.&lt;/p></description></item><item><title>Design for Cloud Computing with GCP</title><link>https://dasarpai.github.io/dscourses/Design-for-Cloud-Computing-with-GCP/</link><pubDate>Sun, 20 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/Design-for-Cloud-Computing-with-GCP/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc320-Design-for-Cloud-Computing-with-GCP.jpg" alt="Design for Cloud Computing with GCP">&lt;/p>
&lt;h1 id="design-for-cloud-computing-with-gcp">Design for Cloud Computing with GCP&lt;a class="td-heading-self-link" href="#design-for-cloud-computing-with-gcp" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Duration: 4 weeks : - 20 Days&lt;/p>
&lt;h2 id="pre-requisites">Pre-requisites:&lt;a class="td-heading-self-link" href="#pre-requisites" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>• Basic Understanding of Cloud Computing
• Fundamentals of IT and Networking
• Knowledge on Application development
• Basic understanding of Linux and Command Line
• Familiarity with DevOps concepts
• Familiarity with Git&lt;/p></description></item><item><title>Train Tensorflow Lite Models for Android</title><link>https://dasarpai.github.io/dscourses/Train-Tensorflow-Lite-Models-for-Android/</link><pubDate>Sun, 20 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/Train-Tensorflow-Lite-Models-for-Android/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc321-Train-Tensorflow-Lite-Models-for-Android.jpg" alt="Train Tensorflow Lite Models for Android">&lt;/p>
&lt;h1 id="train-tensorflow-lite-models-for-android">Train Tensorflow Lite Models for Android&lt;a class="td-heading-self-link" href="#train-tensorflow-lite-models-for-android" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="course-overview">&lt;strong>Course Overview:&lt;/strong>&lt;a class="td-heading-self-link" href="#course-overview" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>We&amp;rsquo;ll begin by exploring the basics of Machine Learning and its various types, and then dive into the world of deep learning and artificial neural networks, which will serve as the foundation for training our machine learning models for Android.&lt;/p></description></item><item><title>AI/ML with Oracle Cloud</title><link>https://dasarpai.github.io/dsblog/AI-ML-With-Oracle-Cloud/</link><pubDate>Sat, 19 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/AI-ML-With-Oracle-Cloud/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6166-AI-ML-With-Oracle-Cloud.jpg" alt="AI/ML with Oracle Cloud">&lt;/p>
&lt;h1 id="aiml-with-oracle-cloud">AI/ML with Oracle Cloud&lt;a class="td-heading-self-link" href="#aiml-with-oracle-cloud" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="oracle-infrastructure-services">&lt;a href="https://docs.oracle.com/en-us/iaas/Content/services.htm">Oracle Infrastructure Services&lt;/a>&lt;a class="td-heading-self-link" href="#oracle-infrastructure-services" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Register for &lt;a href="https://www.oracle.com/cloud/free/?source=:ow:o:h:po:OHPPanel1nav0625&amp;amp;intcmp=:ow:o:h:po:OHPPanel1nav0625">Oracle Cloud Free Tier&lt;/a>&lt;/p>
&lt;h2 id="oracle-ai-main-services">Oracle AI Main services&lt;a class="td-heading-self-link" href="#oracle-ai-main-services" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://cloud.oracle.com/digital-assistant/oda-instances?region=ap-mumbai-1">Digital Assistant&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.oracle.com/en-us/iaas/Content/document-understanding/using/home.htm">Document Understanding&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.oracle.com/en-us/iaas/language/using/pretrain-models.htm#lang-detect">Language&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.oracle.com/en-us/iaas/Content/vision/using/pretrained-model-using-image.htm">Vision&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.oracle.com/en-us/iaas/Content/speech/home.htm">Speech&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.oracle.com/en-us/iaas/Content/Streaming/home.htm">Stream&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.oracle.com/en-us/iaas/process-automation/oci-process-automation/overview-oci-process-automation.html">Cloud Infra Automation&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="generative-ai">&lt;a href="https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm">Generative AI&lt;/a>&lt;a class="td-heading-self-link" href="#generative-ai" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Generative AI is a fully managed Oracle Cloud Infrastructure service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases, including chat, text generation, summarization, and creating text embeddings.&lt;/p></description></item><item><title>Machine Learning Key Concepts</title><link>https://dasarpai.github.io/dsblog/Machine-Learning-Key-Concepts/</link><pubDate>Thu, 03 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Machine-Learning-Key-Concepts/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6152-Machine-Learning-Key-Concepts.jpg" alt="Exploring Docker and VS Code Integration">&lt;/p>
&lt;h1 id="machine-learning-key-concepts">Machine Learning Key Concepts&lt;a class="td-heading-self-link" href="#machine-learning-key-concepts" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>In this article Essential Machine Learning Techniques/Concepts are Explained, some of them are are Cross-Validation, Hyperparameter Optimization, Machine learning types and much More.&lt;/p></description></item><item><title>Automated Machine Learning</title><link>https://dasarpai.github.io/dsblog/AutoML-Tools/</link><pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/AutoML-Tools/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6150-AutoML-Tools.jpg" alt="What is AutoML">&lt;/p>
&lt;h1 id="automated-machine-learning">Automated Machine Learning&lt;a class="td-heading-self-link" href="#automated-machine-learning" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="is-this-article-for-me">Is this article for me?&lt;a class="td-heading-self-link" href="#is-this-article-for-me" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>This is article is for you, if you know&lt;/p>
&lt;ul>
&lt;li>About Machine learning, ML models building&lt;/li>
&lt;li>That machines are capable of building these models themselves.&lt;/li>
&lt;/ul>
&lt;p>But you don&amp;rsquo;t know how it happens and what are different libraries available for this work.&lt;/p></description></item><item><title>Everything About Developer Console</title><link>https://dasarpai.github.io/dsblog/Everything-About-Developer-Console/</link><pubDate>Sun, 29 Sep 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Everything-About-Developer-Console/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6148-Everything-About-Developer-Console.jpg" alt="Everything About Developer Console">&lt;/p>
&lt;h1 id="console-types-every-programmer-should-know">Console Types Every Programmer Should Know&lt;a class="td-heading-self-link" href="#console-types-every-programmer-should-know" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="is-this-article-for-me">Is this article for me?&lt;a class="td-heading-self-link" href="#is-this-article-for-me" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>If you are you confused about a term &amp;ldquo;console&amp;rdquo; which you heard at many places and in many context, and you want to know the following answers, then continue reading.&lt;/p></description></item><item><title>Navigating Google Cloud Security: Key Components, Roles, and Best Practices</title><link>https://dasarpai.github.io/dsblog/Google-Cloud-Security-Components/</link><pubDate>Sat, 28 Sep 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Google-Cloud-Security-Components/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6147-Google-Cloud-Security-Components.jpg" alt="Navigating Google Cloud Security">&lt;/p>
&lt;h1 id="navigating-google-cloud-security">Navigating Google Cloud Security&lt;a class="td-heading-self-link" href="#navigating-google-cloud-security" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="is-this-article-for-me">Is this article for me?&lt;a class="td-heading-self-link" href="#is-this-article-for-me" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>If you are looking answers of these questions then continue reading.&lt;/p>
&lt;ul>
&lt;li>What are various components of GCP security architecture?&lt;/li>
&lt;li>What is overall hierarchy of GCP Security Components?&lt;/li>
&lt;li>What are Principal, Permission, Roles and Policies in GCP and how are they interconnected?&lt;/li>
&lt;li>Can you give examples of Permissions in GCP Security architecture?&lt;/li>
&lt;li>What are different types of resources available on GCP?&lt;/li>
&lt;li>Can you help me visualizing organization, folders and project of GCP?&lt;/li>
&lt;/ul>
&lt;h2 id="question-what-are-various-components-of-gcp-security-architecture">Question: What are various components of GCP security architecture?&lt;a class="td-heading-self-link" href="#question-what-are-various-components-of-gcp-security-architecture" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Google Cloud Platform (GCP) has a complex security architecture that consists of various components. Here’s a list of key components and their hierarchy in GCP&amp;rsquo;s security model:&lt;/p></description></item><item><title>Variations of Language Model in Huggingface</title><link>https://dasarpai.github.io/dsblog/Variations-of-Language-Model-in-Huggingface/</link><pubDate>Thu, 22 Aug 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Variations-of-Language-Model-in-Huggingface/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6138-Variations-of-Language-Model-in-Huggingface.jpg" alt="Variations-of-LanguageModel">&lt;/p>
&lt;h1 id="variations-of-language-model-in-huggingface">Variations of Language Model in Huggingface&lt;a class="td-heading-self-link" href="#variations-of-language-model-in-huggingface" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-the-model-variable-in-huggingface">What the Model variable in Huggingface?&lt;a class="td-heading-self-link" href="#what-the-model-variable-in-huggingface" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>We know base moels like BERT, T5, GPT2, GPT3 etc are developed by researchers working with different companies. But when we look into huggingface model repository we see other models like GPT2LMHeadModel, GPT2ForSequenceClassification, etc what are these?&lt;/p></description></item><item><title>MLOps Tools</title><link>https://dasarpai.github.io/dsblog/MLOps-Tools/</link><pubDate>Tue, 13 Aug 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/MLOps-Tools/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6137-MLOps-Tools.jpg" alt="MLOps-Tools">&lt;/p>
&lt;h1 id="mlops-tools">MLOps Tools&lt;a class="td-heading-self-link" href="#mlops-tools" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>MLOps (Machine Learning Operations) is a set of practices and tools designed to streamline and automate the deployment, monitoring, and management of machine learning models in production environments. It combines principles from both DevOps (Development Operations) and machine learning to ensure that ML models are deployed efficiently, managed effectively, and maintained reliably throughout their lifecycle.&lt;/p></description></item><item><title>AI Usecases in Cybersecurity</title><link>https://dasarpai.github.io/dsblog/AI-Usecases-in-Cybersecurity/</link><pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/AI-Usecases-in-Cybersecurity/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6135-AI-Usecases-in-Cybersecurity.jpg" alt="AI-Usecases-in-Cybersecurity">&lt;/p>
&lt;h1 id="ai-usecases-in-cybersecurity">AI Usecases in Cybersecurity&lt;a class="td-heading-self-link" href="#ai-usecases-in-cybersecurity" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="ai-in-cyber-security-ethics-related-challenges-and-usecases">AI in Cyber Security, Ethics Related Challenges and Usecases&lt;a class="td-heading-self-link" href="#ai-in-cyber-security-ethics-related-challenges-and-usecases" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="ai-usecases-in-cyber-security">AI Usecases in Cyber Security&lt;a class="td-heading-self-link" href="#ai-usecases-in-cyber-security" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>
&lt;p>Threat Detection and Response
AI can enhance the detection and response to cybersecurity threats by:&lt;/p></description></item><item><title>Open Source vs Closed Source AI</title><link>https://dasarpai.github.io/dsblog/Open-Source-vs-Closed-Source-AI/</link><pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Open-Source-vs-Closed-Source-AI/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6134-Open-Source-vs-Closed-Source-AI.jpg" alt="Open-Source-vs-Closed-Source-AI">&lt;/p>
&lt;h1 id="open-source-ai-vs-closed-source-ai">Open Source AI vs Closed Source AI&lt;a class="td-heading-self-link" href="#open-source-ai-vs-closed-source-ai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Major players in the AI industry, such as Google, Microsoft, IBM, Salesforce, etc each have their own proprietary models and infrastructure to host these models. They offer AI services that companies use to develop AI products for either their end customers or internal use. Training or developing AI models requires expensive hardware and highly skilled personnel, making it a costly process. However, the deployment and inference stages are even more expensive, as they involve ongoing costs for hardware and monitoring.&lt;/p></description></item><item><title>LLM Architecture and Training</title><link>https://dasarpai.github.io/dsblog/LLM-Architecture-and-Training/</link><pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/LLM-Architecture-and-Training/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6129-LLM-Architecture-and-Training.jpg" alt="LLM-Architecture-and-Training">&lt;/p>
&lt;h1 id="understanding-llm-architectures-and-model-training">&lt;strong>Understanding LLM Architectures and Model Training&lt;/strong>&lt;a class="td-heading-self-link" href="#understanding-llm-architectures-and-model-training" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Large Language Models (LLMs) are transforming the field of artificial intelligence by enabling machines to understand and generate human language with unprecedented accuracy. This article delves into the architecture, training methods, and practical applications of LLMs. We’ll explore the core components that make these models so powerful and explain how they are trained and fine-tuned for real-world use cases.&lt;/p></description></item><item><title>Why to Finetune LLM?</title><link>https://dasarpai.github.io/dsblog/why-to-finetune-llm/</link><pubDate>Sun, 28 Jul 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/why-to-finetune-llm/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6115-why-to-finetune-llm.jpg" alt="Why to Finetune LLM?">&lt;/p>
&lt;h1 id="finetuning-fewshot-learning-why-and-how">Finetuning, Fewshot Learning, Why and How?&lt;a class="td-heading-self-link" href="#finetuning-fewshot-learning-why-and-how" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="why-to-finetune-a-llm">Why to finetune a LLM?&lt;a class="td-heading-self-link" href="#why-to-finetune-a-llm" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Fine-tuning a large language model (LLM) can provide several benefits, depending on your specific needs and objectives. Here are some key reasons to consider fine-tuning an LLM:&lt;/p></description></item><item><title>Stanford Alpaca</title><link>https://dasarpai.github.io/dsblog/Stanford-Alpaca/</link><pubDate>Sat, 27 Jul 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Stanford-Alpaca/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6116-Stanford-Alpaca.jpg" alt="Stanford-Alpaca">&lt;/p>
&lt;h1 id="stanford-alpaca">Stanford Alpaca&lt;a class="td-heading-self-link" href="#stanford-alpaca" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;a href="https://github.com/tatsu-lab/stanford_alpaca">Stanford Alpaca Github Report&lt;/a>&lt;/p>
&lt;ul>
&lt;li>Stanford Alpaca is An &amp;ldquo;Instruction-following&amp;rdquo; LLaMA Model&lt;/li>
&lt;li>This is the repo aims to build and share an instruction-following LLaMA model. The repo contains:
&lt;ul>
&lt;li>The 52K &lt;a href="https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json">instruction-following data&lt;/a> used for fine-tuning the model.&lt;/li>
&lt;li>The code for generating the data.&lt;/li>
&lt;li>The code for fine-tuning the model.&lt;/li>
&lt;li>The code for recovering Alpaca-7B weights from our released weight diff.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="overview">Overview&lt;a class="td-heading-self-link" href="#overview" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>The current &amp;ldquo;Alpaca 7B model&amp;rdquo; is fine-tuned from a &amp;ldquo;7B LLaMA&amp;rdquo; model on 52K instruction-following data generated by the techniques in the Self-Instruct paper.&lt;/li>
&lt;li>Alpaca 7B model behaves similarly to the text-davinci-003 model on the Self-Instruct instruction-following evaluation suite.&lt;/li>
&lt;li>Alpaca is still under development, and there are many limitations that have to be addressed.&lt;/li>
&lt;li>Alphaca is not yet fine-tuned to be safe and harmless.&lt;/li>
&lt;li>Initial release contains the data generation procedure, dataset, and training recipe.&lt;/li>
&lt;li>Model weights can be released if the creators of LLaMA gives permission.&lt;/li>
&lt;li>Live demo to help readers better understand the capabilities and limits of Alpaca is available.&lt;/li>
&lt;li>Based on followin papers:
&lt;ul>
&lt;li>LLaMA: Open and Efficient Foundation Language Models. &lt;a href="https://arxiv.org/abs/2302.13971v1">Hugo2023&lt;/a>&lt;/li>
&lt;li>Self-Instruct: Aligning Language Model with Self Generated Instructions. &lt;a href="https://arxiv.org/abs/2212.10560">Yizhong2022&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Data Release
&lt;ul>
&lt;li>alpaca_data.json contains 52K instruction-following data we used for fine-tuning the Alpaca model. This JSON file is a list of dictionaries, each dictionary contains the following fields: Instruction, input, output (text-davinci-003 geneated answer).&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="highlevel-activities-of-the-alpaca-project">Highlevel Activities of the Alpaca Project&lt;a class="td-heading-self-link" href="#highlevel-activities-of-the-alpaca-project" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Highlevel Actitivies done by Stanford Alpaca team and Project Output&lt;/p></description></item><item><title>Understanding LLM GAN and Transformers</title><link>https://dasarpai.github.io/dsblog/Understanding-LLM-GAN-and-Transformers/</link><pubDate>Fri, 26 Jul 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Understanding-LLM-GAN-and-Transformers/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6127-Understanding-LLM-GAN-and-Transformers.jpg" alt="Understanding-LLM-GAN-Transformers">&lt;/p>
&lt;h1 id="understanding-llm-gan-and-transformers">Understanding LLM, GAN and Transformers&lt;a class="td-heading-self-link" href="#understanding-llm-gan-and-transformers" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="llm-layers">LLM Layers&lt;a class="td-heading-self-link" href="#llm-layers" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Large Language Models (LLMs) are typically based on Transformer architectures, which consist of several types of layers that work together to process and generate text. Here are the primary kinds of layers found in an LLM:&lt;/p></description></item><item><title>Transformers Demystified A Step-by-Step Guide</title><link>https://dasarpai.github.io/dsblog/transformers-demystified-a-step-by-step-guide/</link><pubDate>Thu, 25 Jul 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/transformers-demystified-a-step-by-step-guide/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6113-transformers-demystified-a-step-by-step-guide.jpg" alt="Transformers Demystified A Step-by-Step Guide">&lt;/p>
&lt;h1 id="transformers-demystified-a-step-by-step-guide">Transformers Demystified A Step-by-Step Guide&lt;a class="td-heading-self-link" href="#transformers-demystified-a-step-by-step-guide" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>All modern Transformers are based on a paper &amp;ldquo;Attention is all you need&amp;rdquo;&lt;/p>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>This was the mother paper of all the transformer architectures we see today around NLP, Multimodal, Deep Learning. It was presented by Ashish Vaswani et al from Deep Learning / Google in 2017. We will discuss following and anything whatever question/observation/idea I have.&lt;/p></description></item><item><title>Dimensionality Reduction and Visualization</title><link>https://dasarpai.github.io/dsblog/Dimensionality-Reduction-and-Visualization/</link><pubDate>Wed, 24 Jul 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Dimensionality-Reduction-and-Visualization/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6126-Dimensionality-Reduction-and-Visualization.jpg" alt="Dimensionality-Reduction-and-Visualization">&lt;/p>
&lt;h1 id="dimensionality-reduction-and-visualization">Dimensionality Reduction and Visualization&lt;a class="td-heading-self-link" href="#dimensionality-reduction-and-visualization" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-are-the-popular-methods-of-dimensionality-reduction">What are the popular methods of dimensionality reduction?&lt;a class="td-heading-self-link" href="#what-are-the-popular-methods-of-dimensionality-reduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Dimensionality reduction is a crucial step in data preprocessing, particularly when dealing with high-dimensional datasets. It helps in reducing the number of features while retaining the essential information, improving computational efficiency, and facilitating data visualization. Here are some popular methods of dimensionality reduction:&lt;/p></description></item><item><title>NLP BenchMarks</title><link>https://dasarpai.github.io/dsblog/NLP-BenchMarks1/</link><pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/NLP-BenchMarks1/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6120-NLP-BenchMarks.jpg" alt="NLP-BenchMarks">&lt;/p>
&lt;h1 id="nlp-benchmarks">NLP BenchMarks&lt;a class="td-heading-self-link" href="#nlp-benchmarks" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-is-language-model">What is Language Model?&lt;a class="td-heading-self-link" href="#what-is-language-model" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>A &lt;strong>language model&lt;/strong> is a computational model that understands and generates human language. It learns the patterns and structure of a language by analyzing large amounts of text data, allowing it to predict the next word in a sequence or generate coherent text. Language models are used in applications like text generation, translation, speech recognition, chatbots, and sentiment analysis.&lt;/p></description></item><item><title>Empowering Language with AI NLP Capabilities</title><link>https://dasarpai.github.io/dsblog/empowering-language-with-ainlp-capabilities/</link><pubDate>Sat, 18 Nov 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/empowering-language-with-ainlp-capabilities/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6106-Empowering-Language-with-AI-NLP-Capabilities.jpg" alt="Empowering-Language-with-AI-NLP-Capabilities">&lt;/p>
&lt;h1 id="empowering-language-with-ai-nlp-capabilities">Empowering-Language-with-AI-NLP-Capabilities&lt;a class="td-heading-self-link" href="#empowering-language-with-ai-nlp-capabilities" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>When envisioning artificial intelligence (AI), the initial images that often come to mind are humanoid robots. However, this perception oversimplifies the vast realm of AI, which is fundamentally distinct from natural intelligence—the inherent cognitive capacity found in living organisms shaped by Mother Nature. Life, in all its forms, from microscopic bacteria to complex human beings, possesses an innate intelligence derived from hydrocarbon-based living cells.&lt;/p></description></item><item><title>Topic Modeling with BERT</title><link>https://dasarpai.github.io/dsblog/topic-modeling-with-bert/</link><pubDate>Mon, 13 Nov 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/topic-modeling-with-bert/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6105-Topic-Modeling-with-BERT.jpg" alt="Topic Modeling with BERT">&lt;/p>
&lt;h1 id="topic-modeling-with-bert">Topic Modeling with BERT&lt;a class="td-heading-self-link" href="#topic-modeling-with-bert" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Key steps in BERTopic modelling are as following.&lt;/p>
&lt;ul>
&lt;li>Use &amp;ldquo;Sentence Embedding&amp;rdquo; models to embed the sentences of the article&lt;/li>
&lt;li>Reduce the dimensionality of embedding using UMAP&lt;/li>
&lt;li>Cluster these documents (reduced dimensions) using HDBSAN&lt;/li>
&lt;li>Use c-TF-IDF extract keywords, their frequency and IDF for each cluster.&lt;/li>
&lt;li>MMR: Maximize Candidate Relevance. How many words in a topic can represent the topic?&lt;/li>
&lt;li>Intertopic Distance Map&lt;/li>
&lt;li>Use similarity matrix (heatmap), dandogram (hierarchical map), to visualize the topics and key_words.&lt;/li>
&lt;li>Traction of topic over time period. Some may be irrelevant and for other traction may be increasing or decreasing.&lt;/li>
&lt;/ul>
&lt;h1 id="installation">Installation&lt;a class="td-heading-self-link" href="#installation" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Installation, with sentence-transformers, can be done using pypi:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">pip&lt;/span> &lt;span class="n">install&lt;/span> &lt;span class="n">bertopic&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># If you want to install BERTopic with other embedding models, you can choose one of the following:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Choose an embedding backend&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">pip&lt;/span> &lt;span class="n">install&lt;/span> &lt;span class="n">bertopic&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">flair&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">gensim&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">spacy&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">use&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Topic modeling with images&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">pip&lt;/span> &lt;span class="n">install&lt;/span> &lt;span class="n">bertopic&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">vision&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="supported-topic-modelling-techniques">Supported Topic Modelling Techniques&lt;a class="td-heading-self-link" href="#supported-topic-modelling-techniques" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>BERTopic supports all kinds of topic modeling techniques as below.&lt;/p></description></item><item><title>Basics of Word Embedding</title><link>https://dasarpai.github.io/dsblog/basics-of-word-embedding/</link><pubDate>Sat, 11 Nov 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/basics-of-word-embedding/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6101-Basics-of-Word-Embedding.jpg" alt="Basics of Word Embedding">&lt;/p>
&lt;h1 id="basics-of-word-embedding">Basics of Word Embedding&lt;a class="td-heading-self-link" href="#basics-of-word-embedding" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-is-context-target-and-window">What is Context, target and window?&lt;a class="td-heading-self-link" href="#what-is-context-target-and-window" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>The &amp;ldquo;context&amp;rdquo; word is the surrounding word.&lt;/li>
&lt;li>The &amp;ldquo;target&amp;rdquo; word is the middle word.&lt;/li>
&lt;li>The &amp;ldquo;window distance&amp;rdquo; is number of words (including) between context words and target word. Window distance 1 means, one word surronding the target, one left side context word, one right context word. Two window distance means 2 words left and 2 words right.&lt;/li>
&lt;/ul>
&lt;p>Let&amp;rsquo;s take a sentence&lt;/p></description></item><item><title>Graph of Thoughts</title><link>https://dasarpai.github.io/dsblog/graph-of-thoughts/</link><pubDate>Sat, 11 Nov 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/graph-of-thoughts/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6103-Graph-of-Thoughts.jpg" alt="Graph of Thoughts">&lt;/p>
&lt;h1 id="graph-of-thoughts">Graph of Thoughts&lt;a class="td-heading-self-link" href="#graph-of-thoughts" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>This is a valuable resource for learning Graph of Thoughts (GoT) concepts. The YouTube video is from code_your_own_AI. I&amp;rsquo;m utilizing the comments made by @wesleychang2005 on the video, which provide an excellent summary of GoT. If you&amp;rsquo;re interested in this topic and find the summary below intriguing, I recommend watching the entire 41-minute video.&lt;/p></description></item><item><title>What is Pinecone</title><link>https://dasarpai.github.io/dsblog/What-is-Pinecone/</link><pubDate>Sun, 03 Sep 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/What-is-Pinecone/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6097-What-is-Pinecone.jpg" alt="What is Pinecone">&lt;/p>
&lt;h2 id="what-is-pinecone">What is pinecone?&lt;a class="td-heading-self-link" href="#what-is-pinecone" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Pinecone is a managed vector database that provides vector search (or “similarity search”) for developers with a straightforward API and usage-based pricing. It’s free to try. &lt;a href="https://www.pinecone.io/learn/vector-search-basics/">Introduction to Vector Search for Developers&lt;/a>.&lt;/p></description></item><item><title>Distances in Machine Learning</title><link>https://dasarpai.github.io/dsblog/Distances-in-Machine-Learning/</link><pubDate>Sun, 27 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Distances-in-Machine-Learning/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6093-Distances-in-Machine-Learning.jpg" alt="Distances in Machine Learning">&lt;/p>
&lt;h1 id="distances-in-machine-learning">Distances in Machine Learning&lt;a class="td-heading-self-link" href="#distances-in-machine-learning" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Every sample, record, word, sentence, object, image etc in the Machine learning language is called vector. If we want to measure the similarity or dissimilarity between two data points then we need distance function.&lt;/p></description></item><item><title>Important AI Paper List</title><link>https://dasarpai.github.io/dsblog/select-ai-papers/</link><pubDate>Tue, 22 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/select-ai-papers/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6090-rps-Important-AI-Paper-List.jpg" alt="Important AI Paper List">&lt;/p>
&lt;h1 id="important-ai-paper-list">Important AI Paper List&lt;a class="td-heading-self-link" href="#important-ai-paper-list" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduciton">Introduciton&lt;a class="td-heading-self-link" href="#introduciton" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>In almost all citations it becomes very difficult to read the title of research papers. Why? Because the contributors&amp;rsquo; information is first and most of the time, it is difficult to read the name other than native people. For example, if an Indian find a native name like &amp;ldquo;Vivek Ramaswami, Kartikeyan Karunanidhi&amp;rdquo; it is easy for them to read the name but the same name becomes difficult to read for non-Indian people, and vice-versa. Giving respect to the creator is very important but more than we need to know what have they done. I know from my experience, for almost every researcher, it becomes very difficult to track good AI research papers. For me, it is more difficult because I need to maintain this blog and I want to give references to the work across different webpages. Therefore I am creating a citation key, which includes the Last name of the first researcher + year of presenting that paper. Along with this, I am describing the title of the paper and where it was presented. If you find a particular title interesting for your work you can search that paper on &amp;ldquo;google scholar&amp;rdquo;, Mendeley, sci-hub or other places with which you are familiar and comfortable. Post that you can download and read that paper at your leisure. Hope you find this list of some use for your work.&lt;/p></description></item><item><title>Paper with Code Resources</title><link>https://dasarpai.github.io/dsblog/paperwithcode-resources/</link><pubDate>Tue, 22 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/paperwithcode-resources/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6091-rps-Paperwithcode-Resources.jpg" alt="Paper with Code Resources">&lt;/p>
&lt;h1 id="paper-with-code-resources">Paper with Code Resources&lt;a class="td-heading-self-link" href="#paper-with-code-resources" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="trending-papers-of-2021">Trending Papers of 2021&lt;a class="td-heading-self-link" href="#trending-papers-of-2021" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>ADOP: Approximate Differentiable One-Pixel Point Rendering — Rückert et al — &lt;a href="https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel">https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel&lt;/a>&lt;/li>
&lt;li>The Bayesian Learning Rule —Khan et al &lt;a href="https://paperswithcode.com/paper/the-bayesian-learning-rule">https://paperswithcode.com/paper/the-bayesian-learning-rule&lt;/a>&lt;/li>
&lt;li>Program Synthesis with Large Language Models — Austin et al &lt;a href="https://paperswithcode.com/paper/program-synthesis-with-large-language-models">https://paperswithcode.com/paper/program-synthesis-with-large-language-models&lt;/a>&lt;/li>
&lt;li>Masked Autoencoders Are Scalable Vision Learners — He et al &lt;a href="https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision">https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision&lt;/a>&lt;/li>
&lt;li>8-bit Optimizers via Block-wise Quantization — Dettmers et al &lt;a href="https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization">https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization&lt;/a>&lt;/li>
&lt;li>Revisiting ResNets: Improved Training and Scaling Strategies — Bello et al &lt;a href="https://paperswithcode.com/paper/revisiting-resnets-improved-training-and">https://paperswithcode.com/paper/revisiting-resnets-improved-training-and&lt;/a>&lt;/li>
&lt;li>Image Super-Resolution via Iterative Refinement — Saharia et al &lt;a href="https://paperswithcode.com/paper/image-super-resolution-via-iterative">https://paperswithcode.com/paper/image-super-resolution-via-iterative&lt;/a>&lt;/li>
&lt;li>Perceiver IO: A General Architecture for Structured Inputs &amp;amp; Outputs — Jaegle et al &lt;a href="https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for">https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for&lt;/a>&lt;/li>
&lt;li>Do Vision Transformers See Like Convolutional Neural Networks? — Raghu et al &lt;a href="https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional">https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional&lt;/a>&lt;/li>
&lt;li>Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions — Niepert et al &lt;a href="https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete">https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="trending-libaries-of-2021">Trending Libaries of 2021&lt;a class="td-heading-self-link" href="#trending-libaries-of-2021" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>PyTorch Image Models — Ross Wightman — &lt;a href="https://github.com/rwightman/pytorch-image-models">https://github.com/rwightman/pytorch-image-models&lt;/a>&lt;/li>
&lt;li>Transformers — Hugging Face — &lt;a href="https://github.com/huggingface/transformers">https://github.com/huggingface/transformers&lt;/a>&lt;/li>
&lt;li>PyTorch-GAN — Erik Linder-Norén — &lt;a href="https://github.com/eriklindernoren/PyTorch-GAN">https://github.com/eriklindernoren/PyTorch-GAN&lt;/a>&lt;/li>
&lt;li>MMDetection — OpenMMLab — &lt;a href="https://github.com/open-mmlab/mmdetection">https://github.com/open-mmlab/mmdetection&lt;/a>&lt;/li>
&lt;li>Darknet — AlexeyAB — &lt;a href="https://github.com/AlexeyAB/darknet">https://github.com/AlexeyAB/darknet&lt;/a>&lt;/li>
&lt;li>Vision Transformer PyTorch — lucidrains — &lt;a href="https://github.com/lucidrains/vit-pytorch">https://github.com/lucidrains/vit-pytorch&lt;/a>&lt;/li>
&lt;li>InsightFace — DeepInsight — &lt;a href="https://github.com/deepinsight/insightface">https://github.com/deepinsight/insightface&lt;/a>&lt;/li>
&lt;li>Detectron2 — Meta AI — &lt;a href="https://github.com/facebookresearch/detectron2">https://github.com/facebookresearch/detectron2&lt;/a>&lt;/li>
&lt;li>PaddleOCR — PaddlePaddle — &lt;a href="https://github.com/PaddlePaddle/PaddleOCR">https://github.com/PaddlePaddle/PaddleOCR&lt;/a>&lt;/li>
&lt;li>FairSeq — Meta AI — &lt;a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="top-dataset---2021">Top Dataset - 2021&lt;a class="td-heading-self-link" href="#top-dataset---2021" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>MATH — Hendrycks et al &lt;a href="https://paperswithcode.com/dataset/math">https://paperswithcode.com/dataset/math&lt;/a>&lt;/li>
&lt;li>UAV-Human — Li et al &lt;a href="https://paperswithcode.com/dataset/uav-human">https://paperswithcode.com/dataset/uav-human&lt;/a>&lt;/li>
&lt;li>UPFD (User Preference-aware Fake News Detection) — Dou et al &lt;a href="https://paperswithcode.com/dataset/upfd">https://paperswithcode.com/dataset/upfd&lt;/a>&lt;/li>
&lt;li>OGB-LSC (OGB Large-Scale Challenge) — Hu et al &lt;a href="https://paperswithcode.com/dataset/ogb-lsc">https://paperswithcode.com/dataset/ogb-lsc&lt;/a>&lt;/li>
&lt;li>CodeXGLUE —Lu et al &lt;a href="https://paperswithcode.com/dataset/codexglue">https://paperswithcode.com/dataset/codexglue&lt;/a>&lt;/li>
&lt;li>AGORA — Patel et al &lt;a href="https://paperswithcode.com/dataset/agora">https://paperswithcode.com/dataset/agora&lt;/a>&lt;/li>
&lt;li>BEIR (Benchmarking IR) — Thakur et al &lt;a href="https://paperswithcode.com/dataset/beir">https://paperswithcode.com/dataset/beir&lt;/a>&lt;/li>
&lt;li>WikiGraphs — Wang et al &lt;a href="https://paperswithcode.com/dataset/wikigraphs">https://paperswithcode.com/dataset/wikigraphs&lt;/a>&lt;/li>
&lt;li>Few-NERD — Ding et al &lt;a href="https://paperswithcode.com/dataset/few-nerd">https://paperswithcode.com/dataset/few-nerd&lt;/a>&lt;/li>
&lt;li>PASS (Pictures without humAns for Self-Supervision) —Asano et al &lt;a href="https://paperswithcode.com/dataset/pass">https://paperswithcode.com/dataset/pass&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="papers-of-2022">Papers of 2022&lt;a class="td-heading-self-link" href="#papers-of-2022" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Controllable Animation of Fluid Elements in Still Images&lt;/li>
&lt;li>F-SfT: Shape-From-Template With A Physics-Based Deformation Model&lt;/li>
&lt;li>TWIST: Two-Way Inter-Label Self-Training for Semi-Supervised 3D Instance Segmentation&lt;/li>
&lt;li>Do Learned Representations Respect Causal Relationships?&lt;/li>
&lt;li>ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic&lt;/li>
&lt;li>3D Moments From Near-Duplicate Photos&lt;/li>
&lt;li>Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization&lt;/li>
&lt;li>Blind2Unblind: Self-Supervised Image Denoising With Visible Blind Spots&lt;/li>
&lt;li>Balanced and Hierarchical Relation Learning for One-Shot Object Detection&lt;/li>
&lt;li>NICE-SLAM: Neural Implicit Scalable Encoding for SLAM&lt;/li>
&lt;li>Stochastic Trajectory Prediction Via Motion Indeterminacy Diffusion&lt;/li>
&lt;li>CLRNet: Cross Layer Refinement Network for Lane Detection&lt;/li>
&lt;li>Motion-Aware Contrastive Video Representation Learning Via Foreground-Background Merging&lt;/li>
&lt;li>DINE: Domain Adaptation From Single and Multiple Black-Box Predictors&lt;/li>
&lt;li>FaceFormer: Speech-Driven 3D Facial Animation With Transformers&lt;/li>
&lt;li>Rotationally Equivariant 3D Object Detection&lt;/li>
&lt;li>Accelerating DETR Convergence Via Semantic-Aligned Matching&lt;/li>
&lt;li>Cloning Outfits From Real-World Images to 3D Characters for Generalizable Person Re-Identification&lt;/li>
&lt;li>GeoNeRF: Generalizing NeRF With Geometry Priors&lt;/li>
&lt;li>ABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo&lt;/li>
&lt;li>Expanding Low-Density Latent Regions for Open-Set Object Detection&lt;/li>
&lt;li>Uformer: A General U-Shaped Transformer for Image Restoration&lt;/li>
&lt;li>Exploring Dual-Task Correlation for Pose Guided Person Image Generation&lt;/li>
&lt;li>Portrait Eyeglasses and Shadow Removal By Leveraging 3D Synthetic Data&lt;/li>
&lt;li>Modeling 3D Layout for Group Re-Identification&lt;/li>
&lt;li>Toward Fast, Flexible, and Robust Low-Light Image Enhancement&lt;/li>
&lt;li>Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos&lt;/li>
&lt;li>HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network&lt;/li>
&lt;li>Modular Action Concept Grounding in Semantic Video Prediction&lt;/li>
&lt;li>StyleSwin: Transformer-Based GAN for High-Resolution Image Generation&lt;/li>
&lt;li>Discrete Cosine Transform Network for Guided Depth Map Super-Resolution&lt;/li>
&lt;li>Cerberus Transformer: Joint Semantic, Affordance and Attribute Parsing&lt;/li>
&lt;li>TransGeo: Transformer Is All You Need for Cross-View Image Geo-Localization&lt;/li>
&lt;li>Contrastive Boundary Learning for Point Cloud Segmentation&lt;/li>
&lt;li>Details or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution&lt;/li>
&lt;li>CVNet: Contour Vibration Network for Building Extraction&lt;/li>
&lt;li>Swin Transformer V2: Scaling Up Capacity and Resolution&lt;/li>
&lt;li>Projective Manifold Gradient Layer for Deep Rotation Regression&lt;/li>
&lt;li>HCSC: Hierarchical Contrastive Selective Coding&lt;/li>
&lt;li>TransRank: Self-Supervised Video Representation Learning Via Ranking-Based Transformation Recognition&lt;/li>
&lt;li>DiSparse: Disentangled Sparsification for Multitask Model Compression&lt;/li>
&lt;li>Pushing The Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make A Difference&lt;/li>
&lt;li>Towards Efficient and Scalable Sharpness-Aware Minimization&lt;/li>
&lt;li>OSSO: Obtaining Skeletal Shape From Outside&lt;/li>
&lt;li>A Study on The Distribution of Social Biases in Self-Supervised Learning Visual Models&lt;/li>
&lt;li>Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes&lt;/li>
&lt;li>Comparing Correspondences: Video Prediction With Correspondence-Wise Losses&lt;/li>
&lt;li>Towards Fewer Annotations: Active Learning Via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation&lt;/li>
&lt;li>CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding&lt;/li>
&lt;li>Few Shot Generative Model Adaption Via Relaxed Spatial Structural Alignment&lt;/li>
&lt;li>Enhancing Adversarial Training With Second-Order Statistics of Weights&lt;/li>
&lt;li>Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo&lt;/li>
&lt;li>Moving Window Regression: A Novel Approach to Ordinal Regression&lt;/li>
&lt;li>Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection&lt;/li>
&lt;li>Robust Optimization As Data Augmentation for Large-Scale Graphs&lt;/li>
&lt;li>Robust Structured Declarative Classifiers for 3D Point Clouds: Defending Adversarial Attacks With Implicit Gradients&lt;/li>
&lt;li>Improving The Transferability of Targeted Adversarial Examples Through Object-Based Diverse Input&lt;/li>
&lt;li>ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer&lt;/li>
&lt;li>360MonoDepth: High-Resolution 360deg Monocular Depth Estimation&lt;/li>
&lt;li>POCO: Point Convolution for Surface Reconstruction&lt;/li>
&lt;li>Neural Texture Extraction and Distribution for Controllable Person Image Synthesis&lt;/li>
&lt;li>Classification-Then-Grounding: Reformulating Video Scene Graphs As Temporal Bipartite Graphs&lt;/li>
&lt;li>DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis&lt;/li>
&lt;li>ZeroWaste Dataset: Towards Deformable Object Segmentation in Cluttered Scenes&lt;/li>
&lt;li>UNIST: Unpaired Neural Implicit Shape Translation Network&lt;/li>
&lt;li>APES: Articulated Part Extraction From Sprite Sheets&lt;/li>
&lt;li>SPAct: Self-Supervised Privacy Preservation for Action Recognition&lt;/li>
&lt;li>De-Rendering 3D Objects in The Wild&lt;/li>
&lt;li>Global Sensing and Measurements Reuse for Image Compressed Sensing&lt;/li>
&lt;li>Practical Evaluation of Adversarial Robustness Via Adaptive Auto Attack&lt;/li>
&lt;li>Cross-View Transformers for Real-Time Map-View Semantic Segmentation&lt;/li>
&lt;li>Controllable Dynamic Multi-Task Architectures&lt;/li>
&lt;li>FastDOG: Fast Discrete Optimization on GPU&lt;/li>
&lt;li>Focal and Global Knowledge Distillation for Detectors&lt;/li>
&lt;li>Learning To Prompt for Continual Learning&lt;/li>
&lt;li>Human Mesh Recovery From Multiple Shots&lt;/li>
&lt;li>Convolution of Convolution: Let Kernels Spatially Collaborate&lt;/li>
&lt;li>Make It Move: Controllable Image-to-Video Generation With Text Descriptions&lt;/li>
&lt;li>Neural Points: Point Cloud Representation With Neural Fields for Arbitrary Upsampling&lt;/li>
&lt;li>Video-Text Representation Learning Via Differentiable Weak Temporal Alignment&lt;/li>
&lt;li>Bi-Directional Object-Context Prioritization Learning for Saliency Ranking&lt;/li>
&lt;li>Vehicle Trajectory Prediction Works, But Not Everywhere&lt;/li>
&lt;li>MonoDTR: Monocular 3D Object Detection With Depth-Aware Transformer&lt;/li>
&lt;li>Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-Shot Learning&lt;/li>
&lt;li>Generalized Category Discovery&lt;/li>
&lt;li>Contour-Hugging Heatmaps for Landmark Detection&lt;/li>
&lt;li>Voxel Field Fusion for 3D Object Detection&lt;/li>
&lt;li>DisARM: Displacement Aware Relation Module for 3D Detection&lt;/li>
&lt;li>MixFormer: Mixing Features Across Windows and Dimensions&lt;/li>
&lt;li>FineDiving: A Fine-Grained Dataset for Procedure-Aware Action Quality Assessment&lt;/li>
&lt;li>HEAT: Holistic Edge Attention Transformer for Structured Reconstruction&lt;/li>
&lt;li>Mobile-Former: Bridging MobileNet and Transformer&lt;/li>
&lt;li>CycleMix: A Holistic Strategy for Medical Image Segmentation From Scribble Supervision&lt;/li>
&lt;li>VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution&lt;/li>
&lt;li>Towards End-to-End Unified Scene Text Detection and Layout Analysis&lt;/li>
&lt;li>AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation&lt;/li>
&lt;li>ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior&lt;/li>
&lt;li>End-to-End Referring Video Object Segmentation With Multimodal Transformers&lt;/li>
&lt;li>IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo&lt;/li>
&lt;li>Not All Points Are Equal: Learning Highly Efficient Point-Based Detectors for 3D LiDAR Point Clouds&lt;/li>
&lt;li>Detecting Camouflaged Object in Frequency Domain&lt;/li>
&lt;li>SelfRecon: Self Reconstruction Your Digital Avatar From Monocular Video&lt;/li>
&lt;li>Equivariant Point Cloud Analysis Via Learning Orientations for Message Passing&lt;/li>
&lt;li>Node Representation Learning in Graph Via Node-to-Neighbourhood Mutual Information Maximization&lt;/li>
&lt;li>Semi-Supervised Video Semantic Segmentation With Inter-Frame Feature Reconstruction&lt;/li>
&lt;li>Amodal Segmentation Through Out-of-Task and Out-of-Distribution Generalization With A Bayesian Model&lt;/li>
&lt;li>How Well Do Sparse ImageNet Models Transfer?&lt;/li>
&lt;li>REX: Reasoning-Aware and Grounded Explanation&lt;/li>
&lt;li>Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes&lt;/li>
&lt;li>Object-Aware Video-Language Pre-Training for Retrieval&lt;/li>
&lt;li>MAT: Mask-Aware Transformer for Large Hole Image Inpainting&lt;/li>
&lt;li>Align and Prompt: Video-and-Language Pre-Training With Entity Prompts&lt;/li>
&lt;li>MSG-Transformer: Exchanging Local Spatial Information By Manipulating Messenger Tokens&lt;/li>
&lt;li>Cross Modal Retrieval With Querybank Normalisation&lt;/li>
&lt;li>Ray3D: Ray-Based 3D Human Pose Estimation for Monocular Absolute 3D Localization&lt;/li>
&lt;li>ASM-Loc: Action-Aware Segment Modeling for Weakly-Supervised Temporal Action Localization&lt;/li>
&lt;li>Scaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs&lt;/li>
&lt;li>End-to-End Multi-Person Pose Estimation With Transformers&lt;/li>
&lt;li>REGTR: End-to-End Point Cloud Correspondences With Transformers&lt;/li>
&lt;li>Neural 3D Scene Reconstruction With The Manhattan-World Assumption&lt;/li>
&lt;li>V2C: Visual Voice Cloning&lt;/li>
&lt;li>Revisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection&lt;/li>
&lt;li>MAD: A Scalable Dataset for Language Grounding in Videos From Movie Audio Descriptions&lt;/li>
&lt;li>Gait Recognition in The Wild With Dense 3D Representations and A Benchmark&lt;/li>
&lt;li>ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation Via Online Exploration and Synthesis&lt;/li>
&lt;li>QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection&lt;/li>
&lt;li>IDEA-Net: Dynamic 3D Point Cloud Interpolation Via Deep Embedding Alignment&lt;/li>
&lt;li>BEHAVE: Dataset and Method for Tracking Human Object Interactions&lt;/li>
&lt;li>Revisiting Random Channel Pruning for Neural Network Compression&lt;/li>
&lt;li>Generating Diverse and Natural 3D Human Motions From Text&lt;/li>
&lt;li>E-CIR: Event-Enhanced Continuous Intensity Recovery&lt;/li>
&lt;li>Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond&lt;/li>
&lt;li>Symmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose Estimation&lt;/li>
&lt;li>AziNorm: Exploiting The Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception&lt;/li>
&lt;li>Weakly Supervised Rotation-Invariant Aerial Object Detection Network&lt;/li>
&lt;li>Surface Reconstruction From Point Clouds By Learning Predictive Context Priors&lt;/li>
&lt;li>IRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes&lt;/li>
&lt;li>DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation&lt;/li>
&lt;li>Weakly Supervised Temporal Action Localization Via Representative Snippet Knowledge Propagation&lt;/li>
&lt;li>E2EC: An End-to-End Contour-Based Method for High-Quality High-Speed Instance Segmentation&lt;/li>
&lt;li>BatchFormer: Learning To Explore Sample Relationships for Robust Representation Learning&lt;/li>
&lt;li>Self-Supervised Image-Specific Prototype Exploration for Weakly Supervised Semantic Segmentation&lt;/li>
&lt;li>Learning Multi-View Aggregation in The Wild for Large-Scale 3D Semantic Segmentation&lt;/li>
&lt;li>PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition&lt;/li>
&lt;li>Clothes-Changing Person Re-Identification With RGB Modality Only&lt;/li>
&lt;li>Robust Image Forgery Detection Over Online Social Network Shared Images&lt;/li>
&lt;li>Representation Compensation Networks for Continual Semantic Segmentation&lt;/li>
&lt;li>Tracking People By Predicting 3D Appearance, Location and Pose&lt;/li>
&lt;li>Text2Mesh: Text-Driven Neural Stylization for Meshes&lt;/li>
&lt;li>C-CAM: Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image&lt;/li>
&lt;li>Forward Compatible Few-Shot Class-Incremental Learning&lt;/li>
&lt;li>Weakly Supervised Object Localization As Domain Adaption&lt;/li>
&lt;li>Tencent-MVSE: A Large-Scale Benchmark Dataset for Multi-Modal Video Similarity Evaluation&lt;/li>
&lt;li>Deep Orientation-Aware Functional Maps: Tackling Symmetry Issues in Shape Matching&lt;/li>
&lt;li>Tree Energy Loss: Towards Sparsely Annotated Semantic Segmentation&lt;/li>
&lt;li>MatteFormer: Transformer-Based Image Matting Via Prior-Tokens&lt;/li>
&lt;li>Video Shadow Detection Via Spatio-Temporal Interpolation Consistency Training&lt;/li>
&lt;li>Robust and Accurate Superquadric Recovery: A Probabilistic Approach&lt;/li>
&lt;li>Grounding Answers for Visual Questions Asked By Visually Impaired People&lt;/li>
&lt;li>Sparse Instance Activation for Real-Time Instance Segmentation&lt;/li>
&lt;li>VisualGPT: Data-Efficient Adaptation of Pretrained Language Models for Image Captioning&lt;/li>
&lt;li>MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation&lt;/li>
&lt;li>Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis&lt;/li>
&lt;li>Towards Implicit Text-Guided 3D Shape Generation&lt;/li>
&lt;li>SoftCollage: A Differentiable Probabilistic Tree Generator for Image Collage&lt;/li>
&lt;li>Query and Attention Augmentation for Knowledge-Based Explainable Reasoning&lt;/li>
&lt;li>Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality&lt;/li>
&lt;li>Progressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection&lt;/li>
&lt;li>Fine-Grained Object Classification Via Self-Supervised Pose Alignment&lt;/li>
&lt;li>Animal Kingdom: A Large and Diverse Dataset for Animal Behavior Understanding&lt;/li>
&lt;li>Fine-Grained Temporal Contrastive Learning for Weakly-Supervised Temporal Action Localization&lt;/li>
&lt;li>Relieving Long-Tailed Instance Segmentation Via Pairwise Class Balance&lt;/li>
&lt;li>Online Convolutional Re-Parameterization&lt;/li>
&lt;li>Mimicking The Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning&lt;/li>
&lt;li>RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition&lt;/li>
&lt;li>Personalized Image Aesthetics Assessment With Rich Attributes&lt;/li>
&lt;li>Part-Based Pseudo Label Refinement for Unsupervised Person Re-Identification&lt;/li>
&lt;li>HDNet: High-Resolution Dual-Domain Learning for Spectral Compressive Imaging&lt;/li>
&lt;li>OW-DETR: Open-World Detection Transformer&lt;/li>
&lt;li>Learning Deep Implicit Functions for 3D Shapes With Dynamic Code Clouds&lt;/li>
&lt;li>Reversible Vision Transformers&lt;/li>
&lt;li>Amodal Panoptic Segmentation&lt;/li>
&lt;li>Correlation Verification for Image Retrieval&lt;/li>
&lt;li>Temporal Feature Alignment and Mutual Information Maximization for Video-Based Human Pose Estimation&lt;/li>
&lt;li>Self-Supervised Transformers for Unsupervised Object Discovery Using Normalized Cut&lt;/li>
&lt;li>Exploring Structure-Aware Transformer Over Interaction Proposals for Human-Object Interaction Detection&lt;/li>
&lt;li>Decoupled Multi-Task Learning With Cyclical Self-Regulation for Face Parsing&lt;/li>
&lt;li>Glass: Geometric Latent Augmentation for Shape Spaces&lt;/li>
&lt;li>DPICT: Deep Progressive Image Compression Using Trit-Planes&lt;/li>
&lt;li>Text to Image Generation With Semantic-Spatial Aware GAN&lt;/li>
&lt;li>Generalizable Cross-Modality Medical Image Segmentation Via Style Augmentation and Dual Normalization&lt;/li>
&lt;li>Learning To Prompt for Open-Vocabulary Object Detection With Vision-Language Model&lt;/li>
&lt;li>Interactive Segmentation and Visualization for Tiny Objects in Multi-Megapixel Images&lt;/li>
&lt;li>Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture&lt;/li>
&lt;li>Surface Representation for Point Clouds&lt;/li>
&lt;li>Implicit Motion Handling for Video Camouflaged Object Detection&lt;/li>
&lt;li>DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides&lt;/li>
&lt;li>Learning With Twin Noisy Labels for Visible-Infrared Person Re-Identification&lt;/li>
&lt;li>Optical Flow Estimation for Spiking Camera&lt;/li>
&lt;li>GradViT: Gradient Inversion of Vision Transformers&lt;/li>
&lt;li>Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution Via Cycle-Projected Mutual Learning&lt;/li>
&lt;li>Joint Global and Local Hierarchical Priors for Learned Image Compression&lt;/li>
&lt;li>Knowledge Distillation Via The Target-Aware Transformer&lt;/li>
&lt;li>Subspace Adversarial Training&lt;/li>
&lt;li>3D-VField: Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection&lt;/li>
&lt;li>Image Segmentation Using Text and Image Prompts&lt;/li>
&lt;li>AutoMine: An Unmanned Mine Dataset&lt;/li>
&lt;li>Background Activation Suppression for Weakly Supervised Object Localization&lt;/li>
&lt;li>Synthetic Generation of Face Videos With Plethysmograph Physiology&lt;/li>
&lt;li>Hallucinated Neural Radiance Fields in The Wild&lt;/li>
&lt;li>Global Tracking Transformers&lt;/li>
&lt;li>Backdoor Attacks on Self-Supervised Learning&lt;/li>
&lt;li>GMFlow: Learning Optical Flow Via Global Matching&lt;/li>
&lt;li>Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation&lt;/li>
&lt;li>Explore Spatio-Temporal Aggregation for Insubstantial Object Detection: Benchmark Dataset and Baseline&lt;/li>
&lt;li>Graph-Based Spatial Transformer With Memory Replay for Multi-Future Pedestrian Trajectory Prediction&lt;/li>
&lt;li>Scanline Homographies for Rolling-Shutter Plane Absolute Pose&lt;/li>
&lt;li>AdaInt: Learning Adaptive Intervals for 3D Lookup Tables on Real-Time Image Enhancement&lt;/li>
&lt;li>Recurrent Glimpse-Based Decoder for Detection With Transformer&lt;/li>
&lt;li>SimMIM: A Simple Framework for Masked Image Modeling&lt;/li>
&lt;li>Label Matching Semi-Supervised Object Detection&lt;/li>
&lt;li>RegionCLIP: Region-Based Language-Image Pretraining&lt;/li>
&lt;li>Video Frame Interpolation Transformer&lt;/li>
&lt;li>BCOT: A Markerless High-Precision 3D Object Tracking Benchmark&lt;/li>
&lt;li>Omni-DETR: Omni-Supervised Object Detection With Transformers&lt;/li>
&lt;li>Transferable Sparse Adversarial Attack&lt;/li>
&lt;li>CREAM: Weakly Supervised Object Localization Via Class RE-Activation Mapping&lt;/li>
&lt;li>VALHALLA: Visual Hallucination for Machine Translation&lt;/li>
&lt;li>HINT: Hierarchical Neuron Concept Explainer&lt;/li>
&lt;li>Neural Face Identification in A 2D Wireframe Projection of A Manifold Object&lt;/li>
&lt;li>Nonuniform-to-Uniform Quantization: Towards Accurate Quantization Via Generalized Straight-Through Estimation&lt;/li>
&lt;li>An Empirical Study of End-to-End Temporal Action Detection&lt;/li>
&lt;li>Object Localization Under Single Coarse Point Supervision&lt;/li>
&lt;li>Unsupervised Learning of Accurate Siamese Tracking&lt;/li>
&lt;li>Non-Parametric Depth Distribution Modelling Based Depth Inference for Multi-View Stereo&lt;/li>
&lt;li>Equalized Focal Loss for Dense Long-Tailed Object Detection&lt;/li>
&lt;li>DeepDPM: Deep Clustering With An Unknown Number of Clusters&lt;/li>
&lt;li>ISDNet: Integrating Shallow and Deep Networks for Efficient Ultra-High Resolution Segmentation&lt;/li>
&lt;li>Unsupervised Domain Adaptation for Nighttime Aerial Tracking&lt;/li>
&lt;li>RestoreFormer: High-Quality Blind Face Restoration From Undegraded Key-Value Pairs&lt;/li>
&lt;li>Mask-Guided Spectral-Wise Transformer for Efficient Hyperspectral Image Reconstruction&lt;/li>
&lt;li>A Variational Bayesian Method for Similarity Learning in Non-Rigid Image Registration&lt;/li>
&lt;li>Not Just Selection, But Exploration: Online Class-Incremental Continual Learning Via Dual View Consistency&lt;/li>
&lt;li>Coupling Vision and Proprioception for Navigation of Legged Robots&lt;/li>
&lt;li>Exploiting Rigidity Constraints for LiDAR Scene Flow Estimation&lt;/li>
&lt;li>EMOCA: Emotion Driven Monocular Face Capture and Animation&lt;/li>
&lt;li>Quarantine: Sparsity Can Uncover The Trojan Attack Trigger for Free&lt;/li>
&lt;li>AlignQ: Alignment Quantization With ADMM-Based Correlation Preservation&lt;/li>
&lt;li>Interactive Multi-Class Tiny-Object Detection&lt;/li>
&lt;li>Learning From Pixel-Level Noisy Label: A New Perspective for Light Field Saliency Detection&lt;/li>
&lt;li>Multi-View Depth Estimation By Fusing Single-View Depth Probability With Multi-View Geometry&lt;/li>
&lt;li>Slimmable Domain Adaptation&lt;/li>
&lt;li>High-Resolution Image Harmonization Via Collaborative Dual Transformations&lt;/li>
&lt;li>MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation&lt;/li>
&lt;li>Self-Supervised Neural Articulated Shape and Appearance Models&lt;/li>
&lt;li>Topology Preserving Local Road Network Estimation From Single Onboard Camera Image&lt;/li>
&lt;li>Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes&lt;/li>
&lt;li>SwinTextSpotter: Scene Text Spotting Via Better Synergy Between Text Detection and Text Recognition&lt;/li>
&lt;li>Deblur-NeRF: Neural Radiance Fields From Blurry Images&lt;/li>
&lt;li>Whose Track Is It Anyway? Improving Robustness to Tracking Errors With Affinity-Based Trajectory Prediction&lt;/li>
&lt;li>Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation&lt;/li>
&lt;li>Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning&lt;/li>
&lt;li>Blind Image Super-Resolution With Elaborate Degradation Modeling on Noise and Kernel&lt;/li>
&lt;li>Faithful Extreme Rescaling Via Generative Prior Reciprocated Invertible Representations&lt;/li>
&lt;li>Proto2Proto: Can You Recognize The Car, The Way I Do?&lt;/li>
&lt;li>TVConv: Efficient Translation Variant Convolution for Layout-Aware Visual Processing&lt;/li>
&lt;li>Dual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution&lt;/li>
&lt;li>Habitat-Web: Learning Embodied Object-Search Strategies From Human Demonstrations at Scale&lt;/li>
&lt;li>Simple But Effective: CLIP Embeddings for Embodied AI&lt;/li>
&lt;li>NomMer: Nominate Synergistic Context in Vision Transformer for Visual Recognition&lt;/li>
&lt;li>Collaborative Transformers for Grounded Situation Recognition&lt;/li>
&lt;li>CPPF: Towards Robust Category-Level 9D Pose Estimation in The Wild&lt;/li>
&lt;li>Continual Test-Time Domain Adaptation&lt;/li>
&lt;li>Dynamic MLP for Fine-Grained Image Classification By Leveraging Geographical and Temporal Information&lt;/li>
&lt;li>MuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-Based Visual Question Answering&lt;/li>
&lt;li>Fair Contrastive Learning for Facial Attribute Classification&lt;/li>
&lt;li>Directional Self-Supervised Learning for Heavy Image Augmentations&lt;/li>
&lt;li>No-Reference Point Cloud Quality Assessment Via Domain Adaptation&lt;/li>
&lt;li>Comprehending and Ordering Semantics for Image Captioning&lt;/li>
&lt;li>A Large-Scale Comprehensive Dataset and Copy-Overlap Aware Evaluation Protocol for Segment-Level Video Copy Detection&lt;/li>
&lt;li>Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification&lt;/li>
&lt;li>HeadNeRF: A Real-Time NeRF-Based Parametric Head Model&lt;/li>
&lt;li>Occlusion-Robust Face Alignment Using A Viewpoint-Invariant Hierarchical Network Architecture&lt;/li>
&lt;li>IDR: Self-Supervised Image Denoising Via Iterative Data Refinement&lt;/li>
&lt;li>MogFace: Towards A Deeper Appreciation on Face Detection&lt;/li>
&lt;li>Learning Affinity From Attention: End-to-End Weakly-Supervised Semantic Segmentation With Transformers&lt;/li>
&lt;li>CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation&lt;/li>
&lt;li>FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos&lt;/li>
&lt;li>Learning To Detect Mobile Objects From LiDAR Scans Without Labels&lt;/li>
&lt;li>WildNet: Learning Domain Generalized Semantic Segmentation From The Wild&lt;/li>
&lt;li>DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection&lt;/li>
&lt;li>Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation&lt;/li>
&lt;li>Generating Diverse 3D Reconstructions From A Single Occluded Face Image&lt;/li>
&lt;li>Stand-Alone Inter-Frame Attention in Video Models&lt;/li>
&lt;li>Large-Scale Pre-Training for Person Re-Identification With Noisy Labels&lt;/li>
&lt;li>Semantic Segmentation By Early Region Proxy&lt;/li>
&lt;li>LD-ConGR: A Large RGB-D Video Dataset for Long-Distance Continuous Gesture Recognition&lt;/li>
&lt;li>HVH: Learning A Hybrid Neural Volumetric Representation for Dynamic Hair Performance Capture&lt;/li>
&lt;li>Rethinking Visual Geo-Localization for Large-Scale Applications&lt;/li>
&lt;li>The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy&lt;/li>
&lt;li>ViM: Out-of-Distribution With Virtual-Logit Matching&lt;/li>
&lt;li>Class-Aware Contrastive Semi-Supervised Learning&lt;/li>
&lt;li>Ditto: Building Digital Twins of Articulated Objects From Interaction&lt;/li>
&lt;li>Adaptive Early-Learning Correction for Segmentation From Noisy Annotations&lt;/li>
&lt;li>Cross-Domain Correlation Distillation for Unsupervised Domain Adaptation in Nighttime Semantic Segmentation&lt;/li>
&lt;li>RSTT: Real-Time Spatial Temporal Transformer for Space-Time Video Super-Resolution&lt;/li>
&lt;li>Partial Class Activation Attention for Semantic Segmentation&lt;/li>
&lt;li>Multi-Scale Memory-Based Video Deblurring&lt;/li>
&lt;li>A Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching&lt;/li>
&lt;li>Geometric Structure Preserving Warp for Natural Image Stitching&lt;/li>
&lt;li>GOAL: Generating 4D Whole-Body Motion for Hand-Object Grasping&lt;/li>
&lt;li>Conditional Prompt Learning for Vision-Language Models&lt;/li>
&lt;li>Graph Sampling Based Deep Metric Learning for Generalizable Person Re-Identification&lt;/li>
&lt;li>Undoing The Damage of Label Shift for Cross-Domain Semantic Segmentation&lt;/li>
&lt;li>FisherMatch: Semi-Supervised Rotation Regression Via Entropy-Based Filtering&lt;/li>
&lt;li>Affine Medical Image Registration With Coarse-To-Fine Vision Transformer&lt;/li>
&lt;li>A Differentiable Two-Stage Alignment Scheme for Burst Image Reconstruction With Large Shift&lt;/li>
&lt;li>Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes&lt;/li>
&lt;li>Restormer: Efficient Transformer for High-Resolution Image Restoration&lt;/li>
&lt;li>IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation&lt;/li>
&lt;li>Large Loss Matters in Weakly Supervised Multi-Label Classification&lt;/li>
&lt;li>Neural Inertial Localization&lt;/li>
&lt;li>GraftNet: Towards Domain Generalized Stereo Matching With A Broad-Spectrum and Task-Oriented Feature&lt;/li>
&lt;li>VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning&lt;/li>
&lt;li>Catching Both Gray and Black Swans: Open-Set Supervised Anomaly Detection&lt;/li>
&lt;li>MLSLT: Towards Multilingual Sign Language Translation&lt;/li>
&lt;li>Towards An End-to-End Framework for Flow-Guided Video Inpainting&lt;/li>
&lt;li>Contrastive Test-Time Adaptation&lt;/li>
&lt;li>MotionAug: Augmentation With Physical Correction for Human Motion Prediction&lt;/li>
&lt;li>Modeling Indirect Illumination for Inverse Rendering&lt;/li>
&lt;li>TransWeather: Transformer-Based Restoration of Images Degraded By Adverse Weather Conditions&lt;/li>
&lt;li>H2FA R-CNN: Holistic and Hierarchical Feature Alignment for Cross-Domain Weakly Supervised Object Detection&lt;/li>
&lt;li>P3Depth: Monocular Depth Estimation With A Piecewise Planarity Prior&lt;/li>
&lt;li>GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection&lt;/li>
&lt;li>Simple Multi-Dataset Detection&lt;/li>
&lt;li>Proactive Image Manipulation Detection&lt;/li>
&lt;li>StyTr2: Image Style Transfer With Transformers&lt;/li>
&lt;li>Global Matching With Overlapping Attention for Optical Flow Estimation&lt;/li>
&lt;li>Language As Queries for Referring Video Object Segmentation&lt;/li>
&lt;li>MViTv2: Improved Multiscale Vision Transformers for Classification and Detection&lt;/li>
&lt;li>Audio-Visual Generalised Zero-Shot Learning With Cross-Modal Attention and Language&lt;/li>
&lt;li>Rethinking Efficient Lane Detection Via Curve Modeling&lt;/li>
&lt;li>Self-Supervised Arbitrary-Scale Point Clouds Upsampling Via Implicit Neural Representation&lt;/li>
&lt;li>Co-Advise: Cross Inductive Bias Distillation&lt;/li>
&lt;li>AdaMixer: A Fast-Converging Query-Based Object Detector&lt;/li>
&lt;li>DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification&lt;/li>
&lt;li>BEVT: BERT Pretraining of Video Transformers&lt;/li>
&lt;li>Deep Generalized Unfolding Networks for Image Restoration&lt;/li>
&lt;li>VISOLO: Grid-Based Space-Time Aggregation for Efficient Online Video Instance Segmentation&lt;/li>
&lt;li>Deep Unlearning Via Randomized Conditionally Independent Hessians&lt;/li>
&lt;li>Revisiting Skeleton-Based Action Recognition&lt;/li>
&lt;li>Stereo Depth From Events Cameras: Concentrate and Focus on The Future&lt;/li>
&lt;li>A Simple Data Mixing Prior for Improving Self-Supervised Learning&lt;/li>
&lt;li>Knowledge Distillation As Efficient Pre-Training: Faster Convergence, Higher Data-Efficiency, and Better Transferability&lt;/li>
&lt;li>BigDL 2.0: Seamless Scaling of AI Pipelines From Laptops to Distributed Cluster&lt;/li>
&lt;li>Attentive Fine-Grained Structured Sparsity for Image Restoration&lt;/li>
&lt;li>Learning Fair Classifiers With Partially Annotated Group Labels&lt;/li>
&lt;li>NightLab: A Dual-Level Architecture With Hardness Detection for Segmentation at Night&lt;/li>
&lt;li>Constrained Few-Shot Class-Incremental Learning&lt;/li>
&lt;li>Threshold Matters in WSSS: Manipulating The Activation for The Robust and Accurate Segmentation Model Against Thresholds&lt;/li>
&lt;li>TransMVSNet: Global Context-Aware Multi-View Stereo Network With Transformers&lt;/li>
&lt;li>DPGEN: Differentially Private Generative Energy-Guided Network for Natural Image Synthesis&lt;/li>
&lt;li>The Majority Can Help The Minority: Context-Rich Minority Oversampling for Long-Tailed Classification&lt;/li>
&lt;li>IntentVizor: Towards Generic Query Guided Interactive Video Summarization&lt;/li>
&lt;li>Shape-Invariant 3D Adversarial Point Clouds&lt;/li>
&lt;li>Bootstrapping ViTs: Towards Liberating Vision Transformers From Pre-Training&lt;/li>
&lt;li>PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents&lt;/li>
&lt;li>Meta-Attention for ViT-Backed Continual Learning&lt;/li>
&lt;li>DST: Dynamic Substitute Training for Data-Free Black-Box Attack&lt;/li>
&lt;li>Unified Contrastive Learning in Image-Text-Label Space&lt;/li>
&lt;li>Unsupervised Pre-Training for Temporal Action Localization Tasks&lt;/li>
&lt;li>Look Outside The Room: Synthesizing A Consistent Long-Term 3D Scene Video From A Single Image&lt;/li>
&lt;li>High-Fidelity Human Avatars From A Single RGB Camera&lt;/li>
&lt;li>Multiview Transformers for Video Recognition&lt;/li>
&lt;li>How Good Is Aesthetic Ability of A Fashion Model?&lt;/li>
&lt;li>Deformation and Correspondence Aware Unsupervised Synthetic-to-Real Scene Flow Estimation for Point Clouds&lt;/li>
&lt;li>Sequential Voting With Relational Box Fields for Active Object Detection&lt;/li>
&lt;li>Semantic-Aware Auto-Encoders for Self-Supervised Representation Learning&lt;/li>
&lt;li>Consistency Learning Via Decoding Path Augmentation for Transformers in Human Object Interaction Detection&lt;/li>
&lt;li>Consistent Explanations By Contrastive Learning&lt;/li>
&lt;li>Hierarchical Modular Network for Video Captioning&lt;/li>
&lt;li>Depth Estimation By Combining Binocular Stereo and Monocular Structured-Light&lt;/li>
&lt;li>Salient-to-Broad Transition for Video Person Re-Identification&lt;/li>
&lt;li>DeeCap: Dynamic Early Exiting for Efficient Image Captioning&lt;/li>
&lt;li>RepMLPNet: Hierarchical Vision MLP With Re-Parameterized Locality&lt;/li>
&lt;li>DR.VIC: Decomposition and Reasoning for Video Individual Counting&lt;/li>
&lt;li>ARCS: Accurate Rotation and Correspondence Search&lt;/li>
&lt;li>Learning To Anticipate Future With Dynamic Context Removal&lt;/li>
&lt;li>GCFSR: A Generative and Controllable Face Super Resolution Method Without Facial and GAN Priors&lt;/li>
&lt;li>On The Integration of Self-Attention and Convolution&lt;/li>
&lt;li>Domain Adaptation on Point Clouds Via Geometry-Aware Implicits&lt;/li>
&lt;li>GroupViT: Semantic Segmentation Emerges From Text Supervision&lt;/li>
&lt;li>DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation&lt;/li>
&lt;li>BppAttack: Stealthy and Efficient Trojan Attacks Against Deep Neural Networks Via Image Quantization and Contrastive Adversarial Learning&lt;/li>
&lt;li>Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation&lt;/li>
&lt;li>Towards Better Plasticity-Stability Trade-Off in Incremental Learning: A Simple Linear Connector&lt;/li>
&lt;li>Topology-Preserving Shape Reconstruction and Registration Via Neural Diffeomorphic Flow&lt;/li>
&lt;li>Segment and Complete: Defending Object Detectors Against Adversarial Patch Attacks With Robust Patch Detection&lt;/li>
&lt;li>MAXIM: Multi-Axis MLP for Image Processing&lt;/li>
&lt;li>Learning Part Segmentation Through Unsupervised Domain Adaptation From Synthetic Vehicles&lt;/li>
&lt;li>PSTR: End-to-End One-Step Person Search With Transformers&lt;/li>
&lt;li>NFormer: Robust Person Re-Identification With Neighbor Transformer&lt;/li>
&lt;li>Bridging Global Context Interactions for High-Fidelity Image Completion&lt;/li>
&lt;li>SwinBERT: End-to-End Transformers With Sparse Attention for Video Captioning&lt;/li>
&lt;li>Not All Tokens Are Equal: Human-Centric Visual Analysis Via Token Clustering Transformer&lt;/li>
&lt;li>Temporally Efficient Vision Transformer for Video Instance Segmentation&lt;/li>
&lt;li>The Devil Is in The Margin: Margin-Based Label Smoothing for Network Calibration&lt;/li>
&lt;li>NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks&lt;/li>
&lt;li>WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation&lt;/li>
&lt;li>Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding&lt;/li>
&lt;li>E2(GO)MOTION: Motion Augmented Event Stream for Egocentric Action Recognition&lt;/li>
&lt;li>OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization&lt;/li>
&lt;li>OnePose: One-Shot Object Pose Estimation Without CAD Models&lt;/li>
&lt;li>Rethinking Minimal Sufficient Representation in Contrastive Learning&lt;/li>
&lt;li>Scalable Penalized Regression for Noise Detection in Learning With Noisy Labels&lt;/li>
&lt;li>Federated Class-Incremental Learning&lt;/li>
&lt;li>Show, Deconfound and Tell: Image Captioning With Causal Inference&lt;/li>
&lt;li>MobRecon: Mobile-Friendly Hand Mesh Reconstruction From Monocular Image&lt;/li>
&lt;li>Parameter-Free Online Test-Time Adaptation&lt;/li>
&lt;li>SIGMA: Semantic-Complete Graph Matching for Domain Adaptive Object Detection&lt;/li>
&lt;li>No Pain, Big Gain: Classify Dynamic Point Cloud Sequences With Static Models By Fitting Feature-Level Space-Time Surfaces&lt;/li>
&lt;li>HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for Snapshot Compressive Imaging&lt;/li>
&lt;li>Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space&lt;/li>
&lt;li>Learning To Estimate Robust 3D Human Mesh From In-the-Wild Crowded Scenes&lt;/li>
&lt;li>Detecting Deepfakes With Self-Blended Images&lt;/li>
&lt;li>Implicit Sample Extension for Unsupervised Person Re-Identification&lt;/li>
&lt;li>Energy-Based Latent Aligner for Incremental Learning&lt;/li>
&lt;li>Towards Semi-Supervised Deep Facial Expression Recognition With An Adaptive Confidence Margin&lt;/li>
&lt;li>Group R-CNN for Weakly Semi-Supervised Object Detection With Points&lt;/li>
&lt;li>Weakly-Supervised Action Transition Learning for Stochastic Human Motion Prediction&lt;/li>
&lt;li>Hybrid Relation Guided Set Matching for Few-Shot Action Recognition&lt;/li>
&lt;li>Cross-Patch Dense Contrastive Learning for Semi-Supervised Segmentation of Cellular Nuclei in Histopathologic Images&lt;/li>
&lt;li>Generalized Binary Search Network for Highly-Efficient Multi-View Stereo&lt;/li>
&lt;li>SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation&lt;/li>
&lt;li>FlexIT: Towards Flexible Semantic Image Translation&lt;/li>
&lt;li>CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow&lt;/li>
&lt;li>BoxeR: Box-Attention for 2D and 3D Transformers&lt;/li>
&lt;li>Neural Architecture Search With Representation Mutual Information&lt;/li>
&lt;li>Can Neural Nets Learn The Same Model Twice? Investigating Reproducibility and Double Descent From The Decision Boundary Perspective&lt;/li>
&lt;li>Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction&lt;/li>
&lt;li>Multi-View Transformer for 3D Visual Grounding&lt;/li>
&lt;li>Structured Sparse R-CNN for Direct Scene Graph Generation&lt;/li>
&lt;li>BARC: Learning To Regress 3D Dog Shape From Images By Exploiting Breed Information&lt;/li>
&lt;li>PCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models&lt;/li>
&lt;li>Towards Understanding Adversarial Robustness of Optical Flow Networks&lt;/li>
&lt;li>Lifelong Graph Learning&lt;/li>
&lt;li>Hypergraph-Induced Semantic Tuplet Loss for Deep Metric Learning&lt;/li>
&lt;li>Computing Wasserstein-p Distance Between Images With Linear Cost&lt;/li>
&lt;li>Unsupervised Representation Learning for Binary Networks By Joint Classifier Learning&lt;/li>
&lt;li>Large-Scale Video Panoptic Segmentation in The Wild: A Benchmark&lt;/li>
&lt;li>GrainSpace: A Large-Scale Dataset for Fine-Grained and Domain-Adaptive Recognition of Cereal Grains&lt;/li>
&lt;li>Learning Modal-Invariant and Temporal-Memory for Video-Based Visible-Infrared Person Re-Identification&lt;/li>
&lt;li>MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning&lt;/li>
&lt;li>Oriented RepPoints for Aerial Object Detection&lt;/li>
&lt;li>Weakly Supervised Temporal Sentence Grounding With Gaussian-Based Contrastive Proposal Learning&lt;/li>
&lt;li>Low-Resource Adaptation for Personalized Co-Speech Gesture Generation&lt;/li>
&lt;li>Task-Specific Inconsistency Alignment for Domain Adaptive Object Detection&lt;/li>
&lt;li>MS2DG-Net: Progressive Correspondence Learning Via Multiple Sparse Semantics Dynamic Graph&lt;/li>
&lt;li>Learning To Listen: Modeling Non-Deterministic Dyadic Facial Motion&lt;/li>
&lt;li>Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation From Monocular Video&lt;/li>
&lt;li>MixFormer: End-to-End Tracking With Iterative Mixed Attention&lt;/li>
&lt;li>Plenoxels: Radiance Fields Without Neural Networks&lt;/li>
&lt;li>Selective-Supervised Contrastive Learning With Noisy Labels&lt;/li>
&lt;li>SimT: Handling Open-Set Noise for Domain Adaptive Semantic Segmentation&lt;/li>
&lt;li>Frequency-Driven Imperceptible Adversarial Attack on Semantic Similarity&lt;/li>
&lt;li>Video Demoireing With Relation-Based Temporal Consistency&lt;/li>
&lt;li>Industrial Style Transfer With Large-Scale Geometric Warping and Content Preservation&lt;/li>
&lt;li>Modeling Image Composition for Complex Scene Generation&lt;/li>
&lt;li>Decoupling Zero-Shot Semantic Segmentation&lt;/li>
&lt;li>Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions&lt;/li>
&lt;li>Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting The Adversarial Transferability&lt;/li>
&lt;li>IFOR: Iterative Flow Minimization for Robotic Object Rearrangement&lt;/li>
&lt;li>Zero Experience Required: Plug &amp;amp; Play Modular Transfer Learning for Semantic Visual Navigation&lt;/li>
&lt;li>TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation&lt;/li>
&lt;li>The Wanderings of Odysseus in 3D Scenes&lt;/li>
&lt;li>All-in-One Image Restoration for Unknown Corruption&lt;/li>
&lt;li>PUMP: Pyramidal and Uniqueness Matching Priors for Unsupervised Learning of Local Descriptors&lt;/li>
&lt;li>MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video&lt;/li>
&lt;li>RCP: Recurrent Closest Point for Point Cloud&lt;/li>
&lt;li>A Dual Weighting Label Assignment Scheme for Object Detection&lt;/li>
&lt;li>Hyperbolic Vision Transformers: Combining Improvements in Metric Learning&lt;/li>
&lt;li>Instance-Aware Dynamic Neural Network Quantization&lt;/li>
&lt;li>Exploring Effective Data for Surrogate Training Towards Black-Box Attack&lt;/li>
&lt;li>JRDB-Act: A Large-Scale Dataset for Spatio-Temporal Action, Social Group and Activity Detection&lt;/li>
&lt;li>Investigating Top-k White-Box and Transferable Black-Box Attack&lt;/li>
&lt;li>Decoupling and Recoupling Spatiotemporal Representation for RGB-D-Based Motion Recognition&lt;/li>
&lt;li>A Self-Supervised Descriptor for Image Copy Detection&lt;/li>
&lt;li>Negative-Aware Attention Framework for Image-Text Matching&lt;/li>
&lt;li>An Image Patch Is A Wave: Phase-Aware Vision MLP&lt;/li>
&lt;li>Shunted Self-Attention Via Multi-Scale Token Aggregation&lt;/li>
&lt;li>Unified Multivariate Gaussian Mixture for Efficient Neural Image Compression&lt;/li>
&lt;li>Recurrent Variational Network: A Deep Learning Inverse Problem Solver Applied to The Task of Accelerated MRI Reconstruction&lt;/li>
&lt;li>Surpassing The Human Accuracy: Detecting Gallbladder Cancer From USG Images With Curriculum Learning&lt;/li>
&lt;li>Appearance and Structure Aware Robust Deep Visual Graph Matching: Attack, Defense and Beyond&lt;/li>
&lt;li>TrackFormer: Multi-Object Tracking With Transformers&lt;/li>
&lt;li>3D Shape Reconstruction From 2D Images With Disentangled Attribute Flow&lt;/li>
&lt;li>Feature Statistics Mixing Regularization for Generative Adversarial Networks&lt;/li>
&lt;li>OpenTAL: Towards Open Set Temporal Action Localization&lt;/li>
&lt;li>Self-Supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection&lt;/li>
&lt;li>Ego4D: Around The World in 3,000 Hours of Egocentric Video&lt;/li>
&lt;li>Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis&lt;/li>
&lt;li>Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data&lt;/li>
&lt;li>DAD-3DHeads: A Large-Scale Dense, Accurate and Diverse Dataset for 3D Head Alignment From A Single Image&lt;/li>
&lt;li>Reconstructing Surfaces for Sparse Point Clouds With On-Surface Priors&lt;/li>
&lt;li>VCLIMB: A Novel Video Class Incremental Learning Benchmark&lt;/li>
&lt;li>Robust Equivariant Imaging: A Fully Unsupervised Framework for Learning To Image From Noisy and Partial Measurements&lt;/li>
&lt;li>ST++: Make Self-Training Work Better for Semi-Supervised Semantic Segmentation&lt;/li>
&lt;li>Interacting Attention Graph for Single Image Two-Hand Reconstruction&lt;/li>
&lt;li>Rope3D: The Roadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task&lt;/li>
&lt;li>Cross-Image Relational Knowledge Distillation for Semantic Segmentation&lt;/li>
&lt;li>Towards Layer-Wise Image Vectorization&lt;/li>
&lt;li>Scenic: A JAX Library for Computer Vision Research and Beyond&lt;/li>
&lt;li>Real-Time Object Detection for Streaming Perception&lt;/li>
&lt;li>VisualHow: Multimodal Problem Solving&lt;/li>
&lt;li>Spatial Commonsense Graph for Object Localisation in Partial Scenes&lt;/li>
&lt;li>OSSGAN: Open-Set Semi-Supervised Image Generation&lt;/li>
&lt;li>Bi-Level Alignment for Cross-Domain Crowd Counting&lt;/li>
&lt;li>ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation&lt;/li>
&lt;li>Efficient Multi-View Stereo By Iterative Dynamic Cost Volume&lt;/li>
&lt;li>TransEditor: Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing&lt;/li>
&lt;li>Use All The Labels: A Hierarchical Multi-Label Contrastive Learning Framework&lt;/li>
&lt;li>SGTR: End-to-End Scene Graph Generation With Transformer&lt;/li>
&lt;li>Decoupled Knowledge Distillation&lt;/li>
&lt;li>DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection&lt;/li>
&lt;li>Reusing The Task-Specific Classifier As A Discriminator: Discriminator-Free Adversarial Domain Adaptation&lt;/li>
&lt;li>Show Me What and Tell Me How: Video Synthesis Via Multimodal Conditioning&lt;/li>
&lt;li>SIMBAR: Single Image-Based Scene Relighting for Effective Data Augmentation for Automated Driving Vision Tasks&lt;/li>
&lt;li>Multi-Label Classification With Partial Annotations Using Class-Aware Selective Loss&lt;/li>
&lt;li>CADTransformer: Panoptic Symbol Spotting Transformer for CAD Drawings&lt;/li>
&lt;li>IntraQ: Learning Synthetic Images With Intra-Class Heterogeneity for Zero-Shot Network Quantization&lt;/li>
&lt;li>I M Avatar: Implicit Morphable Head Avatars From Videos&lt;/li>
&lt;li>Weakly-Supervised Metric Learning With Cross-Module Communications for The Classification of Anterior Chamber Angle Images&lt;/li>
&lt;li>A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-Resolution&lt;/li>
&lt;li>Multi-Modal Dynamic Graph Transformer for Visual Grounding&lt;/li>
&lt;li>Geometric Transformer for Fast and Robust Point Cloud Registration&lt;/li>
&lt;li>UMT: Unified Multi-Modal Transformers for Joint Video Moment Retrieval and Highlight Detection&lt;/li>
&lt;li>Demystifying The Neural Tangent Kernel From A Practical Perspective: Can It Be Trusted for Neural Architecture Search Without Training?&lt;/li>
&lt;li>The Devil Is in The Details: Window-Based Attention for Image Compression&lt;/li>
&lt;li>DiLiGenT102: A Photometric Stereo Benchmark Dataset With Controlled Shape and Material Variation&lt;/li>
&lt;li>PolyWorld: Polygonal Building Extraction With Graph Neural Networks in Satellite Images&lt;/li>
&lt;li>Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation&lt;/li>
&lt;li>Spatio-Temporal Relation Modeling for Few-Shot Action Recognition&lt;/li>
&lt;li>Multi-Person Extreme Motion Prediction&lt;/li>
&lt;li>B-DARTS: Beta-Decay Regularization for Differentiable Architecture Search&lt;/li>
&lt;li>CMT: Convolutional Neural Networks Meet Vision Transformers&lt;/li>
&lt;li>KNN Local Attention for Image Restoration&lt;/li>
&lt;li>Predict, Prevent, and Evaluate: Disentangled Text-Driven Image Manipulation Empowered By Pre-Trained Vision-Language Model&lt;/li>
&lt;li>TransMix: Attend To Mix for Vision Transformers&lt;/li>
&lt;li>Inertia-Guided Flow Completion and Style Fusion for Video Inpainting&lt;/li>
&lt;li>Long-Tailed Visual Recognition Via Gaussian Clouded Logit Adjustment&lt;/li>
&lt;li>Image Animation With Perturbed Masks&lt;/li>
&lt;li>Domain Generalization Via Shuffled Style Assembly for Face Anti-Spoofing&lt;/li>
&lt;li>OcclusionFusion: Occlusion-Aware Motion Estimation for Real-Time Dynamic 3D Reconstruction&lt;/li>
&lt;li>MonoScene: Monocular 3D Semantic Scene Completion&lt;/li>
&lt;li>AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition&lt;/li>
&lt;li>Continuous Scene Representations for Embodied AI&lt;/li>
&lt;li>Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds&lt;/li>
&lt;li>Non-Probability Sampling Network for Stochastic Human Trajectory Prediction&lt;/li>
&lt;li>ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning&lt;/li>
&lt;li>Human-Aware Object Placement for Visual Environment Reconstruction&lt;/li>
&lt;li>X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval&lt;/li>
&lt;li>RAMA: A Rapid Multicut Algorithm on GPU&lt;/li>
&lt;li>Adversarial Parametric Pose Prior&lt;/li>
&lt;li>Mask Transfiner for High-Quality Instance Segmentation&lt;/li>
&lt;li>It Is Okay To Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning By Contrastive Data Collection&lt;/li>
&lt;li>DiRA: Discriminative, Restorative, and Adversarial Learning for Self-Supervised Medical Image Analysis&lt;/li>
&lt;li>Event-Based Video Reconstruction Via Potential-Assisted Spiking Neural Network&lt;/li>
&lt;li>YouMVOS: An Actor-Centric Multi-Shot Video Object Segmentation Dataset&lt;/li>
&lt;li>DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation&lt;/li>
&lt;li>Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification&lt;/li>
&lt;li>Self-Supervised Video Transformer&lt;/li>
&lt;li>AutoRF: Learning 3D Object Radiance Fields From Single View Observations&lt;/li>
&lt;li>Coopernaut: End-to-End Driving With Cooperative Perception for Networked Vehicles&lt;/li>
&lt;li>TubeR: Tubelet Transformer for Video Action Detection&lt;/li>
&lt;li>MUM: Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection&lt;/li>
&lt;li>Learning Non-Target Knowledge for Few-Shot Semantic Segmentation&lt;/li>
&lt;li>UKPGAN: A General Self-Supervised Keypoint Detector&lt;/li>
&lt;li>Raw High-Definition Radar for Multi-Task Learning&lt;/li>
&lt;li>Coarse-To-Fine Feature Mining for Video Semantic Segmentation&lt;/li>
&lt;li>Compressing Models With Few Samples: Mimicking Then Replacing&lt;/li>
&lt;li>PokeBNN: A Binary Pursuit of Lightweight Accuracy&lt;/li>
&lt;li>Zoom in and Out: A Mixed-Scale Triplet Network for Camouflaged Object Detection&lt;/li>
&lt;li>SOMSI: Spherical Novel View Synthesis With Soft Occlusion Multi-Sphere Images&lt;/li>
&lt;li>EMScore: Evaluating Video Captioning Via Coarse-Grained and Fine-Grained Embedding Matching&lt;/li>
&lt;li>PoseTriplet: Co-Evolving 3D Human Pose Estimation, Imitation, and Hallucination Under Self-Supervision&lt;/li>
&lt;li>Group Contextualization for Video Recognition&lt;/li>
&lt;li>Single-Domain Generalized Object Detection in Urban Scene Via Cyclic-Disentangled Self-Distillation&lt;/li>
&lt;li>L2G: A Simple Local-to-Global Knowledge Transfer Framework for Weakly Supervised Semantic Segmentation&lt;/li>
&lt;li>Self-Augmented Unpaired Image Dehazing Via Density and Depth Decomposition&lt;/li>
&lt;li>Neural 3D Video Synthesis From Multi-View Video&lt;/li>
&lt;li>SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation&lt;/li>
&lt;li>Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search&lt;/li>
&lt;li>HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening&lt;/li>
&lt;li>Structure-Aware Flow Generation for Human Body Reshaping&lt;/li>
&lt;li>Learning To Answer Questions in Dynamic Audio-Visual Scenarios&lt;/li>
&lt;li>Synthetic Aperture Imaging With Events and Frames&lt;/li>
&lt;li>MonoGround: Detecting Monocular 3D Objects From The Ground&lt;/li>
&lt;li>Deep Visual Geo-Localization Benchmark&lt;/li>
&lt;li>StyleGAN-V: A Continuous Video Generator With The Price, Image Quality and Perks of StyleGAN2&lt;/li>
&lt;li>LISA: Learning Implicit Shape and Appearance of Hands&lt;/li>
&lt;li>Iterative Deep Homography Estimation&lt;/li>
&lt;li>Learned Queries for Efficient Local Attention&lt;/li>
&lt;li>Colar: Effective and Efficient Online Action Detection By Consulting Exemplars&lt;/li>
&lt;li>SoftGroup for 3D Instance Segmentation on Point Clouds&lt;/li>
&lt;li>MVS2D: Efficient Multi-View Stereo Via Attention-Driven 2D Convolutions&lt;/li>
&lt;li>Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance Segmentation Via Semantic Knowledge Transfer and Self-Refinement&lt;/li>
&lt;li>Deep Constrained Least Squares for Blind Image Super-Resolution&lt;/li>
&lt;li>EDTER: Edge Detection With Transformer&lt;/li>
&lt;li>AirObject: A Temporally Evolving Graph Embedding for Object Identification&lt;/li>
&lt;li>From Representation to Reasoning: Towards Both Evidence and Commonsense Reasoning for Video Question-Answering&lt;/li>
&lt;li>Semantic-Aware Domain Generalized Segmentation&lt;/li>
&lt;li>DanceTrack: Multi-Object Tracking in Uniform Appearance and Diverse Motion&lt;/li>
&lt;li>UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection&lt;/li>
&lt;li>AKB-48: A Real-World Articulated Object Knowledge Base&lt;/li>
&lt;li>Stratified Transformer for 3D Point Cloud Segmentation&lt;/li>
&lt;li>Aug-NeRF: Training Stronger Neural Radiance Fields With Triple-Level Physically-Grounded Augmentations&lt;/li>
&lt;li>Semantic-Shape Adaptive Feature Modulation for Semantic Image Synthesis&lt;/li>
&lt;li>Day-to-Night Image Synthesis for Training Nighttime Neural ISPs Literature ~Highlight: To address this problem, we propose a method that synthesizes nighttime images from daytime images.&lt;/li>
&lt;/ol>
&lt;h2 id="references">References&lt;a class="td-heading-self-link" href="#references" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>&lt;a href="https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/">https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Author&lt;/strong>&lt;br>
Dr Hari Thapliyaal&lt;br>
dasarpai.com &lt;br>
linkedin.com/in/harithapliyal&lt;/p></description></item><item><title>Comprehensive Glossary of LLM, Deep Learning, NLP, and CV Terminology</title><link>https://dasarpai.github.io/dsblog/Comprehensive-Glossary-of-LLM/</link><pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Comprehensive-Glossary-of-LLM/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6089-Comprehensive-Glossary-of-LLM.jpg" alt="Comprehensive Glossary of LLM">&lt;/p>
&lt;h1 id="comprehensive-glossary-of-llm">Comprehensive Glossary of LLM&lt;a class="td-heading-self-link" href="#comprehensive-glossary-of-llm" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>I am developing this Glossary slowly at my own pace. Content on this page keep changing. Better definition, better explaination are part of my learing, my evolution and advancement in the field of Deep Learning and Machine Learning. As of Aug'23 the terms are not in any order therefore if you are look for any specific term you can search on the page. When I will have 50+ terms on this page then I will try to sort them on some attribute of these terms.&lt;/p></description></item><item><title>Machine Learning Metrics</title><link>https://dasarpai.github.io/dsblog/Machine-Learning-Metrics/</link><pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Machine-Learning-Metrics/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6092-Machine-Learning-Metrics.jpg" alt="Comprehensive Glossary of LLM">&lt;/p>
&lt;h1 id="machine-learning-metrics">Machine Learning Metrics&lt;a class="td-heading-self-link" href="#machine-learning-metrics" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>In Machine Learning projects whether classical machine learning, deep learning, computer vision, speech processing, NLP, or any other ML project we keep building different models with different datasets. But how to know that for a particular problem model X is the best one? For that, we need to evaluate these models against certain metrics. What metrics we pick, depends upon the problem statement, data imbalance, type of data, etc. In this article, we will explore an exhaustive list of ML Metrics.&lt;/p></description></item><item><title>Paper-Summary- A Survey Paper# Pretrained Language Models for Text Generation</title><link>https://dasarpai.github.io/dsblog/rps-Pretrained-Language-Models-for-Text-Generation/</link><pubDate>Fri, 18 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/rps-Pretrained-Language-Models-for-Text-Generation/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6088-rps-Pretrained-Language-Models-for-Text-Generation.jpg" alt="Pretrained Language Models for Text Generation">&lt;/p>
&lt;p>&lt;strong>Paper Name :- Pretrained Language Models for Text Generation: A Survey&lt;/strong>&lt;br>
Typer of Paper:- Survey Paper &lt;br>
&lt;a href="https://arxiv.org/abs/2105.10311">Paper URL&lt;/a>&lt;br>
Paper title of the citations mentioned can be found at &lt;a href="../../dsblog/aip">AI Papers with Heading&lt;/a>. Use citation code to locate.&lt;/p></description></item><item><title>What is LLM</title><link>https://dasarpai.github.io/dsblog/what-is-llm/</link><pubDate>Fri, 18 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/what-is-llm/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6087-What-is-LLM.jpg" alt="What is LLM">&lt;/p>
&lt;h1 id="what-is-large-language-model">What is Large Language Model&lt;a class="td-heading-self-link" href="#what-is-large-language-model" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>LLM stands for &lt;strong>Large Language Model&lt;/strong>. It is a type of artificial intelligence (AI) model that is trained on a massive dataset of text and code. This allows LLMs to learn the statistical relationships between words and phrases, and to generate text that is similar to the text that they were trained on.&lt;/p></description></item><item><title>NLP Tasks</title><link>https://dasarpai.github.io/dsblog/nlp-tasks/</link><pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/nlp-tasks/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6085-NLP-Tasks.jpg" alt="NLP Tasks">&lt;/p>
&lt;h1 id="nlp-tasks">NLP Tasks&lt;a class="td-heading-self-link" href="#nlp-tasks" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Processing words of any language and driving some meaning from these is as old as the human language. Recently, AI momentum is taking on many of these language-processing tasks. Here is the summary of these NLP tasks, this list is continuously growing. Researchers keep creating a dataset for these tasks in different languages. Other researchers keep devising new ways to solve these tasks with better performance. They come up with a new architecture, a new set of hyperparameters, a new pipeline, etc. In summary, as of today, there are around 55 tasks. Hundreds of datasets and research papers exist around these. You can check on &lt;a href="https://paperswithcode.com/">PaperWithCode&lt;/a> or &lt;a href="https://huggingface.co/">Hggingface&lt;/a>&lt;/p></description></item><item><title>Model Tuning with VertexAI</title><link>https://dasarpai.github.io/dsblog/Model-Tuning-with-VertexAI/</link><pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Model-Tuning-with-VertexAI/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6081-Model-Tuning-with-VertexAI.jpg" alt="Model Tuning with VertexAI">&lt;/p>
&lt;h1 id="tuning-large-language-model-with-vertexai">Tuning Large Language Model with VertexAI&lt;a class="td-heading-self-link" href="#tuning-large-language-model-with-vertexai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="why-model-tuning">Why Model Tuning?&lt;a class="td-heading-self-link" href="#why-model-tuning" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Tuning is required when you want the model to learn something niche or specific that deviates from general language patterns.&lt;/p></description></item><item><title>AI Product and Services from Google, Azure and AWS</title><link>https://dasarpai.github.io/dsblog/AI-Product-and-Services-from-Google-Azure-and-AWS/</link><pubDate>Thu, 20 Jul 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/AI-Product-and-Services-from-Google-Azure-and-AWS/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6078-AI-Product-and-Services-from-Google-Azure-and-AWS.jpg" alt="AI Product and Services from Google, Azure and AWS">&lt;/p>
&lt;h1 id="ai-product-and-services-from-google-azure-and-aws">AI Product and Services from Google, Azure and AWS&lt;a class="td-heading-self-link" href="#ai-product-and-services-from-google-azure-and-aws" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Sno&lt;/th>
 &lt;th>Azure&lt;/th>
 &lt;th>Google&lt;/th>
 &lt;th>AWS&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>1.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/anomaly-detector/">Anomaly Detector:&lt;/a> Easily add anomaly detection capabilities to your apps.&lt;/td>
 &lt;td>AutoML: Custom low-code models &lt;a href="https://cloud.google.com/vertex-ai/docs/training/training">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/a2i/home?region=us-east-1">Amazon Augmented AI&lt;/a> : Easily implement human review of machine learning predictions&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>2.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/bot-services/">Azure Bot Service:&lt;/a> Build conversational AI experiences for your customers&lt;/td>
 &lt;td>Cloud TPU: Hardware acceleration for ML &lt;a href="https://cloud.google.com/tpu/">Link&lt;/a> &lt;a href="https://cloud.google.com/tpu/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1">Amazon Bedrock&lt;/a> : The easiest way to build and scale generative AI applications with foundation models (FMs).&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>3.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/search/">Azure Cognitive Search:&lt;/a> Enterprise scale search for app development&lt;/td>
 &lt;td>Cloud Translation: Language detection and translation &lt;a href="https://cloud.google.com/translate/">Link&lt;/a> &lt;a href="https://cloud.google.com/translate/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/codeguru/home?region=us-east-1">Amazon CodeGuru&lt;/a> : Intelligent recommendations for building and running modern applications&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>4.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/databricks/">Azure Databricks:&lt;/a> Design AI with Apache Spark™-based analytics&lt;/td>
 &lt;td>Cloud Vision: Image recognition and classification &lt;a href="https://cloud.google.com/vision/">Link&lt;/a> &lt;a href="https://cloud.google.com/vision/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/comprehendmedical/home?region=us-east-1">Amazon Comprehend Medical&lt;/a> : Amazon Comprehend Medical uses machine learning to extract insights and relationships from medical text.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>5.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/machine-learning/">Azure Machine Learning:&lt;/a> Enterprise-grade machine learning service to build and deploy models faster&lt;/td>
 &lt;td>Contact Center AI: AI in your contact center &lt;a href="https://cloud.google.com/solutions/contact-center/">Link&lt;/a> &lt;a href="https://cloud.google.com/solutions/contact-center/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/comprehend/home?region=us-east-1">Amazon Comprehend&lt;/a> : Analyze Unstructured Text&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>6.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/services/open-datasets/">Azure Open Datasets:&lt;/a> Cloud platform to host and share curated open datasets to accelerate development of machine learning models&lt;/td>
 &lt;td>Deep Learning Containers: Preconfigured containers for deep learning &lt;a href="https://cloud.google.com/ai-platform/deep-learning-containers/">Link&lt;/a> &lt;a href="https://cloud.google.com/ai-platform/deep-learning-containers/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/deepcomposer/home?region=us-east-1">AWS DeepComposer&lt;/a> : AWS DeepComposer allows developers of all skill levels to get started with Generative AI.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>7.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/">Azure Cognitive Services:&lt;/a> Deploy high-quality AI models as APIs&lt;/td>
 &lt;td>Deep Learning VM Images: Preconfigured VMs for deep learning &lt;a href="https://cloud.google.com/deep-learning-vm/">Link&lt;/a> &lt;a href="https://cloud.google.com/deep-learning-vm/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/deeplens/home?region=us-east-1">AWS DeepLens&lt;/a> : Deep Learning Enabled Video Camera&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>8.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/services/video-indexer/">Azure Video Analyzer for Media:&lt;/a> Unlock video insights&lt;/td>
 &lt;td>Dialogflow: Create conversational interfaces &lt;a href="https://cloud.google.com/dialogflow-enterprise/">Link&lt;/a> &lt;a href="https://cloud.google.com/dialogflow-enterprise/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/deepracer/home?region=us-east-1">AWS DeepRacer&lt;/a> : Fully autonomous 1/18th scale race car, driven by machine learning&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>9.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/content-safety/">Content Moderator GA:&lt;/a> Automated image, text and video moderation&lt;/td>
 &lt;td>Document AI: Analyze, classify, search documents &lt;a href="https://cloud.google.com/solutions/document-understanding/">Link&lt;/a> &lt;a href="https://cloud.google.com/document-understanding/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/devops-guru/home?region=us-east-1">Amazon DevOps Guru&lt;/a> : ML-powered cloud operations service to improve application availability.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>10.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/custom-vision-service/">Custom Vision:&lt;/a> Easily customise your own state-of-the-art computer vision models for your unique use case&lt;/td>
 &lt;td>Recommendations AI: Create custom recommendations &lt;a href="https://cloud.google.com/recommendations/">Link&lt;/a> &lt;a href="https://cloud.google.com/recommendations-ai/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/forecast/home?region=us-east-1">Amazon Forecast&lt;/a> : Amazon Forecast is a fully-managed service for accurate time-series forecasting&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>11.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/virtual-machines/data-science-virtual-machines/">Data Science Virtual Machines:&lt;/a> Rich pre-configured environment for AI development&lt;/td>
 &lt;td>Speech-To-Text: Convert audio to text &lt;a href="https://cloud.google.com/speech/">Link&lt;/a> &lt;a href="https://cloud.google.com/speech/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/frauddetector/home?region=us-east-1">Amazon Fraud Detector&lt;/a> : Detect more online fraud faster using machine learning&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>12.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/form-recognizer/">Azure Form Recogniser:&lt;/a> Accelerate information extraction from documents&lt;/td>
 &lt;td>Talent Solutions: Job search with ML &lt;a href="https://cloud.google.com/job-discovery/">Link&lt;/a> &lt;a href="https://cloud.google.com/job-discovery/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/healthlake/home?region=us-east-1">Amazon HealthLake&lt;/a> : Making sense of health data&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>13.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/immersive-reader/">Azure Immersive Reader:&lt;/a> Empower users of all ages and abilities to read and comprehend text&lt;/td>
 &lt;td>Text-To-Speech: Convert text to audio &lt;a href="https://cloud.google.com/text-to-speech/">Link&lt;/a> &lt;a href="https://cloud.google.com/text-to-speech/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/kendra/home?region=us-east-1">Amazon Kendra&lt;/a> : Highly accurate enterprise search service powered by machine learning&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>14.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/kinect-dk/">Kinect DK:&lt;/a> Build computer vision and speech models using a developer kit with advanced AI sensors&lt;/td>
 &lt;td>Vertex AI Data Labeling: Data labeling by humans &lt;a href="https://cloud.google.com/data-labeling/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/lexv2/home?region=us-east-1">Amazon Lex&lt;/a> : Build Voice and Text Chatbots&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>15.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/conversational-language-understanding/">Language Understanding:&lt;/a> Teach your apps to understand commands from your users&lt;/td>
 &lt;td>Vertex AI Edge Manager: Deploy monitor edge inferences &lt;a href="https://https://cloud.google.com/vertex-ai/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/lookoutequipment/home?region=us-east-1">Amazon Lookout for Equipment&lt;/a> : Detect abnormal equipment behavior by analyzing sensor data&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>16.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/genomics/">Microsoft Genomics:&lt;/a> Power genome sequencing and research insights&lt;/td>
 &lt;td>Vertex AI Feature Store: Managed ML feature repository &lt;a href="https://cloud.google.com/vertex-ai/docs/featurestore">Link&lt;/a> &lt;a href="https://cloud.google.com/vertex-ai/docs/featurestore/overview">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/lookoutmetrics/home?region=us-east-1">Amazon Lookout for Metrics&lt;/a> : Accurately detect anomalies in your business metrics and quickly understand why&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>17.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/personalizer/">Personaliser:&lt;/a> An AI service that delivers a personalised user experience&lt;/td>
 &lt;td>Vertex AI Matching Engine: Vector similarity searches &lt;a href="https://cloud.google.com/vertex-ai/docs/matching-engine">Link&lt;/a> &lt;a href="https://cloud.google.com/vertex-ai/docs/matching-engine">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/lookoutvision/home?region=us-east-1">Amazon Lookout for Vision&lt;/a> : Identify defects using computer vision to automate quality inspection.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>18.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/services/project-bonsai/">Project Bonsai:&lt;/a> Create intelligent industrial control systems using simulations&lt;/td>
 &lt;td>Vertex AI Model Monitoring: Monitor models for skew/drift &lt;a href="https://cloud.google.com/vertex-ai/docs/model-monitoring">Link&lt;/a> &lt;a href="https://cloud.google.com/vertex-ai/docs/model-monitoring/overview">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/monitron/home?region=us-east-1">Amazon Monitron&lt;/a> : End-to-end system for equipment monitoring&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>19.&lt;/td>
 &lt;td>&lt;a href="https://docs.microsoft.com/en-in/azure/cognitive-services/QnAMaker/Overview/overview">QnA Maker:&lt;/a> Distill information into conversational, easy-to-navigate answers&lt;/td>
 &lt;td>Vertex AI Pipelines: Hosted ML workflows &lt;a href="https://cloud.google.com/ai-platform/pipelines/">Link&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/omics/home?region=us-east-1">Amazon Omics&lt;/a> : Transform omics data into insights.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>20.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/speaker-recognition/">Speaker Recognition:&lt;/a> A Speech service feature that verifies and identifies speakers&lt;/td>
 &lt;td>Vertex AI Predictions: Autoscaled model serving &lt;a href="https://cloud.google.com/ai-platform/prediction/docs/overview">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/panorama/home?region=us-east-1">AWS Panorama&lt;/a> : Enabling computer vision applications at the edge&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>21.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/speech-to-text/">Speech to Text:&lt;/a> A Speech service feature that accurately converts spoken audio to text&lt;/td>
 &lt;td>Vertex AI Tensorboard: Managed TensorBoard for ML-experiment Visualization &lt;a href="https://cloud.google.com/vertex-ai/docs/experiments">Link&lt;/a> &lt;a href="https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/personalize/home?region=us-east-1">Amazon Personalize&lt;/a> : Amazon Personalize helps you easily add real-time recommendations to your apps&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>22.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/speech-translation/">Speech Translation:&lt;/a> Easily integrate real-time speech translation to your app&lt;/td>
 &lt;td>Vertex AI Training: Distributed AI training &lt;a href="https://cloud.google.com/ai-platform/training/docs/overview">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/polly/home?region=us-east-1">Amazon Polly&lt;/a> : Turn Text into Lifelike Speech&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>23.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/language-service/">Cognitive Service for Language:&lt;/a> Add natural language capabilities with a single API call&lt;/td>
 &lt;td>Vertex AI Vizier: black-box hyperparameter tuning &lt;a href="https://cloud.google.com/vertex-ai/docs/vizier/overview">Link&lt;/a> &lt;a href="https://cloud.google.com/vertex-ai/docs/vizier">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/rekognition/home?region=us-east-1">Amazon Rekognition&lt;/a> : Search and Analyze Images&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>24.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/services/cognitive-services/text-to-speech/">Text to Speech:&lt;/a> A Speech service feature that converts text to lifelike speech&lt;/td>
 &lt;td>Vertex AI Workbench:Jupyter-based environment for Data Science &lt;a href="https://cloud.google.com/vertex-ai-workbench">Link&lt;/a> &lt;a href="https://cloud.google.com/vertex-ai/docs/workbench">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1">Amazon SageMaker&lt;/a> : Build, Train, and Deploy Machine Learning Models&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>25.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/services/cognitive-services/translator/">Translator:&lt;/a> Easily conduct machine translation with a simple REST API call&lt;/td>
 &lt;td>Vertex Explainable AI: Understand ML model predictions &lt;a href="https://cloud.google.com/vertex-ai/docs/explainable-ai/overview">Link&lt;/a> &lt;a href="https://cloud.google.com/vertex-ai/docs/explainable-ai">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/textract/home?region=us-east-1">Amazon Textract&lt;/a> : Easily extract text and data from virtually any document&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>26.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/metrics-advisor/">Azure Metrics Advisor:&lt;/a> An AI service that monitors metrics and diagnoses issues&lt;/td>
 &lt;td>Vertex ML Metadata: Artifact, lineage, and execution tracking &lt;a href="https://cloud.google.com/vertex-ai/docs/ml-metadata">Link&lt;/a> &lt;a href="https://cloud.google.com/vertex-ai/docs/ml-metadata/introduction">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/transcribe/home?region=us-east-1">Amazon Transcribe&lt;/a> : Powerful Speech Recognition&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>27.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/bot-services/health-bot/">Health Bot:&lt;/a> A managed service purpose-built for development of virtual healthcare assistants&lt;/td>
 &lt;td>Vision Product Search: Visual search for products &lt;a href="https://cloud.google.com/vision/product-search/docs/">Doc&lt;/a>&lt;/td>
 &lt;td>&lt;a href="https://us-east-1.console.aws.amazon.com/translate/home?region=us-east-1">Amazon Translate&lt;/a> : Powerful Neural Machine Translation&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>28.&lt;/td>
 &lt;td>&lt;a href="https://aka.ms/ScalerHomepage">Azure Applied AI Services:&lt;/a> Specialised services that enable organisations to accelerate time to value in applying AI to solve common scenarios&lt;/td>
 &lt;td>&lt;/td>
 &lt;td>&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>29.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/openai-service/">Azure OpenAI Service:&lt;/a> Apply advanced coding and language models to a variety of use cases&lt;/td>
 &lt;td>&lt;/td>
 &lt;td>&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>30.&lt;/td>
 &lt;td>&lt;a href="https://azure.microsoft.com/en-in/products/cognitive-services/vision-services/">Azure Cognitive Services for Vision:&lt;/a> Unlock insights from image and video content with AI&lt;/td>
 &lt;td>&lt;/td>
 &lt;td>&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table>
&lt;p>&lt;strong>Author&lt;/strong>&lt;br>
Dr Hari Thapliyaal&lt;br>
dasarpai.com &lt;br>
linkedin.com/in/harithapliyal&lt;/p></description></item><item><title>Introduction to ML Model Deployment</title><link>https://dasarpai.github.io/dsblog/Introduction-to-ML-Model-deployment/</link><pubDate>Wed, 19 Jul 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Introduction-to-ML-Model-deployment/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6077-Introduction-to-ML-Model-deployment.jpg" alt="Introduction to AI Model Deployement">&lt;/p>
&lt;h1 id="introduction-to-ai-model-deployment">Introduction to AI Model deployment&lt;a class="td-heading-self-link" href="#introduction-to-ai-model-deployment" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="big-players">Big Players&lt;a class="td-heading-self-link" href="#big-players" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>Amazon
&lt;ul>
&lt;li>Amazon has many products and one of their product is &lt;strong>AWS Cloud&lt;/strong>. Under this product they sell IT infrastructure (storage, memory, network, VM, webhosting etc.)&lt;/li>
&lt;li>&lt;strong>Amazon SageMaker&lt;/strong> is Cloud based Machine Learning Platform, and this is one of the product under AWS Cloud.&lt;/li>
&lt;li>Amazon SageMaker can be used to train AI model, host AI model, monitor the model and hosts many other services which any Data Science project need from data gathering to model serving.&lt;/li>
&lt;li>AWS is oldest cloud service provider in the market.&lt;/li>
&lt;li>AWS Sagemaker was launched in Nov'17.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Google
&lt;ul>
&lt;li>Google has hundreds of products like gmail, youtube, google drive etc. One of their product is called &lt;strong>Google Cloud&lt;/strong>. Under this product they sell IT infrastrcture like Amazon sells under AWS.&lt;/li>
&lt;li>&lt;strong>VertexAI&lt;/strong> is Cloud based Machine Learning platform of Google. VertexAI is part of Google Cloud.&lt;/li>
&lt;li>VertexAI can be used to train AI Model,host AI model, monitor the model etc.&lt;/li>
&lt;li>VertexAI was launched in Jun'21&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Microsoft
&lt;ul>
&lt;li>Like Amazon&amp;rsquo;s cloud platform which is called AWS Cloud, Microsoft&amp;rsquo;s cloud plateform is called &lt;strong>Azure&lt;/strong>.&lt;/li>
&lt;li>Microsoft&amp;rsquo;s AI product is called &lt;strong>Azure Machine Learning&lt;/strong>.&lt;/li>
&lt;li>Today (Jul'23) Azure Machine Learning has has most of the capabilites than any other player&amp;rsquo;s AI product.&lt;/li>
&lt;li>Azure Machine Learning was launched Feb'14&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="what-is-genai">What is GenAI?&lt;a class="td-heading-self-link" href="#what-is-genai" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>There are many kinds of AI models like classifier models, regressor models, clustering models, reinforcement models, etc. An AI model which has the ability to generate text, images, video, and music is called GenAI. They all take inspiration from the human brain, therefore they all have neural network (NN) architecture. There are dozens (if not hundreds) types of NN architecture that can be used to create different kinds of AI models. The type of NN architecture depends upon the data which is used for developing the model and the problem which we want to solve using AI model. Researchers in universities or big corporations like Google, Facebook, Amazon, and Microsoft keep developing new architecture, and using these architectures they develop the foundational models. Once foundational models are developed, they release a research paper. In this, they inform the world what architecture they used, what data they used, what parameters (weights &amp;amp; biases) the model has learned, what are the results of their product and compare that with other existing models. They can develop these foundational models with one set of hyperparameters, and they can release these foundational models of different sizes (it depends upon the number of parameters used). AI product builders pick up these foundational models and fine-tune these based on the exact business problem in their hands. Which foundational model do they choose, it also depends upon the size of the model, the kind of data it has used to create those foundational models, and what was the performance of the model on a similar task which the product developer want to solve.&lt;/p></description></item><item><title>Embedding with FastText</title><link>https://dasarpai.github.io/dsblog/Embedding-with-FastText/</link><pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Embedding-with-FastText/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6073-Embedding-with-FastText.jpg" alt="Embedding with FastText">&lt;/p>
&lt;h1 id="embedding-with-fasttext">Embedding with FastText&lt;a class="td-heading-self-link" href="#embedding-with-fasttext" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;a href="../../dsblog/what-is-nlp#what-is-embedding">What is Embedding?&lt;/a> &lt;br>
&lt;a href="../../dsblog/what-is-nlp#what-are-different-embedding-types">What are Different Types of Embedding&lt;/a>&lt;/p>
&lt;h2 id="what-is-fasttext">What is FastText?&lt;a class="td-heading-self-link" href="#what-is-fasttext" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>FastText is an open-source library for efficient learning of word representations and sentence classification developed by Facebook AI Research. It is designed to handle large-scale text data and provides tools for &lt;strong>training&lt;/strong> and &lt;strong>using word embeddings&lt;/strong>.&lt;/p></description></item><item><title>Major LLM Developers Shaping the AI Landscape</title><link>https://dasarpai.github.io/dsblog/Major-LLM-Developers-Reshaping-NLP-Advancements/</link><pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Major-LLM-Developers-Reshaping-NLP-Advancements/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6075-Major-LLM-Developers-Reshaping-NLP-Advancements.jpg" alt="Major LLM Developers Shaping the AI Landscape">&lt;/p>
&lt;h1 id="major-llm-developers-shaping-the-ai-landscape">Major LLM Developers Shaping the AI Landscape&lt;a class="td-heading-self-link" href="#major-llm-developers-shaping-the-ai-landscape" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;strong>From Text to Intelligence: Major LLM Developers Shaping the AI Landscape&lt;/strong>&lt;/p>
&lt;h2 id="introduction">Introduction:&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>The world of Artificial Intelligence (AI) has experienced an exponential growth, fueled by groundbreaking research and the efforts of innovative developers. Among the key players, Large Language Model (LLM) developers have taken center stage, creating powerful language models that have revolutionized natural language processing and understanding. In this article, we delve into the major LLM developers, their key contributions.&lt;/p></description></item><item><title>What is GAN Architecture?</title><link>https://dasarpai.github.io/dsblog/What-is-GAN-Architecture/</link><pubDate>Mon, 03 Jul 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/What-is-GAN-Architecture/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6069-What-is-GAN-Architecture.jpg" alt="What is GAN Architecture?">&lt;/p>
&lt;h1 id="what-is-gan-architecture">What is GAN Architecture?&lt;a class="td-heading-self-link" href="#what-is-gan-architecture" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Generative Adversarial Networks (GANs) are a powerful class of neural networks that are used for unsupervised learning. It was developed and introduced by Ian J. Goodfellow in 2014. It is a type of artificial intelligence (AI) model that consists of two neural networks: a generator and a discriminator. GANs are used for generative tasks, such as creating realistic images, videos, or even audio.&lt;/p></description></item><item><title>Capabilities of AI Transformers</title><link>https://dasarpai.github.io/dsblog/Capabilities-of-AI-Transformers/</link><pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Capabilities-of-AI-Transformers/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6067-Capabilities-of-AI-Transformers.jpg" alt="Capabilities of AI Transformers">&lt;/p>
&lt;h1 id="capabilities-of-ai-transformers">Capabilities of AI Transformers&lt;a class="td-heading-self-link" href="#capabilities-of-ai-transformers" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="background">Background&lt;a class="td-heading-self-link" href="#background" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Whether GPT, ChatGPT, DALL-E, Whisper, Satablity AI or whatever significant you see in the AI worlds nowdays it is because of Transformer Architecture. Transformers are a type of neural network architecture that have several properties that make them effective for modeling data with long-range dependencies. They generally feature a combination of multi-headed attention mechanisms, residual connections, layer normalization, feedforward connections, and positional embeddings.&lt;/p></description></item><item><title>Model Garden of VertexAI</title><link>https://dasarpai.github.io/dsblog/Model-Garden-of-VertexAI/</link><pubDate>Wed, 21 Jun 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Model-Garden-of-VertexAI/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6065-Model-Garden-of-VertexAI.jpg" alt="All Resources to Learn Data Science">&lt;/p>
&lt;h1 id="model-garden-of-vertexai">Model Garden of VertexAI:&lt;a class="td-heading-self-link" href="#model-garden-of-vertexai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="unlocking-the-power-of-googles-vertexai-exploring-the-world-of-pre-built-models-for-ai-tasks">Unlocking the Power of Google&amp;rsquo;s VertexAI: Exploring the World of Pre-Built Models for AI Tasks&lt;a class="td-heading-self-link" href="#unlocking-the-power-of-googles-vertexai-exploring-the-world-of-pre-built-models-for-ai-tasks" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h2 id="introduction">Introduction:&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Artificial Intelligence (AI) has transformed numerous industries, from healthcare and finance to e-commerce, logistic, eduction and entertainment. But the complexity of developing machine learning models often poses a challenge. As the demand for AI-powered solutions continues to rise, data scientists seek efficient ways to leverage pre-trained models or build custom models to address specific tasks. In this regard, Google&amp;rsquo;s VertexAI emerges as a robust platform that offers an extensive selection of pre-built models for a wide range of AI tasks. VertexAI platform has revolutionized the landscape by seamlessly leveraging LLM (Large Language Models) and Prompt Engineering techniques to perform complex machine learning tasks effortlessly. With VertexAI, data scientists can harness the power of state-of-the-art language models, such as LLM, to accelerate their ML development process. Additionally, the innovative concept of Prompt Engineering enables users to effectively communicate with the models, guiding them to deliver precise and accurate results. From computer vision and natural language processing to speech processing and structured tabular data analysis, Vertex AI&amp;rsquo;s repertoire includes over 100 models catering to diverse application domains. This article explores how Vertex AI, through its integration of LLM and Prompt Engineering, empowers users to effortlessly tackle intricate machine learning tasks across diverse domains, revolutionizing the AI development experience.&lt;/p></description></item><item><title>All Resources to Learn Data Science</title><link>https://dasarpai.github.io/dsblog/all-resources-to-learn-data-science/</link><pubDate>Thu, 08 Jun 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/all-resources-to-learn-data-science/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6064-Resources-to-Learn-Everything-About-AI.jpg" alt="All Resources to Learn Data Science">&lt;/p>
&lt;h1 id="all-resources-to-learn-data-science">All Resources to Learn Data Science&lt;a class="td-heading-self-link" href="#all-resources-to-learn-data-science" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Welcome to the AI ML Resources category page, where you&amp;rsquo;ll find a wealth of knowledge on various topics related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), Natural Language Processing (NLP), Mathematics and statistics required to learn Data Science. Each of the pages mentioned below brings together a wide range of articles, tutorials, and guides that delve into the fascinating world of AI and ML. Whether you&amp;rsquo;re a beginner seeking foundational knowledge or an experienced practitioner looking to expand your skills, these resources offer valuable insights and practical guidance. You need to go through these links one at time. As a master page you can book mark this page.&lt;/p></description></item><item><title>Demystifying DevOps, MLOps, and DataOps</title><link>https://dasarpai.github.io/dsblog/Demystifying-DevOps-MLOps-and-DataOps/</link><pubDate>Thu, 08 Jun 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Demystifying-DevOps-MLOps-and-DataOps/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6066-Demystifying-DevOps-MLOps-and-DataOps.jpg" alt="All Resources to Learn Data Science">&lt;/p>
&lt;h1 id="demystifying-devops-mlops-and-dataops">Demystifying DevOps, MLOps, and DataOps:&lt;a class="td-heading-self-link" href="#demystifying-devops-mlops-and-dataops" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>&lt;strong>Bridging the Gap between Software Development, Machine Learning, and Data Managemen&lt;/strong>&lt;/p>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h2 id="what-is-devops">What is DevOps&lt;a class="td-heading-self-link" href="#what-is-devops" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>DevOps, short for Development and Operations, is a set of practices, principles, and cultural philosophies that aim to improve collaboration and efficiency between software development teams and IT operations teams. It emphasizes the integration of software development and IT operations, breaking down traditional silos and fostering a collaborative approach throughout the entire software delivery lifecycle.&lt;/p></description></item><item><title>God Fathers of AI</title><link>https://dasarpai.github.io/dsblog/God-Fathers-of-AI/</link><pubDate>Fri, 05 May 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/God-Fathers-of-AI/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6058-God-Fathers-of-AI.jpg" alt="God Fathers of AI">&lt;/p>
&lt;h1 id="god-fathers-of-ai">God Fathers of AI&lt;a class="td-heading-self-link" href="#god-fathers-of-ai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>In other fields of studies or in religion, there is only one god or only one godfather. But in the field of AI, that is not the case. There are many pioneers or Godfathers who have done significant work in this field. Recently, the resignation of Dr. Geoffrey Hinton from Google raised eyebrows in the business world and in Governments the world over. Technology is good or bad, it depends upon whose hand it is. Geoffrey raised that concern and for that, he wants better controls in place. What will happen, we need to follow the progress and raise our voices around. In this article, I am mentioning some godfathers of AI, their workplaces, and their contributions. I am sure this will inspire many young minds.&lt;/p></description></item><item><title>Types of Machine Learning</title><link>https://dasarpai.github.io/dsblog/Types-of-Machine-Learning/</link><pubDate>Thu, 27 Apr 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Types-of-Machine-Learning/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6056-Types-of-Machine-Learning.jpg" alt="Types of Machine Learning">&lt;/p>
&lt;h1 id="types-of-machine-learning">Types of Machine Learning&lt;a class="td-heading-self-link" href="#types-of-machine-learning" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Machine learning is a field of artificial intelligence that focuses on developing algorithms that can learn from data and make predictions or decisions. There are several types of machine learning techniques, each with its strengths and weaknesses. In this post, we will explore some of the most commonly used machine learning techniques, including supervised learning, unsupervised learning, reinforcement learning, and more. This post is not about deep diving into these topics but to give you a oneliner understanding and the difference between these different techniques.&lt;/p></description></item><item><title>Cost Functions and Optimizers in Machine Learning</title><link>https://dasarpai.github.io/dsblog/Cost-Functions-and-Optimizers-in-Machine-Learning/</link><pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Cost-Functions-and-Optimizers-in-Machine-Learning/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6045-Cost-Functions-and-Optimizers-in-Machine-Learning.jpg" alt="Cost-Functions-and-Optimizers-in-Machine-Learning">&lt;/p>
&lt;h1 id="cost-functions-and-optimizers-in-machine-learning">Cost-Functions-and-Optimizers-in-Machine-Learning&lt;a class="td-heading-self-link" href="#cost-functions-and-optimizers-in-machine-learning" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-is-machine-learning">What is machine learning?&lt;a class="td-heading-self-link" href="#what-is-machine-learning" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Machine learning is a subfield of artificial intelligence that focuses on the &lt;strong>development of algorithms and statistical models&lt;/strong> that enable computers to improve their performance on a specific task through experience.&lt;/p></description></item><item><title>GPU for Data Science Work</title><link>https://dasarpai.github.io/dsblog/GPU-for-Data-Science-Work/</link><pubDate>Thu, 26 Jan 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/GPU-for-Data-Science-Work/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6042-GPU-for-Data-Science-Work.jpg" alt="GPU for Data Science Work">&lt;/p>
&lt;h1 id="gpu-for-data-science-work">GPU for Data Science Work&lt;a class="td-heading-self-link" href="#gpu-for-data-science-work" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-is-the-difference-between-microprocessor-cpu-and-gpu">What is the difference between microprocessor (CPU) and GPU?&lt;a class="td-heading-self-link" href="#what-is-the-difference-between-microprocessor-cpu-and-gpu" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>A microprocessor and a GPU (graphics processing unit) are both types of processors, but they are designed for different purposes and have different architectures.&lt;/p></description></item><item><title>AI Usecases in Agriculture Industry</title><link>https://dasarpai.github.io/dsblog/AI-usecases-in-Agriculture-Industry/</link><pubDate>Mon, 23 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/AI-usecases-in-Agriculture-Industry/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6037-AI-usecases-in-Agriculture-Industry.jpg" alt="AI Usecases in Agriculture Industry">&lt;/p>
&lt;h1 id="ai-usecases-in-agriculture-industry">AI Usecases in Agriculture Industry&lt;a class="td-heading-self-link" href="#ai-usecases-in-agriculture-industry" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>In the today world where energy saving, climate change, cost and process optimization, effectiveness is the philosophy of all business activities. With ever-increasing demand of food, the agriculture industry is looking for ways to improve crop yields and optimize farming practices. The use of Artificial Intelligence (AI) in agriculture is proving to be a game-changer, providing farmers with new and innovative tools to improve efficiency and productivity. From precision farming to autonomous tractors, AI is revolutionizing the way we think about farming and agriculture.&lt;/p></description></item><item><title>AI Use Cases in Food Processing</title><link>https://dasarpai.github.io/dsblog/AI-Use-Cases-in-Food-Processing/</link><pubDate>Sun, 22 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/AI-Use-Cases-in-Food-Processing/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6036-AI-Use-Cases-in-Food-Processing.jpg" alt="“AI Use Cases in Food Processing">&lt;/p>
&lt;h1 id="ai-use-cases-in-food-processing">AI Use Cases in Food Processing&lt;a class="td-heading-self-link" href="#ai-use-cases-in-food-processing" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>The food processing industry is a vital sector in the global economy, responsible for providing safe and nutritious food to millions of people around the world. Artificial intelligence (AI) is being increasingly used in the food processing industry to improve efficiency, reduce costs, and enhance the quality and safety of food products. From automated sorting and grading of fruits and vegetables to intelligent vending machines, AI is being used in a wide range of applications across the food processing industry.&lt;/p></description></item><item><title>Introduction to Neural Network</title><link>https://dasarpai.github.io/dsblog/Introduction-to-Neural-Network/</link><pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Introduction-to-Neural-Network/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6034-Introduction-to-Neural-Network.jpg" alt="Introduction to Neural Network">&lt;/p>
&lt;h1 id="introduction-to-neural-network">Introduction to Neural Network&lt;a class="td-heading-self-link" href="#introduction-to-neural-network" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction-to-a-perceptron">Introduction to a Perceptron&lt;a class="td-heading-self-link" href="#introduction-to-a-perceptron" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>A perceptron is a type of artificial neural network that can be used for binary classification. It is a simple model that consists of a single layer of artificial neurons and is used to classify input data into one of two categories. The perceptron algorithm learns the weights of the artificial neurons by adjusting them based on the input data and the desired output. The perceptron is considered a basic building block for more complex neural networks.&lt;/p></description></item><item><title>What is GAN?</title><link>https://dasarpai.github.io/dsblog/What-is-GAN/</link><pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/What-is-GAN/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6043-gan.jpg" alt="Partial Dependence Plots">&lt;/p>
&lt;h1 id="what-is-gan">What is GAN?&lt;a class="td-heading-self-link" href="#what-is-gan" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-is-gan-generative-adversarial-network">What is GAN (Generative Adversarial Network)?&lt;a class="td-heading-self-link" href="#what-is-gan-generative-adversarial-network" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Generative adversarial networks (GANs) are besing used to generate images, videos, text, audio and music. GAN is a class of machine-learning models introduced by Ian Goodfellow and his colleagues in 2014. The GANs became popular among researchers quickly because of their property to generate new data with the same statistics as the input training set. It can be applied to images, videos, textual data, tabular data and more, proving useful for semi-supervised, fully supervised, and reinforcement learning.&lt;/p></description></item><item><title>Timeseries Interview Questions</title><link>https://dasarpai.github.io/dsblog/Timeseries-Interview-Questions/</link><pubDate>Sun, 08 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Timeseries-Interview-Questions/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6023-Timeseries-Interview-Questions.jpg" alt="Timeseries Interview Questions">&lt;/p>
&lt;h1 id="timeseries-interview-questions">Timeseries Interview Questions&lt;a class="td-heading-self-link" href="#timeseries-interview-questions" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="what-are-the-characterstics-of--time-series-data">What are the characterstics of time series data?&lt;a class="td-heading-self-link" href="#what-are-the-characterstics-of--time-series-data" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Time series data is a series of data points collected over time. Some characteristics of time series data include:&lt;/p></description></item><item><title>Linear Regression Interview Questions</title><link>https://dasarpai.github.io/dsblog/Linear-Regression-Interview-Questions/</link><pubDate>Sat, 07 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Linear-Regression-Interview-Questions/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6022-Linear-Regression-Interview-Questions.jpg" alt="Prompt Engineering for GPT4">&lt;/p>
&lt;h1 id="linear-regression-interview-questions-and-answers">Linear Regression Interview Questions and Answers&lt;a class="td-heading-self-link" href="#linear-regression-interview-questions-and-answers" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;blockquote>
&lt;p>In this question-answer article, I will try that the start of every answer from example rather than theory (some unavoidable variation may be possible). I firmly believe if examples are clear, human mind is smart enough in generlization and creating theories.&lt;/p></description></item><item><title/><link>https://dasarpai.github.io/dsblog/%23Prompt-Engineering-for-GPT4/</link><pubDate>Fri, 06 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/%23Prompt-Engineering-for-GPT4/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6117-#Prompt-Engineering-for-GPT4.jpg" alt="#Prompt-Engineering-for-GPT4">&lt;/p>
&lt;h1 id="prompt-engineering-for-gpt4">#Prompt Engineering for GPT4&lt;a class="td-heading-self-link" href="#prompt-engineering-for-gpt4" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="prompt-engineering-for-gpt4-1">#Prompt Engineering for GPT4&lt;a class="td-heading-self-link" href="#prompt-engineering-for-gpt4-1" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="prompt-engineering-for-gpt4-2">#Prompt Engineering for GPT4&lt;a class="td-heading-self-link" href="#prompt-engineering-for-gpt4-2" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="prompt-engineering-for-gpt4-3">#Prompt Engineering for GPT4&lt;a class="td-heading-self-link" href="#prompt-engineering-for-gpt4-3" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>##Prompt Engineering for GPT4&lt;/p>
&lt;h1 id="what-is-prompting">What is Prompting?&lt;a class="td-heading-self-link" href="#what-is-prompting" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="trading">Trading&lt;a class="td-heading-self-link" href="#trading" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="generate-code-for-indicator">Generate Code for Indicator&lt;a class="td-heading-self-link" href="#generate-code-for-indicator" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Generate a pine script code to create a simple moving average of the closing price with a period of 14 days which is compatable with v5 of pine script and uses &amp;lsquo;color&amp;rsquo; dot before any color argument and &amp;rsquo;ta&amp;rsquo; before any sma argument&lt;/p></description></item><item><title/><link>https://dasarpai.github.io/dsblog/%23ChatGPT-Business-Ideas/</link><pubDate>Fri, 06 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/%23ChatGPT-Business-Ideas/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6118-#ChatGPT-Business-Ideas.jpg" alt="#ChatGPT-Business-Ideas">&lt;/p>
&lt;h1 id="chatgpt-business-ideas">#ChatGPT Business Ideas&lt;a class="td-heading-self-link" href="#chatgpt-business-ideas" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="chatgpt-business-ideas-1">#ChatGPT Business Ideas&lt;a class="td-heading-self-link" href="#chatgpt-business-ideas-1" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="chatgpt-business-ideas-2">#ChatGPT Business Ideas&lt;a class="td-heading-self-link" href="#chatgpt-business-ideas-2" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="chatgpt-business-ideas-3">#ChatGPT Business Ideas&lt;a class="td-heading-self-link" href="#chatgpt-business-ideas-3" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>##ChatGPT Business Ideas&lt;/p>
&lt;h1 id="chatgpt-business-ideas-4">ChatGPT Business Ideas&lt;a class="td-heading-self-link" href="#chatgpt-business-ideas-4" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>ChatGPT Business Ideas&lt;/p></description></item><item><title>GPT Usecases</title><link>https://dasarpai.github.io/dsblog/gpt-usecases/</link><pubDate>Thu, 05 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/gpt-usecases/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6020-GPT-Usecases.jpg" alt="GPT Usecases">&lt;/p>
&lt;h1 id="what-is-gpt">What is GPT?&lt;a class="td-heading-self-link" href="#what-is-gpt" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>GPT is a transformer. Don&amp;rsquo;t confuse it with your electricity transformer! In Artificial Intelligence there are different kinds of neural network architectures to perform various tasks like classification, translation, segmentation, regression, etc. One of those architectures is transformer architecture. The Foundation of this architecture is based on another two architectures called encoder architecture and decoder architecture. There are lots of other technical complexity but for the business readers I am hiding that for that the time being, we will discuss that at some other place. In nutshell, GPT is a Transformer technology developed by OpenAI and it can perform several NLP tasks. NLP stands for natural language preprocessing. NLP tasks mean tasks like sentiment analysis of the text, text classification, topic modeling, translation, named entity recognition, and dozens of other tasks.&lt;/p></description></item><item><title>ChatGPT Usecases</title><link>https://dasarpai.github.io/dsblog/chatgpt-usecases/</link><pubDate>Wed, 04 Jan 2023 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/chatgpt-usecases/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6019-ChatGPT-Usecases.jpg" alt="ChatGPT Usecases">&lt;/p>
&lt;h1 id="what-is-chatgpt">What is ChatGPT?&lt;a class="td-heading-self-link" href="#what-is-chatgpt" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>ChatGPT is &lt;strong>general purpose&lt;/strong> - &amp;ldquo;chat model&amp;rdquo; from OpenAI. It is a &lt;strong>language model&lt;/strong>, which means if you type some text then it can understand and respond to you appropriately. At this point in time, it is not accepting voice commands, neither able to process images or videos. A &lt;strong>general-purpose model&lt;/strong> means it can understand the question coming from any domain of life. A domain may be vertical or horizontal. A vertical domain means where a vendor is supplying a product or service for a specific type of customer. A horizontal domain is where a vendor supplies products or services for all types of customer. Healthcare, banking, logistic, insurance, agriculture, philosophy, history, and economics are one kind of verticals whereas
BPO, Quality Management, Software Development, Taxation, HR, IT Security, Accounting, Office Administration, Catering, and Entertainment are other kind of domains. A &lt;strong>general-purpose model&lt;/strong> can understand the questions from all aspects of life whether business vertical or horizontal or normal daily family or conflicts with other group members, family members, etc.&lt;/p></description></item><item><title>What is Computer Vision</title><link>https://dasarpai.github.io/dsblog/what-is-computer-vision/</link><pubDate>Wed, 28 Dec 2022 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/what-is-computer-vision/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6018-What-is-Computer-Vision.jpg" alt="What is Computer Vision">&lt;/p>
&lt;h1 id="what-is-computer-vision">What is Computer vision?&lt;a class="td-heading-self-link" href="#what-is-computer-vision" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="background">Background&lt;a class="td-heading-self-link" href="#background" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>In the digital world, scientists are working hard to create machines and robots that can interact with humans the way humans interact with each other. You cannot interact with another human being around if you are not aware of the objects and background around you. There are many ways to know the things around us. We can know them through smell; without looking anything around we can tell, here is a rose flower or samosa or sugar factory around. Without looking we can tell whether a train is coming or going, a person is going or coming, this is a song sung by Lata Mangeshkar. Without looking I can tell this is smooth or rough, hard or soft, cold or hot. In all these cases we could identify the objects and things around us without using our eyes.&lt;/p></description></item><item><title>What is NLP?</title><link>https://dasarpai.github.io/dsblog/what-is-nlp/</link><pubDate>Mon, 19 Dec 2022 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/what-is-nlp/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6016-What-is-NLP.jpg" alt="What is NLP?">&lt;/p>
&lt;h2 id="what-is-nlp">What is NLP?&lt;a class="td-heading-self-link" href="#what-is-nlp" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Humans interact with their surroundings using different kinds of inputs. Eyes deal with inputs of color, shape, and size. Ear deals with inputs of sound, voice, and noise. Similarly, the other 3 senses also deal with other kinds of inputs. When you write something you may be drawing some art or you may be drawing letters of some language. Language is what we use to speak, for example, English, Hindi, Kannada, Tamil, and French are languages. The script is a tool to write what we speak. There are many kinds of scripts and you can use those scripts to write words of the languages. Some scripts are good for some languages. You cannot write all the words of all the languages of the world using one script (without modifying the original letters of the script). The Roman script is good to write English languages but when you want to write any Indian language using Roman then you will make many mistakes when reading the scripts. Because you won&amp;rsquo;t be able to produce the same sound as the original language was producing.&lt;/p></description></item><item><title/><link>https://dasarpai.github.io/dsblog/%23Machine-Learning-in-Nutshell/</link><pubDate>Mon, 07 Nov 2022 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/%23Machine-Learning-in-Nutshell/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6120-#Machine-Learning-in-Nutshell.jpg" alt="#Machine-Learning-in-Nutshell">&lt;/p>
&lt;h1 id="machine-learning-in-nutshell">#Machine Learning in Nutshell&lt;a class="td-heading-self-link" href="#machine-learning-in-nutshell" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="machine-learning-in-nutshell-1">#Machine Learning in Nutshell&lt;a class="td-heading-self-link" href="#machine-learning-in-nutshell-1" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="machine-learning-in-nutshell-2">#Machine Learning in Nutshell&lt;a class="td-heading-self-link" href="#machine-learning-in-nutshell-2" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h1 id="machine-learning-in-nutshell-3">#Machine Learning in Nutshell&lt;a class="td-heading-self-link" href="#machine-learning-in-nutshell-3" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>##Machine Learning in Nutshell&lt;/p>
&lt;h1 id="machine-learning-in-nutshell-4">Machine Learning in Nutshell&lt;a class="td-heading-self-link" href="#machine-learning-in-nutshell-4" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="data-preperation">Data Preperation&lt;a class="td-heading-self-link" href="#data-preperation" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h2 id="supervised-learning">Supervised Learning&lt;a class="td-heading-self-link" href="#supervised-learning" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h2 id="unsupervised-learning">Unsupervised Learning&lt;a class="td-heading-self-link" href="#unsupervised-learning" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h2 id="regression">Regression&lt;a class="td-heading-self-link" href="#regression" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="linear-regression">Linear Regression&lt;a class="td-heading-self-link" href="#linear-regression" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;h2 id="classification">Classification&lt;a class="td-heading-self-link" href="#classification" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="logistic-regression">Logistic Regression&lt;a class="td-heading-self-link" href="#logistic-regression" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;h2 id="clustering">Clustering&lt;a class="td-heading-self-link" href="#clustering" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h2 id="model-evaluation">Model Evaluation&lt;a class="td-heading-self-link" href="#model-evaluation" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="evaluating-linear-regression-model">Evaluating Linear Regression Model&lt;a class="td-heading-self-link" href="#evaluating-linear-regression-model" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;h3 id="evaluating-classification-model">Evaluating Classification Model&lt;a class="td-heading-self-link" href="#evaluating-classification-model" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;h3 id="evaluating-clustering-model">Evaluating Clustering Model&lt;a class="td-heading-self-link" href="#evaluating-clustering-model" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;h2 id="conclusion">Conclusion&lt;a class="td-heading-self-link" href="#conclusion" aria-label="Heading self-link">&lt;/a>&lt;/h2></description></item><item><title>Domain Knowledge in Machine Learning</title><link>https://dasarpai.github.io/dsblog/Domain-Knowledge-in-Machine-Learning/</link><pubDate>Sat, 15 Oct 2022 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Domain-Knowledge-in-Machine-Learning/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6015-domain-knowledge-in-machine-learning.jpg" alt="Domain Knowledge in Machine Learning">&lt;/p>
&lt;h1 id="domain-knowledge-in-machine-learning">Domain Knowledge in Machine Learning&lt;a class="td-heading-self-link" href="#domain-knowledge-in-machine-learning" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Let’s say the domain is a restaurant kitchen. A dataset with 3 variables. Two predictors and one predicted. Predictor variables are flour in kilograms and water in liters. A predicted variable is the number of roti/ bread. You know the model will be something like this.&lt;/p></description></item><item><title>Data Science, AI, ML, eBooks, PDF Books</title><link>https://dasarpai.github.io/dsblog/ds-ai-ml-books/</link><pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/ds-ai-ml-books/</guid><description>&lt;p>&lt;img src="../../assets/images/dsresources/dsr120-Data-Science-AI-ML-eBooks-PDF-Books.jpg" alt="DS, AI, ML, Books Available">&lt;/p>
&lt;h1 id="online-data-science-ai-ml-content">Online Data Science, AI, ML Content&lt;a class="td-heading-self-link" href="#online-data-science-ai-ml-content" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Data Science, AI, Machine Learning, Books/ Guide/ Reports/ Presentations / Jupyter Notebook Available.&lt;/p>
&lt;p>All these books are available in pdf format at &lt;a href="https://drive.google.com/drive/folders/14wS6JWWDsZ2TEXCD9A7jgLVCEVEd1Mpb?usp=sharing" target="_blank"> this link&lt;/a>. I update this page less frequently but keep adding books in the repo. The list below may not contain the name you are looking for. Therefore, it is suggested to visit the link mentioned earlier. This link contains excellent presentations Book, (PPT), Handbook, Report, Articles (ARTC), Book, Booklet, eBook, Notebook, Notes, PAPER, GUIDE, TOC, Syllabus, LINKS, Handbook, Chapter, Tool, BROC – Broacher on Machine Learning, Deep Learning, NLP, Statistics, Reinforcement Learning, GAN. Approx 800 pdf files which inclues 350+ books.&lt;/p></description></item><item><title>Data Science, AI, ML, eBooks, PDF Books</title><link>https://dasarpai.github.io/dsresources/ds-ai-ml-books/</link><pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsresources/ds-ai-ml-books/</guid><description>&lt;p>&lt;img src="../../assets/images/dsresources/dsr120-Data-Science-AI-ML-eBooks-PDF-Books.jpg" alt="DS, AI, ML, Books Available">&lt;/p>
&lt;p>I am sorry, this page has moved to different location. &lt;a href="../../dsblog/ds-ai-ml-books">Click me to go there&lt;/a>&lt;/p></description></item><item><title>RDBMS</title><link>https://dasarpai.github.io/dscourses/rdbms/</link><pubDate>Thu, 30 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/rdbms/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc316-RDBMS.jpg" alt="RDBMS">&lt;/p>
&lt;h1 id="relational-database-management-systems-rdbms">Relational Database Management Systems (RDBMS)&lt;a class="td-heading-self-link" href="#relational-database-management-systems-rdbms" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>A brief summary of the topics covered in this course is as below. This is 60 hours course, it is suggested to complete this course in 1 month.&lt;/p></description></item><item><title>Big Data</title><link>https://dasarpai.github.io/dscourses/big-data/</link><pubDate>Wed, 29 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/big-data/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc315-Big-Data.jpg" alt="Big Data">&lt;/p>
&lt;h1 id="big-data-analytics">Big Data Analytics&lt;a class="td-heading-self-link" href="#big-data-analytics" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="big-data-systems">Big Data Systems&lt;a class="td-heading-self-link" href="#big-data-systems" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>What is Big Data&lt;/li>
&lt;li>Data Warehouse, Data Lakes&lt;/li>
&lt;li>Hadoop – Components&lt;/li>
&lt;li>Storage – HDFS, Hbase&lt;/li>
&lt;li>Resource Manager (MapReduce, YARN)&lt;/li>
&lt;li>Types of data formats (JSON, ORC, Parquet, AVRO)&lt;/li>
&lt;li>Scripting  (Hive, Pig)&lt;/li>
&lt;li>Stream Processing&lt;/li>
&lt;li>Massive Parallel Processing (Spark, Imapala, Mahout)&lt;/li>
&lt;li>RDDs in Spark&lt;/li>
&lt;li>Data Migration (Scoop/ Flume)&lt;/li>
&lt;li>Schedular (Oozie)&lt;/li>
&lt;li>Resource Negotiator (Zookeeper)&lt;/li>
&lt;li>RDBMS Database&lt;/li>
&lt;li>Columnar Database&lt;/li>
&lt;li>Multimodel Database&lt;/li>
&lt;li>NoSQL (HBase, Cassandra, MongoDB, DynamoDB)&lt;/li>
&lt;li>RDBMS (MySQL, PostgreSQL)&lt;/li>
&lt;li>CosmoDB&lt;/li>
&lt;li>In memory database (Redis)&lt;/li>
&lt;li>Spark SQL&lt;/li>
&lt;li>Case Study&lt;/li>
&lt;/ol>
&lt;h2 id="stream-processing--analytics">Stream Processing &amp;amp; Analytics&lt;a class="td-heading-self-link" href="#stream-processing--analytics" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Real Time Streaming Architecture&lt;/li>
&lt;li>Service Configuration and Coordination&lt;/li>
&lt;li>Data Flow Management, Storing and Processing Streaming Data&lt;/li>
&lt;li>Visualization Techniques for Real Time Streaming Data&lt;/li>
&lt;li>Aggregation (Timed Counting, Multi Resolution Time Series Aggregation)&lt;/li>
&lt;li>Statistical Approximation&lt;/li>
&lt;li>Approximating with sketches&lt;/li>
&lt;/ol>
&lt;h2 id="pyspark">PySpark&lt;a class="td-heading-self-link" href="#pyspark" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Overview &amp;amp; Installation.&lt;/li>
&lt;li>RDD&lt;/li>
&lt;li>Dataframe.&lt;/li>
&lt;li>Architecture.&lt;/li>
&lt;li>MLLib&lt;/li>
&lt;li>NLP&lt;/li>
&lt;li>Linear regression&lt;/li>
&lt;li>Logistic regression&lt;/li>
&lt;li>Decision tree&lt;/li>
&lt;li>Naive Bayes&lt;/li>
&lt;li>XGBoost&lt;/li>
&lt;li>Timeseries&lt;/li>
&lt;li>Spark Job automation with Scheduler&lt;/li>
&lt;li>NYC Parking Case Study: Apache Spark&lt;/li>
&lt;/ol></description></item><item><title>Tableau</title><link>https://dasarpai.github.io/dscourses/tableau/</link><pubDate>Tue, 28 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/tableau/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc314-Tableau.jpg" alt="Tableau">&lt;/p>
&lt;h1 id="tableau-course">Tableau Course&lt;a class="td-heading-self-link" href="#tableau-course" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>A brief summary of the topics covered in this Tableau course is as below. This is 16 hours course, it is suggested to complete this course in 1 week.&lt;/p></description></item><item><title>Power BI</title><link>https://dasarpai.github.io/dscourses/power-bi/</link><pubDate>Mon, 27 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/power-bi/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc313-Power-BI.jpg" alt="Power BI">&lt;/p>
&lt;h1 id="microsoft-power-bi-course">Microsoft Power BI Course&lt;a class="td-heading-self-link" href="#microsoft-power-bi-course" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>A brief summary of the topics covered in this Power BI course is as below. This is 16 hours course, it is suggested to complete this course within 1 week.&lt;/p></description></item><item><title>Reinforcement Learning</title><link>https://dasarpai.github.io/dscourses/reinforcement-learning/</link><pubDate>Sun, 26 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/reinforcement-learning/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc312-Reinforcement-Learning.jpg" alt="Reinforcement Learning">&lt;/p>
&lt;h1 id="reinforcement-learning">Reinforcement Learning&lt;a class="td-heading-self-link" href="#reinforcement-learning" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="classical-reinforcement-learning">Classical Reinforcement Learning&lt;a class="td-heading-self-link" href="#classical-reinforcement-learning" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="markov-decision-process">Markov Decision Process&lt;a class="td-heading-self-link" href="#markov-decision-process" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Introduction&lt;/li>
&lt;li>What is Reinforcement Learning?&lt;/li>
&lt;li>Agent-Environment Interaction&lt;/li>
&lt;li>State Vectors&lt;/li>
&lt;li>Objective of RL Agent&lt;/li>
&lt;li>Actions &amp;amp; Policy&lt;/li>
&lt;li>Exploration vs Exploitation&lt;/li>
&lt;li>Markov State&lt;/li>
&lt;li>Markov Decision Process (MDP)&lt;/li>
&lt;li>Value Function&lt;/li>
&lt;li>Optimal Policy&lt;/li>
&lt;li>Model of the Environment&lt;/li>
&lt;li>RL vs Supervised Learning&lt;/li>
&lt;li>Inventory Management (MDP)&lt;/li>
&lt;/ul>
&lt;h3 id="fundamental-equations-in-rl">Fundamental Equations in RL&lt;a class="td-heading-self-link" href="#fundamental-equations-in-rl" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Introduction&lt;/li>
&lt;li>RL Equations – State Value Function&lt;/li>
&lt;li>RL Equations – Action Value Function&lt;/li>
&lt;li>Understanding the RL Equations&lt;/li>
&lt;li>Bellman Equations of Optimality&lt;/li>
&lt;li>Policy Improvement&lt;/li>
&lt;li>Introduction&lt;/li>
&lt;/ul>
&lt;h3 id="model-based-method--dynamic-programming">Model-Based Method – Dynamic Programming&lt;a class="td-heading-self-link" href="#model-based-method--dynamic-programming" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Dynamic Programming&lt;/li>
&lt;li>Policy Iteration – Algorithm&lt;/li>
&lt;li>Policy Evaluation – Prediction&lt;/li>
&lt;li>Policy Improvement – Control&lt;/li>
&lt;li>Policy Iteration – GridWorld&lt;/li>
&lt;li>Value Iteration&lt;/li>
&lt;li>Generalised Policy Iteration (GPI)&lt;/li>
&lt;li>Ad Placement Optimization (Demo)&lt;/li>
&lt;/ul>
&lt;h3 id="model-free-methods">Model-Free Methods&lt;a class="td-heading-self-link" href="#model-free-methods" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Introduction&lt;/li>
&lt;li>Intuition behind Monte-Carlo Methods&lt;/li>
&lt;li>Monte-Carlo Prediction &amp;amp; Demo&lt;/li>
&lt;li>Monte-Carlo Control&lt;/li>
&lt;li>Off Policy&lt;/li>
&lt;li>Temporal Difference&lt;/li>
&lt;li>Q-Learning with Pseudocode&lt;/li>
&lt;li>Cliff Walking Demo&lt;/li>
&lt;li>Ad Placement Optimization Demo -Q Learning&lt;/li>
&lt;li>OpenAI Gym -Taxi v2&lt;/li>
&lt;/ul>
&lt;h3 id="inventory-management-demo">Inventory Management Demo&lt;a class="td-heading-self-link" href="#inventory-management-demo" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Introduction&lt;/li>
&lt;li>Problem Statement&lt;/li>
&lt;li>MDP code&lt;/li>
&lt;li>Q-Learning code&lt;/li>
&lt;li>Results&lt;/li>
&lt;/ul>
&lt;h2 id="assignment--classical-reinforcement-learning">Assignment -Classical Reinforcement Learning&lt;a class="td-heading-self-link" href="#assignment--classical-reinforcement-learning" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h2 id="assignment--tic-tac-toe">Assignment – Tic-Tac-Toe&lt;a class="td-heading-self-link" href="#assignment--tic-tac-toe" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h2 id="deep-reinforcement-learning">Deep Reinforcement Learning&lt;a class="td-heading-self-link" href="#deep-reinforcement-learning" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;p>Want to build your own Atari Game? Learn the Q-function or policy using the various Deep Reinforcement Learning algorithms: Deep Q Learning, Policy Gradient Methods, Actor-Critic method.&lt;/p></description></item><item><title>Explainable AI</title><link>https://dasarpai.github.io/dscourses/explainable-ai/</link><pubDate>Sat, 25 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/explainable-ai/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc311-Explainable-AI.jpg" alt="Explainable AI">&lt;/p>
&lt;h1 id="explainable-ai---xai">Explainable AI - XAI&lt;a class="td-heading-self-link" href="#explainable-ai---xai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="please-contant-me-via--or-whatsapp-91-9-5-3-5-9-9-9-3-3-6">Please contant me via &lt;a href="mailto:hari@dasarpai.com">hari@dasarpai.com&lt;/a> or whatsapp +91 9 5 3 5 9 9 9 3 3 6&lt;a class="td-heading-self-link" href="#please-contant-me-via--or-whatsapp-91-9-5-3-5-9-9-9-3-3-6" aria-label="Heading self-link">&lt;/a>&lt;/h2></description></item><item><title>Microsoft Excel</title><link>https://dasarpai.github.io/dscourses/microsoft-excel/</link><pubDate>Fri, 24 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/microsoft-excel/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc310-Microsoft-Excel.jpg" alt="Microsoft Excel">&lt;/p>
&lt;h1 id="microsoft-excel">Microsoft Excel&lt;a class="td-heading-self-link" href="#microsoft-excel" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction-to-excel">Introduction to Excel&lt;a class="td-heading-self-link" href="#introduction-to-excel" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="basic">Basic&lt;a class="td-heading-self-link" href="#basic" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Microsoft Excel Fundamentals&lt;/li>
&lt;li>Introduction to Interface&lt;/li>
&lt;li>Discovering Shortcuts&lt;/li>
&lt;li>Entering and Editing Text and Formulas&lt;/li>
&lt;li>Excel Data Validation&lt;/li>
&lt;li>Excel List Functions&lt;/li>
&lt;li>Slicing and Dicing Data – Sort and Filter&lt;/li>
&lt;li>Cell Referencing and Text Functions&lt;/li>
&lt;li>Passwords and Naming Files&lt;/li>
&lt;li>Inserting Images and Shapes into an Excel Worksheet&lt;/li>
&lt;li>Modifying an Excel Worksheet&lt;/li>
&lt;li>Protecting Excel Worksheets and Workbooks&lt;/li>
&lt;/ul>
&lt;h3 id="working-with-cells">Working with Cells&lt;a class="td-heading-self-link" href="#working-with-cells" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Cell Referencing and Text Functions&lt;/li>
&lt;li>Common Errors in Excel&lt;/li>
&lt;/ul>
&lt;h3 id="working-with-formulae">Working with Formulae&lt;a class="td-heading-self-link" href="#working-with-formulae" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Introduction to Formulae&lt;/li>
&lt;li>Logical Formulae&lt;/li>
&lt;li>Lookup Functions&lt;/li>
&lt;li>Text Based Functions&lt;/li>
&lt;li>Complex Functions&lt;/li>
&lt;li>Conditional Functions&lt;/li>
&lt;/ul>
&lt;h3 id="working-with-files">Working with Files&lt;a class="td-heading-self-link" href="#working-with-files" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Importing and Exporting Data&lt;/li>
&lt;li>Importing Data from Text Files&lt;/li>
&lt;li>Delimited Files&lt;/li>
&lt;li>Auditing an Excel Worksheet&lt;/li>
&lt;/ul>
&lt;h3 id="printing--formatting">Printing &amp;amp; Formatting&lt;a class="td-heading-self-link" href="#printing--formatting" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Formatting Data in an Excel Worksheet&lt;/li>
&lt;li>Preparing Weekly Report&lt;/li>
&lt;li>Printing an Excel Worksheet&lt;/li>
&lt;li>Printing and Page Layout&lt;/li>
&lt;li>Report Making II: Conditional Formatting&lt;/li>
&lt;li>Report Making III: Advanced Formatting&lt;/li>
&lt;/ul>
&lt;h2 id="advance-excel">Advance Excel&lt;a class="td-heading-self-link" href="#advance-excel" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="charts">Charts&lt;a class="td-heading-self-link" href="#charts" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Types of Charts&lt;/li>
&lt;li>Charts&lt;/li>
&lt;li>Creating Basic Charts in Excel&lt;/li>
&lt;li>Creating and Formatting Charts&lt;/li>
&lt;/ul>
&lt;h3 id="pivot">Pivot&lt;a class="td-heading-self-link" href="#pivot" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Creating a Pivot Table&lt;/li>
&lt;li>Analyzing Data in a Pivot Table&lt;/li>
&lt;li>Filtering Data in a Pivot Table&lt;/li>
&lt;/ul>
&lt;h3 id="automation">Automation&lt;a class="td-heading-self-link" href="#automation" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>VBA&lt;/li>
&lt;li>Automating Repetitive Tasks in Excel with Macros&lt;/li>
&lt;li>Preparing and Cleaning Up Data with VBA&lt;/li>
&lt;/ul>
&lt;h3 id="analysis">Analysis&lt;a class="td-heading-self-link" href="#analysis" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Mastering Excel “What If?” Tools&lt;/li>
&lt;li>Working with Large Sets of Excel Data&lt;/li>
&lt;li>VLOOKUP-Linking Data from Multiple Files &amp;amp; Tables&lt;/li>
&lt;/ul>
&lt;h2 id="visualization-and-eda-in-excel">Visualization and EDA in Excel&lt;a class="td-heading-self-link" href="#visualization-and-eda-in-excel" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h2 id="limitations-of-excel">Limitations of Excel&lt;a class="td-heading-self-link" href="#limitations-of-excel" aria-label="Heading self-link">&lt;/a>&lt;/h2></description></item><item><title>Data Engineering</title><link>https://dasarpai.github.io/dscourses/Data-Engineering/</link><pubDate>Thu, 23 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/Data-Engineering/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc309-Data-Engineering.jpg" alt="Data Engineering">&lt;/p>
&lt;h1 id="data-engineering">Data Engineering&lt;a class="td-heading-self-link" href="#data-engineering" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="exploratory-data-analysis-eda">Exploratory Data Analysis (EDA)&lt;a class="td-heading-self-link" href="#exploratory-data-analysis-eda" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Data sourcing – public and private data&lt;/li>
&lt;li>Data cleaning – handling missing values, handling invalid data, filtering data, standardization, etc.&lt;/li>
&lt;li>Univariate analysis – unordered vs ordered categorical variables, quantitative variables &amp;amp; measures of central tendency&lt;/li>
&lt;li>Segmented univariate analysis – basis of segmentation, comparison of averages and other metrics&lt;/li>
&lt;li>Bivariate analysis – bivariate on quantitative and categorical variables, correlation&lt;/li>
&lt;li>Derived metrics – introduction, type-driven metrics, business-driven metrics, data-driven metrics&lt;/li>
&lt;li>&lt;strong>Examples&lt;/strong>
&lt;ul>
&lt;li>Feature engineering and selection.&lt;/li>
&lt;li>Analyzing bike sharing trends.&lt;/li>
&lt;li>Analyzing movie reviews sentiment.&lt;/li>
&lt;li>Customer segmentation and effective cross-selling.&lt;/li>
&lt;li>Analyzing wine types and quality.&lt;/li>
&lt;li>Analyzing music trends and recommendations.&lt;/li>
&lt;li>Forecasting stock and commodity prices&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="data-mining">Data Mining&lt;a class="td-heading-self-link" href="#data-mining" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Introduction: Definitions, Activities, Process, Key challenges&lt;/li>
&lt;li>Understanding Data:  Data Types/ Attribute Types,  Statistical Descriptions of Data&lt;/li>
&lt;li>Measuring Data Similarity and Dissimilarity&lt;/li>
&lt;li>Data Pre-processing – Overview&lt;/li>
&lt;li>Association Rule Mining&lt;/li>
&lt;/ol>
&lt;h2 id="data-modelling">Data Modelling&lt;a class="td-heading-self-link" href="#data-modelling" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h2 id="data-cleaning">Data Cleaning&lt;a class="td-heading-self-link" href="#data-cleaning" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h2 id="data-visualization--interpretation">Data Visualization &amp;amp; Interpretation&lt;a class="td-heading-self-link" href="#data-visualization--interpretation" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Information overload and issues in decision making&lt;/li>
&lt;li>Design of visual encoding schemes to improve comprehension of data and their use in decision making&lt;/li>
&lt;li>Presentation and visualization of data for effective communication&lt;/li>
&lt;li>Elementary graphics programming, charts, graphs, animations, user interactivity, hierarchical layouts, and techniques for visualization of high dimensional data &amp;amp; discovered patterns&lt;/li>
&lt;/ol>
&lt;h2 id="eda-tools">EDA Tools&lt;a class="td-heading-self-link" href="#eda-tools" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Pandas Profiling&lt;/li>
&lt;li>Lux&lt;/li>
&lt;/ol></description></item><item><title>Python For Data Science</title><link>https://dasarpai.github.io/dscourses/python-for-data-science/</link><pubDate>Wed, 22 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/python-for-data-science/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc308-Python-For-Data-Science.jpg" alt="Python For Data Science">&lt;/p>
&lt;h1 id="python-for-data-science">Python for Data Science&lt;a class="td-heading-self-link" href="#python-for-data-science" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>A brief summary of the topics covered in this course is as below. This is 30 hours course, it is suggested to complete this course in 3 weeks. After the completion of this course, you will have a solid foundation in Python programming. Following that, you need to practice it consistently for a minimum of 6 months.&lt;/p></description></item><item><title>Pandas for Data Science</title><link>https://dasarpai.github.io/dscourses/pandas-for-data-science/</link><pubDate>Tue, 21 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/pandas-for-data-science/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc307-Pandas-for-Data-Science.jpg" alt="Pandas for Data Science">&lt;/p>
&lt;h1 id="pandas-for-data-science">Pandas for Data Science&lt;a class="td-heading-self-link" href="#pandas-for-data-science" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>A brief summary of the topics covered in this course is as below. This is 30 hours course, it is suggested to complete this course in 3 weeks. If you already know python enough, then you can skip the first 3 modules of this course. It will save you one week.&lt;/p></description></item><item><title>Statistics For Data Science</title><link>https://dasarpai.github.io/dscourses/Statistics-For-Data-Science/</link><pubDate>Mon, 20 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/Statistics-For-Data-Science/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc306-Statistics-For-Data-Science.jpg" alt="Statistics For Data Science">&lt;/p>
&lt;h1 id="statistics-for-data-science">Statistics for Data Science&lt;a class="td-heading-self-link" href="#statistics-for-data-science" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>A brief summary of the topics covered in this course is as below. This is 25 hours course, it is suggested to complete this course in 3 weeks.&lt;/p></description></item><item><title>Mathematics for Data Scientist</title><link>https://dasarpai.github.io/dscourses/Mathematics-for-Data-Scientist/</link><pubDate>Sun, 19 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/Mathematics-for-Data-Scientist/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc305-Mathematics-for-Data-Scientist.jpg" alt="Mathematics for Data Scientist">&lt;/p>
&lt;h1 id="mathematical-for-data-scientist">Mathematical for Data Scientist&lt;a class="td-heading-self-link" href="#mathematical-for-data-scientist" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>To excel in the field of data science, especially as a data scientist, I would recommend you have good command over the topics mentioned below. There are many YouTube channels that you can use for this purpose. Because this is 10+2 level mathematics, and it is just a matter of revision. So I am not offering any course unless there is a specific need for some group, organization.&lt;/p></description></item><item><title>Deep Learning for Computer Vision</title><link>https://dasarpai.github.io/dscourses/Deep-Learning-for-Computer-Vision/</link><pubDate>Sat, 18 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/Deep-Learning-for-Computer-Vision/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc304-Deep-Learning-for-Computer-Vision.jpg" alt="Deep Learning for Computer Vision">&lt;/p>
&lt;h1 id="deep-learning--computer-vision">Deep Learning – Computer Vision&lt;a class="td-heading-self-link" href="#deep-learning--computer-vision" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="foundation-of-computer-vision">Foundation of Computer Vision&lt;a class="td-heading-self-link" href="#foundation-of-computer-vision" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Common Architectural Principles of Deep Networks&lt;/li>
&lt;li>Building Blocks of Deep Networks&lt;/li>
&lt;li>Convolutional Neural Networks (CNNs)&lt;/li>
&lt;li>Recurrent Neural Networks&lt;/li>
&lt;li>Recursive Neural Networks; Applications to Sequence Data&lt;/li>
&lt;li>Anomaly Detection&lt;/li>
&lt;li>Tuning Deep Networks&lt;/li>
&lt;li>Vectorization&lt;/li>
&lt;li>Data Mining (Pre-requisites)&lt;/li>
&lt;/ol>
&lt;h2 id="cnn-overview">CNN overview&lt;a class="td-heading-self-link" href="#cnn-overview" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>CNN Definition&lt;/li>
&lt;li>CNN based Architectures&lt;/li>
&lt;li>End to end CNN network&lt;/li>
&lt;li>Training CNN&lt;/li>
&lt;li>Deployment in Azure Cloud&lt;/li>
&lt;li>Performance tuning of CNN network&lt;/li>
&lt;/ol>
&lt;h2 id="advance-computer-vision--part-1">Advance Computer Vision – Part 1&lt;a class="td-heading-self-link" href="#advance-computer-vision--part-1" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>CNN Architectures with research paper and mathematics&lt;/li>
&lt;li>Resnet-5 variants with research paper and practical&lt;/li>
&lt;li>AlexNet variants with research paper and practical&lt;/li>
&lt;li>GoogleNet variants with research paper and practical&lt;/li>
&lt;li>Transfer learning&lt;/li>
&lt;li>VGGNet variants with research paper and practical&lt;/li>
&lt;li>Inception net variants with research paper and practical&lt;/li>
&lt;li>Darknet variants with research paper and practical&lt;/li>
&lt;/ol>
&lt;h2 id="advance-computer-vision--part-2">Advance Computer Vision – Part 2&lt;a class="td-heading-self-link" href="#advance-computer-vision--part-2" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Object detection in-depth&lt;/li>
&lt;li>Transfer learning&lt;/li>
&lt;li>RCNN with research paper and practical&lt;/li>
&lt;li>Fast RCNN with research paper and practical&lt;/li>
&lt;li>Faster RCNN with research paper and practical&lt;/li>
&lt;li>SSD with research paper and practical&lt;/li>
&lt;li>SSD lite with research paper and practical&lt;/li>
&lt;/ol>
&lt;h2 id="training-of-custom-object-detection">Training of Custom Object Detection&lt;a class="td-heading-self-link" href="#training-of-custom-object-detection" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>TFOD introduction&lt;/li>
&lt;li>Environment setup wtih TFOD&lt;/li>
&lt;li>GPU vs TPU vs CPU&lt;/li>
&lt;li>GPU Comparison&lt;/li>
&lt;/ol>
&lt;h2 id="advance-computer-vision--part-3">Advance Computer Vision – Part 3&lt;a class="td-heading-self-link" href="#advance-computer-vision--part-3" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Yolo v1 with research paper and practical&lt;/li>
&lt;li>Retina net&lt;/li>
&lt;li>Face net&lt;/li>
&lt;li>Detectron2 with practical and live testing&lt;/li>
&lt;/ol>
&lt;h2 id="object-segmentation">Object segmentation&lt;a class="td-heading-self-link" href="#object-segmentation" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Semantic segmentation&lt;/li>
&lt;li>Panoptic segmentation&lt;/li>
&lt;li>Masked RCNN&lt;/li>
&lt;li>Practical with Detectron&lt;/li>
&lt;li>Practical with TFOD&lt;/li>
&lt;/ol>
&lt;h2 id="object-tracking">Object tracking&lt;a class="td-heading-self-link" href="#object-tracking" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Detail of object tracking&lt;/li>
&lt;li>Kalman filtering&lt;/li>
&lt;li>Sort&lt;/li>
&lt;li>Deep sort&lt;/li>
&lt;li>Object tracking live project with live camera testing&lt;/li>
&lt;/ol>
&lt;h2 id="ocr">OCR&lt;a class="td-heading-self-link" href="#ocr" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Introduction to OCR&lt;/li>
&lt;li>Various framework and API for OCR&lt;/li>
&lt;li>Practical implementation of OCR&lt;/li>
&lt;li>Live project deployment for bill parsing&lt;/li>
&lt;/ol>
&lt;h2 id="image-captioning">Image captioning&lt;a class="td-heading-self-link" href="#image-captioning" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Image captioning overview&lt;/li>
&lt;li>Image captioning project with deployment&lt;/li>
&lt;/ol></description></item><item><title>Natural Language Processing</title><link>https://dasarpai.github.io/dscourses/Natural-Language-Processing/</link><pubDate>Fri, 17 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/Natural-Language-Processing/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc303-Natural-Language-Processing.jpg" alt="Natural Language Processing">&lt;/p>
&lt;h1 id="natural-language-processing-nlp">Natural Language Processing (NLP)&lt;a class="td-heading-self-link" href="#natural-language-processing-nlp" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="foundation-of-natural-language-processing">Foundation of Natural Language Processing&lt;a class="td-heading-self-link" href="#foundation-of-natural-language-processing" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>Overview computational linguistic.&lt;/li>
&lt;li>History of NLP&lt;/li>
&lt;li>Why NLP&lt;/li>
&lt;li>Use of NLP&lt;/li>
&lt;li>Language modelling with N-gram&lt;/li>
&lt;li>Spelling correction&lt;/li>
&lt;li>Neural networks and neural language models&lt;/li>
&lt;li>Parts-of-Speech tagging&lt;/li>
&lt;li>Syntactic parsing&lt;/li>
&lt;li>Language semantics&lt;/li>
&lt;li>Computational semantics&lt;/li>
&lt;/ul>
&lt;h2 id="text-analytics-processing-and-predictive-modelling">Text Analytics, Processing, and Predictive Modelling&lt;a class="td-heading-self-link" href="#text-analytics-processing-and-predictive-modelling" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>Introduction to text analytics (text encoding, regular expressions*, word frequencies &amp;amp; stop words, tokenization, bag-of-words representation, stemming &amp;amp; lemmatization, TF-IDF)&lt;/li>
&lt;li>The Naive Bayes algorithm (Bayes’ theorem and its building blocks, Naive Bayes for text classification)&lt;/li>
&lt;/ul>
&lt;h2 id="text-processing-importing-text">Text Processing Importing text.&lt;a class="td-heading-self-link" href="#text-processing-importing-text" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>Web scrapping.&lt;/li>
&lt;li>Text processing&lt;/li>
&lt;li>Understanding regex.&lt;/li>
&lt;li>Text normalization&lt;/li>
&lt;li>Word count.&lt;/li>
&lt;li>Frequency distribution.&lt;/li>
&lt;li>Text annotation.&lt;/li>
&lt;li>Use of annotator.&lt;/li>
&lt;li>String tokenization&lt;/li>
&lt;li>Annotator creation.&lt;/li>
&lt;li>Sentence processing.&lt;/li>
&lt;li>Lemmatization in text processing&lt;/li>
&lt;li>POS.&lt;/li>
&lt;li>Named entity recognition&lt;/li>
&lt;li>Dependency parsing in text.&lt;/li>
&lt;li>Sentimental analysis&lt;/li>
&lt;/ul>
&lt;h2 id="word-embedding">Word embedding&lt;a class="td-heading-self-link" href="#word-embedding" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>Word embedding&lt;/li>
&lt;li>Co-occurrence vectors&lt;/li>
&lt;li>Word2vec&lt;/li>
&lt;li>Doc2vec&lt;/li>
&lt;/ul>
&lt;h2 id="rnn-for-nlp">RNN for NLP&lt;a class="td-heading-self-link" href="#rnn-for-nlp" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>Recurrent neural networks.&lt;/li>
&lt;li>Long short term memory (LSTM)&lt;/li>
&lt;li>Bi LSTM.&lt;/li>
&lt;li>Stacked LSTM&lt;/li>
&lt;li>GRU implementation.&lt;/li>
&lt;li>Building a story writer using character level RNN.&lt;/li>
&lt;/ul>
&lt;h2 id="attention-based-model">Attention based model&lt;a class="td-heading-self-link" href="#attention-based-model" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>Seq2Seq.&lt;/li>
&lt;li>Encoders and decoders.&lt;/li>
&lt;li>Attention mechanism.&lt;/li>
&lt;li>Attention neural networks&lt;/li>
&lt;li>Self-attention&lt;/li>
&lt;/ul>
&lt;h2 id="transfer-learning-in-nlp">Transfer learning in NLP&lt;a class="td-heading-self-link" href="#transfer-learning-in-nlp" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>Introduction to transformers.&lt;/li>
&lt;li>Bert model.&lt;/li>
&lt;li>Elmo model.&lt;/li>
&lt;li>GPT2 model&lt;/li>
&lt;li>GPT3 model.&lt;/li>
&lt;li>Albert model.&lt;/li>
&lt;li>Distilbert model&lt;/li>
&lt;/ul>
&lt;h2 id="transformers-for-nlp">Transformers for NLP&lt;a class="td-heading-self-link" href="#transformers-for-nlp" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ul>
&lt;li>GPT3&lt;/li>
&lt;li>BERT&lt;/li>
&lt;/ul>
&lt;h2 id="nlp-libraries">NLP Libraries&lt;a class="td-heading-self-link" href="#nlp-libraries" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;h3 id="spacy">Spacy&lt;a class="td-heading-self-link" href="#spacy" aria-label="Heading self-link">&lt;/a>&lt;/h3>
&lt;ul>
&lt;li>Spacy overview&lt;/li>
&lt;li>Spacy function&lt;/li>
&lt;li>Spacy function implementation in text processing.&lt;/li>
&lt;li>Pos tagging, challenges and accuracy.&lt;/li>
&lt;li>Entities and named entry recognition&lt;/li>
&lt;li>Interpolation, language models&lt;/li>
&lt;li>NLTK&lt;/li>
&lt;li>Text blob&lt;/li>
&lt;li>Stanford NLP&lt;/li>
&lt;/ul></description></item><item><title>Machine Learning for Timeseries</title><link>https://dasarpai.github.io/dscourses/Machine-Learning-for-Timeseries/</link><pubDate>Thu, 16 Sep 2021 15:46:43 -0400</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/Machine-Learning-for-Timeseries/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc302-Machine-Learning-for-Timeseries.jpg" alt="Machine Learning for Timeseries">&lt;/p>
&lt;h1 id="machine-learning-for-timeseries">Machine Learning for Timeseries&lt;a class="td-heading-self-link" href="#machine-learning-for-timeseries" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>A brief summary of the topics covered in this course is as below. This is 24 hours course, it is suggested to complete this course in 3 weeks. Apart from my classroom course, you will be given exercises, and it will take another 100 hours in the course duration to complete these exercises.&lt;/p></description></item><item><title>What Are Transformers in AI</title><link>https://dasarpai.github.io/dsblog/What-Are-Transformers-in-AI/</link><pubDate>Tue, 03 Aug 2021 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/What-Are-Transformers-in-AI/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6031-What-are-Transformers-in-AI.jpg" alt="What-are-Transformers-in-AI">&lt;/p>
&lt;h1 id="what-are-transformers-in-ai">What Are Transformers in AI&lt;a class="td-heading-self-link" href="#what-are-transformers-in-ai" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="transformer-architecture">Transformer Architecture&lt;a class="td-heading-self-link" href="#transformer-architecture" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>&lt;img src="../../assets/images/dspost/transformer/transformer-arch.jpg" alt="Transformer">&lt;/p>
&lt;h2 id="background">Background&lt;a class="td-heading-self-link" href="#background" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Whether GPT, ChatGPT, DALL-E, Whisper, Satablity AI or whatever significant you see in the AI worlds nowdays it is because of Transformer Architecture. Transformers are a type of neural network architecture that have several properties that make them effective for modeling data with long-range dependencies. They generally feature a combination of multi-headed attention mechanisms, residual connections, layer normalization, feedforward connections, and positional embeddings.&lt;/p></description></item><item><title>Machine Learning Course</title><link>https://dasarpai.github.io/dscourses/machine-learning/</link><pubDate>Fri, 02 Jul 2021 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dscourses/machine-learning/</guid><description>&lt;p>&lt;img src="../../assets/images/dscourses/dsc301-Machine-Learning.jpg" alt="Machine Learning Course">&lt;/p>
&lt;h1 id="machine-learning-courses">Machine Learning Courses&lt;a class="td-heading-self-link" href="#machine-learning-courses" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>A brief summary of the topics covered in this course is as below. This is 150 hours course, it is suggested to complete this course in 2 Months. Apart from my classroom course, you will be given exercises, and it will take another 100 hours in the course duration to complete these exercises.&lt;/p></description></item><item><title>How Naive Bayes Classifier Works</title><link>https://dasarpai.github.io/dsblog/How-Naive-Bayes-Classifier-Works/</link><pubDate>Wed, 31 Mar 2021 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/How-Naive-Bayes-Classifier-Works/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6005-How-Naive-Bayes-Work-for-Recommendation.jpg" alt="Naive Bayes">&lt;/p>
&lt;h1 id="how-naive-bayes-classifier-works">How Naive Bayes Classifier Works?&lt;a class="td-heading-self-link" href="#how-naive-bayes-classifier-works" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="naive-bayes-classifier-example">Naive Bayes classifier example&lt;a class="td-heading-self-link" href="#naive-bayes-classifier-example" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>In this presentation, I am not going into the depth of the Naive Bayes algorithm. I am assuming you have heard this term many times but are not able to visualize it mentally or struggling to comprehend this. If that is the case, then you are on the right page.&lt;/p></description></item><item><title>EDA &amp; Feature Engineering 101</title><link>https://dasarpai.github.io/dsblog/EDA-Feature-Engineering-101/</link><pubDate>Mon, 24 Aug 2020 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/EDA-Feature-Engineering-101/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6008-EDA101.jpg" alt="EDA &amp;amp; Feature Engineering">&lt;/p>
&lt;h2 id="what-is-eda">What is EDA?&lt;a class="td-heading-self-link" href="#what-is-eda" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>EDA means Exploratory Data Analysis. The purpose of data analysis is to explore. Exploration means try to understand what kind of data I have in my hand. Using EDA we try to get the answer to the following questions.&lt;/p></description></item><item><title>DS, AI, ML Online Course, Tutorial, Videos</title><link>https://dasarpai.github.io/dsblog/data-science-tutorial-video-resources/</link><pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/data-science-tutorial-video-resources/</guid><description>&lt;p>&lt;img src="../../assets/images/dsresources/dsr119-DS-AI-ML-Online-Course-Tutorial-Videos.jpg" alt="DS, AI, ML Online Course, Tutorial, Videos">&lt;/p>
&lt;h1 id="ds-ai-ml-online-course-tutorial-videos">DS, AI, ML Online Course, Tutorial, Videos&lt;a class="td-heading-self-link" href="#ds-ai-ml-online-course-tutorial-videos" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="courses">Courses&lt;a class="td-heading-self-link" href="#courses" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://class.coursera.org/ml-005">Machine Learning – Stanford&lt;/a> by Andrew Ng in Coursera (2010-2014)&lt;/li>
&lt;li>&lt;a href="https://work.caltech.edu/lectures.html">Machine Learning – Caltech&lt;/a> by Yaser Abu-Mostafa (2012-2014)&lt;/li>
&lt;li>&lt;a href="https://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml">Machine Learning – Carnegie Mellon&lt;/a> by Tom Mitchell (Spring 2011)&lt;/li>
&lt;li>&lt;a href="https://class.coursera.org/neuralnets-2012-001">Neural Networks for Machine Learning&lt;/a> by Geoffrey Hinton in Coursera (2012)&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH">Neural networks class&lt;/a> by Hugo Larochelle from Université de Sherbrooke (2013)&lt;/li>
&lt;li>&lt;a href="https://cilvr.cs.nyu.edu/doku.php?id=deeplearning:slides:start">Deep Learning Course&lt;/a> by CILVR lab @ NYU (2014)&lt;/li>
&lt;li>&lt;a href="https://courses.edx.org/courses/BerkeleyX/CS188x_1/1T2013/courseware/">A.I – Berkeley&lt;/a> by Dan Klein and Pieter Abbeel (2013)&lt;/li>
&lt;li>&lt;a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/">A.I – MIT&lt;/a> by Patrick Henry Winston (2010)&lt;/li>
&lt;li>&lt;a href="https://web.mit.edu/course/other/i2course/www/vision_and_learning_fall_2013.html">Vision and learning – computers and brains&lt;/a> by Shimon Ullman, Tomaso Poggio, Ethan Meyers @ MIT (2013)&lt;/li>
&lt;li>&lt;a href="https://vision.stanford.edu/teaching/cs231n/syllabus.html">Convolutional Neural Networks for Visual Recognition – Stanford&lt;/a> by Fei-Fei Li, Andrej Karpathy (2017)&lt;/li>
&lt;li>&lt;a href="https://cs224d.stanford.edu/">Deep Learning for Natural Language Processing – Stanford&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://info.usherbrooke.ca/hlarochelle/neural_networks/content.html">Neural Networks – usherbrooke&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/">Machine Learning – Oxford&lt;/a> (2014-2015)&lt;/li>
&lt;li>&lt;a href="https://developer.nvidia.com/deep-learning-courses">Deep Learning – Nvidia&lt;/a> (2015)&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/playlist?list=PLHyI3Fbmv0SdzMHAy0aN59oYnLy5vyyTA">Graduate Summer School: Deep Learning, Feature Learning&lt;/a> by Geoffrey Hinton, Yoshua Bengio, Yann LeCun, Andrew Ng, Nando de Freitas and several others @ IPAM, UCLA (2012)&lt;/li>
&lt;li>&lt;a href="https://www.udacity.com/course/deep-learning--ud730">Deep Learning – Udacity/Google&lt;/a> by Vincent Vanhoucke and Arpan Chakraborty (2016)&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/playlist?list=PLehuLRPyt1Hyi78UOkMPWCGRxGcA9NVOE">Deep Learning – UWaterloo&lt;/a> by Prof. Ali Ghodsi at University of Waterloo (2015)&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=azaLcvuql_g&amp;amp;list=PLjbUi5mgii6BWEUZf7He6nowWvGne_Y8r">Statistical Machine Learning – CMU&lt;/a> by Prof. Larry Wasserman&lt;/li>
&lt;li>&lt;a href="https://www.college-de-france.fr/site/en-yann-lecun/course-2015-2016.htm">Deep Learning Course&lt;/a> by Yann LeCun (2016)&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/playlist?list=PLkFD6_40KJIxopmdJF_CLNqG3QuDFHQUm">Designing, Visualizing and Understanding Deep Neural Networks-UC Berkeley&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://uvadlc.github.io/">UVA Deep Learning Course&lt;/a> MSc in Artificial Intelligence for the University of Amsterdam.&lt;/li>
&lt;li>&lt;a href="https://selfdrivingcars.mit.edu/">MIT 6.S094: Deep Learning for Self-Driving Cars&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://introtodeeplearning.com/">MIT 6.S191: Introduction to Deep Learning&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://rll.berkeley.edu/deeprlcourse/">Berkeley CS 294: Deep Reinforcement Learning&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.manning.com/livevideo/keras-in-motion">Keras in Motion video course&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://course.fast.ai/">Practical Deep Learning For Coders&lt;/a> by Jeremy Howard – Fast.ai&lt;/li>
&lt;li>&lt;a href="https://deeplearning.cs.cmu.edu/">Introduction to Deep Learning&lt;/a> by Prof. Bhiksha Raj (2017)&lt;/li>
&lt;li>&lt;a href="https://www.deeplearning.ai/ai-for-everyone/">AI for Everyone&lt;/a> by Andrew Ng (2019)&lt;/li>
&lt;li>&lt;a href="https://introtodeeplearning.com/">MIT Intro to Deep Learning 7 day bootcamp&lt;/a> – A seven day bootcamp designed in MIT to introduce deep learning methods and applications (2019)&lt;/li>
&lt;li>&lt;a href="https://mithi.github.io/deep-blueberry">Deep Blueberry: Deep Learning&lt;/a> – A free five-weekend plan to self-learners to learn the basics of deep-learning architectures like CNNs, LSTMs, RNNs, VAEs, GANs, DQN, A3C and more (2019)&lt;/li>
&lt;li>&lt;a href="https://spinningup.openai.com/">Spinning Up in Deep Reinforcement Learning&lt;/a> – A free deep reinforcement learning course by OpenAI (2019)&lt;/li>
&lt;li>&lt;a href="https://www.coursera.org/specializations/deep-learning">Deep Learning Specialization – Coursera&lt;/a> – Breaking into AI with the best course from Andrew NG.&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/playlist?list=PLZSO_6-bSqHQHBCoGaObUljoXAyyqhpFW">Deep Learning – UC Berkeley STAT-157&lt;/a> by Alex Smola and Mu Li (2019)&lt;/li>
&lt;li>&lt;a href="https://www.manning.com/livevideo/machine-learning-for-mere-mortals">Machine Learning for Mere Mortals video course&lt;/a> by Nick Chase&lt;/li>
&lt;li>&lt;a href="https://developers.google.com/machine-learning/crash-course/">Machine Learning Crash Course with TensorFlow APIs&lt;/a> -Google AI&lt;/li>
&lt;li>&lt;a href="https://course.fast.ai/part2">Deep Learning from the Foundations&lt;/a> Jeremy Howard – Fast.ai&lt;/li>
&lt;li>&lt;a href="https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893">Deep Reinforcement Learning (nanodegree) – Udacity&lt;/a> a 3-6 month Udacity nanodegree, spanning multiple courses (2018)&lt;/li>
&lt;li>&lt;a href="https://www.manning.com/livevideo/grokking-deep-learning-in-motion">Grokking Deep Learning in Motion&lt;/a> by Beau Carnes (2018)&lt;/li>
&lt;li>&lt;a href="https://www.udemy.com/share/1000gAA0QdcV9aQng=/">Face Detection with Computer Vision and Deep Learning&lt;/a> by Hakan Cebeci&lt;/li>
&lt;li>&lt;a href="https://www.coursera.org/learn/slides?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-CmOo_hUqOR9Oj8ApcOw0Kg&amp;amp;siteID=SAyYsTvLiGQ-CmOo_hUqOR9Oj8ApcOw0Kg&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ">Presentation skills: Designing Presentation Slides - Coursera&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.coursera.org/learn/multivariate-calculus-machine-learning?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-heqdps0Uveezr1XmtoOPDQ&amp;amp;siteID=SAyYsTvLiGQ-heqdps0Uveezr1XmtoOPDQ&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ">Mathematics for Machine Learning: Multivariate Calculus - Coursera&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.coursera.org/learn/machine-learning/home/welcome">Machine Learning – Home Coursera&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.coursera.org/learn/multivariate-calculus-machine-learning?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-P3iVNag0daUW2nModtd2GA&amp;amp;siteID=SAyYsTvLiGQ-P3iVNag0daUW2nModtd2GA&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ">Mathematics for Machine Learning: Multivariate Calculus - Coursera&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.coursera.org/browse/data-science">Data Science Certificates - Coursera&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://learning.edureka.co/mycourses">Edureka&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://bdlabs.edureka.co:50001/cmf/services/18/status">Edureka-Cloudera Manager&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.udemy.com/">Udemy Courses&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://onlinereikicourse.com/">Courses – Online Reiki Course&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.datacamp.com/courses">DataCamp Courses&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://learn.byjus.com/video/chapter-videos/44724">Byju&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229">udacity&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://intellipaat.com/blog/what-is-apache-spark/">What is Spark – A Comparison Between Spark vs. Hadoop&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://studio.azureml.net/Home/ViewWorkspaceCached/086ca408664942138b618398589b02ff#Workspace/Settings/Name">Microsoft Azure Machine Learning Studio (classic)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.apache.org/">Welcome to The Apache Software Foundation!&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://makingindiaemployable.com/">Making India Employable - Vivid Vision 10 10 10&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ideone.com/">GpI8H5 – Online Python3 Interpreter &amp;amp; Debugging Tool – Ideone.com&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/playlist?list=PLOU2XLYxmsILVTiOlMJdo7RQS55jYhsMi">Google I/O 2019 – All Sessions – YouTube&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/playlist?list=PLQY2H8rRoyvy2_vtWvCpQWM9GJXNTa5rV">TensorFlow at Google I/O 2019 – YouTube&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://bsc.hcverma.in/course/quantum">Quantum Mechanics - BSc Lectures by Prof. H C Verma and Team&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://openpathshala.com/">Open Pathshala - Your Best Source to Learn Sanskrit&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.classcentral.com/">Class Central #1 Search Engine for Free Online Courses &amp;amp; MOOCs&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.class-central.com/course/coursera-mathematics-for-machine-learning-multivariate-calculus-10452">Free Online Course: Mathematics for Machine Learning: Multivariate Calculus from Coursera - Class Central&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://byjus.com/">e Learning for Basic Science and Maths&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.skillshare.com/">Online Classes by Skillshare - Start for Free Today&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://learndigital.withgoogle.com/digitalgarage">Learn online marketing with free courses – Google Digital Garage&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://moz.com/blog">Moz Blog – SEO and Inbound Marketing Blog – Moz&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://onlinecourses.nptel.ac.in/m#/lesson/noc19_hs53/8/15">NPTEL Online Courses Mobile&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.kaggle.com/learn/overview">Learn Python, Data Viz, Pandas &amp;amp; More - Tutorials - Kaggle&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.superdatascience.com/training/">Data Science Training&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="tutorials">Tutorials&lt;a class="td-heading-self-link" href="#tutorials" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial">UFLDL Tutorial 1&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ufldl.stanford.edu/tutorial/supervised/LinearRegression/">UFLDL Tutorial 2&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.socher.org/index.php/DeepLearningTutorial/DeepLearningTutorial">Deep Learning for NLP (without Magic)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks">A Deep Learning Tutorial: From Perceptrons to Deep Networks&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.metacademy.org/roadmaps/rgrosse/deep_learning">Deep Learning from the Bottom up&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://deeplearning.net/tutorial/deeplearning.pdf">Theano Tutorial&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://uk.mathworks.com/help/pdf_doc/nnet/nnet_ug.pdf">Neural Networks for Matlab&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/">Using convolutional neural nets to detect facial keypoints tutorial&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/clementfarabet/ipam-tutorials/tree/master/th_tutorials">Torch7 Tutorials&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/josephmisiti/machine-learning-module">The Best Machine Learning Tutorials On The Web&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.robots.ox.ac.uk/~vgg/practicals/cnn/index.html">VGG Convolutional Neural Networks Practical&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/nlintz/TensorFlow-Tutorials">TensorFlow tutorials&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/pkmital/tensorflow_tutorials">More TensorFlow tutorials&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/aymericdamien/TensorFlow-Examples">TensorFlow Python Notebooks&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/Vict0rSch/deep_learning">Keras and Lasagne Deep Learning Tutorials&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition">Classification on raw time series in TensorFlow with a LSTM RNN&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/">Using convolutional neural nets to detect facial keypoints tutorial&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/astorfi/TensorFlow-World">TensorFlow-World&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.manning.com/books/deep-learning-with-python">Deep Learning with Python&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.manning.com/books/grokking-deep-learning">Grokking Deep Learning&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.manning.com/books/deep-learning-for-search">Deep Learning for Search&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://blog.sicara.com/keras-tutorial-content-based-image-retrieval-convolutional-denoising-autoencoder-dc91450cc511">Keras Tutorial: Content Based Image Retrieval Using a Convolutional Denoising Autoencoder&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/yunjey/pytorch-tutorial">Pytorch Tutorial by Yunjey Choi&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html">Understanding deep Convolutional Neural Networks with a practical use-case in Tensorflow and Keras&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ahmedbesbes.com/overview-and-benchmark-of-traditional-and-deep-learning-models-in-text-classification.html">Overview and benchmark of traditional and deep learning models in text classification&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/MelAbgrall/HardwareforAI">Hardware for AI: Understanding computer hardware &amp;amp; build your own computer&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://hackr.io/tutorials/learn-artificial-intelligence-ai">Programming Community Curated Resources&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://amitness.com/2020/02/illustrated-self-supervised-learning/">The Illustrated Self-Supervised Learning&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://amitness.com/2020/02/albert-visual-summary/">Visual Paper Summary: ALBERT (A Lite BERT)&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="videos-and-lectures">Videos and Lectures&lt;a class="td-heading-self-link" href="#videos-and-lectures" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=RIkxVci-R4k">How To Create A Mind&lt;/a> By Ray Kurzweil&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=n1ViNeWhC24">Deep Learning, Self-Taught Learning and Unsupervised Feature Learning&lt;/a> By Andrew Ng&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=vShMxxqtDDs&amp;amp;index=3&amp;amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT">Recent Developments in Deep Learning&lt;/a> By Geoff Hinton&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=sc-KbuZqGkI">The Unreasonable Effectiveness of Deep Learning&lt;/a> by Yann LeCun&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=4xsVFLnHC_0">Deep Learning of Representations&lt;/a> by Yoshua bengio&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=6ufPpZDmPKA">Principles of Hierarchical Temporal Memory&lt;/a> by Jeff Hawkins&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=2QJi0ArLq7s&amp;amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT">Machine Learning Discussion Group – Deep Learning w/ Stanford AI Lab&lt;/a> by Adam Coates&lt;/li>
&lt;li>&lt;a href="https://vimeo.com/80821560">Making Sense of the World with Deep Learning&lt;/a> By Adam Coates&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=wZfVBwOO0-k">Demystifying Unsupervised Feature Learning&lt;/a> By Adam Coates&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=3boKlkPBckA">Visual Perception with Deep Learning&lt;/a> By Yann LeCun&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=AyzOUbkUf3M">The Next Generation of Neural Networks&lt;/a> By Geoffrey Hinton at GoogleTechTalks&lt;/li>
&lt;li>&lt;a href="https://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn">The wonderful and terrifying implications of computers that can learn&lt;/a> By Jeremy Howard at TEDxBrussels&lt;/li>
&lt;li>&lt;a href="https://web.stanford.edu/class/cs294a/handouts.html">Unsupervised Deep Learning – Stanford&lt;/a> by Andrew Ng in Stanford (2011)&lt;/li>
&lt;li>&lt;a href="https://web.stanford.edu/class/cs224n/handouts/">Natural Language Processing&lt;/a> By Chris Manning in Stanford&lt;/li>
&lt;li>&lt;a href="https://googleresearch.blogspot.com/2015/09/a-beginners-guide-to-deep-neural.html">A beginners Guide to Deep Neural Networks&lt;/a> By Natalie Hammel and Lorraine Yurshansky&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=czLI3oLDe8M">Deep Learning: Intelligence from Big Data&lt;/a> by Steve Jurvetson (and panel) at VLAB in Stanford.&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=FoO8qDB8gUU">Introduction to Artificial Neural Networks and Deep Learning&lt;/a> by Leo Isikdogan at Motorola Mobility HQ&lt;/li>
&lt;li>&lt;a href="https://nips.cc/Conferences/2016/Schedule">NIPS 2016 lecture and workshop videos&lt;/a> – NIPS 2016&lt;/li>
&lt;li>&lt;a href="https://www.youtube.com/watch?v=oS5fz_mHVz0&amp;amp;list=PLWKotBjTDoLj3rXBL-nEIPRN9V3a9Cx07">Deep Learning Crash Course&lt;/a>: a series of mini-lectures by Leo Isikdogan on YouTube (2018)&lt;/li>
&lt;li>&lt;a href="https://www.manning.com/livevideo/deep-learning-crash-course">Deep Learning Crash Course&lt;/a> By Oliver Zeigermann&lt;/li>
&lt;li>&lt;a href="https://www.manning.com/livevideo/deep-learning-with-r-in-motion">Deep Learning with R in Motion&lt;/a>: a live video course that teaches how to apply deep learning to text and images using the powerful Keras library and its R language interface.&lt;/li>
&lt;li>&lt;a href="https://lnkd.in/f5vUg6i">8 Essential Tips for People starting a Career in Data Science&lt;/a>.&lt;/li>
&lt;li>&lt;a href="https://lnkd.in/fMEhi4D">Cheatsheet: How to become a data scientist&lt;/a>.&lt;/li>
&lt;li>&lt;a href="https://lnkd.in/fruY2AC">The Art of Learning Data Science&lt;/a>.&lt;/li>
&lt;li>&lt;a href="https://lnkd.in/fxReDab">The Periodic Table of Data Science&lt;/a>.&lt;/li>
&lt;li>&lt;a href="https://lnkd.in/fXSE-us">Aspiring Data Scientists! Start to learn Statistics with these 6 books&lt;/a>!&lt;/li>
&lt;li>&lt;a href="https://lnkd.in/f8S3Ygd">8 Skills You Need to Be a Data Scientist&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://lnkd.in/fKugicE">Top 10 Essential Books for the Data Enthusiast&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://lnkd.in/fTGDkju">Aspiring data scientist? Master these fundamentals&lt;/a>.&lt;/li>
&lt;li>&lt;a href="https://lnkd.in/f_Zhpzf">How to Become a Data Scientist – On your own.&lt;/a>&lt;/li>
&lt;/ol>
&lt;h2 id="gretl--great-statistical-software-for-beginners">GRETL – Great Statistical software for Beginners&lt;a class="td-heading-self-link" href="#gretl--great-statistical-software-for-beginners" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;ol>
&lt;li>Simple Linear Regression &lt;a href="https://lnkd.in/ecfsV9c">https://lnkd.in/ecfsV9c&lt;/a>&lt;/li>
&lt;li>Coding Dummy Variables &lt;a href="https://lnkd.in/ef7Yd7f">https://lnkd.in/ef7Yd7f&lt;/a>&lt;/li>
&lt;li>Forecasting New Observations &lt;a href="https://lnkd.in/eNKbxbU">https://lnkd.in/eNKbxbU&lt;/a>&lt;/li>
&lt;li>Forecasting a Large Number of Observations &lt;a href="https://lnkd.in/eHmibGs">https://lnkd.in/eHmibGs&lt;/a>&lt;/li>
&lt;li>Logistic Regression &lt;a href="https://lnkd.in/eRfhQ87">https://lnkd.in/eRfhQ87&lt;/a>&lt;/li>
&lt;li>Forecasting and Confusion Matrix &lt;a href="https://lnkd.in/eaqrFJr">https://lnkd.in/eaqrFJr&lt;/a>&lt;/li>
&lt;li>Modeling and Forecasting Time Series Data &lt;a href="https://lnkd.in/e6fqKpF">https://lnkd.in/e6fqKpF&lt;/a>&lt;/li>
&lt;li>Comparing Time Series Trend Models &lt;a href="https://lnkd.in/eKjEUAE">https://lnkd.in/eKjEUAE&lt;/a>&lt;/li>
&lt;li>Khan Academy is the best online free resource to learn Math for Data Science. ( &lt;a href="https://www.khanacademy.org/math/">https://www.khanacademy.org/math/&lt;/a>).&lt;/li>
&lt;li>Krista King has also done a great job in creating an exceptionally good introductory course. She is too good at designing the course. ( &lt;a href="https://www.udemy.com/user/kristaking/">https://www.udemy.com/user/kristaking/&lt;/a>.&lt;/li>
&lt;li>3Blue1Brown ( &lt;a href="https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/playlists">https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/playlists&lt;/a>).&lt;/li>
&lt;li>Every Intro to Data Science Course on the Internet, Ranked. (&lt;a href="https://lnkd.in/fQDMiNX">https://lnkd.in/fQDMiNX&lt;/a> )&lt;/li>
&lt;li>What would be useful for aspiring data scientists to know? (&lt;a href="https://lnkd.in/fmcFyN7">https://lnkd.in/fmcFyN7&lt;/a>)&lt;/li>
&lt;/ol></description></item><item><title>DS, AI, ML Online Course, Tutorial, Videos</title><link>https://dasarpai.github.io/dsresources/data-science-tutorial-video-resources/</link><pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsresources/data-science-tutorial-video-resources/</guid><description>&lt;p>&lt;img src="../../assets/images/dsresources/dsr119-DS-AI-ML-Online-Course-Tutorial-Videos.jpg" alt="DS, AI, ML Online Course, Tutorial, Videos">&lt;/p>
&lt;p>I am sorry, this page has moved to different location. &lt;a href="../../dsblog/data-science-tutorial-video-resources">Click me to go there&lt;/a>&lt;/p></description></item><item><title>Reinforcement Learning Git Repositories</title><link>https://dasarpai.github.io/dsblog/rl-git-repo/</link><pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/rl-git-repo/</guid><description>&lt;p>&lt;img src="../../assets/images/dsresources/dsr101-Reinforcement-Learning-Git-Repositories.jpg" alt="Reinforcement Learning Git Repositories">&lt;/p>
&lt;h1 id="reinforcement-learning-git-repositories">Reinforcement Learning Git Repositories&lt;a class="td-heading-self-link" href="#reinforcement-learning-git-repositories" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;table>
 &lt;thead>
 &lt;tr>
 &lt;th>Sno.&lt;/th>
 &lt;th>URL&lt;/th>
 &lt;th>Description&lt;/th>
 &lt;/tr>
 &lt;/thead>
 &lt;tbody>
 &lt;tr>
 &lt;td>1&lt;/td>
 &lt;td>&lt;a href="https://github.com/openai/baselines">https://github.com/openai/baselines&lt;/a>&lt;/td>
 &lt;td>OpenAI Baselines: high-quality implementations of reinforcement learning algorithms&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>2&lt;/td>
 &lt;td>&lt;a href="https://github.com/hill-a/stable-baselines">https://github.com/hill-a/stable-baselines&lt;/a>&lt;/td>
 &lt;td>A fork of OpenAI Baselines, implementations of reinforcement learning algorithms&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>3&lt;/td>
 &lt;td>&lt;a href="https://github.com/openai/spinningup">https://github.com/openai/spinningup&lt;/a>&lt;/td>
 &lt;td>An educational resource to help anyone learn deep reinforcement learning.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>4&lt;/td>
 &lt;td>&lt;a href="https://github.com/google/dopamine">https://github.com/google/dopamine&lt;/a>&lt;/td>
 &lt;td>Dopamine is a research framework for fast prototyping of reinforcement learning algorithms.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>5&lt;/td>
 &lt;td>&lt;a href="https://github.com/tensorflow/agents">https://github.com/tensorflow/agents&lt;/a>&lt;/td>
 &lt;td>TF-Agents is a library for Reinforcement Learning in TensorFlow&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>6&lt;/td>
 &lt;td>&lt;a href="https://github.com/deepmind/trfl">https://github.com/deepmind/trfl&lt;/a>&lt;/td>
 &lt;td>TensorFlow Reinforcement Learning&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>7&lt;/td>
 &lt;td>&lt;a href="https://github.com/facebookresearch/Horizon">https://github.com/facebookresearch/Horizon&lt;/a>&lt;/td>
 &lt;td>A platform for Applied Reinforcement Learning (Applied RL)&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>8&lt;/td>
 &lt;td>&lt;a href="https://github.com/facebookresearch/ELF">https://github.com/facebookresearch/ELF&lt;/a>&lt;/td>
 &lt;td>An End-To-End, Lightweight and Flexible Platform for Game Research&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>9&lt;/td>
 &lt;td>&lt;a href="https://github.com/NervanaSystems/coach">https://github.com/NervanaSystems/coach&lt;/a>&lt;/td>
 &lt;td>Reinforcement Learning Coach by Intel AI Lab enables easy experimentation with state of the art Reinforcement Learning algorithms&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>10&lt;/td>
 &lt;td>&lt;a href="https://github.com/ray-project/ray/tree/master/python/ray/rllib">https://github.com/ray-project/ray/tree/master/python/ray/rllib&lt;/a>&lt;/td>
 &lt;td>A fast and simple framework for building and running distributed applications.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>11&lt;/td>
 &lt;td>&lt;a href="https://github.com/keras-rl/keras-rl">https://github.com/keras-rl/keras-rl&lt;/a>&lt;/td>
 &lt;td>Deep Reinforcement Learning for Keras.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>12&lt;/td>
 &lt;td>&lt;a href="https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail">https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&lt;/a>&lt;/td>
 &lt;td>PyTorch implementation of Advantage Actor Critic (A2C), Proximal Policy Optimization (PPO), Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation (ACKTR) and Generative Adversarial Imitation Learning (GAIL).&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>13&lt;/td>
 &lt;td>&lt;a href="https://github.com/Kaixhin/Rainbow">https://github.com/Kaixhin/Rainbow&lt;/a>&lt;/td>
 &lt;td>Rainbow: Combining Improvements in Deep Reinforcement Learning&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>14&lt;/td>
 &lt;td>&lt;a href="https://github.com/MillionIntegrals/vel">https://github.com/MillionIntegrals/vel&lt;/a>&lt;/td>
 &lt;td>Velocity in deep-learning research&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>15&lt;/td>
 &lt;td>&lt;a href="https://github.com/tensorforce/tensorforce">https://github.com/tensorforce/tensorforce&lt;/a>&lt;/td>
 &lt;td>Tensorforce: A TensorFlow library for applied reinforcement learning&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>16&lt;/td>
 &lt;td>&lt;a href="https://github.com/kengz/SLM-Lab">https://github.com/kengz/SLM-Lab&lt;/a>&lt;/td>
 &lt;td>Modular Deep Reinforcement Learning framework in PyTorch.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>17&lt;/td>
 &lt;td>&lt;a href="https://github.com/rlworkgroup/garage">https://github.com/rlworkgroup/garage&lt;/a>&lt;/td>
 &lt;td>A framework for reproducible reinforcement learning research&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>18&lt;/td>
 &lt;td>&lt;a href="https://github.com/catalyst-team/catalyst">https://github.com/catalyst-team/catalyst&lt;/a>&lt;/td>
 &lt;td>Reproducible and fast DL &amp;amp; RL.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>19&lt;/td>
 &lt;td>&lt;a href="https://github.com/higgsfield/RL-Adventure">https://github.com/higgsfield/RL-Adventure&lt;/a>&lt;/td>
 &lt;td>Pytorch Implementation of DQN / DDQN / Prioritized replay/ noisy networks/ distributional values/ Rainbow/ hierarchical RL&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>20&lt;/td>
 &lt;td>&lt;a href="https://github.com/qfettes/DeepRL-Tutorials">https://github.com/qfettes/DeepRL-Tutorials&lt;/a>&lt;/td>
 &lt;td>Contains high quality implementations of Deep Reinforcement Learning algorithms written in PyTorch&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>21&lt;/td>
 &lt;td>&lt;a href="https://github.com/openai/gym">https://github.com/openai/gym&lt;/a>&lt;/td>
 &lt;td>A toolkit for developing and comparing reinforcement learning algorithms.&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>22&lt;/td>
 &lt;td>&lt;a href="https://github.com/deepmind/lab">https://github.com/deepmind/lab&lt;/a>&lt;/td>
 &lt;td>A customisable 3D platform for agent-based AI research&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>23&lt;/td>
 &lt;td>&lt;a href="https://github.com/Microsoft/malmo">https://github.com/Microsoft/malmo&lt;/a>&lt;/td>
 &lt;td>Project Malmo is a platform for Artificial Intelligence experimentation and research built on top of Minecraft. We aim to inspire a new generation of research into challenging new problems presented by this unique environment. — For installation instruct&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>24&lt;/td>
 &lt;td>&lt;a href="https://github.com/openai/retro">https://github.com/openai/retro&lt;/a>&lt;/td>
 &lt;td>Retro Games in Gym&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>25&lt;/td>
 &lt;td>&lt;a href="https://github.com/deepmind/dm_control">https://github.com/deepmind/dm_control&lt;/a>&lt;/td>
 &lt;td>The DeepMind Control Suite and Package&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>26&lt;/td>
 &lt;td>&lt;a href="https://github.com/openai/neural-mmo">https://github.com/openai/neural-mmo&lt;/a>&lt;/td>
 &lt;td>Neural MMO – A Massively Multiagent Game Environment&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>27&lt;/td>
 &lt;td>&lt;a href="https://github.com/openai/gym">https://github.com/openai/gym&lt;/a>&lt;/td>
 &lt;td>Gym @ OpenAI&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>28&lt;/td>
 &lt;td>&lt;a href="https://github.com/deepmind/lab">https://github.com/deepmind/lab&lt;/a>&lt;/td>
 &lt;td>Lab @ DeepMind&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>29&lt;/td>
 &lt;td>&lt;a href="https://github.com/Microsoft/malmo">https://github.com/Microsoft/malmo&lt;/a>&lt;/td>
 &lt;td>Project Malmo @ Microsoft&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>30&lt;/td>
 &lt;td>&lt;a href="https://github.com/openai/retro">https://github.com/openai/retro&lt;/a>&lt;/td>
 &lt;td>Retro @ OpenAI&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>31&lt;/td>
 &lt;td>&lt;a href="https://github.com/deepmind/dm_control">https://github.com/deepmind/dm_control&lt;/a>&lt;/td>
 &lt;td>Control Suite @ DeepMind&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>32&lt;/td>
 &lt;td>&lt;a href="https://github.com/openai/neural-mmo">https://github.com/openai/neural-mmo&lt;/a>&lt;/td>
 &lt;td>Neural MMO @ OpenAI&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>33&lt;/td>
 &lt;td>&lt;a href="https://github.com/openai/baselines">https://github.com/openai/baselines&lt;/a>&lt;/td>
 &lt;td>Tensorflow Maintained by OpenAI&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>34&lt;/td>
 &lt;td>&lt;a href="https://github.com/hill-a/stable-baselines">https://github.com/hill-a/stable-baselines&lt;/a>&lt;/td>
 &lt;td>Tensorflow Maintained by Antonin Raffin, Ashley Hill&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>35&lt;/td>
 &lt;td>&lt;a href="https://github.com/catalyst-team/catalyst">https://github.com/catalyst-team/catalyst&lt;/a>&lt;/td>
 &lt;td>PyTorch Maintained by Sergey Kolesnikov&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>36&lt;/td>
 &lt;td>&lt;a href="https://github.com/ray-project/ray/tree/master/python/ray/rllib">https://github.com/ray-project/ray/tree/master/python/ray/rllib&lt;/a>&lt;/td>
 &lt;td>Tensorflow Maintained by Ray Team&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>37&lt;/td>
 &lt;td>&lt;a href="https://github.com/tensorflow/agents">https://github.com/tensorflow/agents&lt;/a>&lt;/td>
 &lt;td>Tensorflow Maintained by Google&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>38&lt;/td>
 &lt;td>&lt;a href="https://github.com/facebookresearch/Horizon">https://github.com/facebookresearch/Horizon&lt;/a>&lt;/td>
 &lt;td>PyTorch Maintained by Facebook&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>39&lt;/td>
 &lt;td>&lt;a href="https://github.com/NervanaSystems/coach">https://github.com/NervanaSystems/coach&lt;/a>&lt;/td>
 &lt;td>Tensorflow Maintained by Intel&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>40&lt;/td>
 &lt;td>&lt;a href="https://github.com/rlworkgroup/garage">https://github.com/rlworkgroup/garage&lt;/a>&lt;/td>
 &lt;td>Tensorflow Maintained by community&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>41&lt;/td>
 &lt;td>&lt;a href="https://github.com/kengz/SLM-Lab">https://github.com/kengz/SLM-Lab&lt;/a>&lt;/td>
 &lt;td>PyTorch Maintained by Wah Loon Keng, Laura Graesser&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>42&lt;/td>
 &lt;td>&lt;a href="https://github.com/google/dopamine">https://github.com/google/dopamine&lt;/a>&lt;/td>
 &lt;td>Tensorflow Maintained by Google&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>43&lt;/td>
 &lt;td>&lt;a href="https://github.com/openai/spinningup">https://github.com/openai/spinningup&lt;/a>&lt;/td>
 &lt;td>Tensorflow Maintained by OpenAI&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>44&lt;/td>
 &lt;td>&lt;a href="https://github.com/deepmind/trfl">https://github.com/deepmind/trfl&lt;/a>&lt;/td>
 &lt;td>Tensorflow Maintained by DeepMind&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>45&lt;/td>
 &lt;td>&lt;a href="https://github.com/deepmind/scalable_agent">https://github.com/deepmind/scalable_agent&lt;/a>&lt;/td>
 &lt;td>Tensorflow Maintained by DeepMind&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>46&lt;/td>
 &lt;td>&lt;a href="https://github.com/facebookresearch/ELF">https://github.com/facebookresearch/ELF&lt;/a>&lt;/td>
 &lt;td>PyTorch Maintained by Facebook&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>47&lt;/td>
 &lt;td>&lt;a href="https://github.com/keras-rl/keras-rl">https://github.com/keras-rl/keras-rl&lt;/a>&lt;/td>
 &lt;td>Tensorflow Maintained by Matthias Plappert&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>48&lt;/td>
 &lt;td>&lt;a href="https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail">https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&lt;/a>&lt;/td>
 &lt;td>PyTorch Maintained by Ilya Kostrikov&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>49&lt;/td>
 &lt;td>&lt;a href="https://github.com/Kaixhin/Rainbow">https://github.com/Kaixhin/Rainbow&lt;/a>&lt;/td>
 &lt;td>PyTorch Maintained by Kai Arulkumaran&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>50&lt;/td>
 &lt;td>&lt;a href="https://github.com/MillionIntegrals/vel">https://github.com/MillionIntegrals/vel&lt;/a>&lt;/td>
 &lt;td>PyTorch Maintained by Jerry (?)&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>51&lt;/td>
 &lt;td>&lt;a href="https://github.com/Khrylx/PyTorch-RL">https://github.com/Khrylx/PyTorch-RL&lt;/a>&lt;/td>
 &lt;td>PyTorch&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>52&lt;/td>
 &lt;td>&lt;a href="https://github.com/tensorforce/tensorforce">https://github.com/tensorforce/tensorforce&lt;/a>&lt;/td>
 &lt;td>Tensorflow&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>53&lt;/td>
 &lt;td>&lt;a href="https://github.com/higgsfield/RL-Adventure">https://github.com/higgsfield/RL-Adventure&lt;/a>&lt;/td>
 &lt;td>PyTorch&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>54&lt;/td>
 &lt;td>&lt;a href="https://github.com/qfettes/DeepRL-Tutorials">https://github.com/qfettes/DeepRL-Tutorials&lt;/a>&lt;/td>
 &lt;td>PyTorch&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>55&lt;/td>
 &lt;td>&lt;a href="https://github.com/SurrealAI/surreal">https://github.com/SurrealAI/surreal&lt;/a>&lt;/td>
 &lt;td>TorchX&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>56&lt;/td>
 &lt;td>&lt;a href="https://github.com/zuoxingdong/lagom">https://github.com/zuoxingdong/lagom&lt;/a>&lt;/td>
 &lt;td>PyTorch&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>57&lt;/td>
 &lt;td>&lt;a href="https://github.com/dennybritz/reinforcement-learning">https://github.com/dennybritz/reinforcement-learning&lt;/a>&lt;/td>
 &lt;td>Tensorflow&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>58&lt;/td>
 &lt;td>&lt;a href="https://github.com/unixpickle/anyrl-py">https://github.com/unixpickle/anyrl-py&lt;/a>&lt;/td>
 &lt;td>Tensorflow&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>59&lt;/td>
 &lt;td>&lt;a href="https://github.com/Scitator/rl-course-experiments">https://github.com/Scitator/rl-course-experiments&lt;/a>&lt;/td>
 &lt;td>Tensorflow&lt;/td>
 &lt;/tr>
 &lt;tr>
 &lt;td>60&lt;/td>
 &lt;td>&lt;a href="https://github.com/oxwhirl/pymarl">https://github.com/oxwhirl/pymarl&lt;/a>&lt;/td>
 &lt;td>PyTorch&lt;/td>
 &lt;/tr>
 &lt;/tbody>
&lt;/table></description></item></channel></rss>