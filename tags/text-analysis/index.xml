<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Text Analysis on Blowfish</title><link>https://dasarpai.github.io/tags/text-analysis/</link><description>Recent content in Text Analysis on Blowfish</description><generator>Hugo</generator><language>en</language><managingEditor>nuno@n9o.xyz (Blowfish)</managingEditor><webMaster>nuno@n9o.xyz (Blowfish)</webMaster><lastBuildDate>Sat, 18 Nov 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://dasarpai.github.io/tags/text-analysis/index.xml" rel="self" type="application/rss+xml"/><item><title>Empowering Language with AI NLP Capabilities</title><link>https://dasarpai.github.io/dsblog/empowering-language-with-ainlp-capabilities/</link><pubDate>Sat, 18 Nov 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/empowering-language-with-ainlp-capabilities/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6106-Empowering-Language-with-AI-NLP-Capabilities.jpg" alt="Empowering-Language-with-AI-NLP-Capabilities">&lt;/p>
&lt;h1 id="empowering-language-with-ai-nlp-capabilities">Empowering-Language-with-AI-NLP-Capabilities&lt;a class="td-heading-self-link" href="#empowering-language-with-ai-nlp-capabilities" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>When envisioning artificial intelligence (AI), the initial images that often come to mind are humanoid robots. However, this perception oversimplifies the vast realm of AI, which is fundamentally distinct from natural intelligenceâ€”the inherent cognitive capacity found in living organisms shaped by Mother Nature. Life, in all its forms, from microscopic bacteria to complex human beings, possesses an innate intelligence derived from hydrocarbon-based living cells.&lt;/p></description></item><item><title>Topic Modeling with BERT</title><link>https://dasarpai.github.io/dsblog/topic-modeling-with-bert/</link><pubDate>Mon, 13 Nov 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/topic-modeling-with-bert/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6105-Topic-Modeling-with-BERT.jpg" alt="Topic Modeling with BERT">&lt;/p>
&lt;h1 id="topic-modeling-with-bert">Topic Modeling with BERT&lt;a class="td-heading-self-link" href="#topic-modeling-with-bert" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>Key steps in BERTopic modelling are as following.&lt;/p>
&lt;ul>
&lt;li>Use &amp;ldquo;Sentence Embedding&amp;rdquo; models to embed the sentences of the article&lt;/li>
&lt;li>Reduce the dimensionality of embedding using UMAP&lt;/li>
&lt;li>Cluster these documents (reduced dimensions) using HDBSAN&lt;/li>
&lt;li>Use c-TF-IDF extract keywords, their frequency and IDF for each cluster.&lt;/li>
&lt;li>MMR: Maximize Candidate Relevance. How many words in a topic can represent the topic?&lt;/li>
&lt;li>Intertopic Distance Map&lt;/li>
&lt;li>Use similarity matrix (heatmap), dandogram (hierarchical map), to visualize the topics and key_words.&lt;/li>
&lt;li>Traction of topic over time period. Some may be irrelevant and for other traction may be increasing or decreasing.&lt;/li>
&lt;/ul>
&lt;h1 id="installation">Installation&lt;a class="td-heading-self-link" href="#installation" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-python" data-lang="python">&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Installation, with sentence-transformers, can be done using pypi:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">pip&lt;/span> &lt;span class="n">install&lt;/span> &lt;span class="n">bertopic&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># If you want to install BERTopic with other embedding models, you can choose one of the following:&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Choose an embedding backend&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">pip&lt;/span> &lt;span class="n">install&lt;/span> &lt;span class="n">bertopic&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">flair&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">gensim&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">spacy&lt;/span>&lt;span class="p">,&lt;/span> &lt;span class="n">use&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1"># Topic modeling with images&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="n">pip&lt;/span> &lt;span class="n">install&lt;/span> &lt;span class="n">bertopic&lt;/span>&lt;span class="p">[&lt;/span>&lt;span class="n">vision&lt;/span>&lt;span class="p">]&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;h1 id="supported-topic-modelling-techniques">Supported Topic Modelling Techniques&lt;a class="td-heading-self-link" href="#supported-topic-modelling-techniques" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>BERTopic supports all kinds of topic modeling techniques as below.&lt;/p></description></item><item><title>NLP Tasks</title><link>https://dasarpai.github.io/dsblog/nlp-tasks/</link><pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/nlp-tasks/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6085-NLP-Tasks.jpg" alt="NLP Tasks">&lt;/p>
&lt;h1 id="nlp-tasks">NLP Tasks&lt;a class="td-heading-self-link" href="#nlp-tasks" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Processing words of any language and driving some meaning from these is as old as the human language. Recently, AI momentum is taking on many of these language-processing tasks. Here is the summary of these NLP tasks, this list is continuously growing. Researchers keep creating a dataset for these tasks in different languages. Other researchers keep devising new ways to solve these tasks with better performance. They come up with a new architecture, a new set of hyperparameters, a new pipeline, etc. In summary, as of today, there are around 55 tasks. Hundreds of datasets and research papers exist around these. You can check on &lt;a href="https://paperswithcode.com/">PaperWithCode&lt;/a> or &lt;a href="https://huggingface.co/">Hggingface&lt;/a>&lt;/p></description></item><item><title>What is NLP?</title><link>https://dasarpai.github.io/dsblog/what-is-nlp/</link><pubDate>Mon, 19 Dec 2022 15:50:00 +0530</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/what-is-nlp/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6016-What-is-NLP.jpg" alt="What is NLP?">&lt;/p>
&lt;h2 id="what-is-nlp">What is NLP?&lt;a class="td-heading-self-link" href="#what-is-nlp" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Humans interact with their surroundings using different kinds of inputs. Eyes deal with inputs of color, shape, and size. Ear deals with inputs of sound, voice, and noise. Similarly, the other 3 senses also deal with other kinds of inputs. When you write something you may be drawing some art or you may be drawing letters of some language. Language is what we use to speak, for example, English, Hindi, Kannada, Tamil, and French are languages. The script is a tool to write what we speak. There are many kinds of scripts and you can use those scripts to write words of the languages. Some scripts are good for some languages. You cannot write all the words of all the languages of the world using one script (without modifying the original letters of the script). The Roman script is good to write English languages but when you want to write any Indian language using Roman then you will make many mistakes when reading the scripts. Because you won&amp;rsquo;t be able to produce the same sound as the original language was producing.&lt;/p></description></item></channel></rss>