<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>TensorFlow on Blowfish</title><link>https://dasarpai.github.io/tags/tensorflow/</link><description>Recent content in TensorFlow on Blowfish</description><generator>Hugo</generator><language>en</language><managingEditor>nuno@n9o.xyz (Blowfish)</managingEditor><webMaster>nuno@n9o.xyz (Blowfish)</webMaster><lastBuildDate>Tue, 12 Nov 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://dasarpai.github.io/tags/tensorflow/index.xml" rel="self" type="application/rss+xml"/><item><title>Exploring GGUF and Other Model Formats</title><link>https://dasarpai.github.io/dsblog/exploring-gguf-and-other-model-formats/</link><pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/exploring-gguf-and-other-model-formats/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6180-exploring-gguf.jpg" alt="Understanding GGUF and Other Model Formats in Machine Learning">&lt;/p>
&lt;h1 id="understanding-gguf-and-other-model-formats-in-machine-learning">&lt;strong>Understanding GGUF and Other Model Formats in Machine Learning&lt;/strong>&lt;a class="td-heading-self-link" href="#understanding-gguf-and-other-model-formats-in-machine-learning" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;p>As machine learning models continue to grow in complexity, the need for efficient, flexible, and versatile model formats becomes more pronounced. While formats like ONNX, TensorFlow’s SavedModel, and PyTorch’s native format have been around for some time, newer formats like GGUF are gaining attention for their unique benefits. This article explores these formats, their use cases, and how they support various aspects of machine learning, including deployment, compatibility, and optimization.&lt;/p></description></item><item><title>Tensorflow GPU Setup on Local Machine</title><link>https://dasarpai.github.io/dsblog/Tensorflow-gpu-setup-on-local-machine/</link><pubDate>Wed, 28 Aug 2024 00:00:00 +0000</pubDate><author>nuno@n9o.xyz (Blowfish)</author><guid>https://dasarpai.github.io/dsblog/Tensorflow-gpu-setup-on-local-machine/</guid><description>&lt;p>&lt;img src="../../assets/images/dspost/dsp6140-Tensorflow-gpu-setup-on-local-machine.jpg" alt="Tensorflow GPU Setup on Local Machine">&lt;/p>
&lt;h1 id="tensorflow-gpu-setup-on-local-machine">Tensorflow GPU Setup on Local Machine&lt;a class="td-heading-self-link" href="#tensorflow-gpu-setup-on-local-machine" aria-label="Heading self-link">&lt;/a>&lt;/h1>
&lt;h2 id="introduction">Introduction&lt;a class="td-heading-self-link" href="#introduction" aria-label="Heading self-link">&lt;/a>&lt;/h2>
&lt;p>Tensorflow, pytorch are deep learning libraries or packages. Tensorflow is developed by google and pytorch is developed by Meta. There are some other but these are the most popular one among Machine Learning and Deep Learning Engineers. If you are doing anything significant in NLP, computer vision, voice processing you must have used this library. But the power of the these libraries lies in parallel metrics/tensor computation. For that they use hardwardes like GPU or TPU which has thousands of core and they designed purely for metrics/tensor processing. Intially they were used for gaming purpose but with the surge of AI these machines are in high use and used for model training and inference purpose.&lt;/p></description></item></channel></rss>