<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Privacy on </title>
    <link>https://localhost:1313/tags/privacy/</link>
    <description>Recent content in Privacy on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>hari@dasarpai.com (Hari Thapliyaal)</managingEditor>
    <webMaster>hari@dasarpai.com (Hari Thapliyaal)</webMaster>
    <copyright>© 2025 Hari Thapliyaal</copyright>
    <lastBuildDate>Mon, 21 Apr 2025 00:00:00 +0000</lastBuildDate><atom:link href="https://localhost:1313/tags/privacy/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Partials</title>
      <link>https://localhost:1313/docs/partials/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://localhost:1313/docs/partials/</guid>
      <description>&lt;h2 class=&#34;relative group&#34;&gt;Analytics 
    &lt;div id=&#34;analytics&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#analytics&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;Blowfish provides built-in support for Fathom Analytics, Google Analytics and Umami Analytics. Fathom is a paid alternative to Google Analytics that respects user privacy.&lt;/p&gt;</description>
      <media:content xmlns:media="http://search.yahoo.com/mrss/" url="https://localhost:1313/docs/partials/featured.svg" />
    </item>
    
    <item>
      <title>BitNet b1.58-2B4T: Revolutionary Binary Neural Network for Efficient AI</title>
      <link>https://localhost:1313/dsblog/BitNet-b1-58-2B4T-for-efficient-ai-processing/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://localhost:1313/dsblog/BitNet-b1-58-2B4T-for-efficient-ai-processing/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://localhost:1313/assets/images/dspost/dsp6263-BitNet-b1.58-2B4T.jpg&#34; alt=&#34;BitNet b1.58-2B4T&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2504.12285&#34; target=&#34;_blank&#34;&gt;Archive Paper Link&lt;/a&gt;&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;BitNet b1.58-2B4T: The Future of Efficient AI Processing 
    &lt;div id=&#34;bitnet-b158-2b4t-the-future-of-efficient-ai-processing&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#bitnet-b158-2b4t-the-future-of-efficient-ai-processing&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;A History of 1 bit Transformer Model 
    &lt;div id=&#34;a-history-of-1-bit-transformer-model&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#a-history-of-1-bit-transformer-model&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;A paper &amp;ldquo;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&amp;rdquo; was published by Stanford University, ETH Zürich, and EPFL. It was published on October 2023 (published on arXiv on October 17, 2023). &lt;a href=&#34;https://arxiv.org/pdf/2310.11453&#34; target=&#34;_blank&#34;&gt;Standord Paper Link&lt;/a&gt;. The core Concept of 1.58 bits per parameter, was introduced here. This demonstrated that LLMs could be effectively trained and operated with extremely low-bit representation while maintaining competitive performance&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>LLM Security and Ethics Considerations</title>
      <link>https://localhost:1313/dsblog/LLM-Security-and-Ethics-Considerations/</link>
      <pubDate>Fri, 02 Aug 2024 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://localhost:1313/dsblog/LLM-Security-and-Ethics-Considerations/</guid>
      <description>&lt;p&gt;
    &lt;figure&gt;
      &lt;img class=&#34;my-0 rounded-md&#34; loading=&#34;lazy&#34; src=&#34;https://localhost:1313/assets/images/dspost/dsp6128-LLM-Security-and-Ethics-Considerations.jpg&#34; alt=&#34;LLM-Security-and-Ethics-Considerations&#34; /&gt;
      
    &lt;/figure&gt;
&lt;/p&gt;


&lt;h1 class=&#34;relative group&#34;&gt;LLM Security and Ethics Considerations 
    &lt;div id=&#34;llm-security-and-ethics-considerations&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#llm-security-and-ethics-considerations&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h1&gt;


&lt;h2 class=&#34;relative group&#34;&gt;Question: For my client&amp;rsquo;s highly secured data like health industry data, banking, insurnace, internal security, etc. data can I use gpt4 for finetuning? 
    &lt;div id=&#34;question-for-my-clients-highly-secured-data-like-health-industry-data-banking-insurnace-internal-security-etc-data-can-i-use-gpt4-for-finetuning&#34; class=&#34;anchor&#34;&gt;&lt;/div&gt;
    
    &lt;span
        class=&#34;absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100&#34;&gt;
        &lt;a class=&#34;group-hover:text-primary-300 dark:group-hover:text-neutral-700&#34;
            style=&#34;text-decoration-line: none !important;&#34; href=&#34;#question-for-my-clients-highly-secured-data-like-health-industry-data-banking-insurnace-internal-security-etc-data-can-i-use-gpt4-for-finetuning&#34; aria-label=&#34;Anchor&#34;&gt;#&lt;/a&gt;
    &lt;/span&gt;        
    
&lt;/h2&gt;
&lt;p&gt;For highly sensitive data, such as health industry data, banking information, insurance details, and security data, using models like ChatGPT-3.5 or GPT-4 involves several considerations to ensure security and compliance:&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Rich Content</title>
      <link>https://localhost:1313/samples/rich-content/</link>
      <pubDate>Sun, 10 Mar 2019 00:00:00 +0000</pubDate>
      <author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>https://localhost:1313/samples/rich-content/</guid>
      <description>This is an &lt;em&gt;example&lt;/em&gt; of a &lt;strong&gt;rich&lt;/strong&gt; content summary.</description>
      
    </item>
    
  </channel>
</rss>
