<!DOCTYPE html>
<html lang="en" dir="ltr" class="scroll-smooth" data-default-appearance="dark"
  data-auto-appearance="true"><head>
  <meta charset="utf-8" />
  
  <meta http-equiv="content-language" content="en" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title>Paper with Code Resources &middot; </title>
  <meta name="title" content="Paper with Code Resources &middot; " />
  
  
  <meta name="keywords" content="Research Implementation, ML Libraries, Code Resources, AI Development, Machine Learning, Deep Learning, Computer Vision, Research Papers, " />
  
  
  <link rel="canonical" href="https://dasarpai.com/dsblog/paperwithcode-resources/" />
  
  
  
  
  
  
  
  
  
  
  
  
  <link type="text/css" rel="stylesheet" href="/css/main.bundle.min.d335c1c6fee4163b424b4aa7d14752445031097c25817767a55d8a7db1621ca481e0287c82b86b87ea9c9a649f872dd80f066f485f3a8695959a63d7f01643d1.css"
    integrity="sha512-0zXBxv7kFjtCS0qn0UdSRFAxCXwlgXdnpV2KfbFiHKSB4Ch8grhrh&#43;qcmmSfhy3YDwZvSF86hpWVmmPX8BZD0Q==" />
  
  
  <script type="text/javascript" src="/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js"
    integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj&#43;e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script>
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <script defer type="text/javascript" id="script-bundle" src="/js/main.bundle.min.d216f70fb590d5fe69353ea31ace5a1c496a6ac5dd460871bf068a266962b270837f78a38bc9975746955acc580b40b63a33b8197693cd73c8f86a3589442db9.js"
    integrity="sha512-0hb3D7WQ1f5pNT6jGs5aHElqasXdRghxvwaKJmlisnCDf3iji8mXV0aVWsxYC0C2OjO4GXaTzXPI&#43;Go1iUQtuQ==" data-copy="Copy" data-copied="Copied"></script>
  
  
  
  <script src="/lib/zoom/zoom.min.f592a181a15d2a5b042daa7f746c3721acf9063f8b6acd175d989129865a37d400ae0e85b640f9ad42cd98d1f8ad30931718cf8811abdcc5fcb264400d1a2b0c.js" integrity="sha512-9ZKhgaFdKlsELap/dGw3Iaz5Bj&#43;Las0XXZiRKYZaN9QArg6FtkD5rULNmNH4rTCTFxjPiBGr3MX8smRADRorDA=="></script>
  
  
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="manifest" href="/site.webmanifest" />
  
  
  
  <meta name="google-site-verification" content="google926354b0a3e2593e.html" />
  
  
  
  
  
  
  <meta property="og:url" content="https://dasarpai.com/dsblog/paperwithcode-resources/">
  <meta property="og:title" content="Paper with Code Resources">
  <meta property="og:description" content="Paper with Code Resources # Trending Papers of 2021 # ADOP: Approximate Differentiable One-Pixel Point Rendering — Rückert et al — https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel The Bayesian Learning Rule —Khan et al https://paperswithcode.com/paper/the-bayesian-learning-rule Program Synthesis with Large Language Models — Austin et al https://paperswithcode.com/paper/program-synthesis-with-large-language-models Masked Autoencoders Are Scalable Vision Learners — He et al https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision 8-bit Optimizers via Block-wise Quantization — Dettmers et al https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization Revisiting ResNets: Improved Training and Scaling Strategies — Bello et al https://paperswithcode.com/paper/revisiting-resnets-improved-training-and Image Super-Resolution via Iterative Refinement — Saharia et al https://paperswithcode.com/paper/image-super-resolution-via-iterative Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs — Jaegle et al https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for Do Vision Transformers See Like Convolutional Neural Networks? — Raghu et al https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions — Niepert et al https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete Trending Libaries of 2021 # PyTorch Image Models — Ross Wightman — https://github.com/rwightman/pytorch-image-models Transformers — Hugging Face — https://github.com/huggingface/transformers PyTorch-GAN — Erik Linder-Norén — https://github.com/eriklindernoren/PyTorch-GAN MMDetection — OpenMMLab — https://github.com/open-mmlab/mmdetection Darknet — AlexeyAB — https://github.com/AlexeyAB/darknet Vision Transformer PyTorch — lucidrains — https://github.com/lucidrains/vit-pytorch InsightFace — DeepInsight — https://github.com/deepinsight/insightface Detectron2 — Meta AI — https://github.com/facebookresearch/detectron2 PaddleOCR — PaddlePaddle — https://github.com/PaddlePaddle/PaddleOCR FairSeq — Meta AI — https://github.com/pytorch/fairseq Top Dataset - 2021 # MATH — Hendrycks et al https://paperswithcode.com/dataset/math UAV-Human — Li et al https://paperswithcode.com/dataset/uav-human UPFD (User Preference-aware Fake News Detection) — Dou et al https://paperswithcode.com/dataset/upfd OGB-LSC (OGB Large-Scale Challenge) — Hu et al https://paperswithcode.com/dataset/ogb-lsc CodeXGLUE —Lu et al https://paperswithcode.com/dataset/codexglue AGORA — Patel et al https://paperswithcode.com/dataset/agora BEIR (Benchmarking IR) — Thakur et al https://paperswithcode.com/dataset/beir WikiGraphs — Wang et al https://paperswithcode.com/dataset/wikigraphs Few-NERD — Ding et al https://paperswithcode.com/dataset/few-nerd PASS (Pictures without humAns for Self-Supervision) —Asano et al https://paperswithcode.com/dataset/pass Papers of 2022 # Controllable Animation of Fluid Elements in Still Images F-SfT: Shape-From-Template With A Physics-Based Deformation Model TWIST: Two-Way Inter-Label Self-Training for Semi-Supervised 3D Instance Segmentation Do Learned Representations Respect Causal Relationships? ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic 3D Moments From Near-Duplicate Photos Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization Blind2Unblind: Self-Supervised Image Denoising With Visible Blind Spots Balanced and Hierarchical Relation Learning for One-Shot Object Detection NICE-SLAM: Neural Implicit Scalable Encoding for SLAM Stochastic Trajectory Prediction Via Motion Indeterminacy Diffusion CLRNet: Cross Layer Refinement Network for Lane Detection Motion-Aware Contrastive Video Representation Learning Via Foreground-Background Merging DINE: Domain Adaptation From Single and Multiple Black-Box Predictors FaceFormer: Speech-Driven 3D Facial Animation With Transformers Rotationally Equivariant 3D Object Detection Accelerating DETR Convergence Via Semantic-Aligned Matching Cloning Outfits From Real-World Images to 3D Characters for Generalizable Person Re-Identification GeoNeRF: Generalizing NeRF With Geometry Priors ABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo Expanding Low-Density Latent Regions for Open-Set Object Detection Uformer: A General U-Shaped Transformer for Image Restoration Exploring Dual-Task Correlation for Pose Guided Person Image Generation Portrait Eyeglasses and Shadow Removal By Leveraging 3D Synthetic Data Modeling 3D Layout for Group Re-Identification Toward Fast, Flexible, and Robust Low-Light Image Enhancement Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network Modular Action Concept Grounding in Semantic Video Prediction StyleSwin: Transformer-Based GAN for High-Resolution Image Generation Discrete Cosine Transform Network for Guided Depth Map Super-Resolution Cerberus Transformer: Joint Semantic, Affordance and Attribute Parsing TransGeo: Transformer Is All You Need for Cross-View Image Geo-Localization Contrastive Boundary Learning for Point Cloud Segmentation Details or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution CVNet: Contour Vibration Network for Building Extraction Swin Transformer V2: Scaling Up Capacity and Resolution Projective Manifold Gradient Layer for Deep Rotation Regression HCSC: Hierarchical Contrastive Selective Coding TransRank: Self-Supervised Video Representation Learning Via Ranking-Based Transformation Recognition DiSparse: Disentangled Sparsification for Multitask Model Compression Pushing The Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make A Difference Towards Efficient and Scalable Sharpness-Aware Minimization OSSO: Obtaining Skeletal Shape From Outside A Study on The Distribution of Social Biases in Self-Supervised Learning Visual Models Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes Comparing Correspondences: Video Prediction With Correspondence-Wise Losses Towards Fewer Annotations: Active Learning Via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding Few Shot Generative Model Adaption Via Relaxed Spatial Structural Alignment Enhancing Adversarial Training With Second-Order Statistics of Weights Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo Moving Window Regression: A Novel Approach to Ordinal Regression Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection Robust Optimization As Data Augmentation for Large-Scale Graphs Robust Structured Declarative Classifiers for 3D Point Clouds: Defending Adversarial Attacks With Implicit Gradients Improving The Transferability of Targeted Adversarial Examples Through Object-Based Diverse Input ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer 360MonoDepth: High-Resolution 360deg Monocular Depth Estimation POCO: Point Convolution for Surface Reconstruction Neural Texture Extraction and Distribution for Controllable Person Image Synthesis Classification-Then-Grounding: Reformulating Video Scene Graphs As Temporal Bipartite Graphs DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis ZeroWaste Dataset: Towards Deformable Object Segmentation in Cluttered Scenes UNIST: Unpaired Neural Implicit Shape Translation Network APES: Articulated Part Extraction From Sprite Sheets SPAct: Self-Supervised Privacy Preservation for Action Recognition De-Rendering 3D Objects in The Wild Global Sensing and Measurements Reuse for Image Compressed Sensing Practical Evaluation of Adversarial Robustness Via Adaptive Auto Attack Cross-View Transformers for Real-Time Map-View Semantic Segmentation Controllable Dynamic Multi-Task Architectures FastDOG: Fast Discrete Optimization on GPU Focal and Global Knowledge Distillation for Detectors Learning To Prompt for Continual Learning Human Mesh Recovery From Multiple Shots Convolution of Convolution: Let Kernels Spatially Collaborate Make It Move: Controllable Image-to-Video Generation With Text Descriptions Neural Points: Point Cloud Representation With Neural Fields for Arbitrary Upsampling Video-Text Representation Learning Via Differentiable Weak Temporal Alignment Bi-Directional Object-Context Prioritization Learning for Saliency Ranking Vehicle Trajectory Prediction Works, But Not Everywhere MonoDTR: Monocular 3D Object Detection With Depth-Aware Transformer Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-Shot Learning Generalized Category Discovery Contour-Hugging Heatmaps for Landmark Detection Voxel Field Fusion for 3D Object Detection DisARM: Displacement Aware Relation Module for 3D Detection MixFormer: Mixing Features Across Windows and Dimensions FineDiving: A Fine-Grained Dataset for Procedure-Aware Action Quality Assessment HEAT: Holistic Edge Attention Transformer for Structured Reconstruction Mobile-Former: Bridging MobileNet and Transformer CycleMix: A Holistic Strategy for Medical Image Segmentation From Scribble Supervision VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution Towards End-to-End Unified Scene Text Detection and Layout Analysis AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior End-to-End Referring Video Object Segmentation With Multimodal Transformers IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo Not All Points Are Equal: Learning Highly Efficient Point-Based Detectors for 3D LiDAR Point Clouds Detecting Camouflaged Object in Frequency Domain SelfRecon: Self Reconstruction Your Digital Avatar From Monocular Video Equivariant Point Cloud Analysis Via Learning Orientations for Message Passing Node Representation Learning in Graph Via Node-to-Neighbourhood Mutual Information Maximization Semi-Supervised Video Semantic Segmentation With Inter-Frame Feature Reconstruction Amodal Segmentation Through Out-of-Task and Out-of-Distribution Generalization With A Bayesian Model How Well Do Sparse ImageNet Models Transfer? REX: Reasoning-Aware and Grounded Explanation Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes Object-Aware Video-Language Pre-Training for Retrieval MAT: Mask-Aware Transformer for Large Hole Image Inpainting Align and Prompt: Video-and-Language Pre-Training With Entity Prompts MSG-Transformer: Exchanging Local Spatial Information By Manipulating Messenger Tokens Cross Modal Retrieval With Querybank Normalisation Ray3D: Ray-Based 3D Human Pose Estimation for Monocular Absolute 3D Localization ASM-Loc: Action-Aware Segment Modeling for Weakly-Supervised Temporal Action Localization Scaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs End-to-End Multi-Person Pose Estimation With Transformers REGTR: End-to-End Point Cloud Correspondences With Transformers Neural 3D Scene Reconstruction With The Manhattan-World Assumption V2C: Visual Voice Cloning Revisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection MAD: A Scalable Dataset for Language Grounding in Videos From Movie Audio Descriptions Gait Recognition in The Wild With Dense 3D Representations and A Benchmark ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation Via Online Exploration and Synthesis QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection IDEA-Net: Dynamic 3D Point Cloud Interpolation Via Deep Embedding Alignment BEHAVE: Dataset and Method for Tracking Human Object Interactions Revisiting Random Channel Pruning for Neural Network Compression Generating Diverse and Natural 3D Human Motions From Text E-CIR: Event-Enhanced Continuous Intensity Recovery Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond Symmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose Estimation AziNorm: Exploiting The Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception Weakly Supervised Rotation-Invariant Aerial Object Detection Network Surface Reconstruction From Point Clouds By Learning Predictive Context Priors IRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation Weakly Supervised Temporal Action Localization Via Representative Snippet Knowledge Propagation E2EC: An End-to-End Contour-Based Method for High-Quality High-Speed Instance Segmentation BatchFormer: Learning To Explore Sample Relationships for Robust Representation Learning Self-Supervised Image-Specific Prototype Exploration for Weakly Supervised Semantic Segmentation Learning Multi-View Aggregation in The Wild for Large-Scale 3D Semantic Segmentation PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition Clothes-Changing Person Re-Identification With RGB Modality Only Robust Image Forgery Detection Over Online Social Network Shared Images Representation Compensation Networks for Continual Semantic Segmentation Tracking People By Predicting 3D Appearance, Location and Pose Text2Mesh: Text-Driven Neural Stylization for Meshes C-CAM: Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image Forward Compatible Few-Shot Class-Incremental Learning Weakly Supervised Object Localization As Domain Adaption Tencent-MVSE: A Large-Scale Benchmark Dataset for Multi-Modal Video Similarity Evaluation Deep Orientation-Aware Functional Maps: Tackling Symmetry Issues in Shape Matching Tree Energy Loss: Towards Sparsely Annotated Semantic Segmentation MatteFormer: Transformer-Based Image Matting Via Prior-Tokens Video Shadow Detection Via Spatio-Temporal Interpolation Consistency Training Robust and Accurate Superquadric Recovery: A Probabilistic Approach Grounding Answers for Visual Questions Asked By Visually Impaired People Sparse Instance Activation for Real-Time Instance Segmentation VisualGPT: Data-Efficient Adaptation of Pretrained Language Models for Image Captioning MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis Towards Implicit Text-Guided 3D Shape Generation SoftCollage: A Differentiable Probabilistic Tree Generator for Image Collage Query and Attention Augmentation for Knowledge-Based Explainable Reasoning Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality Progressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection Fine-Grained Object Classification Via Self-Supervised Pose Alignment Animal Kingdom: A Large and Diverse Dataset for Animal Behavior Understanding Fine-Grained Temporal Contrastive Learning for Weakly-Supervised Temporal Action Localization Relieving Long-Tailed Instance Segmentation Via Pairwise Class Balance Online Convolutional Re-Parameterization Mimicking The Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition Personalized Image Aesthetics Assessment With Rich Attributes Part-Based Pseudo Label Refinement for Unsupervised Person Re-Identification HDNet: High-Resolution Dual-Domain Learning for Spectral Compressive Imaging OW-DETR: Open-World Detection Transformer Learning Deep Implicit Functions for 3D Shapes With Dynamic Code Clouds Reversible Vision Transformers Amodal Panoptic Segmentation Correlation Verification for Image Retrieval Temporal Feature Alignment and Mutual Information Maximization for Video-Based Human Pose Estimation Self-Supervised Transformers for Unsupervised Object Discovery Using Normalized Cut Exploring Structure-Aware Transformer Over Interaction Proposals for Human-Object Interaction Detection Decoupled Multi-Task Learning With Cyclical Self-Regulation for Face Parsing Glass: Geometric Latent Augmentation for Shape Spaces DPICT: Deep Progressive Image Compression Using Trit-Planes Text to Image Generation With Semantic-Spatial Aware GAN Generalizable Cross-Modality Medical Image Segmentation Via Style Augmentation and Dual Normalization Learning To Prompt for Open-Vocabulary Object Detection With Vision-Language Model Interactive Segmentation and Visualization for Tiny Objects in Multi-Megapixel Images Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture Surface Representation for Point Clouds Implicit Motion Handling for Video Camouflaged Object Detection DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides Learning With Twin Noisy Labels for Visible-Infrared Person Re-Identification Optical Flow Estimation for Spiking Camera GradViT: Gradient Inversion of Vision Transformers Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution Via Cycle-Projected Mutual Learning Joint Global and Local Hierarchical Priors for Learned Image Compression Knowledge Distillation Via The Target-Aware Transformer Subspace Adversarial Training 3D-VField: Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection Image Segmentation Using Text and Image Prompts AutoMine: An Unmanned Mine Dataset Background Activation Suppression for Weakly Supervised Object Localization Synthetic Generation of Face Videos With Plethysmograph Physiology Hallucinated Neural Radiance Fields in The Wild Global Tracking Transformers Backdoor Attacks on Self-Supervised Learning GMFlow: Learning Optical Flow Via Global Matching Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation Explore Spatio-Temporal Aggregation for Insubstantial Object Detection: Benchmark Dataset and Baseline Graph-Based Spatial Transformer With Memory Replay for Multi-Future Pedestrian Trajectory Prediction Scanline Homographies for Rolling-Shutter Plane Absolute Pose AdaInt: Learning Adaptive Intervals for 3D Lookup Tables on Real-Time Image Enhancement Recurrent Glimpse-Based Decoder for Detection With Transformer SimMIM: A Simple Framework for Masked Image Modeling Label Matching Semi-Supervised Object Detection RegionCLIP: Region-Based Language-Image Pretraining Video Frame Interpolation Transformer BCOT: A Markerless High-Precision 3D Object Tracking Benchmark Omni-DETR: Omni-Supervised Object Detection With Transformers Transferable Sparse Adversarial Attack CREAM: Weakly Supervised Object Localization Via Class RE-Activation Mapping VALHALLA: Visual Hallucination for Machine Translation HINT: Hierarchical Neuron Concept Explainer Neural Face Identification in A 2D Wireframe Projection of A Manifold Object Nonuniform-to-Uniform Quantization: Towards Accurate Quantization Via Generalized Straight-Through Estimation An Empirical Study of End-to-End Temporal Action Detection Object Localization Under Single Coarse Point Supervision Unsupervised Learning of Accurate Siamese Tracking Non-Parametric Depth Distribution Modelling Based Depth Inference for Multi-View Stereo Equalized Focal Loss for Dense Long-Tailed Object Detection DeepDPM: Deep Clustering With An Unknown Number of Clusters ISDNet: Integrating Shallow and Deep Networks for Efficient Ultra-High Resolution Segmentation Unsupervised Domain Adaptation for Nighttime Aerial Tracking RestoreFormer: High-Quality Blind Face Restoration From Undegraded Key-Value Pairs Mask-Guided Spectral-Wise Transformer for Efficient Hyperspectral Image Reconstruction A Variational Bayesian Method for Similarity Learning in Non-Rigid Image Registration Not Just Selection, But Exploration: Online Class-Incremental Continual Learning Via Dual View Consistency Coupling Vision and Proprioception for Navigation of Legged Robots Exploiting Rigidity Constraints for LiDAR Scene Flow Estimation EMOCA: Emotion Driven Monocular Face Capture and Animation Quarantine: Sparsity Can Uncover The Trojan Attack Trigger for Free AlignQ: Alignment Quantization With ADMM-Based Correlation Preservation Interactive Multi-Class Tiny-Object Detection Learning From Pixel-Level Noisy Label: A New Perspective for Light Field Saliency Detection Multi-View Depth Estimation By Fusing Single-View Depth Probability With Multi-View Geometry Slimmable Domain Adaptation High-Resolution Image Harmonization Via Collaborative Dual Transformations MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation Self-Supervised Neural Articulated Shape and Appearance Models Topology Preserving Local Road Network Estimation From Single Onboard Camera Image Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes SwinTextSpotter: Scene Text Spotting Via Better Synergy Between Text Detection and Text Recognition Deblur-NeRF: Neural Radiance Fields From Blurry Images Whose Track Is It Anyway? Improving Robustness to Tracking Errors With Affinity-Based Trajectory Prediction Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning Blind Image Super-Resolution With Elaborate Degradation Modeling on Noise and Kernel Faithful Extreme Rescaling Via Generative Prior Reciprocated Invertible Representations Proto2Proto: Can You Recognize The Car, The Way I Do? TVConv: Efficient Translation Variant Convolution for Layout-Aware Visual Processing Dual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution Habitat-Web: Learning Embodied Object-Search Strategies From Human Demonstrations at Scale Simple But Effective: CLIP Embeddings for Embodied AI NomMer: Nominate Synergistic Context in Vision Transformer for Visual Recognition Collaborative Transformers for Grounded Situation Recognition CPPF: Towards Robust Category-Level 9D Pose Estimation in The Wild Continual Test-Time Domain Adaptation Dynamic MLP for Fine-Grained Image Classification By Leveraging Geographical and Temporal Information MuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-Based Visual Question Answering Fair Contrastive Learning for Facial Attribute Classification Directional Self-Supervised Learning for Heavy Image Augmentations No-Reference Point Cloud Quality Assessment Via Domain Adaptation Comprehending and Ordering Semantics for Image Captioning A Large-Scale Comprehensive Dataset and Copy-Overlap Aware Evaluation Protocol for Segment-Level Video Copy Detection Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification HeadNeRF: A Real-Time NeRF-Based Parametric Head Model Occlusion-Robust Face Alignment Using A Viewpoint-Invariant Hierarchical Network Architecture IDR: Self-Supervised Image Denoising Via Iterative Data Refinement MogFace: Towards A Deeper Appreciation on Face Detection Learning Affinity From Attention: End-to-End Weakly-Supervised Semantic Segmentation With Transformers CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos Learning To Detect Mobile Objects From LiDAR Scans Without Labels WildNet: Learning Domain Generalized Semantic Segmentation From The Wild DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation Generating Diverse 3D Reconstructions From A Single Occluded Face Image Stand-Alone Inter-Frame Attention in Video Models Large-Scale Pre-Training for Person Re-Identification With Noisy Labels Semantic Segmentation By Early Region Proxy LD-ConGR: A Large RGB-D Video Dataset for Long-Distance Continuous Gesture Recognition HVH: Learning A Hybrid Neural Volumetric Representation for Dynamic Hair Performance Capture Rethinking Visual Geo-Localization for Large-Scale Applications The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy ViM: Out-of-Distribution With Virtual-Logit Matching Class-Aware Contrastive Semi-Supervised Learning Ditto: Building Digital Twins of Articulated Objects From Interaction Adaptive Early-Learning Correction for Segmentation From Noisy Annotations Cross-Domain Correlation Distillation for Unsupervised Domain Adaptation in Nighttime Semantic Segmentation RSTT: Real-Time Spatial Temporal Transformer for Space-Time Video Super-Resolution Partial Class Activation Attention for Semantic Segmentation Multi-Scale Memory-Based Video Deblurring A Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching Geometric Structure Preserving Warp for Natural Image Stitching GOAL: Generating 4D Whole-Body Motion for Hand-Object Grasping Conditional Prompt Learning for Vision-Language Models Graph Sampling Based Deep Metric Learning for Generalizable Person Re-Identification Undoing The Damage of Label Shift for Cross-Domain Semantic Segmentation FisherMatch: Semi-Supervised Rotation Regression Via Entropy-Based Filtering Affine Medical Image Registration With Coarse-To-Fine Vision Transformer A Differentiable Two-Stage Alignment Scheme for Burst Image Reconstruction With Large Shift Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes Restormer: Efficient Transformer for High-Resolution Image Restoration IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation Large Loss Matters in Weakly Supervised Multi-Label Classification Neural Inertial Localization GraftNet: Towards Domain Generalized Stereo Matching With A Broad-Spectrum and Task-Oriented Feature VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning Catching Both Gray and Black Swans: Open-Set Supervised Anomaly Detection MLSLT: Towards Multilingual Sign Language Translation Towards An End-to-End Framework for Flow-Guided Video Inpainting Contrastive Test-Time Adaptation MotionAug: Augmentation With Physical Correction for Human Motion Prediction Modeling Indirect Illumination for Inverse Rendering TransWeather: Transformer-Based Restoration of Images Degraded By Adverse Weather Conditions H2FA R-CNN: Holistic and Hierarchical Feature Alignment for Cross-Domain Weakly Supervised Object Detection P3Depth: Monocular Depth Estimation With A Piecewise Planarity Prior GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection Simple Multi-Dataset Detection Proactive Image Manipulation Detection StyTr2: Image Style Transfer With Transformers Global Matching With Overlapping Attention for Optical Flow Estimation Language As Queries for Referring Video Object Segmentation MViTv2: Improved Multiscale Vision Transformers for Classification and Detection Audio-Visual Generalised Zero-Shot Learning With Cross-Modal Attention and Language Rethinking Efficient Lane Detection Via Curve Modeling Self-Supervised Arbitrary-Scale Point Clouds Upsampling Via Implicit Neural Representation Co-Advise: Cross Inductive Bias Distillation AdaMixer: A Fast-Converging Query-Based Object Detector DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification BEVT: BERT Pretraining of Video Transformers Deep Generalized Unfolding Networks for Image Restoration VISOLO: Grid-Based Space-Time Aggregation for Efficient Online Video Instance Segmentation Deep Unlearning Via Randomized Conditionally Independent Hessians Revisiting Skeleton-Based Action Recognition Stereo Depth From Events Cameras: Concentrate and Focus on The Future A Simple Data Mixing Prior for Improving Self-Supervised Learning Knowledge Distillation As Efficient Pre-Training: Faster Convergence, Higher Data-Efficiency, and Better Transferability BigDL 2.0: Seamless Scaling of AI Pipelines From Laptops to Distributed Cluster Attentive Fine-Grained Structured Sparsity for Image Restoration Learning Fair Classifiers With Partially Annotated Group Labels NightLab: A Dual-Level Architecture With Hardness Detection for Segmentation at Night Constrained Few-Shot Class-Incremental Learning Threshold Matters in WSSS: Manipulating The Activation for The Robust and Accurate Segmentation Model Against Thresholds TransMVSNet: Global Context-Aware Multi-View Stereo Network With Transformers DPGEN: Differentially Private Generative Energy-Guided Network for Natural Image Synthesis The Majority Can Help The Minority: Context-Rich Minority Oversampling for Long-Tailed Classification IntentVizor: Towards Generic Query Guided Interactive Video Summarization Shape-Invariant 3D Adversarial Point Clouds Bootstrapping ViTs: Towards Liberating Vision Transformers From Pre-Training PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents Meta-Attention for ViT-Backed Continual Learning DST: Dynamic Substitute Training for Data-Free Black-Box Attack Unified Contrastive Learning in Image-Text-Label Space Unsupervised Pre-Training for Temporal Action Localization Tasks Look Outside The Room: Synthesizing A Consistent Long-Term 3D Scene Video From A Single Image High-Fidelity Human Avatars From A Single RGB Camera Multiview Transformers for Video Recognition How Good Is Aesthetic Ability of A Fashion Model? Deformation and Correspondence Aware Unsupervised Synthetic-to-Real Scene Flow Estimation for Point Clouds Sequential Voting With Relational Box Fields for Active Object Detection Semantic-Aware Auto-Encoders for Self-Supervised Representation Learning Consistency Learning Via Decoding Path Augmentation for Transformers in Human Object Interaction Detection Consistent Explanations By Contrastive Learning Hierarchical Modular Network for Video Captioning Depth Estimation By Combining Binocular Stereo and Monocular Structured-Light Salient-to-Broad Transition for Video Person Re-Identification DeeCap: Dynamic Early Exiting for Efficient Image Captioning RepMLPNet: Hierarchical Vision MLP With Re-Parameterized Locality DR.VIC: Decomposition and Reasoning for Video Individual Counting ARCS: Accurate Rotation and Correspondence Search Learning To Anticipate Future With Dynamic Context Removal GCFSR: A Generative and Controllable Face Super Resolution Method Without Facial and GAN Priors On The Integration of Self-Attention and Convolution Domain Adaptation on Point Clouds Via Geometry-Aware Implicits GroupViT: Semantic Segmentation Emerges From Text Supervision DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation BppAttack: Stealthy and Efficient Trojan Attacks Against Deep Neural Networks Via Image Quantization and Contrastive Adversarial Learning Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation Towards Better Plasticity-Stability Trade-Off in Incremental Learning: A Simple Linear Connector Topology-Preserving Shape Reconstruction and Registration Via Neural Diffeomorphic Flow Segment and Complete: Defending Object Detectors Against Adversarial Patch Attacks With Robust Patch Detection MAXIM: Multi-Axis MLP for Image Processing Learning Part Segmentation Through Unsupervised Domain Adaptation From Synthetic Vehicles PSTR: End-to-End One-Step Person Search With Transformers NFormer: Robust Person Re-Identification With Neighbor Transformer Bridging Global Context Interactions for High-Fidelity Image Completion SwinBERT: End-to-End Transformers With Sparse Attention for Video Captioning Not All Tokens Are Equal: Human-Centric Visual Analysis Via Token Clustering Transformer Temporally Efficient Vision Transformer for Video Instance Segmentation The Devil Is in The Margin: Margin-Based Label Smoothing for Network Calibration NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding E2(GO)MOTION: Motion Augmented Event Stream for Egocentric Action Recognition OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization OnePose: One-Shot Object Pose Estimation Without CAD Models Rethinking Minimal Sufficient Representation in Contrastive Learning Scalable Penalized Regression for Noise Detection in Learning With Noisy Labels Federated Class-Incremental Learning Show, Deconfound and Tell: Image Captioning With Causal Inference MobRecon: Mobile-Friendly Hand Mesh Reconstruction From Monocular Image Parameter-Free Online Test-Time Adaptation SIGMA: Semantic-Complete Graph Matching for Domain Adaptive Object Detection No Pain, Big Gain: Classify Dynamic Point Cloud Sequences With Static Models By Fitting Feature-Level Space-Time Surfaces HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for Snapshot Compressive Imaging Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space Learning To Estimate Robust 3D Human Mesh From In-the-Wild Crowded Scenes Detecting Deepfakes With Self-Blended Images Implicit Sample Extension for Unsupervised Person Re-Identification Energy-Based Latent Aligner for Incremental Learning Towards Semi-Supervised Deep Facial Expression Recognition With An Adaptive Confidence Margin Group R-CNN for Weakly Semi-Supervised Object Detection With Points Weakly-Supervised Action Transition Learning for Stochastic Human Motion Prediction Hybrid Relation Guided Set Matching for Few-Shot Action Recognition Cross-Patch Dense Contrastive Learning for Semi-Supervised Segmentation of Cellular Nuclei in Histopathologic Images Generalized Binary Search Network for Highly-Efficient Multi-View Stereo SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation FlexIT: Towards Flexible Semantic Image Translation CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow BoxeR: Box-Attention for 2D and 3D Transformers Neural Architecture Search With Representation Mutual Information Can Neural Nets Learn The Same Model Twice? Investigating Reproducibility and Double Descent From The Decision Boundary Perspective Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction Multi-View Transformer for 3D Visual Grounding Structured Sparse R-CNN for Direct Scene Graph Generation BARC: Learning To Regress 3D Dog Shape From Images By Exploiting Breed Information PCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models Towards Understanding Adversarial Robustness of Optical Flow Networks Lifelong Graph Learning Hypergraph-Induced Semantic Tuplet Loss for Deep Metric Learning Computing Wasserstein-p Distance Between Images With Linear Cost Unsupervised Representation Learning for Binary Networks By Joint Classifier Learning Large-Scale Video Panoptic Segmentation in The Wild: A Benchmark GrainSpace: A Large-Scale Dataset for Fine-Grained and Domain-Adaptive Recognition of Cereal Grains Learning Modal-Invariant and Temporal-Memory for Video-Based Visible-Infrared Person Re-Identification MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning Oriented RepPoints for Aerial Object Detection Weakly Supervised Temporal Sentence Grounding With Gaussian-Based Contrastive Proposal Learning Low-Resource Adaptation for Personalized Co-Speech Gesture Generation Task-Specific Inconsistency Alignment for Domain Adaptive Object Detection MS2DG-Net: Progressive Correspondence Learning Via Multiple Sparse Semantics Dynamic Graph Learning To Listen: Modeling Non-Deterministic Dyadic Facial Motion Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation From Monocular Video MixFormer: End-to-End Tracking With Iterative Mixed Attention Plenoxels: Radiance Fields Without Neural Networks Selective-Supervised Contrastive Learning With Noisy Labels SimT: Handling Open-Set Noise for Domain Adaptive Semantic Segmentation Frequency-Driven Imperceptible Adversarial Attack on Semantic Similarity Video Demoireing With Relation-Based Temporal Consistency Industrial Style Transfer With Large-Scale Geometric Warping and Content Preservation Modeling Image Composition for Complex Scene Generation Decoupling Zero-Shot Semantic Segmentation Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting The Adversarial Transferability IFOR: Iterative Flow Minimization for Robotic Object Rearrangement Zero Experience Required: Plug &amp; Play Modular Transfer Learning for Semantic Visual Navigation TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation The Wanderings of Odysseus in 3D Scenes All-in-One Image Restoration for Unknown Corruption PUMP: Pyramidal and Uniqueness Matching Priors for Unsupervised Learning of Local Descriptors MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video RCP: Recurrent Closest Point for Point Cloud A Dual Weighting Label Assignment Scheme for Object Detection Hyperbolic Vision Transformers: Combining Improvements in Metric Learning Instance-Aware Dynamic Neural Network Quantization Exploring Effective Data for Surrogate Training Towards Black-Box Attack JRDB-Act: A Large-Scale Dataset for Spatio-Temporal Action, Social Group and Activity Detection Investigating Top-k White-Box and Transferable Black-Box Attack Decoupling and Recoupling Spatiotemporal Representation for RGB-D-Based Motion Recognition A Self-Supervised Descriptor for Image Copy Detection Negative-Aware Attention Framework for Image-Text Matching An Image Patch Is A Wave: Phase-Aware Vision MLP Shunted Self-Attention Via Multi-Scale Token Aggregation Unified Multivariate Gaussian Mixture for Efficient Neural Image Compression Recurrent Variational Network: A Deep Learning Inverse Problem Solver Applied to The Task of Accelerated MRI Reconstruction Surpassing The Human Accuracy: Detecting Gallbladder Cancer From USG Images With Curriculum Learning Appearance and Structure Aware Robust Deep Visual Graph Matching: Attack, Defense and Beyond TrackFormer: Multi-Object Tracking With Transformers 3D Shape Reconstruction From 2D Images With Disentangled Attribute Flow Feature Statistics Mixing Regularization for Generative Adversarial Networks OpenTAL: Towards Open Set Temporal Action Localization Self-Supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection Ego4D: Around The World in 3,000 Hours of Egocentric Video Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data DAD-3DHeads: A Large-Scale Dense, Accurate and Diverse Dataset for 3D Head Alignment From A Single Image Reconstructing Surfaces for Sparse Point Clouds With On-Surface Priors VCLIMB: A Novel Video Class Incremental Learning Benchmark Robust Equivariant Imaging: A Fully Unsupervised Framework for Learning To Image From Noisy and Partial Measurements ST&#43;&#43;: Make Self-Training Work Better for Semi-Supervised Semantic Segmentation Interacting Attention Graph for Single Image Two-Hand Reconstruction Rope3D: The Roadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task Cross-Image Relational Knowledge Distillation for Semantic Segmentation Towards Layer-Wise Image Vectorization Scenic: A JAX Library for Computer Vision Research and Beyond Real-Time Object Detection for Streaming Perception VisualHow: Multimodal Problem Solving Spatial Commonsense Graph for Object Localisation in Partial Scenes OSSGAN: Open-Set Semi-Supervised Image Generation Bi-Level Alignment for Cross-Domain Crowd Counting ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation Efficient Multi-View Stereo By Iterative Dynamic Cost Volume TransEditor: Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing Use All The Labels: A Hierarchical Multi-Label Contrastive Learning Framework SGTR: End-to-End Scene Graph Generation With Transformer Decoupled Knowledge Distillation DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection Reusing The Task-Specific Classifier As A Discriminator: Discriminator-Free Adversarial Domain Adaptation Show Me What and Tell Me How: Video Synthesis Via Multimodal Conditioning SIMBAR: Single Image-Based Scene Relighting for Effective Data Augmentation for Automated Driving Vision Tasks Multi-Label Classification With Partial Annotations Using Class-Aware Selective Loss CADTransformer: Panoptic Symbol Spotting Transformer for CAD Drawings IntraQ: Learning Synthetic Images With Intra-Class Heterogeneity for Zero-Shot Network Quantization I M Avatar: Implicit Morphable Head Avatars From Videos Weakly-Supervised Metric Learning With Cross-Module Communications for The Classification of Anterior Chamber Angle Images A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-Resolution Multi-Modal Dynamic Graph Transformer for Visual Grounding Geometric Transformer for Fast and Robust Point Cloud Registration UMT: Unified Multi-Modal Transformers for Joint Video Moment Retrieval and Highlight Detection Demystifying The Neural Tangent Kernel From A Practical Perspective: Can It Be Trusted for Neural Architecture Search Without Training? The Devil Is in The Details: Window-Based Attention for Image Compression DiLiGenT102: A Photometric Stereo Benchmark Dataset With Controlled Shape and Material Variation PolyWorld: Polygonal Building Extraction With Graph Neural Networks in Satellite Images Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation Spatio-Temporal Relation Modeling for Few-Shot Action Recognition Multi-Person Extreme Motion Prediction B-DARTS: Beta-Decay Regularization for Differentiable Architecture Search CMT: Convolutional Neural Networks Meet Vision Transformers KNN Local Attention for Image Restoration Predict, Prevent, and Evaluate: Disentangled Text-Driven Image Manipulation Empowered By Pre-Trained Vision-Language Model TransMix: Attend To Mix for Vision Transformers Inertia-Guided Flow Completion and Style Fusion for Video Inpainting Long-Tailed Visual Recognition Via Gaussian Clouded Logit Adjustment Image Animation With Perturbed Masks Domain Generalization Via Shuffled Style Assembly for Face Anti-Spoofing OcclusionFusion: Occlusion-Aware Motion Estimation for Real-Time Dynamic 3D Reconstruction MonoScene: Monocular 3D Semantic Scene Completion AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition Continuous Scene Representations for Embodied AI Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds Non-Probability Sampling Network for Stochastic Human Trajectory Prediction ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning Human-Aware Object Placement for Visual Environment Reconstruction X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval RAMA: A Rapid Multicut Algorithm on GPU Adversarial Parametric Pose Prior Mask Transfiner for High-Quality Instance Segmentation It Is Okay To Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning By Contrastive Data Collection DiRA: Discriminative, Restorative, and Adversarial Learning for Self-Supervised Medical Image Analysis Event-Based Video Reconstruction Via Potential-Assisted Spiking Neural Network YouMVOS: An Actor-Centric Multi-Shot Video Object Segmentation Dataset DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification Self-Supervised Video Transformer AutoRF: Learning 3D Object Radiance Fields From Single View Observations Coopernaut: End-to-End Driving With Cooperative Perception for Networked Vehicles TubeR: Tubelet Transformer for Video Action Detection MUM: Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection Learning Non-Target Knowledge for Few-Shot Semantic Segmentation UKPGAN: A General Self-Supervised Keypoint Detector Raw High-Definition Radar for Multi-Task Learning Coarse-To-Fine Feature Mining for Video Semantic Segmentation Compressing Models With Few Samples: Mimicking Then Replacing PokeBNN: A Binary Pursuit of Lightweight Accuracy Zoom in and Out: A Mixed-Scale Triplet Network for Camouflaged Object Detection SOMSI: Spherical Novel View Synthesis With Soft Occlusion Multi-Sphere Images EMScore: Evaluating Video Captioning Via Coarse-Grained and Fine-Grained Embedding Matching PoseTriplet: Co-Evolving 3D Human Pose Estimation, Imitation, and Hallucination Under Self-Supervision Group Contextualization for Video Recognition Single-Domain Generalized Object Detection in Urban Scene Via Cyclic-Disentangled Self-Distillation L2G: A Simple Local-to-Global Knowledge Transfer Framework for Weakly Supervised Semantic Segmentation Self-Augmented Unpaired Image Dehazing Via Density and Depth Decomposition Neural 3D Video Synthesis From Multi-View Video SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening Structure-Aware Flow Generation for Human Body Reshaping Learning To Answer Questions in Dynamic Audio-Visual Scenarios Synthetic Aperture Imaging With Events and Frames MonoGround: Detecting Monocular 3D Objects From The Ground Deep Visual Geo-Localization Benchmark StyleGAN-V: A Continuous Video Generator With The Price, Image Quality and Perks of StyleGAN2 LISA: Learning Implicit Shape and Appearance of Hands Iterative Deep Homography Estimation Learned Queries for Efficient Local Attention Colar: Effective and Efficient Online Action Detection By Consulting Exemplars SoftGroup for 3D Instance Segmentation on Point Clouds MVS2D: Efficient Multi-View Stereo Via Attention-Driven 2D Convolutions Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance Segmentation Via Semantic Knowledge Transfer and Self-Refinement Deep Constrained Least Squares for Blind Image Super-Resolution EDTER: Edge Detection With Transformer AirObject: A Temporally Evolving Graph Embedding for Object Identification From Representation to Reasoning: Towards Both Evidence and Commonsense Reasoning for Video Question-Answering Semantic-Aware Domain Generalized Segmentation DanceTrack: Multi-Object Tracking in Uniform Appearance and Diverse Motion UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection AKB-48: A Real-World Articulated Object Knowledge Base Stratified Transformer for 3D Point Cloud Segmentation Aug-NeRF: Training Stronger Neural Radiance Fields With Triple-Level Physically-Grounded Augmentations Semantic-Shape Adaptive Feature Modulation for Semantic Image Synthesis Day-to-Night Image Synthesis for Training Nighttime Neural ISPs Literature ~Highlight: To address this problem, we propose a method that synthesizes nighttime images from daytime images. References # https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/ Author
Dr Hari Thapliyaal
dasarpai.com linkedin.com/in/harithapliyal">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="dsblog">
    <meta property="article:published_time" content="2023-08-22T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-08-22T00:00:00+00:00">
    <meta property="article:tag" content="Research Implementation">
    <meta property="article:tag" content="ML Libraries">
    <meta property="article:tag" content="Code Resources">
    <meta property="article:tag" content="AI Development">
    <meta property="article:tag" content="Machine Learning">
    <meta property="article:tag" content="Deep Learning">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Paper with Code Resources">
  <meta name="twitter:description" content="Paper with Code Resources # Trending Papers of 2021 # ADOP: Approximate Differentiable One-Pixel Point Rendering — Rückert et al — https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel The Bayesian Learning Rule —Khan et al https://paperswithcode.com/paper/the-bayesian-learning-rule Program Synthesis with Large Language Models — Austin et al https://paperswithcode.com/paper/program-synthesis-with-large-language-models Masked Autoencoders Are Scalable Vision Learners — He et al https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision 8-bit Optimizers via Block-wise Quantization — Dettmers et al https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization Revisiting ResNets: Improved Training and Scaling Strategies — Bello et al https://paperswithcode.com/paper/revisiting-resnets-improved-training-and Image Super-Resolution via Iterative Refinement — Saharia et al https://paperswithcode.com/paper/image-super-resolution-via-iterative Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs — Jaegle et al https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for Do Vision Transformers See Like Convolutional Neural Networks? — Raghu et al https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions — Niepert et al https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete Trending Libaries of 2021 # PyTorch Image Models — Ross Wightman — https://github.com/rwightman/pytorch-image-models Transformers — Hugging Face — https://github.com/huggingface/transformers PyTorch-GAN — Erik Linder-Norén — https://github.com/eriklindernoren/PyTorch-GAN MMDetection — OpenMMLab — https://github.com/open-mmlab/mmdetection Darknet — AlexeyAB — https://github.com/AlexeyAB/darknet Vision Transformer PyTorch — lucidrains — https://github.com/lucidrains/vit-pytorch InsightFace — DeepInsight — https://github.com/deepinsight/insightface Detectron2 — Meta AI — https://github.com/facebookresearch/detectron2 PaddleOCR — PaddlePaddle — https://github.com/PaddlePaddle/PaddleOCR FairSeq — Meta AI — https://github.com/pytorch/fairseq Top Dataset - 2021 # MATH — Hendrycks et al https://paperswithcode.com/dataset/math UAV-Human — Li et al https://paperswithcode.com/dataset/uav-human UPFD (User Preference-aware Fake News Detection) — Dou et al https://paperswithcode.com/dataset/upfd OGB-LSC (OGB Large-Scale Challenge) — Hu et al https://paperswithcode.com/dataset/ogb-lsc CodeXGLUE —Lu et al https://paperswithcode.com/dataset/codexglue AGORA — Patel et al https://paperswithcode.com/dataset/agora BEIR (Benchmarking IR) — Thakur et al https://paperswithcode.com/dataset/beir WikiGraphs — Wang et al https://paperswithcode.com/dataset/wikigraphs Few-NERD — Ding et al https://paperswithcode.com/dataset/few-nerd PASS (Pictures without humAns for Self-Supervision) —Asano et al https://paperswithcode.com/dataset/pass Papers of 2022 # Controllable Animation of Fluid Elements in Still Images F-SfT: Shape-From-Template With A Physics-Based Deformation Model TWIST: Two-Way Inter-Label Self-Training for Semi-Supervised 3D Instance Segmentation Do Learned Representations Respect Causal Relationships? ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic 3D Moments From Near-Duplicate Photos Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization Blind2Unblind: Self-Supervised Image Denoising With Visible Blind Spots Balanced and Hierarchical Relation Learning for One-Shot Object Detection NICE-SLAM: Neural Implicit Scalable Encoding for SLAM Stochastic Trajectory Prediction Via Motion Indeterminacy Diffusion CLRNet: Cross Layer Refinement Network for Lane Detection Motion-Aware Contrastive Video Representation Learning Via Foreground-Background Merging DINE: Domain Adaptation From Single and Multiple Black-Box Predictors FaceFormer: Speech-Driven 3D Facial Animation With Transformers Rotationally Equivariant 3D Object Detection Accelerating DETR Convergence Via Semantic-Aligned Matching Cloning Outfits From Real-World Images to 3D Characters for Generalizable Person Re-Identification GeoNeRF: Generalizing NeRF With Geometry Priors ABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo Expanding Low-Density Latent Regions for Open-Set Object Detection Uformer: A General U-Shaped Transformer for Image Restoration Exploring Dual-Task Correlation for Pose Guided Person Image Generation Portrait Eyeglasses and Shadow Removal By Leveraging 3D Synthetic Data Modeling 3D Layout for Group Re-Identification Toward Fast, Flexible, and Robust Low-Light Image Enhancement Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network Modular Action Concept Grounding in Semantic Video Prediction StyleSwin: Transformer-Based GAN for High-Resolution Image Generation Discrete Cosine Transform Network for Guided Depth Map Super-Resolution Cerberus Transformer: Joint Semantic, Affordance and Attribute Parsing TransGeo: Transformer Is All You Need for Cross-View Image Geo-Localization Contrastive Boundary Learning for Point Cloud Segmentation Details or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution CVNet: Contour Vibration Network for Building Extraction Swin Transformer V2: Scaling Up Capacity and Resolution Projective Manifold Gradient Layer for Deep Rotation Regression HCSC: Hierarchical Contrastive Selective Coding TransRank: Self-Supervised Video Representation Learning Via Ranking-Based Transformation Recognition DiSparse: Disentangled Sparsification for Multitask Model Compression Pushing The Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make A Difference Towards Efficient and Scalable Sharpness-Aware Minimization OSSO: Obtaining Skeletal Shape From Outside A Study on The Distribution of Social Biases in Self-Supervised Learning Visual Models Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes Comparing Correspondences: Video Prediction With Correspondence-Wise Losses Towards Fewer Annotations: Active Learning Via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding Few Shot Generative Model Adaption Via Relaxed Spatial Structural Alignment Enhancing Adversarial Training With Second-Order Statistics of Weights Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo Moving Window Regression: A Novel Approach to Ordinal Regression Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection Robust Optimization As Data Augmentation for Large-Scale Graphs Robust Structured Declarative Classifiers for 3D Point Clouds: Defending Adversarial Attacks With Implicit Gradients Improving The Transferability of Targeted Adversarial Examples Through Object-Based Diverse Input ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer 360MonoDepth: High-Resolution 360deg Monocular Depth Estimation POCO: Point Convolution for Surface Reconstruction Neural Texture Extraction and Distribution for Controllable Person Image Synthesis Classification-Then-Grounding: Reformulating Video Scene Graphs As Temporal Bipartite Graphs DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis ZeroWaste Dataset: Towards Deformable Object Segmentation in Cluttered Scenes UNIST: Unpaired Neural Implicit Shape Translation Network APES: Articulated Part Extraction From Sprite Sheets SPAct: Self-Supervised Privacy Preservation for Action Recognition De-Rendering 3D Objects in The Wild Global Sensing and Measurements Reuse for Image Compressed Sensing Practical Evaluation of Adversarial Robustness Via Adaptive Auto Attack Cross-View Transformers for Real-Time Map-View Semantic Segmentation Controllable Dynamic Multi-Task Architectures FastDOG: Fast Discrete Optimization on GPU Focal and Global Knowledge Distillation for Detectors Learning To Prompt for Continual Learning Human Mesh Recovery From Multiple Shots Convolution of Convolution: Let Kernels Spatially Collaborate Make It Move: Controllable Image-to-Video Generation With Text Descriptions Neural Points: Point Cloud Representation With Neural Fields for Arbitrary Upsampling Video-Text Representation Learning Via Differentiable Weak Temporal Alignment Bi-Directional Object-Context Prioritization Learning for Saliency Ranking Vehicle Trajectory Prediction Works, But Not Everywhere MonoDTR: Monocular 3D Object Detection With Depth-Aware Transformer Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-Shot Learning Generalized Category Discovery Contour-Hugging Heatmaps for Landmark Detection Voxel Field Fusion for 3D Object Detection DisARM: Displacement Aware Relation Module for 3D Detection MixFormer: Mixing Features Across Windows and Dimensions FineDiving: A Fine-Grained Dataset for Procedure-Aware Action Quality Assessment HEAT: Holistic Edge Attention Transformer for Structured Reconstruction Mobile-Former: Bridging MobileNet and Transformer CycleMix: A Holistic Strategy for Medical Image Segmentation From Scribble Supervision VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution Towards End-to-End Unified Scene Text Detection and Layout Analysis AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior End-to-End Referring Video Object Segmentation With Multimodal Transformers IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo Not All Points Are Equal: Learning Highly Efficient Point-Based Detectors for 3D LiDAR Point Clouds Detecting Camouflaged Object in Frequency Domain SelfRecon: Self Reconstruction Your Digital Avatar From Monocular Video Equivariant Point Cloud Analysis Via Learning Orientations for Message Passing Node Representation Learning in Graph Via Node-to-Neighbourhood Mutual Information Maximization Semi-Supervised Video Semantic Segmentation With Inter-Frame Feature Reconstruction Amodal Segmentation Through Out-of-Task and Out-of-Distribution Generalization With A Bayesian Model How Well Do Sparse ImageNet Models Transfer? REX: Reasoning-Aware and Grounded Explanation Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes Object-Aware Video-Language Pre-Training for Retrieval MAT: Mask-Aware Transformer for Large Hole Image Inpainting Align and Prompt: Video-and-Language Pre-Training With Entity Prompts MSG-Transformer: Exchanging Local Spatial Information By Manipulating Messenger Tokens Cross Modal Retrieval With Querybank Normalisation Ray3D: Ray-Based 3D Human Pose Estimation for Monocular Absolute 3D Localization ASM-Loc: Action-Aware Segment Modeling for Weakly-Supervised Temporal Action Localization Scaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs End-to-End Multi-Person Pose Estimation With Transformers REGTR: End-to-End Point Cloud Correspondences With Transformers Neural 3D Scene Reconstruction With The Manhattan-World Assumption V2C: Visual Voice Cloning Revisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection MAD: A Scalable Dataset for Language Grounding in Videos From Movie Audio Descriptions Gait Recognition in The Wild With Dense 3D Representations and A Benchmark ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation Via Online Exploration and Synthesis QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection IDEA-Net: Dynamic 3D Point Cloud Interpolation Via Deep Embedding Alignment BEHAVE: Dataset and Method for Tracking Human Object Interactions Revisiting Random Channel Pruning for Neural Network Compression Generating Diverse and Natural 3D Human Motions From Text E-CIR: Event-Enhanced Continuous Intensity Recovery Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond Symmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose Estimation AziNorm: Exploiting The Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception Weakly Supervised Rotation-Invariant Aerial Object Detection Network Surface Reconstruction From Point Clouds By Learning Predictive Context Priors IRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation Weakly Supervised Temporal Action Localization Via Representative Snippet Knowledge Propagation E2EC: An End-to-End Contour-Based Method for High-Quality High-Speed Instance Segmentation BatchFormer: Learning To Explore Sample Relationships for Robust Representation Learning Self-Supervised Image-Specific Prototype Exploration for Weakly Supervised Semantic Segmentation Learning Multi-View Aggregation in The Wild for Large-Scale 3D Semantic Segmentation PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition Clothes-Changing Person Re-Identification With RGB Modality Only Robust Image Forgery Detection Over Online Social Network Shared Images Representation Compensation Networks for Continual Semantic Segmentation Tracking People By Predicting 3D Appearance, Location and Pose Text2Mesh: Text-Driven Neural Stylization for Meshes C-CAM: Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image Forward Compatible Few-Shot Class-Incremental Learning Weakly Supervised Object Localization As Domain Adaption Tencent-MVSE: A Large-Scale Benchmark Dataset for Multi-Modal Video Similarity Evaluation Deep Orientation-Aware Functional Maps: Tackling Symmetry Issues in Shape Matching Tree Energy Loss: Towards Sparsely Annotated Semantic Segmentation MatteFormer: Transformer-Based Image Matting Via Prior-Tokens Video Shadow Detection Via Spatio-Temporal Interpolation Consistency Training Robust and Accurate Superquadric Recovery: A Probabilistic Approach Grounding Answers for Visual Questions Asked By Visually Impaired People Sparse Instance Activation for Real-Time Instance Segmentation VisualGPT: Data-Efficient Adaptation of Pretrained Language Models for Image Captioning MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis Towards Implicit Text-Guided 3D Shape Generation SoftCollage: A Differentiable Probabilistic Tree Generator for Image Collage Query and Attention Augmentation for Knowledge-Based Explainable Reasoning Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality Progressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection Fine-Grained Object Classification Via Self-Supervised Pose Alignment Animal Kingdom: A Large and Diverse Dataset for Animal Behavior Understanding Fine-Grained Temporal Contrastive Learning for Weakly-Supervised Temporal Action Localization Relieving Long-Tailed Instance Segmentation Via Pairwise Class Balance Online Convolutional Re-Parameterization Mimicking The Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition Personalized Image Aesthetics Assessment With Rich Attributes Part-Based Pseudo Label Refinement for Unsupervised Person Re-Identification HDNet: High-Resolution Dual-Domain Learning for Spectral Compressive Imaging OW-DETR: Open-World Detection Transformer Learning Deep Implicit Functions for 3D Shapes With Dynamic Code Clouds Reversible Vision Transformers Amodal Panoptic Segmentation Correlation Verification for Image Retrieval Temporal Feature Alignment and Mutual Information Maximization for Video-Based Human Pose Estimation Self-Supervised Transformers for Unsupervised Object Discovery Using Normalized Cut Exploring Structure-Aware Transformer Over Interaction Proposals for Human-Object Interaction Detection Decoupled Multi-Task Learning With Cyclical Self-Regulation for Face Parsing Glass: Geometric Latent Augmentation for Shape Spaces DPICT: Deep Progressive Image Compression Using Trit-Planes Text to Image Generation With Semantic-Spatial Aware GAN Generalizable Cross-Modality Medical Image Segmentation Via Style Augmentation and Dual Normalization Learning To Prompt for Open-Vocabulary Object Detection With Vision-Language Model Interactive Segmentation and Visualization for Tiny Objects in Multi-Megapixel Images Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture Surface Representation for Point Clouds Implicit Motion Handling for Video Camouflaged Object Detection DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides Learning With Twin Noisy Labels for Visible-Infrared Person Re-Identification Optical Flow Estimation for Spiking Camera GradViT: Gradient Inversion of Vision Transformers Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution Via Cycle-Projected Mutual Learning Joint Global and Local Hierarchical Priors for Learned Image Compression Knowledge Distillation Via The Target-Aware Transformer Subspace Adversarial Training 3D-VField: Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection Image Segmentation Using Text and Image Prompts AutoMine: An Unmanned Mine Dataset Background Activation Suppression for Weakly Supervised Object Localization Synthetic Generation of Face Videos With Plethysmograph Physiology Hallucinated Neural Radiance Fields in The Wild Global Tracking Transformers Backdoor Attacks on Self-Supervised Learning GMFlow: Learning Optical Flow Via Global Matching Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation Explore Spatio-Temporal Aggregation for Insubstantial Object Detection: Benchmark Dataset and Baseline Graph-Based Spatial Transformer With Memory Replay for Multi-Future Pedestrian Trajectory Prediction Scanline Homographies for Rolling-Shutter Plane Absolute Pose AdaInt: Learning Adaptive Intervals for 3D Lookup Tables on Real-Time Image Enhancement Recurrent Glimpse-Based Decoder for Detection With Transformer SimMIM: A Simple Framework for Masked Image Modeling Label Matching Semi-Supervised Object Detection RegionCLIP: Region-Based Language-Image Pretraining Video Frame Interpolation Transformer BCOT: A Markerless High-Precision 3D Object Tracking Benchmark Omni-DETR: Omni-Supervised Object Detection With Transformers Transferable Sparse Adversarial Attack CREAM: Weakly Supervised Object Localization Via Class RE-Activation Mapping VALHALLA: Visual Hallucination for Machine Translation HINT: Hierarchical Neuron Concept Explainer Neural Face Identification in A 2D Wireframe Projection of A Manifold Object Nonuniform-to-Uniform Quantization: Towards Accurate Quantization Via Generalized Straight-Through Estimation An Empirical Study of End-to-End Temporal Action Detection Object Localization Under Single Coarse Point Supervision Unsupervised Learning of Accurate Siamese Tracking Non-Parametric Depth Distribution Modelling Based Depth Inference for Multi-View Stereo Equalized Focal Loss for Dense Long-Tailed Object Detection DeepDPM: Deep Clustering With An Unknown Number of Clusters ISDNet: Integrating Shallow and Deep Networks for Efficient Ultra-High Resolution Segmentation Unsupervised Domain Adaptation for Nighttime Aerial Tracking RestoreFormer: High-Quality Blind Face Restoration From Undegraded Key-Value Pairs Mask-Guided Spectral-Wise Transformer for Efficient Hyperspectral Image Reconstruction A Variational Bayesian Method for Similarity Learning in Non-Rigid Image Registration Not Just Selection, But Exploration: Online Class-Incremental Continual Learning Via Dual View Consistency Coupling Vision and Proprioception for Navigation of Legged Robots Exploiting Rigidity Constraints for LiDAR Scene Flow Estimation EMOCA: Emotion Driven Monocular Face Capture and Animation Quarantine: Sparsity Can Uncover The Trojan Attack Trigger for Free AlignQ: Alignment Quantization With ADMM-Based Correlation Preservation Interactive Multi-Class Tiny-Object Detection Learning From Pixel-Level Noisy Label: A New Perspective for Light Field Saliency Detection Multi-View Depth Estimation By Fusing Single-View Depth Probability With Multi-View Geometry Slimmable Domain Adaptation High-Resolution Image Harmonization Via Collaborative Dual Transformations MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation Self-Supervised Neural Articulated Shape and Appearance Models Topology Preserving Local Road Network Estimation From Single Onboard Camera Image Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes SwinTextSpotter: Scene Text Spotting Via Better Synergy Between Text Detection and Text Recognition Deblur-NeRF: Neural Radiance Fields From Blurry Images Whose Track Is It Anyway? Improving Robustness to Tracking Errors With Affinity-Based Trajectory Prediction Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning Blind Image Super-Resolution With Elaborate Degradation Modeling on Noise and Kernel Faithful Extreme Rescaling Via Generative Prior Reciprocated Invertible Representations Proto2Proto: Can You Recognize The Car, The Way I Do? TVConv: Efficient Translation Variant Convolution for Layout-Aware Visual Processing Dual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution Habitat-Web: Learning Embodied Object-Search Strategies From Human Demonstrations at Scale Simple But Effective: CLIP Embeddings for Embodied AI NomMer: Nominate Synergistic Context in Vision Transformer for Visual Recognition Collaborative Transformers for Grounded Situation Recognition CPPF: Towards Robust Category-Level 9D Pose Estimation in The Wild Continual Test-Time Domain Adaptation Dynamic MLP for Fine-Grained Image Classification By Leveraging Geographical and Temporal Information MuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-Based Visual Question Answering Fair Contrastive Learning for Facial Attribute Classification Directional Self-Supervised Learning for Heavy Image Augmentations No-Reference Point Cloud Quality Assessment Via Domain Adaptation Comprehending and Ordering Semantics for Image Captioning A Large-Scale Comprehensive Dataset and Copy-Overlap Aware Evaluation Protocol for Segment-Level Video Copy Detection Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification HeadNeRF: A Real-Time NeRF-Based Parametric Head Model Occlusion-Robust Face Alignment Using A Viewpoint-Invariant Hierarchical Network Architecture IDR: Self-Supervised Image Denoising Via Iterative Data Refinement MogFace: Towards A Deeper Appreciation on Face Detection Learning Affinity From Attention: End-to-End Weakly-Supervised Semantic Segmentation With Transformers CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos Learning To Detect Mobile Objects From LiDAR Scans Without Labels WildNet: Learning Domain Generalized Semantic Segmentation From The Wild DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation Generating Diverse 3D Reconstructions From A Single Occluded Face Image Stand-Alone Inter-Frame Attention in Video Models Large-Scale Pre-Training for Person Re-Identification With Noisy Labels Semantic Segmentation By Early Region Proxy LD-ConGR: A Large RGB-D Video Dataset for Long-Distance Continuous Gesture Recognition HVH: Learning A Hybrid Neural Volumetric Representation for Dynamic Hair Performance Capture Rethinking Visual Geo-Localization for Large-Scale Applications The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy ViM: Out-of-Distribution With Virtual-Logit Matching Class-Aware Contrastive Semi-Supervised Learning Ditto: Building Digital Twins of Articulated Objects From Interaction Adaptive Early-Learning Correction for Segmentation From Noisy Annotations Cross-Domain Correlation Distillation for Unsupervised Domain Adaptation in Nighttime Semantic Segmentation RSTT: Real-Time Spatial Temporal Transformer for Space-Time Video Super-Resolution Partial Class Activation Attention for Semantic Segmentation Multi-Scale Memory-Based Video Deblurring A Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching Geometric Structure Preserving Warp for Natural Image Stitching GOAL: Generating 4D Whole-Body Motion for Hand-Object Grasping Conditional Prompt Learning for Vision-Language Models Graph Sampling Based Deep Metric Learning for Generalizable Person Re-Identification Undoing The Damage of Label Shift for Cross-Domain Semantic Segmentation FisherMatch: Semi-Supervised Rotation Regression Via Entropy-Based Filtering Affine Medical Image Registration With Coarse-To-Fine Vision Transformer A Differentiable Two-Stage Alignment Scheme for Burst Image Reconstruction With Large Shift Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes Restormer: Efficient Transformer for High-Resolution Image Restoration IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation Large Loss Matters in Weakly Supervised Multi-Label Classification Neural Inertial Localization GraftNet: Towards Domain Generalized Stereo Matching With A Broad-Spectrum and Task-Oriented Feature VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning Catching Both Gray and Black Swans: Open-Set Supervised Anomaly Detection MLSLT: Towards Multilingual Sign Language Translation Towards An End-to-End Framework for Flow-Guided Video Inpainting Contrastive Test-Time Adaptation MotionAug: Augmentation With Physical Correction for Human Motion Prediction Modeling Indirect Illumination for Inverse Rendering TransWeather: Transformer-Based Restoration of Images Degraded By Adverse Weather Conditions H2FA R-CNN: Holistic and Hierarchical Feature Alignment for Cross-Domain Weakly Supervised Object Detection P3Depth: Monocular Depth Estimation With A Piecewise Planarity Prior GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection Simple Multi-Dataset Detection Proactive Image Manipulation Detection StyTr2: Image Style Transfer With Transformers Global Matching With Overlapping Attention for Optical Flow Estimation Language As Queries for Referring Video Object Segmentation MViTv2: Improved Multiscale Vision Transformers for Classification and Detection Audio-Visual Generalised Zero-Shot Learning With Cross-Modal Attention and Language Rethinking Efficient Lane Detection Via Curve Modeling Self-Supervised Arbitrary-Scale Point Clouds Upsampling Via Implicit Neural Representation Co-Advise: Cross Inductive Bias Distillation AdaMixer: A Fast-Converging Query-Based Object Detector DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification BEVT: BERT Pretraining of Video Transformers Deep Generalized Unfolding Networks for Image Restoration VISOLO: Grid-Based Space-Time Aggregation for Efficient Online Video Instance Segmentation Deep Unlearning Via Randomized Conditionally Independent Hessians Revisiting Skeleton-Based Action Recognition Stereo Depth From Events Cameras: Concentrate and Focus on The Future A Simple Data Mixing Prior for Improving Self-Supervised Learning Knowledge Distillation As Efficient Pre-Training: Faster Convergence, Higher Data-Efficiency, and Better Transferability BigDL 2.0: Seamless Scaling of AI Pipelines From Laptops to Distributed Cluster Attentive Fine-Grained Structured Sparsity for Image Restoration Learning Fair Classifiers With Partially Annotated Group Labels NightLab: A Dual-Level Architecture With Hardness Detection for Segmentation at Night Constrained Few-Shot Class-Incremental Learning Threshold Matters in WSSS: Manipulating The Activation for The Robust and Accurate Segmentation Model Against Thresholds TransMVSNet: Global Context-Aware Multi-View Stereo Network With Transformers DPGEN: Differentially Private Generative Energy-Guided Network for Natural Image Synthesis The Majority Can Help The Minority: Context-Rich Minority Oversampling for Long-Tailed Classification IntentVizor: Towards Generic Query Guided Interactive Video Summarization Shape-Invariant 3D Adversarial Point Clouds Bootstrapping ViTs: Towards Liberating Vision Transformers From Pre-Training PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents Meta-Attention for ViT-Backed Continual Learning DST: Dynamic Substitute Training for Data-Free Black-Box Attack Unified Contrastive Learning in Image-Text-Label Space Unsupervised Pre-Training for Temporal Action Localization Tasks Look Outside The Room: Synthesizing A Consistent Long-Term 3D Scene Video From A Single Image High-Fidelity Human Avatars From A Single RGB Camera Multiview Transformers for Video Recognition How Good Is Aesthetic Ability of A Fashion Model? Deformation and Correspondence Aware Unsupervised Synthetic-to-Real Scene Flow Estimation for Point Clouds Sequential Voting With Relational Box Fields for Active Object Detection Semantic-Aware Auto-Encoders for Self-Supervised Representation Learning Consistency Learning Via Decoding Path Augmentation for Transformers in Human Object Interaction Detection Consistent Explanations By Contrastive Learning Hierarchical Modular Network for Video Captioning Depth Estimation By Combining Binocular Stereo and Monocular Structured-Light Salient-to-Broad Transition for Video Person Re-Identification DeeCap: Dynamic Early Exiting for Efficient Image Captioning RepMLPNet: Hierarchical Vision MLP With Re-Parameterized Locality DR.VIC: Decomposition and Reasoning for Video Individual Counting ARCS: Accurate Rotation and Correspondence Search Learning To Anticipate Future With Dynamic Context Removal GCFSR: A Generative and Controllable Face Super Resolution Method Without Facial and GAN Priors On The Integration of Self-Attention and Convolution Domain Adaptation on Point Clouds Via Geometry-Aware Implicits GroupViT: Semantic Segmentation Emerges From Text Supervision DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation BppAttack: Stealthy and Efficient Trojan Attacks Against Deep Neural Networks Via Image Quantization and Contrastive Adversarial Learning Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation Towards Better Plasticity-Stability Trade-Off in Incremental Learning: A Simple Linear Connector Topology-Preserving Shape Reconstruction and Registration Via Neural Diffeomorphic Flow Segment and Complete: Defending Object Detectors Against Adversarial Patch Attacks With Robust Patch Detection MAXIM: Multi-Axis MLP for Image Processing Learning Part Segmentation Through Unsupervised Domain Adaptation From Synthetic Vehicles PSTR: End-to-End One-Step Person Search With Transformers NFormer: Robust Person Re-Identification With Neighbor Transformer Bridging Global Context Interactions for High-Fidelity Image Completion SwinBERT: End-to-End Transformers With Sparse Attention for Video Captioning Not All Tokens Are Equal: Human-Centric Visual Analysis Via Token Clustering Transformer Temporally Efficient Vision Transformer for Video Instance Segmentation The Devil Is in The Margin: Margin-Based Label Smoothing for Network Calibration NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding E2(GO)MOTION: Motion Augmented Event Stream for Egocentric Action Recognition OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization OnePose: One-Shot Object Pose Estimation Without CAD Models Rethinking Minimal Sufficient Representation in Contrastive Learning Scalable Penalized Regression for Noise Detection in Learning With Noisy Labels Federated Class-Incremental Learning Show, Deconfound and Tell: Image Captioning With Causal Inference MobRecon: Mobile-Friendly Hand Mesh Reconstruction From Monocular Image Parameter-Free Online Test-Time Adaptation SIGMA: Semantic-Complete Graph Matching for Domain Adaptive Object Detection No Pain, Big Gain: Classify Dynamic Point Cloud Sequences With Static Models By Fitting Feature-Level Space-Time Surfaces HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for Snapshot Compressive Imaging Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space Learning To Estimate Robust 3D Human Mesh From In-the-Wild Crowded Scenes Detecting Deepfakes With Self-Blended Images Implicit Sample Extension for Unsupervised Person Re-Identification Energy-Based Latent Aligner for Incremental Learning Towards Semi-Supervised Deep Facial Expression Recognition With An Adaptive Confidence Margin Group R-CNN for Weakly Semi-Supervised Object Detection With Points Weakly-Supervised Action Transition Learning for Stochastic Human Motion Prediction Hybrid Relation Guided Set Matching for Few-Shot Action Recognition Cross-Patch Dense Contrastive Learning for Semi-Supervised Segmentation of Cellular Nuclei in Histopathologic Images Generalized Binary Search Network for Highly-Efficient Multi-View Stereo SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation FlexIT: Towards Flexible Semantic Image Translation CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow BoxeR: Box-Attention for 2D and 3D Transformers Neural Architecture Search With Representation Mutual Information Can Neural Nets Learn The Same Model Twice? Investigating Reproducibility and Double Descent From The Decision Boundary Perspective Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction Multi-View Transformer for 3D Visual Grounding Structured Sparse R-CNN for Direct Scene Graph Generation BARC: Learning To Regress 3D Dog Shape From Images By Exploiting Breed Information PCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models Towards Understanding Adversarial Robustness of Optical Flow Networks Lifelong Graph Learning Hypergraph-Induced Semantic Tuplet Loss for Deep Metric Learning Computing Wasserstein-p Distance Between Images With Linear Cost Unsupervised Representation Learning for Binary Networks By Joint Classifier Learning Large-Scale Video Panoptic Segmentation in The Wild: A Benchmark GrainSpace: A Large-Scale Dataset for Fine-Grained and Domain-Adaptive Recognition of Cereal Grains Learning Modal-Invariant and Temporal-Memory for Video-Based Visible-Infrared Person Re-Identification MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning Oriented RepPoints for Aerial Object Detection Weakly Supervised Temporal Sentence Grounding With Gaussian-Based Contrastive Proposal Learning Low-Resource Adaptation for Personalized Co-Speech Gesture Generation Task-Specific Inconsistency Alignment for Domain Adaptive Object Detection MS2DG-Net: Progressive Correspondence Learning Via Multiple Sparse Semantics Dynamic Graph Learning To Listen: Modeling Non-Deterministic Dyadic Facial Motion Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation From Monocular Video MixFormer: End-to-End Tracking With Iterative Mixed Attention Plenoxels: Radiance Fields Without Neural Networks Selective-Supervised Contrastive Learning With Noisy Labels SimT: Handling Open-Set Noise for Domain Adaptive Semantic Segmentation Frequency-Driven Imperceptible Adversarial Attack on Semantic Similarity Video Demoireing With Relation-Based Temporal Consistency Industrial Style Transfer With Large-Scale Geometric Warping and Content Preservation Modeling Image Composition for Complex Scene Generation Decoupling Zero-Shot Semantic Segmentation Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting The Adversarial Transferability IFOR: Iterative Flow Minimization for Robotic Object Rearrangement Zero Experience Required: Plug &amp; Play Modular Transfer Learning for Semantic Visual Navigation TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation The Wanderings of Odysseus in 3D Scenes All-in-One Image Restoration for Unknown Corruption PUMP: Pyramidal and Uniqueness Matching Priors for Unsupervised Learning of Local Descriptors MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video RCP: Recurrent Closest Point for Point Cloud A Dual Weighting Label Assignment Scheme for Object Detection Hyperbolic Vision Transformers: Combining Improvements in Metric Learning Instance-Aware Dynamic Neural Network Quantization Exploring Effective Data for Surrogate Training Towards Black-Box Attack JRDB-Act: A Large-Scale Dataset for Spatio-Temporal Action, Social Group and Activity Detection Investigating Top-k White-Box and Transferable Black-Box Attack Decoupling and Recoupling Spatiotemporal Representation for RGB-D-Based Motion Recognition A Self-Supervised Descriptor for Image Copy Detection Negative-Aware Attention Framework for Image-Text Matching An Image Patch Is A Wave: Phase-Aware Vision MLP Shunted Self-Attention Via Multi-Scale Token Aggregation Unified Multivariate Gaussian Mixture for Efficient Neural Image Compression Recurrent Variational Network: A Deep Learning Inverse Problem Solver Applied to The Task of Accelerated MRI Reconstruction Surpassing The Human Accuracy: Detecting Gallbladder Cancer From USG Images With Curriculum Learning Appearance and Structure Aware Robust Deep Visual Graph Matching: Attack, Defense and Beyond TrackFormer: Multi-Object Tracking With Transformers 3D Shape Reconstruction From 2D Images With Disentangled Attribute Flow Feature Statistics Mixing Regularization for Generative Adversarial Networks OpenTAL: Towards Open Set Temporal Action Localization Self-Supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection Ego4D: Around The World in 3,000 Hours of Egocentric Video Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data DAD-3DHeads: A Large-Scale Dense, Accurate and Diverse Dataset for 3D Head Alignment From A Single Image Reconstructing Surfaces for Sparse Point Clouds With On-Surface Priors VCLIMB: A Novel Video Class Incremental Learning Benchmark Robust Equivariant Imaging: A Fully Unsupervised Framework for Learning To Image From Noisy and Partial Measurements ST&#43;&#43;: Make Self-Training Work Better for Semi-Supervised Semantic Segmentation Interacting Attention Graph for Single Image Two-Hand Reconstruction Rope3D: The Roadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task Cross-Image Relational Knowledge Distillation for Semantic Segmentation Towards Layer-Wise Image Vectorization Scenic: A JAX Library for Computer Vision Research and Beyond Real-Time Object Detection for Streaming Perception VisualHow: Multimodal Problem Solving Spatial Commonsense Graph for Object Localisation in Partial Scenes OSSGAN: Open-Set Semi-Supervised Image Generation Bi-Level Alignment for Cross-Domain Crowd Counting ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation Efficient Multi-View Stereo By Iterative Dynamic Cost Volume TransEditor: Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing Use All The Labels: A Hierarchical Multi-Label Contrastive Learning Framework SGTR: End-to-End Scene Graph Generation With Transformer Decoupled Knowledge Distillation DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection Reusing The Task-Specific Classifier As A Discriminator: Discriminator-Free Adversarial Domain Adaptation Show Me What and Tell Me How: Video Synthesis Via Multimodal Conditioning SIMBAR: Single Image-Based Scene Relighting for Effective Data Augmentation for Automated Driving Vision Tasks Multi-Label Classification With Partial Annotations Using Class-Aware Selective Loss CADTransformer: Panoptic Symbol Spotting Transformer for CAD Drawings IntraQ: Learning Synthetic Images With Intra-Class Heterogeneity for Zero-Shot Network Quantization I M Avatar: Implicit Morphable Head Avatars From Videos Weakly-Supervised Metric Learning With Cross-Module Communications for The Classification of Anterior Chamber Angle Images A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-Resolution Multi-Modal Dynamic Graph Transformer for Visual Grounding Geometric Transformer for Fast and Robust Point Cloud Registration UMT: Unified Multi-Modal Transformers for Joint Video Moment Retrieval and Highlight Detection Demystifying The Neural Tangent Kernel From A Practical Perspective: Can It Be Trusted for Neural Architecture Search Without Training? The Devil Is in The Details: Window-Based Attention for Image Compression DiLiGenT102: A Photometric Stereo Benchmark Dataset With Controlled Shape and Material Variation PolyWorld: Polygonal Building Extraction With Graph Neural Networks in Satellite Images Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation Spatio-Temporal Relation Modeling for Few-Shot Action Recognition Multi-Person Extreme Motion Prediction B-DARTS: Beta-Decay Regularization for Differentiable Architecture Search CMT: Convolutional Neural Networks Meet Vision Transformers KNN Local Attention for Image Restoration Predict, Prevent, and Evaluate: Disentangled Text-Driven Image Manipulation Empowered By Pre-Trained Vision-Language Model TransMix: Attend To Mix for Vision Transformers Inertia-Guided Flow Completion and Style Fusion for Video Inpainting Long-Tailed Visual Recognition Via Gaussian Clouded Logit Adjustment Image Animation With Perturbed Masks Domain Generalization Via Shuffled Style Assembly for Face Anti-Spoofing OcclusionFusion: Occlusion-Aware Motion Estimation for Real-Time Dynamic 3D Reconstruction MonoScene: Monocular 3D Semantic Scene Completion AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition Continuous Scene Representations for Embodied AI Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds Non-Probability Sampling Network for Stochastic Human Trajectory Prediction ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning Human-Aware Object Placement for Visual Environment Reconstruction X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval RAMA: A Rapid Multicut Algorithm on GPU Adversarial Parametric Pose Prior Mask Transfiner for High-Quality Instance Segmentation It Is Okay To Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning By Contrastive Data Collection DiRA: Discriminative, Restorative, and Adversarial Learning for Self-Supervised Medical Image Analysis Event-Based Video Reconstruction Via Potential-Assisted Spiking Neural Network YouMVOS: An Actor-Centric Multi-Shot Video Object Segmentation Dataset DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification Self-Supervised Video Transformer AutoRF: Learning 3D Object Radiance Fields From Single View Observations Coopernaut: End-to-End Driving With Cooperative Perception for Networked Vehicles TubeR: Tubelet Transformer for Video Action Detection MUM: Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection Learning Non-Target Knowledge for Few-Shot Semantic Segmentation UKPGAN: A General Self-Supervised Keypoint Detector Raw High-Definition Radar for Multi-Task Learning Coarse-To-Fine Feature Mining for Video Semantic Segmentation Compressing Models With Few Samples: Mimicking Then Replacing PokeBNN: A Binary Pursuit of Lightweight Accuracy Zoom in and Out: A Mixed-Scale Triplet Network for Camouflaged Object Detection SOMSI: Spherical Novel View Synthesis With Soft Occlusion Multi-Sphere Images EMScore: Evaluating Video Captioning Via Coarse-Grained and Fine-Grained Embedding Matching PoseTriplet: Co-Evolving 3D Human Pose Estimation, Imitation, and Hallucination Under Self-Supervision Group Contextualization for Video Recognition Single-Domain Generalized Object Detection in Urban Scene Via Cyclic-Disentangled Self-Distillation L2G: A Simple Local-to-Global Knowledge Transfer Framework for Weakly Supervised Semantic Segmentation Self-Augmented Unpaired Image Dehazing Via Density and Depth Decomposition Neural 3D Video Synthesis From Multi-View Video SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening Structure-Aware Flow Generation for Human Body Reshaping Learning To Answer Questions in Dynamic Audio-Visual Scenarios Synthetic Aperture Imaging With Events and Frames MonoGround: Detecting Monocular 3D Objects From The Ground Deep Visual Geo-Localization Benchmark StyleGAN-V: A Continuous Video Generator With The Price, Image Quality and Perks of StyleGAN2 LISA: Learning Implicit Shape and Appearance of Hands Iterative Deep Homography Estimation Learned Queries for Efficient Local Attention Colar: Effective and Efficient Online Action Detection By Consulting Exemplars SoftGroup for 3D Instance Segmentation on Point Clouds MVS2D: Efficient Multi-View Stereo Via Attention-Driven 2D Convolutions Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance Segmentation Via Semantic Knowledge Transfer and Self-Refinement Deep Constrained Least Squares for Blind Image Super-Resolution EDTER: Edge Detection With Transformer AirObject: A Temporally Evolving Graph Embedding for Object Identification From Representation to Reasoning: Towards Both Evidence and Commonsense Reasoning for Video Question-Answering Semantic-Aware Domain Generalized Segmentation DanceTrack: Multi-Object Tracking in Uniform Appearance and Diverse Motion UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection AKB-48: A Real-World Articulated Object Knowledge Base Stratified Transformer for 3D Point Cloud Segmentation Aug-NeRF: Training Stronger Neural Radiance Fields With Triple-Level Physically-Grounded Augmentations Semantic-Shape Adaptive Feature Modulation for Semantic Image Synthesis Day-to-Night Image Synthesis for Training Nighttime Neural ISPs Literature ~Highlight: To address this problem, we propose a method that synthesizes nighttime images from daytime images. References # https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/ Author
Dr Hari Thapliyaal
dasarpai.com linkedin.com/in/harithapliyal">

  
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

<script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$']],     
        displayMath: [['$$', '$$']]   
      }
    };
</script>  
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>




  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Data Science Blog",
    "name": "Paper with Code Resources",
    "headline": "Paper with Code Resources",
    
    "abstract": "\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\u0022my-0 rounded-md\u0022 loading=\u0022lazy\u0022 src=\u0022\/assets\/images\/dspost\/dsp6091-rps-Paperwithcode-Resources.jpg\u0022 alt=\u0022Paper with Code Resources\u0022 \/\u003e\n      \n    \u003c\/figure\u003e\n\u003c\/p\u003e\n\n\n\u003ch1 class=\u0022relative group\u0022\u003ePaper with Code Resources \n    \u003cdiv id=\u0022paper-with-code-resources\u0022 class=\u0022anchor\u0022\u003e\u003c\/div\u003e\n    \n    \u003cspan\n        class=\u0022absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\u0022\u003e\n        \u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022\n            style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#paper-with-code-resources\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\n    \u003c\/span\u003e        \n    \n\u003c\/h1\u003e\n\n\n\u003ch2 class=\u0022relative group\u0022\u003eTrending Papers of 2021 \n    \u003cdiv id=\u0022trending-papers-of-2021\u0022 class=\u0022anchor\u0022\u003e\u003c\/div\u003e\n    \n    \u003cspan\n        class=\u0022absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\u0022\u003e\n        \u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022\n            style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#trending-papers-of-2021\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\n    \u003c\/span\u003e        \n    \n\u003c\/h2\u003e\n\u003col\u003e\n\u003cli\u003eADOP: Approximate Differentiable One-Pixel Point Rendering — Rückert et al — \u003ca href=\u0022https:\/\/paperswithcode.com\/paper\/adop-approximate-differentiable-one-pixel\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/paper\/adop-approximate-differentiable-one-pixel\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eThe Bayesian Learning Rule —Khan et al \u003ca href=\u0022https:\/\/paperswithcode.com\/paper\/the-bayesian-learning-rule\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/paper\/the-bayesian-learning-rule\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eProgram Synthesis with Large Language Models — Austin et al \u003ca href=\u0022https:\/\/paperswithcode.com\/paper\/program-synthesis-with-large-language-models\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/paper\/program-synthesis-with-large-language-models\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eMasked Autoencoders Are Scalable Vision Learners — He et al \u003ca href=\u0022https:\/\/paperswithcode.com\/paper\/masked-autoencoders-are-scalable-vision\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/paper\/masked-autoencoders-are-scalable-vision\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003e8-bit Optimizers via Block-wise Quantization — Dettmers et al \u003ca href=\u0022https:\/\/paperswithcode.com\/paper\/8-bit-optimizers-via-block-wise-quantization\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/paper\/8-bit-optimizers-via-block-wise-quantization\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eRevisiting ResNets: Improved Training and Scaling Strategies — Bello et al \u003ca href=\u0022https:\/\/paperswithcode.com\/paper\/revisiting-resnets-improved-training-and\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/paper\/revisiting-resnets-improved-training-and\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eImage Super-Resolution via Iterative Refinement — Saharia et al \u003ca href=\u0022https:\/\/paperswithcode.com\/paper\/image-super-resolution-via-iterative\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/paper\/image-super-resolution-via-iterative\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003ePerceiver IO: A General Architecture for Structured Inputs \u0026amp; Outputs — Jaegle et al \u003ca href=\u0022https:\/\/paperswithcode.com\/paper\/perceiver-io-a-general-architecture-for\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/paper\/perceiver-io-a-general-architecture-for\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eDo Vision Transformers See Like Convolutional Neural Networks? — Raghu et al \u003ca href=\u0022https:\/\/paperswithcode.com\/paper\/do-vision-transformers-see-like-convolutional\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/paper\/do-vision-transformers-see-like-convolutional\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eImplicit MLE: Backpropagating Through Discrete Exponential Family Distributions — Niepert et al \u003ca href=\u0022https:\/\/paperswithcode.com\/paper\/implicit-mle-backpropagating-through-discrete\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/paper\/implicit-mle-backpropagating-through-discrete\u003c\/a\u003e\u003c\/li\u003e\n\u003c\/ol\u003e\n\n\n\u003ch2 class=\u0022relative group\u0022\u003eTrending Libaries of 2021 \n    \u003cdiv id=\u0022trending-libaries-of-2021\u0022 class=\u0022anchor\u0022\u003e\u003c\/div\u003e\n    \n    \u003cspan\n        class=\u0022absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\u0022\u003e\n        \u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022\n            style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#trending-libaries-of-2021\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\n    \u003c\/span\u003e        \n    \n\u003c\/h2\u003e\n\u003col\u003e\n\u003cli\u003ePyTorch Image Models — Ross Wightman — \u003ca href=\u0022https:\/\/github.com\/rwightman\/pytorch-image-models\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/github.com\/rwightman\/pytorch-image-models\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eTransformers — Hugging Face — \u003ca href=\u0022https:\/\/github.com\/huggingface\/transformers\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/github.com\/huggingface\/transformers\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003ePyTorch-GAN — Erik Linder-Norén — \u003ca href=\u0022https:\/\/github.com\/eriklindernoren\/PyTorch-GAN\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/github.com\/eriklindernoren\/PyTorch-GAN\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eMMDetection — OpenMMLab — \u003ca href=\u0022https:\/\/github.com\/open-mmlab\/mmdetection\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/github.com\/open-mmlab\/mmdetection\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eDarknet — AlexeyAB — \u003ca href=\u0022https:\/\/github.com\/AlexeyAB\/darknet\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/github.com\/AlexeyAB\/darknet\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eVision Transformer PyTorch — lucidrains — \u003ca href=\u0022https:\/\/github.com\/lucidrains\/vit-pytorch\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/github.com\/lucidrains\/vit-pytorch\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eInsightFace — DeepInsight — \u003ca href=\u0022https:\/\/github.com\/deepinsight\/insightface\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/github.com\/deepinsight\/insightface\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eDetectron2 — Meta AI — \u003ca href=\u0022https:\/\/github.com\/facebookresearch\/detectron2\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/github.com\/facebookresearch\/detectron2\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003ePaddleOCR — PaddlePaddle — \u003ca href=\u0022https:\/\/github.com\/PaddlePaddle\/PaddleOCR\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/github.com\/PaddlePaddle\/PaddleOCR\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eFairSeq — Meta AI — \u003ca href=\u0022https:\/\/github.com\/pytorch\/fairseq\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/github.com\/pytorch\/fairseq\u003c\/a\u003e\u003c\/li\u003e\n\u003c\/ol\u003e\n\n\n\u003ch2 class=\u0022relative group\u0022\u003eTop Dataset - 2021 \n    \u003cdiv id=\u0022top-dataset---2021\u0022 class=\u0022anchor\u0022\u003e\u003c\/div\u003e\n    \n    \u003cspan\n        class=\u0022absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\u0022\u003e\n        \u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022\n            style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#top-dataset---2021\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\n    \u003c\/span\u003e        \n    \n\u003c\/h2\u003e\n\u003col\u003e\n\u003cli\u003eMATH — Hendrycks et al \u003ca href=\u0022https:\/\/paperswithcode.com\/dataset\/math\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/dataset\/math\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eUAV-Human — Li et al \u003ca href=\u0022https:\/\/paperswithcode.com\/dataset\/uav-human\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/dataset\/uav-human\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eUPFD (User Preference-aware Fake News Detection) — Dou et al \u003ca href=\u0022https:\/\/paperswithcode.com\/dataset\/upfd\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/dataset\/upfd\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eOGB-LSC (OGB Large-Scale Challenge) — Hu et al \u003ca href=\u0022https:\/\/paperswithcode.com\/dataset\/ogb-lsc\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/dataset\/ogb-lsc\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eCodeXGLUE —Lu et al \u003ca href=\u0022https:\/\/paperswithcode.com\/dataset\/codexglue\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/dataset\/codexglue\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eAGORA — Patel et al \u003ca href=\u0022https:\/\/paperswithcode.com\/dataset\/agora\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/dataset\/agora\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eBEIR (Benchmarking IR) — Thakur et al \u003ca href=\u0022https:\/\/paperswithcode.com\/dataset\/beir\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/dataset\/beir\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eWikiGraphs — Wang et al \u003ca href=\u0022https:\/\/paperswithcode.com\/dataset\/wikigraphs\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/dataset\/wikigraphs\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003eFew-NERD — Ding et al \u003ca href=\u0022https:\/\/paperswithcode.com\/dataset\/few-nerd\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/dataset\/few-nerd\u003c\/a\u003e\u003c\/li\u003e\n\u003cli\u003ePASS (Pictures without humAns for Self-Supervision) —Asano et al \u003ca href=\u0022https:\/\/paperswithcode.com\/dataset\/pass\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/paperswithcode.com\/dataset\/pass\u003c\/a\u003e\u003c\/li\u003e\n\u003c\/ol\u003e\n\n\n\u003ch2 class=\u0022relative group\u0022\u003ePapers of 2022 \n    \u003cdiv id=\u0022papers-of-2022\u0022 class=\u0022anchor\u0022\u003e\u003c\/div\u003e\n    \n    \u003cspan\n        class=\u0022absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\u0022\u003e\n        \u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022\n            style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#papers-of-2022\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\n    \u003c\/span\u003e        \n    \n\u003c\/h2\u003e\n\u003col\u003e\n\u003cli\u003eControllable Animation of Fluid Elements in Still Images\u003c\/li\u003e\n\u003cli\u003eF-SfT: Shape-From-Template With A Physics-Based Deformation Model\u003c\/li\u003e\n\u003cli\u003eTWIST: Two-Way Inter-Label Self-Training for Semi-Supervised 3D Instance Segmentation\u003c\/li\u003e\n\u003cli\u003eDo Learned Representations Respect Causal Relationships?\u003c\/li\u003e\n\u003cli\u003eZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic\u003c\/li\u003e\n\u003cli\u003e3D Moments From Near-Duplicate Photos\u003c\/li\u003e\n\u003cli\u003eExact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization\u003c\/li\u003e\n\u003cli\u003eBlind2Unblind: Self-Supervised Image Denoising With Visible Blind Spots\u003c\/li\u003e\n\u003cli\u003eBalanced and Hierarchical Relation Learning for One-Shot Object Detection\u003c\/li\u003e\n\u003cli\u003eNICE-SLAM: Neural Implicit Scalable Encoding for SLAM\u003c\/li\u003e\n\u003cli\u003eStochastic Trajectory Prediction Via Motion Indeterminacy Diffusion\u003c\/li\u003e\n\u003cli\u003eCLRNet: Cross Layer Refinement Network for Lane Detection\u003c\/li\u003e\n\u003cli\u003eMotion-Aware Contrastive Video Representation Learning Via Foreground-Background Merging\u003c\/li\u003e\n\u003cli\u003eDINE: Domain Adaptation From Single and Multiple Black-Box Predictors\u003c\/li\u003e\n\u003cli\u003eFaceFormer: Speech-Driven 3D Facial Animation With Transformers\u003c\/li\u003e\n\u003cli\u003eRotationally Equivariant 3D Object Detection\u003c\/li\u003e\n\u003cli\u003eAccelerating DETR Convergence Via Semantic-Aligned Matching\u003c\/li\u003e\n\u003cli\u003eCloning Outfits From Real-World Images to 3D Characters for Generalizable Person Re-Identification\u003c\/li\u003e\n\u003cli\u003eGeoNeRF: Generalizing NeRF With Geometry Priors\u003c\/li\u003e\n\u003cli\u003eABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo\u003c\/li\u003e\n\u003cli\u003eExpanding Low-Density Latent Regions for Open-Set Object Detection\u003c\/li\u003e\n\u003cli\u003eUformer: A General U-Shaped Transformer for Image Restoration\u003c\/li\u003e\n\u003cli\u003eExploring Dual-Task Correlation for Pose Guided Person Image Generation\u003c\/li\u003e\n\u003cli\u003ePortrait Eyeglasses and Shadow Removal By Leveraging 3D Synthetic Data\u003c\/li\u003e\n\u003cli\u003eModeling 3D Layout for Group Re-Identification\u003c\/li\u003e\n\u003cli\u003eToward Fast, Flexible, and Robust Low-Light Image Enhancement\u003c\/li\u003e\n\u003cli\u003eBridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos\u003c\/li\u003e\n\u003cli\u003eHandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network\u003c\/li\u003e\n\u003cli\u003eModular Action Concept Grounding in Semantic Video Prediction\u003c\/li\u003e\n\u003cli\u003eStyleSwin: Transformer-Based GAN for High-Resolution Image Generation\u003c\/li\u003e\n\u003cli\u003eDiscrete Cosine Transform Network for Guided Depth Map Super-Resolution\u003c\/li\u003e\n\u003cli\u003eCerberus Transformer: Joint Semantic, Affordance and Attribute Parsing\u003c\/li\u003e\n\u003cli\u003eTransGeo: Transformer Is All You Need for Cross-View Image Geo-Localization\u003c\/li\u003e\n\u003cli\u003eContrastive Boundary Learning for Point Cloud Segmentation\u003c\/li\u003e\n\u003cli\u003eDetails or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution\u003c\/li\u003e\n\u003cli\u003eCVNet: Contour Vibration Network for Building Extraction\u003c\/li\u003e\n\u003cli\u003eSwin Transformer V2: Scaling Up Capacity and Resolution\u003c\/li\u003e\n\u003cli\u003eProjective Manifold Gradient Layer for Deep Rotation Regression\u003c\/li\u003e\n\u003cli\u003eHCSC: Hierarchical Contrastive Selective Coding\u003c\/li\u003e\n\u003cli\u003eTransRank: Self-Supervised Video Representation Learning Via Ranking-Based Transformation Recognition\u003c\/li\u003e\n\u003cli\u003eDiSparse: Disentangled Sparsification for Multitask Model Compression\u003c\/li\u003e\n\u003cli\u003ePushing The Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make A Difference\u003c\/li\u003e\n\u003cli\u003eTowards Efficient and Scalable Sharpness-Aware Minimization\u003c\/li\u003e\n\u003cli\u003eOSSO: Obtaining Skeletal Shape From Outside\u003c\/li\u003e\n\u003cli\u003eA Study on The Distribution of Social Biases in Self-Supervised Learning Visual Models\u003c\/li\u003e\n\u003cli\u003eSelf-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes\u003c\/li\u003e\n\u003cli\u003eComparing Correspondences: Video Prediction With Correspondence-Wise Losses\u003c\/li\u003e\n\u003cli\u003eTowards Fewer Annotations: Active Learning Via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eCrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding\u003c\/li\u003e\n\u003cli\u003eFew Shot Generative Model Adaption Via Relaxed Spatial Structural Alignment\u003c\/li\u003e\n\u003cli\u003eEnhancing Adversarial Training With Second-Order Statistics of Weights\u003c\/li\u003e\n\u003cli\u003eDual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo\u003c\/li\u003e\n\u003cli\u003eMoving Window Regression: A Novel Approach to Ordinal Regression\u003c\/li\u003e\n\u003cli\u003eSelf-Supervised Predictive Convolutional Attentive Block for Anomaly Detection\u003c\/li\u003e\n\u003cli\u003eRobust Optimization As Data Augmentation for Large-Scale Graphs\u003c\/li\u003e\n\u003cli\u003eRobust Structured Declarative Classifiers for 3D Point Clouds: Defending Adversarial Attacks With Implicit Gradients\u003c\/li\u003e\n\u003cli\u003eImproving The Transferability of Targeted Adversarial Examples Through Object-Based Diverse Input\u003c\/li\u003e\n\u003cli\u003eObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer\u003c\/li\u003e\n\u003cli\u003e360MonoDepth: High-Resolution 360deg Monocular Depth Estimation\u003c\/li\u003e\n\u003cli\u003ePOCO: Point Convolution for Surface Reconstruction\u003c\/li\u003e\n\u003cli\u003eNeural Texture Extraction and Distribution for Controllable Person Image Synthesis\u003c\/li\u003e\n\u003cli\u003eClassification-Then-Grounding: Reformulating Video Scene Graphs As Temporal Bipartite Graphs\u003c\/li\u003e\n\u003cli\u003eDF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis\u003c\/li\u003e\n\u003cli\u003eZeroWaste Dataset: Towards Deformable Object Segmentation in Cluttered Scenes\u003c\/li\u003e\n\u003cli\u003eUNIST: Unpaired Neural Implicit Shape Translation Network\u003c\/li\u003e\n\u003cli\u003eAPES: Articulated Part Extraction From Sprite Sheets\u003c\/li\u003e\n\u003cli\u003eSPAct: Self-Supervised Privacy Preservation for Action Recognition\u003c\/li\u003e\n\u003cli\u003eDe-Rendering 3D Objects in The Wild\u003c\/li\u003e\n\u003cli\u003eGlobal Sensing and Measurements Reuse for Image Compressed Sensing\u003c\/li\u003e\n\u003cli\u003ePractical Evaluation of Adversarial Robustness Via Adaptive Auto Attack\u003c\/li\u003e\n\u003cli\u003eCross-View Transformers for Real-Time Map-View Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eControllable Dynamic Multi-Task Architectures\u003c\/li\u003e\n\u003cli\u003eFastDOG: Fast Discrete Optimization on GPU\u003c\/li\u003e\n\u003cli\u003eFocal and Global Knowledge Distillation for Detectors\u003c\/li\u003e\n\u003cli\u003eLearning To Prompt for Continual Learning\u003c\/li\u003e\n\u003cli\u003eHuman Mesh Recovery From Multiple Shots\u003c\/li\u003e\n\u003cli\u003eConvolution of Convolution: Let Kernels Spatially Collaborate\u003c\/li\u003e\n\u003cli\u003eMake It Move: Controllable Image-to-Video Generation With Text Descriptions\u003c\/li\u003e\n\u003cli\u003eNeural Points: Point Cloud Representation With Neural Fields for Arbitrary Upsampling\u003c\/li\u003e\n\u003cli\u003eVideo-Text Representation Learning Via Differentiable Weak Temporal Alignment\u003c\/li\u003e\n\u003cli\u003eBi-Directional Object-Context Prioritization Learning for Saliency Ranking\u003c\/li\u003e\n\u003cli\u003eVehicle Trajectory Prediction Works, But Not Everywhere\u003c\/li\u003e\n\u003cli\u003eMonoDTR: Monocular 3D Object Detection With Depth-Aware Transformer\u003c\/li\u003e\n\u003cli\u003eAttribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-Shot Learning\u003c\/li\u003e\n\u003cli\u003eGeneralized Category Discovery\u003c\/li\u003e\n\u003cli\u003eContour-Hugging Heatmaps for Landmark Detection\u003c\/li\u003e\n\u003cli\u003eVoxel Field Fusion for 3D Object Detection\u003c\/li\u003e\n\u003cli\u003eDisARM: Displacement Aware Relation Module for 3D Detection\u003c\/li\u003e\n\u003cli\u003eMixFormer: Mixing Features Across Windows and Dimensions\u003c\/li\u003e\n\u003cli\u003eFineDiving: A Fine-Grained Dataset for Procedure-Aware Action Quality Assessment\u003c\/li\u003e\n\u003cli\u003eHEAT: Holistic Edge Attention Transformer for Structured Reconstruction\u003c\/li\u003e\n\u003cli\u003eMobile-Former: Bridging MobileNet and Transformer\u003c\/li\u003e\n\u003cli\u003eCycleMix: A Holistic Strategy for Medical Image Segmentation From Scribble Supervision\u003c\/li\u003e\n\u003cli\u003eVideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution\u003c\/li\u003e\n\u003cli\u003eTowards End-to-End Unified Scene Text Detection and Layout Analysis\u003c\/li\u003e\n\u003cli\u003eAutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation\u003c\/li\u003e\n\u003cli\u003eISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior\u003c\/li\u003e\n\u003cli\u003eEnd-to-End Referring Video Object Segmentation With Multimodal Transformers\u003c\/li\u003e\n\u003cli\u003eIterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo\u003c\/li\u003e\n\u003cli\u003eNot All Points Are Equal: Learning Highly Efficient Point-Based Detectors for 3D LiDAR Point Clouds\u003c\/li\u003e\n\u003cli\u003eDetecting Camouflaged Object in Frequency Domain\u003c\/li\u003e\n\u003cli\u003eSelfRecon: Self Reconstruction Your Digital Avatar From Monocular Video\u003c\/li\u003e\n\u003cli\u003eEquivariant Point Cloud Analysis Via Learning Orientations for Message Passing\u003c\/li\u003e\n\u003cli\u003eNode Representation Learning in Graph Via Node-to-Neighbourhood Mutual Information Maximization\u003c\/li\u003e\n\u003cli\u003eSemi-Supervised Video Semantic Segmentation With Inter-Frame Feature Reconstruction\u003c\/li\u003e\n\u003cli\u003eAmodal Segmentation Through Out-of-Task and Out-of-Distribution Generalization With A Bayesian Model\u003c\/li\u003e\n\u003cli\u003eHow Well Do Sparse ImageNet Models Transfer?\u003c\/li\u003e\n\u003cli\u003eREX: Reasoning-Aware and Grounded Explanation\u003c\/li\u003e\n\u003cli\u003eCanonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes\u003c\/li\u003e\n\u003cli\u003eObject-Aware Video-Language Pre-Training for Retrieval\u003c\/li\u003e\n\u003cli\u003eMAT: Mask-Aware Transformer for Large Hole Image Inpainting\u003c\/li\u003e\n\u003cli\u003eAlign and Prompt: Video-and-Language Pre-Training With Entity Prompts\u003c\/li\u003e\n\u003cli\u003eMSG-Transformer: Exchanging Local Spatial Information By Manipulating Messenger Tokens\u003c\/li\u003e\n\u003cli\u003eCross Modal Retrieval With Querybank Normalisation\u003c\/li\u003e\n\u003cli\u003eRay3D: Ray-Based 3D Human Pose Estimation for Monocular Absolute 3D Localization\u003c\/li\u003e\n\u003cli\u003eASM-Loc: Action-Aware Segment Modeling for Weakly-Supervised Temporal Action Localization\u003c\/li\u003e\n\u003cli\u003eScaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs\u003c\/li\u003e\n\u003cli\u003eEnd-to-End Multi-Person Pose Estimation With Transformers\u003c\/li\u003e\n\u003cli\u003eREGTR: End-to-End Point Cloud Correspondences With Transformers\u003c\/li\u003e\n\u003cli\u003eNeural 3D Scene Reconstruction With The Manhattan-World Assumption\u003c\/li\u003e\n\u003cli\u003eV2C: Visual Voice Cloning\u003c\/li\u003e\n\u003cli\u003eRevisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection\u003c\/li\u003e\n\u003cli\u003eMAD: A Scalable Dataset for Language Grounding in Videos From Movie Audio Descriptions\u003c\/li\u003e\n\u003cli\u003eGait Recognition in The Wild With Dense 3D Representations and A Benchmark\u003c\/li\u003e\n\u003cli\u003eArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation Via Online Exploration and Synthesis\u003c\/li\u003e\n\u003cli\u003eQueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection\u003c\/li\u003e\n\u003cli\u003eIDEA-Net: Dynamic 3D Point Cloud Interpolation Via Deep Embedding Alignment\u003c\/li\u003e\n\u003cli\u003eBEHAVE: Dataset and Method for Tracking Human Object Interactions\u003c\/li\u003e\n\u003cli\u003eRevisiting Random Channel Pruning for Neural Network Compression\u003c\/li\u003e\n\u003cli\u003eGenerating Diverse and Natural 3D Human Motions From Text\u003c\/li\u003e\n\u003cli\u003eE-CIR: Event-Enhanced Continuous Intensity Recovery\u003c\/li\u003e\n\u003cli\u003eTowards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond\u003c\/li\u003e\n\u003cli\u003eSymmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose Estimation\u003c\/li\u003e\n\u003cli\u003eAziNorm: Exploiting The Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception\u003c\/li\u003e\n\u003cli\u003eWeakly Supervised Rotation-Invariant Aerial Object Detection Network\u003c\/li\u003e\n\u003cli\u003eSurface Reconstruction From Point Clouds By Learning Predictive Context Priors\u003c\/li\u003e\n\u003cli\u003eIRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes\u003c\/li\u003e\n\u003cli\u003eDynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation\u003c\/li\u003e\n\u003cli\u003eWeakly Supervised Temporal Action Localization Via Representative Snippet Knowledge Propagation\u003c\/li\u003e\n\u003cli\u003eE2EC: An End-to-End Contour-Based Method for High-Quality High-Speed Instance Segmentation\u003c\/li\u003e\n\u003cli\u003eBatchFormer: Learning To Explore Sample Relationships for Robust Representation Learning\u003c\/li\u003e\n\u003cli\u003eSelf-Supervised Image-Specific Prototype Exploration for Weakly Supervised Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eLearning Multi-View Aggregation in The Wild for Large-Scale 3D Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003ePIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition\u003c\/li\u003e\n\u003cli\u003eClothes-Changing Person Re-Identification With RGB Modality Only\u003c\/li\u003e\n\u003cli\u003eRobust Image Forgery Detection Over Online Social Network Shared Images\u003c\/li\u003e\n\u003cli\u003eRepresentation Compensation Networks for Continual Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eTracking People By Predicting 3D Appearance, Location and Pose\u003c\/li\u003e\n\u003cli\u003eText2Mesh: Text-Driven Neural Stylization for Meshes\u003c\/li\u003e\n\u003cli\u003eC-CAM: Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image\u003c\/li\u003e\n\u003cli\u003eForward Compatible Few-Shot Class-Incremental Learning\u003c\/li\u003e\n\u003cli\u003eWeakly Supervised Object Localization As Domain Adaption\u003c\/li\u003e\n\u003cli\u003eTencent-MVSE: A Large-Scale Benchmark Dataset for Multi-Modal Video Similarity Evaluation\u003c\/li\u003e\n\u003cli\u003eDeep Orientation-Aware Functional Maps: Tackling Symmetry Issues in Shape Matching\u003c\/li\u003e\n\u003cli\u003eTree Energy Loss: Towards Sparsely Annotated Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eMatteFormer: Transformer-Based Image Matting Via Prior-Tokens\u003c\/li\u003e\n\u003cli\u003eVideo Shadow Detection Via Spatio-Temporal Interpolation Consistency Training\u003c\/li\u003e\n\u003cli\u003eRobust and Accurate Superquadric Recovery: A Probabilistic Approach\u003c\/li\u003e\n\u003cli\u003eGrounding Answers for Visual Questions Asked By Visually Impaired People\u003c\/li\u003e\n\u003cli\u003eSparse Instance Activation for Real-Time Instance Segmentation\u003c\/li\u003e\n\u003cli\u003eVisualGPT: Data-Efficient Adaptation of Pretrained Language Models for Image Captioning\u003c\/li\u003e\n\u003cli\u003eMHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation\u003c\/li\u003e\n\u003cli\u003eSurface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis\u003c\/li\u003e\n\u003cli\u003eTowards Implicit Text-Guided 3D Shape Generation\u003c\/li\u003e\n\u003cli\u003eSoftCollage: A Differentiable Probabilistic Tree Generator for Image Collage\u003c\/li\u003e\n\u003cli\u003eQuery and Attention Augmentation for Knowledge-Based Explainable Reasoning\u003c\/li\u003e\n\u003cli\u003eWinoground: Probing Vision and Language Models for Visio-Linguistic Compositionality\u003c\/li\u003e\n\u003cli\u003eProgressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection\u003c\/li\u003e\n\u003cli\u003eFine-Grained Object Classification Via Self-Supervised Pose Alignment\u003c\/li\u003e\n\u003cli\u003eAnimal Kingdom: A Large and Diverse Dataset for Animal Behavior Understanding\u003c\/li\u003e\n\u003cli\u003eFine-Grained Temporal Contrastive Learning for Weakly-Supervised Temporal Action Localization\u003c\/li\u003e\n\u003cli\u003eRelieving Long-Tailed Instance Segmentation Via Pairwise Class Balance\u003c\/li\u003e\n\u003cli\u003eOnline Convolutional Re-Parameterization\u003c\/li\u003e\n\u003cli\u003eMimicking The Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning\u003c\/li\u003e\n\u003cli\u003eRelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition\u003c\/li\u003e\n\u003cli\u003ePersonalized Image Aesthetics Assessment With Rich Attributes\u003c\/li\u003e\n\u003cli\u003ePart-Based Pseudo Label Refinement for Unsupervised Person Re-Identification\u003c\/li\u003e\n\u003cli\u003eHDNet: High-Resolution Dual-Domain Learning for Spectral Compressive Imaging\u003c\/li\u003e\n\u003cli\u003eOW-DETR: Open-World Detection Transformer\u003c\/li\u003e\n\u003cli\u003eLearning Deep Implicit Functions for 3D Shapes With Dynamic Code Clouds\u003c\/li\u003e\n\u003cli\u003eReversible Vision Transformers\u003c\/li\u003e\n\u003cli\u003eAmodal Panoptic Segmentation\u003c\/li\u003e\n\u003cli\u003eCorrelation Verification for Image Retrieval\u003c\/li\u003e\n\u003cli\u003eTemporal Feature Alignment and Mutual Information Maximization for Video-Based Human Pose Estimation\u003c\/li\u003e\n\u003cli\u003eSelf-Supervised Transformers for Unsupervised Object Discovery Using Normalized Cut\u003c\/li\u003e\n\u003cli\u003eExploring Structure-Aware Transformer Over Interaction Proposals for Human-Object Interaction Detection\u003c\/li\u003e\n\u003cli\u003eDecoupled Multi-Task Learning With Cyclical Self-Regulation for Face Parsing\u003c\/li\u003e\n\u003cli\u003eGlass: Geometric Latent Augmentation for Shape Spaces\u003c\/li\u003e\n\u003cli\u003eDPICT: Deep Progressive Image Compression Using Trit-Planes\u003c\/li\u003e\n\u003cli\u003eText to Image Generation With Semantic-Spatial Aware GAN\u003c\/li\u003e\n\u003cli\u003eGeneralizable Cross-Modality Medical Image Segmentation Via Style Augmentation and Dual Normalization\u003c\/li\u003e\n\u003cli\u003eLearning To Prompt for Open-Vocabulary Object Detection With Vision-Language Model\u003c\/li\u003e\n\u003cli\u003eInteractive Segmentation and Visualization for Tiny Objects in Multi-Megapixel Images\u003c\/li\u003e\n\u003cli\u003eNeural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture\u003c\/li\u003e\n\u003cli\u003eSurface Representation for Point Clouds\u003c\/li\u003e\n\u003cli\u003eImplicit Motion Handling for Video Camouflaged Object Detection\u003c\/li\u003e\n\u003cli\u003eDeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides\u003c\/li\u003e\n\u003cli\u003eLearning With Twin Noisy Labels for Visible-Infrared Person Re-Identification\u003c\/li\u003e\n\u003cli\u003eOptical Flow Estimation for Spiking Camera\u003c\/li\u003e\n\u003cli\u003eGradViT: Gradient Inversion of Vision Transformers\u003c\/li\u003e\n\u003cli\u003eSpatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution Via Cycle-Projected Mutual Learning\u003c\/li\u003e\n\u003cli\u003eJoint Global and Local Hierarchical Priors for Learned Image Compression\u003c\/li\u003e\n\u003cli\u003eKnowledge Distillation Via The Target-Aware Transformer\u003c\/li\u003e\n\u003cli\u003eSubspace Adversarial Training\u003c\/li\u003e\n\u003cli\u003e3D-VField: Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection\u003c\/li\u003e\n\u003cli\u003eImage Segmentation Using Text and Image Prompts\u003c\/li\u003e\n\u003cli\u003eAutoMine: An Unmanned Mine Dataset\u003c\/li\u003e\n\u003cli\u003eBackground Activation Suppression for Weakly Supervised Object Localization\u003c\/li\u003e\n\u003cli\u003eSynthetic Generation of Face Videos With Plethysmograph Physiology\u003c\/li\u003e\n\u003cli\u003eHallucinated Neural Radiance Fields in The Wild\u003c\/li\u003e\n\u003cli\u003eGlobal Tracking Transformers\u003c\/li\u003e\n\u003cli\u003eBackdoor Attacks on Self-Supervised Learning\u003c\/li\u003e\n\u003cli\u003eGMFlow: Learning Optical Flow Via Global Matching\u003c\/li\u003e\n\u003cli\u003eLearning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation\u003c\/li\u003e\n\u003cli\u003eExplore Spatio-Temporal Aggregation for Insubstantial Object Detection: Benchmark Dataset and Baseline\u003c\/li\u003e\n\u003cli\u003eGraph-Based Spatial Transformer With Memory Replay for Multi-Future Pedestrian Trajectory Prediction\u003c\/li\u003e\n\u003cli\u003eScanline Homographies for Rolling-Shutter Plane Absolute Pose\u003c\/li\u003e\n\u003cli\u003eAdaInt: Learning Adaptive Intervals for 3D Lookup Tables on Real-Time Image Enhancement\u003c\/li\u003e\n\u003cli\u003eRecurrent Glimpse-Based Decoder for Detection With Transformer\u003c\/li\u003e\n\u003cli\u003eSimMIM: A Simple Framework for Masked Image Modeling\u003c\/li\u003e\n\u003cli\u003eLabel Matching Semi-Supervised Object Detection\u003c\/li\u003e\n\u003cli\u003eRegionCLIP: Region-Based Language-Image Pretraining\u003c\/li\u003e\n\u003cli\u003eVideo Frame Interpolation Transformer\u003c\/li\u003e\n\u003cli\u003eBCOT: A Markerless High-Precision 3D Object Tracking Benchmark\u003c\/li\u003e\n\u003cli\u003eOmni-DETR: Omni-Supervised Object Detection With Transformers\u003c\/li\u003e\n\u003cli\u003eTransferable Sparse Adversarial Attack\u003c\/li\u003e\n\u003cli\u003eCREAM: Weakly Supervised Object Localization Via Class RE-Activation Mapping\u003c\/li\u003e\n\u003cli\u003eVALHALLA: Visual Hallucination for Machine Translation\u003c\/li\u003e\n\u003cli\u003eHINT: Hierarchical Neuron Concept Explainer\u003c\/li\u003e\n\u003cli\u003eNeural Face Identification in A 2D Wireframe Projection of A Manifold Object\u003c\/li\u003e\n\u003cli\u003eNonuniform-to-Uniform Quantization: Towards Accurate Quantization Via Generalized Straight-Through Estimation\u003c\/li\u003e\n\u003cli\u003eAn Empirical Study of End-to-End Temporal Action Detection\u003c\/li\u003e\n\u003cli\u003eObject Localization Under Single Coarse Point Supervision\u003c\/li\u003e\n\u003cli\u003eUnsupervised Learning of Accurate Siamese Tracking\u003c\/li\u003e\n\u003cli\u003eNon-Parametric Depth Distribution Modelling Based Depth Inference for Multi-View Stereo\u003c\/li\u003e\n\u003cli\u003eEqualized Focal Loss for Dense Long-Tailed Object Detection\u003c\/li\u003e\n\u003cli\u003eDeepDPM: Deep Clustering With An Unknown Number of Clusters\u003c\/li\u003e\n\u003cli\u003eISDNet: Integrating Shallow and Deep Networks for Efficient Ultra-High Resolution Segmentation\u003c\/li\u003e\n\u003cli\u003eUnsupervised Domain Adaptation for Nighttime Aerial Tracking\u003c\/li\u003e\n\u003cli\u003eRestoreFormer: High-Quality Blind Face Restoration From Undegraded Key-Value Pairs\u003c\/li\u003e\n\u003cli\u003eMask-Guided Spectral-Wise Transformer for Efficient Hyperspectral Image Reconstruction\u003c\/li\u003e\n\u003cli\u003eA Variational Bayesian Method for Similarity Learning in Non-Rigid Image Registration\u003c\/li\u003e\n\u003cli\u003eNot Just Selection, But Exploration: Online Class-Incremental Continual Learning Via Dual View Consistency\u003c\/li\u003e\n\u003cli\u003eCoupling Vision and Proprioception for Navigation of Legged Robots\u003c\/li\u003e\n\u003cli\u003eExploiting Rigidity Constraints for LiDAR Scene Flow Estimation\u003c\/li\u003e\n\u003cli\u003eEMOCA: Emotion Driven Monocular Face Capture and Animation\u003c\/li\u003e\n\u003cli\u003eQuarantine: Sparsity Can Uncover The Trojan Attack Trigger for Free\u003c\/li\u003e\n\u003cli\u003eAlignQ: Alignment Quantization With ADMM-Based Correlation Preservation\u003c\/li\u003e\n\u003cli\u003eInteractive Multi-Class Tiny-Object Detection\u003c\/li\u003e\n\u003cli\u003eLearning From Pixel-Level Noisy Label: A New Perspective for Light Field Saliency Detection\u003c\/li\u003e\n\u003cli\u003eMulti-View Depth Estimation By Fusing Single-View Depth Probability With Multi-View Geometry\u003c\/li\u003e\n\u003cli\u003eSlimmable Domain Adaptation\u003c\/li\u003e\n\u003cli\u003eHigh-Resolution Image Harmonization Via Collaborative Dual Transformations\u003c\/li\u003e\n\u003cli\u003eMM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eSelf-Supervised Neural Articulated Shape and Appearance Models\u003c\/li\u003e\n\u003cli\u003eTopology Preserving Local Road Network Estimation From Single Onboard Camera Image\u003c\/li\u003e\n\u003cli\u003eEigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes\u003c\/li\u003e\n\u003cli\u003eSwinTextSpotter: Scene Text Spotting Via Better Synergy Between Text Detection and Text Recognition\u003c\/li\u003e\n\u003cli\u003eDeblur-NeRF: Neural Radiance Fields From Blurry Images\u003c\/li\u003e\n\u003cli\u003eWhose Track Is It Anyway? Improving Robustness to Tracking Errors With Affinity-Based Trajectory Prediction\u003c\/li\u003e\n\u003cli\u003eVideo K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation\u003c\/li\u003e\n\u003cli\u003eLocal Learning Matters: Rethinking Data Heterogeneity in Federated Learning\u003c\/li\u003e\n\u003cli\u003eBlind Image Super-Resolution With Elaborate Degradation Modeling on Noise and Kernel\u003c\/li\u003e\n\u003cli\u003eFaithful Extreme Rescaling Via Generative Prior Reciprocated Invertible Representations\u003c\/li\u003e\n\u003cli\u003eProto2Proto: Can You Recognize The Car, The Way I Do?\u003c\/li\u003e\n\u003cli\u003eTVConv: Efficient Translation Variant Convolution for Layout-Aware Visual Processing\u003c\/li\u003e\n\u003cli\u003eDual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution\u003c\/li\u003e\n\u003cli\u003eHabitat-Web: Learning Embodied Object-Search Strategies From Human Demonstrations at Scale\u003c\/li\u003e\n\u003cli\u003eSimple But Effective: CLIP Embeddings for Embodied AI\u003c\/li\u003e\n\u003cli\u003eNomMer: Nominate Synergistic Context in Vision Transformer for Visual Recognition\u003c\/li\u003e\n\u003cli\u003eCollaborative Transformers for Grounded Situation Recognition\u003c\/li\u003e\n\u003cli\u003eCPPF: Towards Robust Category-Level 9D Pose Estimation in The Wild\u003c\/li\u003e\n\u003cli\u003eContinual Test-Time Domain Adaptation\u003c\/li\u003e\n\u003cli\u003eDynamic MLP for Fine-Grained Image Classification By Leveraging Geographical and Temporal Information\u003c\/li\u003e\n\u003cli\u003eMuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-Based Visual Question Answering\u003c\/li\u003e\n\u003cli\u003eFair Contrastive Learning for Facial Attribute Classification\u003c\/li\u003e\n\u003cli\u003eDirectional Self-Supervised Learning for Heavy Image Augmentations\u003c\/li\u003e\n\u003cli\u003eNo-Reference Point Cloud Quality Assessment Via Domain Adaptation\u003c\/li\u003e\n\u003cli\u003eComprehending and Ordering Semantics for Image Captioning\u003c\/li\u003e\n\u003cli\u003eA Large-Scale Comprehensive Dataset and Copy-Overlap Aware Evaluation Protocol for Segment-Level Video Copy Detection\u003c\/li\u003e\n\u003cli\u003eLabel Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification\u003c\/li\u003e\n\u003cli\u003eHeadNeRF: A Real-Time NeRF-Based Parametric Head Model\u003c\/li\u003e\n\u003cli\u003eOcclusion-Robust Face Alignment Using A Viewpoint-Invariant Hierarchical Network Architecture\u003c\/li\u003e\n\u003cli\u003eIDR: Self-Supervised Image Denoising Via Iterative Data Refinement\u003c\/li\u003e\n\u003cli\u003eMogFace: Towards A Deeper Appreciation on Face Detection\u003c\/li\u003e\n\u003cli\u003eLearning Affinity From Attention: End-to-End Weakly-Supervised Semantic Segmentation With Transformers\u003c\/li\u003e\n\u003cli\u003eCamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation\u003c\/li\u003e\n\u003cli\u003eFERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos\u003c\/li\u003e\n\u003cli\u003eLearning To Detect Mobile Objects From LiDAR Scans Without Labels\u003c\/li\u003e\n\u003cli\u003eWildNet: Learning Domain Generalized Semantic Segmentation From The Wild\u003c\/li\u003e\n\u003cli\u003eDAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection\u003c\/li\u003e\n\u003cli\u003ePoint-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eGenerating Diverse 3D Reconstructions From A Single Occluded Face Image\u003c\/li\u003e\n\u003cli\u003eStand-Alone Inter-Frame Attention in Video Models\u003c\/li\u003e\n\u003cli\u003eLarge-Scale Pre-Training for Person Re-Identification With Noisy Labels\u003c\/li\u003e\n\u003cli\u003eSemantic Segmentation By Early Region Proxy\u003c\/li\u003e\n\u003cli\u003eLD-ConGR: A Large RGB-D Video Dataset for Long-Distance Continuous Gesture Recognition\u003c\/li\u003e\n\u003cli\u003eHVH: Learning A Hybrid Neural Volumetric Representation for Dynamic Hair Performance Capture\u003c\/li\u003e\n\u003cli\u003eRethinking Visual Geo-Localization for Large-Scale Applications\u003c\/li\u003e\n\u003cli\u003eThe Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy\u003c\/li\u003e\n\u003cli\u003eViM: Out-of-Distribution With Virtual-Logit Matching\u003c\/li\u003e\n\u003cli\u003eClass-Aware Contrastive Semi-Supervised Learning\u003c\/li\u003e\n\u003cli\u003eDitto: Building Digital Twins of Articulated Objects From Interaction\u003c\/li\u003e\n\u003cli\u003eAdaptive Early-Learning Correction for Segmentation From Noisy Annotations\u003c\/li\u003e\n\u003cli\u003eCross-Domain Correlation Distillation for Unsupervised Domain Adaptation in Nighttime Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eRSTT: Real-Time Spatial Temporal Transformer for Space-Time Video Super-Resolution\u003c\/li\u003e\n\u003cli\u003ePartial Class Activation Attention for Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eMulti-Scale Memory-Based Video Deblurring\u003c\/li\u003e\n\u003cli\u003eA Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching\u003c\/li\u003e\n\u003cli\u003eGeometric Structure Preserving Warp for Natural Image Stitching\u003c\/li\u003e\n\u003cli\u003eGOAL: Generating 4D Whole-Body Motion for Hand-Object Grasping\u003c\/li\u003e\n\u003cli\u003eConditional Prompt Learning for Vision-Language Models\u003c\/li\u003e\n\u003cli\u003eGraph Sampling Based Deep Metric Learning for Generalizable Person Re-Identification\u003c\/li\u003e\n\u003cli\u003eUndoing The Damage of Label Shift for Cross-Domain Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eFisherMatch: Semi-Supervised Rotation Regression Via Entropy-Based Filtering\u003c\/li\u003e\n\u003cli\u003eAffine Medical Image Registration With Coarse-To-Fine Vision Transformer\u003c\/li\u003e\n\u003cli\u003eA Differentiable Two-Stage Alignment Scheme for Burst Image Reconstruction With Large Shift\u003c\/li\u003e\n\u003cli\u003eDeformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes\u003c\/li\u003e\n\u003cli\u003eRestormer: Efficient Transformer for High-Resolution Image Restoration\u003c\/li\u003e\n\u003cli\u003eIFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation\u003c\/li\u003e\n\u003cli\u003eLarge Loss Matters in Weakly Supervised Multi-Label Classification\u003c\/li\u003e\n\u003cli\u003eNeural Inertial Localization\u003c\/li\u003e\n\u003cli\u003eGraftNet: Towards Domain Generalized Stereo Matching With A Broad-Spectrum and Task-Oriented Feature\u003c\/li\u003e\n\u003cli\u003eVGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning\u003c\/li\u003e\n\u003cli\u003eCatching Both Gray and Black Swans: Open-Set Supervised Anomaly Detection\u003c\/li\u003e\n\u003cli\u003eMLSLT: Towards Multilingual Sign Language Translation\u003c\/li\u003e\n\u003cli\u003eTowards An End-to-End Framework for Flow-Guided Video Inpainting\u003c\/li\u003e\n\u003cli\u003eContrastive Test-Time Adaptation\u003c\/li\u003e\n\u003cli\u003eMotionAug: Augmentation With Physical Correction for Human Motion Prediction\u003c\/li\u003e\n\u003cli\u003eModeling Indirect Illumination for Inverse Rendering\u003c\/li\u003e\n\u003cli\u003eTransWeather: Transformer-Based Restoration of Images Degraded By Adverse Weather Conditions\u003c\/li\u003e\n\u003cli\u003eH2FA R-CNN: Holistic and Hierarchical Feature Alignment for Cross-Domain Weakly Supervised Object Detection\u003c\/li\u003e\n\u003cli\u003eP3Depth: Monocular Depth Estimation With A Piecewise Planarity Prior\u003c\/li\u003e\n\u003cli\u003eGEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection\u003c\/li\u003e\n\u003cli\u003eSimple Multi-Dataset Detection\u003c\/li\u003e\n\u003cli\u003eProactive Image Manipulation Detection\u003c\/li\u003e\n\u003cli\u003eStyTr2: Image Style Transfer With Transformers\u003c\/li\u003e\n\u003cli\u003eGlobal Matching With Overlapping Attention for Optical Flow Estimation\u003c\/li\u003e\n\u003cli\u003eLanguage As Queries for Referring Video Object Segmentation\u003c\/li\u003e\n\u003cli\u003eMViTv2: Improved Multiscale Vision Transformers for Classification and Detection\u003c\/li\u003e\n\u003cli\u003eAudio-Visual Generalised Zero-Shot Learning With Cross-Modal Attention and Language\u003c\/li\u003e\n\u003cli\u003eRethinking Efficient Lane Detection Via Curve Modeling\u003c\/li\u003e\n\u003cli\u003eSelf-Supervised Arbitrary-Scale Point Clouds Upsampling Via Implicit Neural Representation\u003c\/li\u003e\n\u003cli\u003eCo-Advise: Cross Inductive Bias Distillation\u003c\/li\u003e\n\u003cli\u003eAdaMixer: A Fast-Converging Query-Based Object Detector\u003c\/li\u003e\n\u003cli\u003eDTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification\u003c\/li\u003e\n\u003cli\u003eBEVT: BERT Pretraining of Video Transformers\u003c\/li\u003e\n\u003cli\u003eDeep Generalized Unfolding Networks for Image Restoration\u003c\/li\u003e\n\u003cli\u003eVISOLO: Grid-Based Space-Time Aggregation for Efficient Online Video Instance Segmentation\u003c\/li\u003e\n\u003cli\u003eDeep Unlearning Via Randomized Conditionally Independent Hessians\u003c\/li\u003e\n\u003cli\u003eRevisiting Skeleton-Based Action Recognition\u003c\/li\u003e\n\u003cli\u003eStereo Depth From Events Cameras: Concentrate and Focus on The Future\u003c\/li\u003e\n\u003cli\u003eA Simple Data Mixing Prior for Improving Self-Supervised Learning\u003c\/li\u003e\n\u003cli\u003eKnowledge Distillation As Efficient Pre-Training: Faster Convergence, Higher Data-Efficiency, and Better Transferability\u003c\/li\u003e\n\u003cli\u003eBigDL 2.0: Seamless Scaling of AI Pipelines From Laptops to Distributed Cluster\u003c\/li\u003e\n\u003cli\u003eAttentive Fine-Grained Structured Sparsity for Image Restoration\u003c\/li\u003e\n\u003cli\u003eLearning Fair Classifiers With Partially Annotated Group Labels\u003c\/li\u003e\n\u003cli\u003eNightLab: A Dual-Level Architecture With Hardness Detection for Segmentation at Night\u003c\/li\u003e\n\u003cli\u003eConstrained Few-Shot Class-Incremental Learning\u003c\/li\u003e\n\u003cli\u003eThreshold Matters in WSSS: Manipulating The Activation for The Robust and Accurate Segmentation Model Against Thresholds\u003c\/li\u003e\n\u003cli\u003eTransMVSNet: Global Context-Aware Multi-View Stereo Network With Transformers\u003c\/li\u003e\n\u003cli\u003eDPGEN: Differentially Private Generative Energy-Guided Network for Natural Image Synthesis\u003c\/li\u003e\n\u003cli\u003eThe Majority Can Help The Minority: Context-Rich Minority Oversampling for Long-Tailed Classification\u003c\/li\u003e\n\u003cli\u003eIntentVizor: Towards Generic Query Guided Interactive Video Summarization\u003c\/li\u003e\n\u003cli\u003eShape-Invariant 3D Adversarial Point Clouds\u003c\/li\u003e\n\u003cli\u003eBootstrapping ViTs: Towards Liberating Vision Transformers From Pre-Training\u003c\/li\u003e\n\u003cli\u003ePubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents\u003c\/li\u003e\n\u003cli\u003eMeta-Attention for ViT-Backed Continual Learning\u003c\/li\u003e\n\u003cli\u003eDST: Dynamic Substitute Training for Data-Free Black-Box Attack\u003c\/li\u003e\n\u003cli\u003eUnified Contrastive Learning in Image-Text-Label Space\u003c\/li\u003e\n\u003cli\u003eUnsupervised Pre-Training for Temporal Action Localization Tasks\u003c\/li\u003e\n\u003cli\u003eLook Outside The Room: Synthesizing A Consistent Long-Term 3D Scene Video From A Single Image\u003c\/li\u003e\n\u003cli\u003eHigh-Fidelity Human Avatars From A Single RGB Camera\u003c\/li\u003e\n\u003cli\u003eMultiview Transformers for Video Recognition\u003c\/li\u003e\n\u003cli\u003eHow Good Is Aesthetic Ability of A Fashion Model?\u003c\/li\u003e\n\u003cli\u003eDeformation and Correspondence Aware Unsupervised Synthetic-to-Real Scene Flow Estimation for Point Clouds\u003c\/li\u003e\n\u003cli\u003eSequential Voting With Relational Box Fields for Active Object Detection\u003c\/li\u003e\n\u003cli\u003eSemantic-Aware Auto-Encoders for Self-Supervised Representation Learning\u003c\/li\u003e\n\u003cli\u003eConsistency Learning Via Decoding Path Augmentation for Transformers in Human Object Interaction Detection\u003c\/li\u003e\n\u003cli\u003eConsistent Explanations By Contrastive Learning\u003c\/li\u003e\n\u003cli\u003eHierarchical Modular Network for Video Captioning\u003c\/li\u003e\n\u003cli\u003eDepth Estimation By Combining Binocular Stereo and Monocular Structured-Light\u003c\/li\u003e\n\u003cli\u003eSalient-to-Broad Transition for Video Person Re-Identification\u003c\/li\u003e\n\u003cli\u003eDeeCap: Dynamic Early Exiting for Efficient Image Captioning\u003c\/li\u003e\n\u003cli\u003eRepMLPNet: Hierarchical Vision MLP With Re-Parameterized Locality\u003c\/li\u003e\n\u003cli\u003eDR.VIC: Decomposition and Reasoning for Video Individual Counting\u003c\/li\u003e\n\u003cli\u003eARCS: Accurate Rotation and Correspondence Search\u003c\/li\u003e\n\u003cli\u003eLearning To Anticipate Future With Dynamic Context Removal\u003c\/li\u003e\n\u003cli\u003eGCFSR: A Generative and Controllable Face Super Resolution Method Without Facial and GAN Priors\u003c\/li\u003e\n\u003cli\u003eOn The Integration of Self-Attention and Convolution\u003c\/li\u003e\n\u003cli\u003eDomain Adaptation on Point Clouds Via Geometry-Aware Implicits\u003c\/li\u003e\n\u003cli\u003eGroupViT: Semantic Segmentation Emerges From Text Supervision\u003c\/li\u003e\n\u003cli\u003eDiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation\u003c\/li\u003e\n\u003cli\u003eBppAttack: Stealthy and Efficient Trojan Attacks Against Deep Neural Networks Via Image Quantization and Contrastive Adversarial Learning\u003c\/li\u003e\n\u003cli\u003eStacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation\u003c\/li\u003e\n\u003cli\u003eTowards Better Plasticity-Stability Trade-Off in Incremental Learning: A Simple Linear Connector\u003c\/li\u003e\n\u003cli\u003eTopology-Preserving Shape Reconstruction and Registration Via Neural Diffeomorphic Flow\u003c\/li\u003e\n\u003cli\u003eSegment and Complete: Defending Object Detectors Against Adversarial Patch Attacks With Robust Patch Detection\u003c\/li\u003e\n\u003cli\u003eMAXIM: Multi-Axis MLP for Image Processing\u003c\/li\u003e\n\u003cli\u003eLearning Part Segmentation Through Unsupervised Domain Adaptation From Synthetic Vehicles\u003c\/li\u003e\n\u003cli\u003ePSTR: End-to-End One-Step Person Search With Transformers\u003c\/li\u003e\n\u003cli\u003eNFormer: Robust Person Re-Identification With Neighbor Transformer\u003c\/li\u003e\n\u003cli\u003eBridging Global Context Interactions for High-Fidelity Image Completion\u003c\/li\u003e\n\u003cli\u003eSwinBERT: End-to-End Transformers With Sparse Attention for Video Captioning\u003c\/li\u003e\n\u003cli\u003eNot All Tokens Are Equal: Human-Centric Visual Analysis Via Token Clustering Transformer\u003c\/li\u003e\n\u003cli\u003eTemporally Efficient Vision Transformer for Video Instance Segmentation\u003c\/li\u003e\n\u003cli\u003eThe Devil Is in The Margin: Margin-Based Label Smoothing for Network Calibration\u003c\/li\u003e\n\u003cli\u003eNLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks\u003c\/li\u003e\n\u003cli\u003eWarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation\u003c\/li\u003e\n\u003cli\u003ePseudo-Q: Generating Pseudo Language Queries for Visual Grounding\u003c\/li\u003e\n\u003cli\u003eE2(GO)MOTION: Motion Augmented Event Stream for Egocentric Action Recognition\u003c\/li\u003e\n\u003cli\u003eOoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization\u003c\/li\u003e\n\u003cli\u003eOnePose: One-Shot Object Pose Estimation Without CAD Models\u003c\/li\u003e\n\u003cli\u003eRethinking Minimal Sufficient Representation in Contrastive Learning\u003c\/li\u003e\n\u003cli\u003eScalable Penalized Regression for Noise Detection in Learning With Noisy Labels\u003c\/li\u003e\n\u003cli\u003eFederated Class-Incremental Learning\u003c\/li\u003e\n\u003cli\u003eShow, Deconfound and Tell: Image Captioning With Causal Inference\u003c\/li\u003e\n\u003cli\u003eMobRecon: Mobile-Friendly Hand Mesh Reconstruction From Monocular Image\u003c\/li\u003e\n\u003cli\u003eParameter-Free Online Test-Time Adaptation\u003c\/li\u003e\n\u003cli\u003eSIGMA: Semantic-Complete Graph Matching for Domain Adaptive Object Detection\u003c\/li\u003e\n\u003cli\u003eNo Pain, Big Gain: Classify Dynamic Point Cloud Sequences With Static Models By Fitting Feature-Level Space-Time Surfaces\u003c\/li\u003e\n\u003cli\u003eHerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for Snapshot Compressive Imaging\u003c\/li\u003e\n\u003cli\u003eVision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space\u003c\/li\u003e\n\u003cli\u003eLearning To Estimate Robust 3D Human Mesh From In-the-Wild Crowded Scenes\u003c\/li\u003e\n\u003cli\u003eDetecting Deepfakes With Self-Blended Images\u003c\/li\u003e\n\u003cli\u003eImplicit Sample Extension for Unsupervised Person Re-Identification\u003c\/li\u003e\n\u003cli\u003eEnergy-Based Latent Aligner for Incremental Learning\u003c\/li\u003e\n\u003cli\u003eTowards Semi-Supervised Deep Facial Expression Recognition With An Adaptive Confidence Margin\u003c\/li\u003e\n\u003cli\u003eGroup R-CNN for Weakly Semi-Supervised Object Detection With Points\u003c\/li\u003e\n\u003cli\u003eWeakly-Supervised Action Transition Learning for Stochastic Human Motion Prediction\u003c\/li\u003e\n\u003cli\u003eHybrid Relation Guided Set Matching for Few-Shot Action Recognition\u003c\/li\u003e\n\u003cli\u003eCross-Patch Dense Contrastive Learning for Semi-Supervised Segmentation of Cellular Nuclei in Histopathologic Images\u003c\/li\u003e\n\u003cli\u003eGeneralized Binary Search Network for Highly-Efficient Multi-View Stereo\u003c\/li\u003e\n\u003cli\u003eSHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation\u003c\/li\u003e\n\u003cli\u003eFlexIT: Towards Flexible Semantic Image Translation\u003c\/li\u003e\n\u003cli\u003eCRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow\u003c\/li\u003e\n\u003cli\u003eBoxeR: Box-Attention for 2D and 3D Transformers\u003c\/li\u003e\n\u003cli\u003eNeural Architecture Search With Representation Mutual Information\u003c\/li\u003e\n\u003cli\u003eCan Neural Nets Learn The Same Model Twice? Investigating Reproducibility and Double Descent From The Decision Boundary Perspective\u003c\/li\u003e\n\u003cli\u003eHierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction\u003c\/li\u003e\n\u003cli\u003eMulti-View Transformer for 3D Visual Grounding\u003c\/li\u003e\n\u003cli\u003eStructured Sparse R-CNN for Direct Scene Graph Generation\u003c\/li\u003e\n\u003cli\u003eBARC: Learning To Regress 3D Dog Shape From Images By Exploiting Breed Information\u003c\/li\u003e\n\u003cli\u003ePCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models\u003c\/li\u003e\n\u003cli\u003eTowards Understanding Adversarial Robustness of Optical Flow Networks\u003c\/li\u003e\n\u003cli\u003eLifelong Graph Learning\u003c\/li\u003e\n\u003cli\u003eHypergraph-Induced Semantic Tuplet Loss for Deep Metric Learning\u003c\/li\u003e\n\u003cli\u003eComputing Wasserstein-p Distance Between Images With Linear Cost\u003c\/li\u003e\n\u003cli\u003eUnsupervised Representation Learning for Binary Networks By Joint Classifier Learning\u003c\/li\u003e\n\u003cli\u003eLarge-Scale Video Panoptic Segmentation in The Wild: A Benchmark\u003c\/li\u003e\n\u003cli\u003eGrainSpace: A Large-Scale Dataset for Fine-Grained and Domain-Adaptive Recognition of Cereal Grains\u003c\/li\u003e\n\u003cli\u003eLearning Modal-Invariant and Temporal-Memory for Video-Based Visible-Infrared Person Re-Identification\u003c\/li\u003e\n\u003cli\u003eMSDN: Mutually Semantic Distillation Network for Zero-Shot Learning\u003c\/li\u003e\n\u003cli\u003eOriented RepPoints for Aerial Object Detection\u003c\/li\u003e\n\u003cli\u003eWeakly Supervised Temporal Sentence Grounding With Gaussian-Based Contrastive Proposal Learning\u003c\/li\u003e\n\u003cli\u003eLow-Resource Adaptation for Personalized Co-Speech Gesture Generation\u003c\/li\u003e\n\u003cli\u003eTask-Specific Inconsistency Alignment for Domain Adaptive Object Detection\u003c\/li\u003e\n\u003cli\u003eMS2DG-Net: Progressive Correspondence Learning Via Multiple Sparse Semantics Dynamic Graph\u003c\/li\u003e\n\u003cli\u003eLearning To Listen: Modeling Non-Deterministic Dyadic Facial Motion\u003c\/li\u003e\n\u003cli\u003eCapturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation From Monocular Video\u003c\/li\u003e\n\u003cli\u003eMixFormer: End-to-End Tracking With Iterative Mixed Attention\u003c\/li\u003e\n\u003cli\u003ePlenoxels: Radiance Fields Without Neural Networks\u003c\/li\u003e\n\u003cli\u003eSelective-Supervised Contrastive Learning With Noisy Labels\u003c\/li\u003e\n\u003cli\u003eSimT: Handling Open-Set Noise for Domain Adaptive Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eFrequency-Driven Imperceptible Adversarial Attack on Semantic Similarity\u003c\/li\u003e\n\u003cli\u003eVideo Demoireing With Relation-Based Temporal Consistency\u003c\/li\u003e\n\u003cli\u003eIndustrial Style Transfer With Large-Scale Geometric Warping and Content Preservation\u003c\/li\u003e\n\u003cli\u003eModeling Image Composition for Complex Scene Generation\u003c\/li\u003e\n\u003cli\u003eDecoupling Zero-Shot Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eTemplates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions\u003c\/li\u003e\n\u003cli\u003eStochastic Variance Reduced Ensemble Adversarial Attack for Boosting The Adversarial Transferability\u003c\/li\u003e\n\u003cli\u003eIFOR: Iterative Flow Minimization for Robotic Object Rearrangement\u003c\/li\u003e\n\u003cli\u003eZero Experience Required: Plug \u0026amp; Play Modular Transfer Learning for Semantic Visual Navigation\u003c\/li\u003e\n\u003cli\u003eTopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eThe Wanderings of Odysseus in 3D Scenes\u003c\/li\u003e\n\u003cli\u003eAll-in-One Image Restoration for Unknown Corruption\u003c\/li\u003e\n\u003cli\u003ePUMP: Pyramidal and Uniqueness Matching Priors for Unsupervised Learning of Local Descriptors\u003c\/li\u003e\n\u003cli\u003eMixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video\u003c\/li\u003e\n\u003cli\u003eRCP: Recurrent Closest Point for Point Cloud\u003c\/li\u003e\n\u003cli\u003eA Dual Weighting Label Assignment Scheme for Object Detection\u003c\/li\u003e\n\u003cli\u003eHyperbolic Vision Transformers: Combining Improvements in Metric Learning\u003c\/li\u003e\n\u003cli\u003eInstance-Aware Dynamic Neural Network Quantization\u003c\/li\u003e\n\u003cli\u003eExploring Effective Data for Surrogate Training Towards Black-Box Attack\u003c\/li\u003e\n\u003cli\u003eJRDB-Act: A Large-Scale Dataset for Spatio-Temporal Action, Social Group and Activity Detection\u003c\/li\u003e\n\u003cli\u003eInvestigating Top-k White-Box and Transferable Black-Box Attack\u003c\/li\u003e\n\u003cli\u003eDecoupling and Recoupling Spatiotemporal Representation for RGB-D-Based Motion Recognition\u003c\/li\u003e\n\u003cli\u003eA Self-Supervised Descriptor for Image Copy Detection\u003c\/li\u003e\n\u003cli\u003eNegative-Aware Attention Framework for Image-Text Matching\u003c\/li\u003e\n\u003cli\u003eAn Image Patch Is A Wave: Phase-Aware Vision MLP\u003c\/li\u003e\n\u003cli\u003eShunted Self-Attention Via Multi-Scale Token Aggregation\u003c\/li\u003e\n\u003cli\u003eUnified Multivariate Gaussian Mixture for Efficient Neural Image Compression\u003c\/li\u003e\n\u003cli\u003eRecurrent Variational Network: A Deep Learning Inverse Problem Solver Applied to The Task of Accelerated MRI Reconstruction\u003c\/li\u003e\n\u003cli\u003eSurpassing The Human Accuracy: Detecting Gallbladder Cancer From USG Images With Curriculum Learning\u003c\/li\u003e\n\u003cli\u003eAppearance and Structure Aware Robust Deep Visual Graph Matching: Attack, Defense and Beyond\u003c\/li\u003e\n\u003cli\u003eTrackFormer: Multi-Object Tracking With Transformers\u003c\/li\u003e\n\u003cli\u003e3D Shape Reconstruction From 2D Images With Disentangled Attribute Flow\u003c\/li\u003e\n\u003cli\u003eFeature Statistics Mixing Regularization for Generative Adversarial Networks\u003c\/li\u003e\n\u003cli\u003eOpenTAL: Towards Open Set Temporal Action Localization\u003c\/li\u003e\n\u003cli\u003eSelf-Supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection\u003c\/li\u003e\n\u003cli\u003eEgo4D: Around The World in 3,000 Hours of Egocentric Video\u003c\/li\u003e\n\u003cli\u003eSelf-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis\u003c\/li\u003e\n\u003cli\u003eWeakly Supervised Semantic Segmentation Using Out-of-Distribution Data\u003c\/li\u003e\n\u003cli\u003eDAD-3DHeads: A Large-Scale Dense, Accurate and Diverse Dataset for 3D Head Alignment From A Single Image\u003c\/li\u003e\n\u003cli\u003eReconstructing Surfaces for Sparse Point Clouds With On-Surface Priors\u003c\/li\u003e\n\u003cli\u003eVCLIMB: A Novel Video Class Incremental Learning Benchmark\u003c\/li\u003e\n\u003cli\u003eRobust Equivariant Imaging: A Fully Unsupervised Framework for Learning To Image From Noisy and Partial Measurements\u003c\/li\u003e\n\u003cli\u003eST\u002b\u002b: Make Self-Training Work Better for Semi-Supervised Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eInteracting Attention Graph for Single Image Two-Hand Reconstruction\u003c\/li\u003e\n\u003cli\u003eRope3D: The Roadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task\u003c\/li\u003e\n\u003cli\u003eCross-Image Relational Knowledge Distillation for Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eTowards Layer-Wise Image Vectorization\u003c\/li\u003e\n\u003cli\u003eScenic: A JAX Library for Computer Vision Research and Beyond\u003c\/li\u003e\n\u003cli\u003eReal-Time Object Detection for Streaming Perception\u003c\/li\u003e\n\u003cli\u003eVisualHow: Multimodal Problem Solving\u003c\/li\u003e\n\u003cli\u003eSpatial Commonsense Graph for Object Localisation in Partial Scenes\u003c\/li\u003e\n\u003cli\u003eOSSGAN: Open-Set Semi-Supervised Image Generation\u003c\/li\u003e\n\u003cli\u003eBi-Level Alignment for Cross-Domain Crowd Counting\u003c\/li\u003e\n\u003cli\u003eST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation\u003c\/li\u003e\n\u003cli\u003eEfficient Multi-View Stereo By Iterative Dynamic Cost Volume\u003c\/li\u003e\n\u003cli\u003eTransEditor: Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing\u003c\/li\u003e\n\u003cli\u003eUse All The Labels: A Hierarchical Multi-Label Contrastive Learning Framework\u003c\/li\u003e\n\u003cli\u003eSGTR: End-to-End Scene Graph Generation With Transformer\u003c\/li\u003e\n\u003cli\u003eDecoupled Knowledge Distillation\u003c\/li\u003e\n\u003cli\u003eDeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection\u003c\/li\u003e\n\u003cli\u003eReusing The Task-Specific Classifier As A Discriminator: Discriminator-Free Adversarial Domain Adaptation\u003c\/li\u003e\n\u003cli\u003eShow Me What and Tell Me How: Video Synthesis Via Multimodal Conditioning\u003c\/li\u003e\n\u003cli\u003eSIMBAR: Single Image-Based Scene Relighting for Effective Data Augmentation for Automated Driving Vision Tasks\u003c\/li\u003e\n\u003cli\u003eMulti-Label Classification With Partial Annotations Using Class-Aware Selective Loss\u003c\/li\u003e\n\u003cli\u003eCADTransformer: Panoptic Symbol Spotting Transformer for CAD Drawings\u003c\/li\u003e\n\u003cli\u003eIntraQ: Learning Synthetic Images With Intra-Class Heterogeneity for Zero-Shot Network Quantization\u003c\/li\u003e\n\u003cli\u003eI M Avatar: Implicit Morphable Head Avatars From Videos\u003c\/li\u003e\n\u003cli\u003eWeakly-Supervised Metric Learning With Cross-Module Communications for The Classification of Anterior Chamber Angle Images\u003c\/li\u003e\n\u003cli\u003eA Text Attention Network for Spatial Deformation Robust Scene Text Image Super-Resolution\u003c\/li\u003e\n\u003cli\u003eMulti-Modal Dynamic Graph Transformer for Visual Grounding\u003c\/li\u003e\n\u003cli\u003eGeometric Transformer for Fast and Robust Point Cloud Registration\u003c\/li\u003e\n\u003cli\u003eUMT: Unified Multi-Modal Transformers for Joint Video Moment Retrieval and Highlight Detection\u003c\/li\u003e\n\u003cli\u003eDemystifying The Neural Tangent Kernel From A Practical Perspective: Can It Be Trusted for Neural Architecture Search Without Training?\u003c\/li\u003e\n\u003cli\u003eThe Devil Is in The Details: Window-Based Attention for Image Compression\u003c\/li\u003e\n\u003cli\u003eDiLiGenT102: A Photometric Stereo Benchmark Dataset With Controlled Shape and Material Variation\u003c\/li\u003e\n\u003cli\u003ePolyWorld: Polygonal Building Extraction With Graph Neural Networks in Satellite Images\u003c\/li\u003e\n\u003cli\u003eLite Pose: Efficient Architecture Design for 2D Human Pose Estimation\u003c\/li\u003e\n\u003cli\u003eSpatio-Temporal Relation Modeling for Few-Shot Action Recognition\u003c\/li\u003e\n\u003cli\u003eMulti-Person Extreme Motion Prediction\u003c\/li\u003e\n\u003cli\u003eB-DARTS: Beta-Decay Regularization for Differentiable Architecture Search\u003c\/li\u003e\n\u003cli\u003eCMT: Convolutional Neural Networks Meet Vision Transformers\u003c\/li\u003e\n\u003cli\u003eKNN Local Attention for Image Restoration\u003c\/li\u003e\n\u003cli\u003ePredict, Prevent, and Evaluate: Disentangled Text-Driven Image Manipulation Empowered By Pre-Trained Vision-Language Model\u003c\/li\u003e\n\u003cli\u003eTransMix: Attend To Mix for Vision Transformers\u003c\/li\u003e\n\u003cli\u003eInertia-Guided Flow Completion and Style Fusion for Video Inpainting\u003c\/li\u003e\n\u003cli\u003eLong-Tailed Visual Recognition Via Gaussian Clouded Logit Adjustment\u003c\/li\u003e\n\u003cli\u003eImage Animation With Perturbed Masks\u003c\/li\u003e\n\u003cli\u003eDomain Generalization Via Shuffled Style Assembly for Face Anti-Spoofing\u003c\/li\u003e\n\u003cli\u003eOcclusionFusion: Occlusion-Aware Motion Estimation for Real-Time Dynamic 3D Reconstruction\u003c\/li\u003e\n\u003cli\u003eMonoScene: Monocular 3D Semantic Scene Completion\u003c\/li\u003e\n\u003cli\u003eAdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition\u003c\/li\u003e\n\u003cli\u003eContinuous Scene Representations for Embodied AI\u003c\/li\u003e\n\u003cli\u003eBeyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds\u003c\/li\u003e\n\u003cli\u003eNon-Probability Sampling Network for Stochastic Human Trajectory Prediction\u003c\/li\u003e\n\u003cli\u003eResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning\u003c\/li\u003e\n\u003cli\u003eHuman-Aware Object Placement for Visual Environment Reconstruction\u003c\/li\u003e\n\u003cli\u003eX-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval\u003c\/li\u003e\n\u003cli\u003eRAMA: A Rapid Multicut Algorithm on GPU\u003c\/li\u003e\n\u003cli\u003eAdversarial Parametric Pose Prior\u003c\/li\u003e\n\u003cli\u003eMask Transfiner for High-Quality Instance Segmentation\u003c\/li\u003e\n\u003cli\u003eIt Is Okay To Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning By Contrastive Data Collection\u003c\/li\u003e\n\u003cli\u003eDiRA: Discriminative, Restorative, and Adversarial Learning for Self-Supervised Medical Image Analysis\u003c\/li\u003e\n\u003cli\u003eEvent-Based Video Reconstruction Via Potential-Assisted Spiking Neural Network\u003c\/li\u003e\n\u003cli\u003eYouMVOS: An Actor-Centric Multi-Shot Video Object Segmentation Dataset\u003c\/li\u003e\n\u003cli\u003eDAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eJoint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification\u003c\/li\u003e\n\u003cli\u003eSelf-Supervised Video Transformer\u003c\/li\u003e\n\u003cli\u003eAutoRF: Learning 3D Object Radiance Fields From Single View Observations\u003c\/li\u003e\n\u003cli\u003eCoopernaut: End-to-End Driving With Cooperative Perception for Networked Vehicles\u003c\/li\u003e\n\u003cli\u003eTubeR: Tubelet Transformer for Video Action Detection\u003c\/li\u003e\n\u003cli\u003eMUM: Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection\u003c\/li\u003e\n\u003cli\u003eLearning Non-Target Knowledge for Few-Shot Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eUKPGAN: A General Self-Supervised Keypoint Detector\u003c\/li\u003e\n\u003cli\u003eRaw High-Definition Radar for Multi-Task Learning\u003c\/li\u003e\n\u003cli\u003eCoarse-To-Fine Feature Mining for Video Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eCompressing Models With Few Samples: Mimicking Then Replacing\u003c\/li\u003e\n\u003cli\u003ePokeBNN: A Binary Pursuit of Lightweight Accuracy\u003c\/li\u003e\n\u003cli\u003eZoom in and Out: A Mixed-Scale Triplet Network for Camouflaged Object Detection\u003c\/li\u003e\n\u003cli\u003eSOMSI: Spherical Novel View Synthesis With Soft Occlusion Multi-Sphere Images\u003c\/li\u003e\n\u003cli\u003eEMScore: Evaluating Video Captioning Via Coarse-Grained and Fine-Grained Embedding Matching\u003c\/li\u003e\n\u003cli\u003ePoseTriplet: Co-Evolving 3D Human Pose Estimation, Imitation, and Hallucination Under Self-Supervision\u003c\/li\u003e\n\u003cli\u003eGroup Contextualization for Video Recognition\u003c\/li\u003e\n\u003cli\u003eSingle-Domain Generalized Object Detection in Urban Scene Via Cyclic-Disentangled Self-Distillation\u003c\/li\u003e\n\u003cli\u003eL2G: A Simple Local-to-Global Knowledge Transfer Framework for Weakly Supervised Semantic Segmentation\u003c\/li\u003e\n\u003cli\u003eSelf-Augmented Unpaired Image Dehazing Via Density and Depth Decomposition\u003c\/li\u003e\n\u003cli\u003eNeural 3D Video Synthesis From Multi-View Video\u003c\/li\u003e\n\u003cli\u003eSemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation\u003c\/li\u003e\n\u003cli\u003eShapley-NAS: Discovering Operation Contribution for Neural Architecture Search\u003c\/li\u003e\n\u003cli\u003eHyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening\u003c\/li\u003e\n\u003cli\u003eStructure-Aware Flow Generation for Human Body Reshaping\u003c\/li\u003e\n\u003cli\u003eLearning To Answer Questions in Dynamic Audio-Visual Scenarios\u003c\/li\u003e\n\u003cli\u003eSynthetic Aperture Imaging With Events and Frames\u003c\/li\u003e\n\u003cli\u003eMonoGround: Detecting Monocular 3D Objects From The Ground\u003c\/li\u003e\n\u003cli\u003eDeep Visual Geo-Localization Benchmark\u003c\/li\u003e\n\u003cli\u003eStyleGAN-V: A Continuous Video Generator With The Price, Image Quality and Perks of StyleGAN2\u003c\/li\u003e\n\u003cli\u003eLISA: Learning Implicit Shape and Appearance of Hands\u003c\/li\u003e\n\u003cli\u003eIterative Deep Homography Estimation\u003c\/li\u003e\n\u003cli\u003eLearned Queries for Efficient Local Attention\u003c\/li\u003e\n\u003cli\u003eColar: Effective and Efficient Online Action Detection By Consulting Exemplars\u003c\/li\u003e\n\u003cli\u003eSoftGroup for 3D Instance Segmentation on Point Clouds\u003c\/li\u003e\n\u003cli\u003eMVS2D: Efficient Multi-View Stereo Via Attention-Driven 2D Convolutions\u003c\/li\u003e\n\u003cli\u003eBeyond Semantic to Instance Segmentation: Weakly-Supervised Instance Segmentation Via Semantic Knowledge Transfer and Self-Refinement\u003c\/li\u003e\n\u003cli\u003eDeep Constrained Least Squares for Blind Image Super-Resolution\u003c\/li\u003e\n\u003cli\u003eEDTER: Edge Detection With Transformer\u003c\/li\u003e\n\u003cli\u003eAirObject: A Temporally Evolving Graph Embedding for Object Identification\u003c\/li\u003e\n\u003cli\u003eFrom Representation to Reasoning: Towards Both Evidence and Commonsense Reasoning for Video Question-Answering\u003c\/li\u003e\n\u003cli\u003eSemantic-Aware Domain Generalized Segmentation\u003c\/li\u003e\n\u003cli\u003eDanceTrack: Multi-Object Tracking in Uniform Appearance and Diverse Motion\u003c\/li\u003e\n\u003cli\u003eUBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection\u003c\/li\u003e\n\u003cli\u003eAKB-48: A Real-World Articulated Object Knowledge Base\u003c\/li\u003e\n\u003cli\u003eStratified Transformer for 3D Point Cloud Segmentation\u003c\/li\u003e\n\u003cli\u003eAug-NeRF: Training Stronger Neural Radiance Fields With Triple-Level Physically-Grounded Augmentations\u003c\/li\u003e\n\u003cli\u003eSemantic-Shape Adaptive Feature Modulation for Semantic Image Synthesis\u003c\/li\u003e\n\u003cli\u003eDay-to-Night Image Synthesis for Training Nighttime Neural ISPs Literature ~Highlight: To address this problem, we propose a method that synthesizes nighttime images from daytime images.\u003c\/li\u003e\n\u003c\/ol\u003e\n\n\n\u003ch2 class=\u0022relative group\u0022\u003eReferences \n    \u003cdiv id=\u0022references\u0022 class=\u0022anchor\u0022\u003e\u003c\/div\u003e\n    \n    \u003cspan\n        class=\u0022absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\u0022\u003e\n        \u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022\n            style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#references\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\n    \u003c\/span\u003e        \n    \n\u003c\/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\u0022https:\/\/www.paperdigest.org\/2022\/06\/cvpr-2022-papers-with-code-data\/\u0022 target=\u0022_blank\u0022\u003ehttps:\/\/www.paperdigest.org\/2022\/06\/cvpr-2022-papers-with-code-data\/\u003c\/a\u003e\u003c\/li\u003e\n\u003c\/ul\u003e\n\u003cp\u003e\u003cstrong\u003eAuthor\u003c\/strong\u003e\u003cbr\u003e\nDr Hari Thapliyaal\u003cbr\u003e\ndasarpai.com \u003cbr\u003e\nlinkedin.com\/in\/harithapliyal\u003c\/p\u003e",
    "inLanguage": "en",
    "url" : "https:\/\/dasarpai.com\/dsblog\/paperwithcode-resources\/",
    "author" : {
      "@type": "Person",
      "name": "Hari Thapliyaal"
    },
    "copyrightYear": "2023",
    "dateCreated": "2023-08-22T00:00:00\u002b00:00",
    "datePublished": "2023-08-22T00:00:00\u002b00:00",
    
    "dateModified": "2023-08-22T00:00:00\u002b00:00",
    
    "keywords": ["Papers with Code","AI Implementation","Research Code","Machine Learning Resources","Deep Learning Code","Computer Vision Implementation","AI Research Resources"],
    
    "mainEntityOfPage": "true",
    "wordCount": "5601"
  }]
  </script>


  
  
  <meta name="author" content="Hari Thapliyaal" />
  
  
  

<script src="/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js" integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj&#43;KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script>






















  
  

<script async src="https://www.googletagmanager.com/gtag/js?id=G-PEDMYR1V0K"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PEDMYR1V0K');
</script>



  
  
  <meta name="theme-color"/>
  
  

  <link
  rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
/>

</head>
<body
  class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600">
  <div id="the-top" class="absolute flex self-center">
    <a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
      href="#main-content"><span
        class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a>
  </div>
  
  
  <div class="min-h-[148px]"></div>
<div class="fixed inset-x-0 pl-[24px] pr-[24px]" style="z-index:100">
  <div id="menu-blur" class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div>
  <div class="relative max-w-[64rem] ml-auto mr-auto">
    <div style="padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px"
    class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3">
    
    <div class="flex flex-1 items-center justify-between">
        <nav class="flex space-x-3">

            
            <a href="/" class="text-base font-medium text-gray-500 hover:text-gray-900"></a>
            

        </nav>
        <nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12">

            
            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Home
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/aboutme"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            About Me
          </p>
        </a>
        
        <a href="/clients"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Clients
          </p>
        </a>
        
        <a href="/dscourses"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            DS/AI Courses/Services
          </p>
        </a>
        
        <a href="/corpus-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            History Corpus
          </p>
        </a>
        
        <a href="/management"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PM Courses/Services
          </p>
        </a>
        
        <a href="/project-index-page"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Project/Work Catalog
          </p>
        </a>
        
        <a href="/publications-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Publications
          </p>
        </a>
        
        <a href="/testimonials"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Testimonial
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Data Science
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/news"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            AI and Business News
          </p>
        </a>
        
        <a href="/dsblog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Data Science Blog
          </p>
        </a>
        
        <a href="/dsblog/data-science-cheatsheets"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Data Science Cheatsheets
          </p>
        </a>
        
        <a href="/datascience-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Data Science Topics
          </p>
        </a>
        
        <a href="/dsblog/ds-ai-ml-books"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Data Science-Books
          </p>
        </a>
        
        <a href="/dsblog/ds-ai-ml-interview-resources"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            DS Interview Questions
          </p>
        </a>
        
        <a href="/datascience-resources"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            DS Resources
          </p>
        </a>
        
        <a href="/dsblog/best-youtube-channels-for-ds"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Video Channels to Learn DS
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Project Management
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/pmglossary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PM Glossary
          </p>
        </a>
        
        <a href=""  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PM Resources
          </p>
        </a>
        
        <a href="/pmlogy-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PM Topics
          </p>
        </a>
        
        <a href="/pmbok6-summary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PMBOK6
          </p>
        </a>
        
        <a href="/pmbok6"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PMBOK6 Explorer
          </p>
        </a>
        
        <a href="/pmbok6-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PMBOK6 Topics
          </p>
        </a>
        
        <a href="/pmblog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PMLOGY Blog
          </p>
        </a>
        
        <a href="/pmlogy-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PMLOGY Home
          </p>
        </a>
        
        <a href=""  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Project Management Hindi
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      SpiritualDrops
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/booksummary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Book Summary
          </p>
        </a>
        
        <a href="/gk"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            GK Blog
          </p>
        </a>
        
        <a href="/gk-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            GK Topic
          </p>
        </a>
        
        <a href="/wiaposts"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            WIA Blog
          </p>
        </a>
        
        <a href="/wia-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            WIA Home
          </p>
        </a>
        
        <a href="/quotations-blog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            WIA Quotes
          </p>
        </a>
        
        <a href="/wia-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            WIA Topics
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  href="/gallary"   class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Gallery
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/gallary/slider-pm-selected-photos"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Management Classes
          </p>
        </a>
        
        <a href="/gallary/slider-online-sessions1"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Online AI Classes 1
          </p>
        </a>
        
        <a href="/gallary/slider-online-sessions2"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Online AI Classes 2
          </p>
        </a>
        
        <a href="/gallary/slider-online-sessions3"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Online AI Classes 3
          </p>
        </a>
        
        <a href="/gallary/slider-online-sessions4"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Online AI Classes 4
          </p>
        </a>
        
        <a href="/gallary/slider-pm-workshops"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PM &amp; DS Workshop Photos
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Samskrut
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/mychanting"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            My Vedic Chantings
          </p>
        </a>
        
        <a href="/samskrutyatra"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Samskrut Blog
          </p>
        </a>
        
        <a href="/samskrutyatra-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Samskrut Topics
          </p>
        </a>
        
        <a href="/samskrutyatra-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            SamskrutYatra Home
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
            

            


            
            <button id="search-button" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            


            
            
            <div
                class=" flex items-center">
                <button id="appearance-switcher" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400">
                    <div class="flex items-center justify-center dark:hidden">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                    </div>
                    <div class="items-center justify-center hidden dark:flex">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                    </div>
                </button>
            </div>
            

        </nav>
        <div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12">

            <span></span>

            


            
            <button id="search-button-mobile" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            

            
            
            <button id="appearance-switcher-mobile" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400 ltr:mr-1 rtl:ml-1">
                <div class="flex items-center justify-center dark:hidden">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                </div>
                <div class="items-center justify-center hidden dark:flex">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                </div>
            </button>
            

        </div>
    </div>
    <div class="-my-2 md:hidden">

        <label id="menu-button" class="block">
            
            <div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400">
                

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>

  </span>


            </div>
            <div id="menu-wrapper" style="padding-top:5px;"
                class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50">
                <ul
                    class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl">

                    <li id="menu-close-button">
                        <span
                            class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>

</span>
                    </li>

                    

                     
  <li class="mt-1">
    <a href="" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Home
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/aboutme"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            About Me
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/clients"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Clients
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dscourses"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            DS/AI Courses/Services
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/corpus-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            History Corpus
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/management"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PM Courses/Services
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/project-index-page"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Project/Work Catalog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/publications-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Publications
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/testimonials"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Testimonial
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a href="" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Data Science
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/news"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            AI and Business News
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dsblog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Data Science Blog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dsblog/data-science-cheatsheets"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Data Science Cheatsheets
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/datascience-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Data Science Topics
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dsblog/ds-ai-ml-books"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Data Science-Books
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dsblog/ds-ai-ml-interview-resources"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            DS Interview Questions
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/datascience-resources"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            DS Resources
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dsblog/best-youtube-channels-for-ds"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Video Channels to Learn DS
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a href="" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Project Management
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/pmglossary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PM Glossary
        </p>
    </a>
</li>

<li class="mt-1">
    <a href=""  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PM Resources
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmlogy-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PM Topics
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmbok6-summary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PMBOK6
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmbok6"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PMBOK6 Explorer
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmbok6-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PMBOK6 Topics
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmblog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PMLOGY Blog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmlogy-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PMLOGY Home
        </p>
    </a>
</li>

<li class="mt-1">
    <a href=""  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Project Management Hindi
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a href="" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            SpiritualDrops
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/booksummary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Book Summary
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gk"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            GK Blog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gk-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            GK Topic
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/wiaposts"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            WIA Blog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/wia-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            WIA Home
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/quotations-blog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            WIA Quotes
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/wia-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            WIA Topics
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a href="/gallary" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Gallery
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-pm-selected-photos"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Management Classes
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-online-sessions1"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Online AI Classes 1
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-online-sessions2"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Online AI Classes 2
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-online-sessions3"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Online AI Classes 3
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-online-sessions4"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Online AI Classes 4
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-pm-workshops"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PM &amp; DS Workshop Photos
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a href="" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Samskrut
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/mychanting"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            My Vedic Chantings
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/samskrutyatra"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Samskrut Blog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/samskrutyatra-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Samskrut Topics
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/samskrutyatra-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            SamskrutYatra Home
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                </ul>
                
                

            </div>
        </label>
    </div>
</div>




<script>
    (function () {
        var $mainmenu = $('.main-menu');
        var path = window.location.pathname;
        $mainmenu.find('a[href="' + path + '"]').each(function (i, e) {
            $(e).children('p').addClass('active');
        });
    })();
</script>


  </div>
</div>
<script>
  window.addEventListener('scroll', function (e) {
    var scroll = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop || 0;
    var background_blur = document.getElementById('menu-blur');
    background_blur.style.opacity = (scroll / 300);
  });
</script>

  
  <div class="relative flex flex-col grow">
    <main id="main-content" class="grow">
      


<style>
  .article-content img {
    width: 100%;
    max-width: 100vw;
    height: auto;
    object-fit: contain;
    margin-left: 50%;
    transform: translateX(-50%);
  }
  @media (max-width: 768px) {
    .article-content img {
      width: 100%;
      margin-left: 0;
      transform: none;
    }
  }
</style>

<article>
  

  <header id="single_header" class="mt-5">
    
      <ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden">
  
  
    
  
    
  
  <li class="hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/"
      >dasarpAI</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="inline">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/dsblog/"
      >Data Science Blog</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/dsblog/paperwithcode-resources/"
      >Paper with Code Resources</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

</ol>


    

    <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
      Paper with Code Resources
    </h1>

    <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
      





  
  







  





  



  











  



<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2023-08-22T00:00:00&#43;00:00">22 August 2023</time><span class="px-2 text-primary-500">&middot;</span><span>5601 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">27 mins</span><span class="px-2 text-primary-500">&middot;</span>


<script type="text/javascript" src="/js/zen-mode.min.eea5245cf9244ecbdf2c150d1c8833226c1541cadf6e98f63a7c9192b1a3676df2c3ec603b14f4cfaaa53971fd9d8955640c0f405bf3de2b43ee7a5fb29ae721.js" integrity="sha512-7qUkXPkkTsvfLBUNHIgzImwVQcrfbpj2OnyRkrGjZ23yw&#43;xgOxT0z6qlOXH9nYlVZAwPQFvz3itD7npfsprnIQ=="></script>

<span class="mb-[2px]">
    <span id="zen-mode-button"
          class="text-lg hover:text-primary-500"
          title="Enable zen mode"
          data-title-i18n-disable="Enable zen mode"
          data-title-i18n-enable="Disable zen mode">
        <span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="50px" height="50px">
    <path fill="currentColor" d="M 12.980469 4 C 9.1204688 4 5.9804688 7.14 5.9804688 11 L 6 26 L 9.9804688 26 L 9.9804688 11 C 9.9804688 9.35 11.320469 8 12.980469 8 L 40.019531 8 C 41.679531 8 43.019531 9.35 43.019531 11 L 43.019531 39 C 43.019531 40.65 41.679531 42 40.019531 42 L 29 42 C 29 43.54 28.420938 44.94 27.460938 46 L 40.019531 46 C 43.879531 46 47.019531 42.86 47.019531 39 L 47.019531 11 C 47.019531 7.14 43.879531 4 40.019531 4 L 12.980469 4 z M 7 28 C 4.794 28 3 29.794 3 32 L 3 42 C 3 44.206 4.794 46 7 46 L 23 46 C 25.206 46 27 44.206 27 42 L 27 32 C 27 29.794 25.206 28 23 28 L 7 28 z M 7 32 L 23 32 L 23.001953 42 L 7 42 L 7 32 z"/>
</svg>
  </span>

</span>
    </span>
</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/research-implementation/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Research Implementation
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ml-libraries/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    ML Libraries
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/code-resources/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Code Resources
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-development/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Development
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/machine-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Machine Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/computer-vision/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Computer Vision
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/research-papers/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Research Papers
  </span>
</span>
  </span>
  
  
  
  
</div>




    </div>

    

    
    

    

    
      

      

      
    
  </header>

  <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
    
    
    

    
      <div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8">
        <div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]">
          
            <h4>On This Page</h4>
<details open id="TOCView"
  class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block">
  <summary
    class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    Table of Contents
  </summary>
  <div
    class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#trending-papers-of-2021">Trending Papers of 2021</a></li>
    <li><a href="#trending-libaries-of-2021">Trending Libaries of 2021</a></li>
    <li><a href="#top-dataset---2021">Top Dataset - 2021</a></li>
    <li><a href="#papers-of-2022">Papers of 2022</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
  </div>
</details>
<details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden">
  <summary
    class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    Table of Contents
  </summary>
  <div
    class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#trending-papers-of-2021">Trending Papers of 2021</a></li>
    <li><a href="#trending-libaries-of-2021">Trending Libaries of 2021</a></li>
    <li><a href="#top-dataset---2021">Top Dataset - 2021</a></li>
    <li><a href="#papers-of-2022">Papers of 2022</a></li>
    <li><a href="#references">References</a></li>
  </ul>
</nav>
  </div>
</details>

<script>

  var margin = 200;
  var marginError = 50;

  (function () {
    var $window = $(window);
    var $toc = $('#TOCView');
    var tocHeight = $toc.height();

    function onResize() {
      var windowAndMarginHeight = $window.height() - margin;
      if(tocHeight >= windowAndMarginHeight) {
        $toc.css("overflow-y", "scroll")
        $toc.css("max-height", (windowAndMarginHeight + marginError) + "px")
      } else {
        $toc.css("overflow-y", "hidden")
        $toc.css("max-height", "9999999px")
      }
    }

    $window.on('resize', onResize);
    $(document).ready(onResize);
  })();



  (function () {
    var $toc = $('#TableOfContents');
    if ($toc.length > 0) {
      var $window = $(window);

      function onScroll() {
        var currentScroll = $window.scrollTop();
        var h = $('.anchor');
        var id = "";
        h.each(function (i, e) {
          e = $(e);
          if (e.offset().top - $(window).height()/3 <= currentScroll) {
            id = decodeURIComponent(e.attr('id'));
          }
        });
        var active = $toc.find('a.active');      
        if (active.length == 1 && active.eq(0).attr('href') == '#' + id) return true;

        active.each(function (i, e) {
          
            $(e).removeClass('active');
          
        });
        $toc.find('a[href="#' + id + '"]').addClass('active')
        $toc.find('a[href="#' + id + '"]').parentsUntil('#TableOfContents').each(function (i, e) {
          $(e).children('a').parents('ul').show();          
        });
      }

      $window.on('scroll', onScroll);
      $(document).ready(function () {
        
        onScroll();
      });
    }
  })();


</script>

          
          
          
        </div>
      </div>
    

    <div class="min-w-0 min-h-0 max-w-fit">
      


      <div class="article-content mb-20">
        <p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="/assets/images/dspost/dsp6091-rps-Paperwithcode-Resources.jpg" alt="Paper with Code Resources" />
      
    </figure>
</p>


<h1 class="relative group">Paper with Code Resources 
    <div id="paper-with-code-resources" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#paper-with-code-resources" aria-label="Anchor">#</a>
    </span>        
    
</h1>


<h2 class="relative group">Trending Papers of 2021 
    <div id="trending-papers-of-2021" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#trending-papers-of-2021" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<ol>
<li>ADOP: Approximate Differentiable One-Pixel Point Rendering — Rückert et al — <a href="https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel" target="_blank">https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel</a></li>
<li>The Bayesian Learning Rule —Khan et al <a href="https://paperswithcode.com/paper/the-bayesian-learning-rule" target="_blank">https://paperswithcode.com/paper/the-bayesian-learning-rule</a></li>
<li>Program Synthesis with Large Language Models — Austin et al <a href="https://paperswithcode.com/paper/program-synthesis-with-large-language-models" target="_blank">https://paperswithcode.com/paper/program-synthesis-with-large-language-models</a></li>
<li>Masked Autoencoders Are Scalable Vision Learners — He et al <a href="https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision" target="_blank">https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision</a></li>
<li>8-bit Optimizers via Block-wise Quantization — Dettmers et al <a href="https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization" target="_blank">https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization</a></li>
<li>Revisiting ResNets: Improved Training and Scaling Strategies — Bello et al <a href="https://paperswithcode.com/paper/revisiting-resnets-improved-training-and" target="_blank">https://paperswithcode.com/paper/revisiting-resnets-improved-training-and</a></li>
<li>Image Super-Resolution via Iterative Refinement — Saharia et al <a href="https://paperswithcode.com/paper/image-super-resolution-via-iterative" target="_blank">https://paperswithcode.com/paper/image-super-resolution-via-iterative</a></li>
<li>Perceiver IO: A General Architecture for Structured Inputs &amp; Outputs — Jaegle et al <a href="https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for" target="_blank">https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for</a></li>
<li>Do Vision Transformers See Like Convolutional Neural Networks? — Raghu et al <a href="https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional" target="_blank">https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional</a></li>
<li>Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions — Niepert et al <a href="https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete" target="_blank">https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete</a></li>
</ol>


<h2 class="relative group">Trending Libaries of 2021 
    <div id="trending-libaries-of-2021" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#trending-libaries-of-2021" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<ol>
<li>PyTorch Image Models — Ross Wightman — <a href="https://github.com/rwightman/pytorch-image-models" target="_blank">https://github.com/rwightman/pytorch-image-models</a></li>
<li>Transformers — Hugging Face — <a href="https://github.com/huggingface/transformers" target="_blank">https://github.com/huggingface/transformers</a></li>
<li>PyTorch-GAN — Erik Linder-Norén — <a href="https://github.com/eriklindernoren/PyTorch-GAN" target="_blank">https://github.com/eriklindernoren/PyTorch-GAN</a></li>
<li>MMDetection — OpenMMLab — <a href="https://github.com/open-mmlab/mmdetection" target="_blank">https://github.com/open-mmlab/mmdetection</a></li>
<li>Darknet — AlexeyAB — <a href="https://github.com/AlexeyAB/darknet" target="_blank">https://github.com/AlexeyAB/darknet</a></li>
<li>Vision Transformer PyTorch — lucidrains — <a href="https://github.com/lucidrains/vit-pytorch" target="_blank">https://github.com/lucidrains/vit-pytorch</a></li>
<li>InsightFace — DeepInsight — <a href="https://github.com/deepinsight/insightface" target="_blank">https://github.com/deepinsight/insightface</a></li>
<li>Detectron2 — Meta AI — <a href="https://github.com/facebookresearch/detectron2" target="_blank">https://github.com/facebookresearch/detectron2</a></li>
<li>PaddleOCR — PaddlePaddle — <a href="https://github.com/PaddlePaddle/PaddleOCR" target="_blank">https://github.com/PaddlePaddle/PaddleOCR</a></li>
<li>FairSeq — Meta AI — <a href="https://github.com/pytorch/fairseq" target="_blank">https://github.com/pytorch/fairseq</a></li>
</ol>


<h2 class="relative group">Top Dataset - 2021 
    <div id="top-dataset---2021" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#top-dataset---2021" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<ol>
<li>MATH — Hendrycks et al <a href="https://paperswithcode.com/dataset/math" target="_blank">https://paperswithcode.com/dataset/math</a></li>
<li>UAV-Human — Li et al <a href="https://paperswithcode.com/dataset/uav-human" target="_blank">https://paperswithcode.com/dataset/uav-human</a></li>
<li>UPFD (User Preference-aware Fake News Detection) — Dou et al <a href="https://paperswithcode.com/dataset/upfd" target="_blank">https://paperswithcode.com/dataset/upfd</a></li>
<li>OGB-LSC (OGB Large-Scale Challenge) — Hu et al <a href="https://paperswithcode.com/dataset/ogb-lsc" target="_blank">https://paperswithcode.com/dataset/ogb-lsc</a></li>
<li>CodeXGLUE —Lu et al <a href="https://paperswithcode.com/dataset/codexglue" target="_blank">https://paperswithcode.com/dataset/codexglue</a></li>
<li>AGORA — Patel et al <a href="https://paperswithcode.com/dataset/agora" target="_blank">https://paperswithcode.com/dataset/agora</a></li>
<li>BEIR (Benchmarking IR) — Thakur et al <a href="https://paperswithcode.com/dataset/beir" target="_blank">https://paperswithcode.com/dataset/beir</a></li>
<li>WikiGraphs — Wang et al <a href="https://paperswithcode.com/dataset/wikigraphs" target="_blank">https://paperswithcode.com/dataset/wikigraphs</a></li>
<li>Few-NERD — Ding et al <a href="https://paperswithcode.com/dataset/few-nerd" target="_blank">https://paperswithcode.com/dataset/few-nerd</a></li>
<li>PASS (Pictures without humAns for Self-Supervision) —Asano et al <a href="https://paperswithcode.com/dataset/pass" target="_blank">https://paperswithcode.com/dataset/pass</a></li>
</ol>


<h2 class="relative group">Papers of 2022 
    <div id="papers-of-2022" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#papers-of-2022" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<ol>
<li>Controllable Animation of Fluid Elements in Still Images</li>
<li>F-SfT: Shape-From-Template With A Physics-Based Deformation Model</li>
<li>TWIST: Two-Way Inter-Label Self-Training for Semi-Supervised 3D Instance Segmentation</li>
<li>Do Learned Representations Respect Causal Relationships?</li>
<li>ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic</li>
<li>3D Moments From Near-Duplicate Photos</li>
<li>Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization</li>
<li>Blind2Unblind: Self-Supervised Image Denoising With Visible Blind Spots</li>
<li>Balanced and Hierarchical Relation Learning for One-Shot Object Detection</li>
<li>NICE-SLAM: Neural Implicit Scalable Encoding for SLAM</li>
<li>Stochastic Trajectory Prediction Via Motion Indeterminacy Diffusion</li>
<li>CLRNet: Cross Layer Refinement Network for Lane Detection</li>
<li>Motion-Aware Contrastive Video Representation Learning Via Foreground-Background Merging</li>
<li>DINE: Domain Adaptation From Single and Multiple Black-Box Predictors</li>
<li>FaceFormer: Speech-Driven 3D Facial Animation With Transformers</li>
<li>Rotationally Equivariant 3D Object Detection</li>
<li>Accelerating DETR Convergence Via Semantic-Aligned Matching</li>
<li>Cloning Outfits From Real-World Images to 3D Characters for Generalizable Person Re-Identification</li>
<li>GeoNeRF: Generalizing NeRF With Geometry Priors</li>
<li>ABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo</li>
<li>Expanding Low-Density Latent Regions for Open-Set Object Detection</li>
<li>Uformer: A General U-Shaped Transformer for Image Restoration</li>
<li>Exploring Dual-Task Correlation for Pose Guided Person Image Generation</li>
<li>Portrait Eyeglasses and Shadow Removal By Leveraging 3D Synthetic Data</li>
<li>Modeling 3D Layout for Group Re-Identification</li>
<li>Toward Fast, Flexible, and Robust Low-Light Image Enhancement</li>
<li>Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos</li>
<li>HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network</li>
<li>Modular Action Concept Grounding in Semantic Video Prediction</li>
<li>StyleSwin: Transformer-Based GAN for High-Resolution Image Generation</li>
<li>Discrete Cosine Transform Network for Guided Depth Map Super-Resolution</li>
<li>Cerberus Transformer: Joint Semantic, Affordance and Attribute Parsing</li>
<li>TransGeo: Transformer Is All You Need for Cross-View Image Geo-Localization</li>
<li>Contrastive Boundary Learning for Point Cloud Segmentation</li>
<li>Details or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution</li>
<li>CVNet: Contour Vibration Network for Building Extraction</li>
<li>Swin Transformer V2: Scaling Up Capacity and Resolution</li>
<li>Projective Manifold Gradient Layer for Deep Rotation Regression</li>
<li>HCSC: Hierarchical Contrastive Selective Coding</li>
<li>TransRank: Self-Supervised Video Representation Learning Via Ranking-Based Transformation Recognition</li>
<li>DiSparse: Disentangled Sparsification for Multitask Model Compression</li>
<li>Pushing The Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make A Difference</li>
<li>Towards Efficient and Scalable Sharpness-Aware Minimization</li>
<li>OSSO: Obtaining Skeletal Shape From Outside</li>
<li>A Study on The Distribution of Social Biases in Self-Supervised Learning Visual Models</li>
<li>Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes</li>
<li>Comparing Correspondences: Video Prediction With Correspondence-Wise Losses</li>
<li>Towards Fewer Annotations: Active Learning Via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation</li>
<li>CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding</li>
<li>Few Shot Generative Model Adaption Via Relaxed Spatial Structural Alignment</li>
<li>Enhancing Adversarial Training With Second-Order Statistics of Weights</li>
<li>Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo</li>
<li>Moving Window Regression: A Novel Approach to Ordinal Regression</li>
<li>Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection</li>
<li>Robust Optimization As Data Augmentation for Large-Scale Graphs</li>
<li>Robust Structured Declarative Classifiers for 3D Point Clouds: Defending Adversarial Attacks With Implicit Gradients</li>
<li>Improving The Transferability of Targeted Adversarial Examples Through Object-Based Diverse Input</li>
<li>ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer</li>
<li>360MonoDepth: High-Resolution 360deg Monocular Depth Estimation</li>
<li>POCO: Point Convolution for Surface Reconstruction</li>
<li>Neural Texture Extraction and Distribution for Controllable Person Image Synthesis</li>
<li>Classification-Then-Grounding: Reformulating Video Scene Graphs As Temporal Bipartite Graphs</li>
<li>DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis</li>
<li>ZeroWaste Dataset: Towards Deformable Object Segmentation in Cluttered Scenes</li>
<li>UNIST: Unpaired Neural Implicit Shape Translation Network</li>
<li>APES: Articulated Part Extraction From Sprite Sheets</li>
<li>SPAct: Self-Supervised Privacy Preservation for Action Recognition</li>
<li>De-Rendering 3D Objects in The Wild</li>
<li>Global Sensing and Measurements Reuse for Image Compressed Sensing</li>
<li>Practical Evaluation of Adversarial Robustness Via Adaptive Auto Attack</li>
<li>Cross-View Transformers for Real-Time Map-View Semantic Segmentation</li>
<li>Controllable Dynamic Multi-Task Architectures</li>
<li>FastDOG: Fast Discrete Optimization on GPU</li>
<li>Focal and Global Knowledge Distillation for Detectors</li>
<li>Learning To Prompt for Continual Learning</li>
<li>Human Mesh Recovery From Multiple Shots</li>
<li>Convolution of Convolution: Let Kernels Spatially Collaborate</li>
<li>Make It Move: Controllable Image-to-Video Generation With Text Descriptions</li>
<li>Neural Points: Point Cloud Representation With Neural Fields for Arbitrary Upsampling</li>
<li>Video-Text Representation Learning Via Differentiable Weak Temporal Alignment</li>
<li>Bi-Directional Object-Context Prioritization Learning for Saliency Ranking</li>
<li>Vehicle Trajectory Prediction Works, But Not Everywhere</li>
<li>MonoDTR: Monocular 3D Object Detection With Depth-Aware Transformer</li>
<li>Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-Shot Learning</li>
<li>Generalized Category Discovery</li>
<li>Contour-Hugging Heatmaps for Landmark Detection</li>
<li>Voxel Field Fusion for 3D Object Detection</li>
<li>DisARM: Displacement Aware Relation Module for 3D Detection</li>
<li>MixFormer: Mixing Features Across Windows and Dimensions</li>
<li>FineDiving: A Fine-Grained Dataset for Procedure-Aware Action Quality Assessment</li>
<li>HEAT: Holistic Edge Attention Transformer for Structured Reconstruction</li>
<li>Mobile-Former: Bridging MobileNet and Transformer</li>
<li>CycleMix: A Holistic Strategy for Medical Image Segmentation From Scribble Supervision</li>
<li>VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution</li>
<li>Towards End-to-End Unified Scene Text Detection and Layout Analysis</li>
<li>AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation</li>
<li>ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior</li>
<li>End-to-End Referring Video Object Segmentation With Multimodal Transformers</li>
<li>IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo</li>
<li>Not All Points Are Equal: Learning Highly Efficient Point-Based Detectors for 3D LiDAR Point Clouds</li>
<li>Detecting Camouflaged Object in Frequency Domain</li>
<li>SelfRecon: Self Reconstruction Your Digital Avatar From Monocular Video</li>
<li>Equivariant Point Cloud Analysis Via Learning Orientations for Message Passing</li>
<li>Node Representation Learning in Graph Via Node-to-Neighbourhood Mutual Information Maximization</li>
<li>Semi-Supervised Video Semantic Segmentation With Inter-Frame Feature Reconstruction</li>
<li>Amodal Segmentation Through Out-of-Task and Out-of-Distribution Generalization With A Bayesian Model</li>
<li>How Well Do Sparse ImageNet Models Transfer?</li>
<li>REX: Reasoning-Aware and Grounded Explanation</li>
<li>Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes</li>
<li>Object-Aware Video-Language Pre-Training for Retrieval</li>
<li>MAT: Mask-Aware Transformer for Large Hole Image Inpainting</li>
<li>Align and Prompt: Video-and-Language Pre-Training With Entity Prompts</li>
<li>MSG-Transformer: Exchanging Local Spatial Information By Manipulating Messenger Tokens</li>
<li>Cross Modal Retrieval With Querybank Normalisation</li>
<li>Ray3D: Ray-Based 3D Human Pose Estimation for Monocular Absolute 3D Localization</li>
<li>ASM-Loc: Action-Aware Segment Modeling for Weakly-Supervised Temporal Action Localization</li>
<li>Scaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs</li>
<li>End-to-End Multi-Person Pose Estimation With Transformers</li>
<li>REGTR: End-to-End Point Cloud Correspondences With Transformers</li>
<li>Neural 3D Scene Reconstruction With The Manhattan-World Assumption</li>
<li>V2C: Visual Voice Cloning</li>
<li>Revisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection</li>
<li>MAD: A Scalable Dataset for Language Grounding in Videos From Movie Audio Descriptions</li>
<li>Gait Recognition in The Wild With Dense 3D Representations and A Benchmark</li>
<li>ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation Via Online Exploration and Synthesis</li>
<li>QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection</li>
<li>IDEA-Net: Dynamic 3D Point Cloud Interpolation Via Deep Embedding Alignment</li>
<li>BEHAVE: Dataset and Method for Tracking Human Object Interactions</li>
<li>Revisiting Random Channel Pruning for Neural Network Compression</li>
<li>Generating Diverse and Natural 3D Human Motions From Text</li>
<li>E-CIR: Event-Enhanced Continuous Intensity Recovery</li>
<li>Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond</li>
<li>Symmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose Estimation</li>
<li>AziNorm: Exploiting The Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception</li>
<li>Weakly Supervised Rotation-Invariant Aerial Object Detection Network</li>
<li>Surface Reconstruction From Point Clouds By Learning Predictive Context Priors</li>
<li>IRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes</li>
<li>DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation</li>
<li>Weakly Supervised Temporal Action Localization Via Representative Snippet Knowledge Propagation</li>
<li>E2EC: An End-to-End Contour-Based Method for High-Quality High-Speed Instance Segmentation</li>
<li>BatchFormer: Learning To Explore Sample Relationships for Robust Representation Learning</li>
<li>Self-Supervised Image-Specific Prototype Exploration for Weakly Supervised Semantic Segmentation</li>
<li>Learning Multi-View Aggregation in The Wild for Large-Scale 3D Semantic Segmentation</li>
<li>PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition</li>
<li>Clothes-Changing Person Re-Identification With RGB Modality Only</li>
<li>Robust Image Forgery Detection Over Online Social Network Shared Images</li>
<li>Representation Compensation Networks for Continual Semantic Segmentation</li>
<li>Tracking People By Predicting 3D Appearance, Location and Pose</li>
<li>Text2Mesh: Text-Driven Neural Stylization for Meshes</li>
<li>C-CAM: Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image</li>
<li>Forward Compatible Few-Shot Class-Incremental Learning</li>
<li>Weakly Supervised Object Localization As Domain Adaption</li>
<li>Tencent-MVSE: A Large-Scale Benchmark Dataset for Multi-Modal Video Similarity Evaluation</li>
<li>Deep Orientation-Aware Functional Maps: Tackling Symmetry Issues in Shape Matching</li>
<li>Tree Energy Loss: Towards Sparsely Annotated Semantic Segmentation</li>
<li>MatteFormer: Transformer-Based Image Matting Via Prior-Tokens</li>
<li>Video Shadow Detection Via Spatio-Temporal Interpolation Consistency Training</li>
<li>Robust and Accurate Superquadric Recovery: A Probabilistic Approach</li>
<li>Grounding Answers for Visual Questions Asked By Visually Impaired People</li>
<li>Sparse Instance Activation for Real-Time Instance Segmentation</li>
<li>VisualGPT: Data-Efficient Adaptation of Pretrained Language Models for Image Captioning</li>
<li>MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation</li>
<li>Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis</li>
<li>Towards Implicit Text-Guided 3D Shape Generation</li>
<li>SoftCollage: A Differentiable Probabilistic Tree Generator for Image Collage</li>
<li>Query and Attention Augmentation for Knowledge-Based Explainable Reasoning</li>
<li>Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality</li>
<li>Progressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection</li>
<li>Fine-Grained Object Classification Via Self-Supervised Pose Alignment</li>
<li>Animal Kingdom: A Large and Diverse Dataset for Animal Behavior Understanding</li>
<li>Fine-Grained Temporal Contrastive Learning for Weakly-Supervised Temporal Action Localization</li>
<li>Relieving Long-Tailed Instance Segmentation Via Pairwise Class Balance</li>
<li>Online Convolutional Re-Parameterization</li>
<li>Mimicking The Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning</li>
<li>RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition</li>
<li>Personalized Image Aesthetics Assessment With Rich Attributes</li>
<li>Part-Based Pseudo Label Refinement for Unsupervised Person Re-Identification</li>
<li>HDNet: High-Resolution Dual-Domain Learning for Spectral Compressive Imaging</li>
<li>OW-DETR: Open-World Detection Transformer</li>
<li>Learning Deep Implicit Functions for 3D Shapes With Dynamic Code Clouds</li>
<li>Reversible Vision Transformers</li>
<li>Amodal Panoptic Segmentation</li>
<li>Correlation Verification for Image Retrieval</li>
<li>Temporal Feature Alignment and Mutual Information Maximization for Video-Based Human Pose Estimation</li>
<li>Self-Supervised Transformers for Unsupervised Object Discovery Using Normalized Cut</li>
<li>Exploring Structure-Aware Transformer Over Interaction Proposals for Human-Object Interaction Detection</li>
<li>Decoupled Multi-Task Learning With Cyclical Self-Regulation for Face Parsing</li>
<li>Glass: Geometric Latent Augmentation for Shape Spaces</li>
<li>DPICT: Deep Progressive Image Compression Using Trit-Planes</li>
<li>Text to Image Generation With Semantic-Spatial Aware GAN</li>
<li>Generalizable Cross-Modality Medical Image Segmentation Via Style Augmentation and Dual Normalization</li>
<li>Learning To Prompt for Open-Vocabulary Object Detection With Vision-Language Model</li>
<li>Interactive Segmentation and Visualization for Tiny Objects in Multi-Megapixel Images</li>
<li>Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture</li>
<li>Surface Representation for Point Clouds</li>
<li>Implicit Motion Handling for Video Camouflaged Object Detection</li>
<li>DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides</li>
<li>Learning With Twin Noisy Labels for Visible-Infrared Person Re-Identification</li>
<li>Optical Flow Estimation for Spiking Camera</li>
<li>GradViT: Gradient Inversion of Vision Transformers</li>
<li>Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution Via Cycle-Projected Mutual Learning</li>
<li>Joint Global and Local Hierarchical Priors for Learned Image Compression</li>
<li>Knowledge Distillation Via The Target-Aware Transformer</li>
<li>Subspace Adversarial Training</li>
<li>3D-VField: Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection</li>
<li>Image Segmentation Using Text and Image Prompts</li>
<li>AutoMine: An Unmanned Mine Dataset</li>
<li>Background Activation Suppression for Weakly Supervised Object Localization</li>
<li>Synthetic Generation of Face Videos With Plethysmograph Physiology</li>
<li>Hallucinated Neural Radiance Fields in The Wild</li>
<li>Global Tracking Transformers</li>
<li>Backdoor Attacks on Self-Supervised Learning</li>
<li>GMFlow: Learning Optical Flow Via Global Matching</li>
<li>Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation</li>
<li>Explore Spatio-Temporal Aggregation for Insubstantial Object Detection: Benchmark Dataset and Baseline</li>
<li>Graph-Based Spatial Transformer With Memory Replay for Multi-Future Pedestrian Trajectory Prediction</li>
<li>Scanline Homographies for Rolling-Shutter Plane Absolute Pose</li>
<li>AdaInt: Learning Adaptive Intervals for 3D Lookup Tables on Real-Time Image Enhancement</li>
<li>Recurrent Glimpse-Based Decoder for Detection With Transformer</li>
<li>SimMIM: A Simple Framework for Masked Image Modeling</li>
<li>Label Matching Semi-Supervised Object Detection</li>
<li>RegionCLIP: Region-Based Language-Image Pretraining</li>
<li>Video Frame Interpolation Transformer</li>
<li>BCOT: A Markerless High-Precision 3D Object Tracking Benchmark</li>
<li>Omni-DETR: Omni-Supervised Object Detection With Transformers</li>
<li>Transferable Sparse Adversarial Attack</li>
<li>CREAM: Weakly Supervised Object Localization Via Class RE-Activation Mapping</li>
<li>VALHALLA: Visual Hallucination for Machine Translation</li>
<li>HINT: Hierarchical Neuron Concept Explainer</li>
<li>Neural Face Identification in A 2D Wireframe Projection of A Manifold Object</li>
<li>Nonuniform-to-Uniform Quantization: Towards Accurate Quantization Via Generalized Straight-Through Estimation</li>
<li>An Empirical Study of End-to-End Temporal Action Detection</li>
<li>Object Localization Under Single Coarse Point Supervision</li>
<li>Unsupervised Learning of Accurate Siamese Tracking</li>
<li>Non-Parametric Depth Distribution Modelling Based Depth Inference for Multi-View Stereo</li>
<li>Equalized Focal Loss for Dense Long-Tailed Object Detection</li>
<li>DeepDPM: Deep Clustering With An Unknown Number of Clusters</li>
<li>ISDNet: Integrating Shallow and Deep Networks for Efficient Ultra-High Resolution Segmentation</li>
<li>Unsupervised Domain Adaptation for Nighttime Aerial Tracking</li>
<li>RestoreFormer: High-Quality Blind Face Restoration From Undegraded Key-Value Pairs</li>
<li>Mask-Guided Spectral-Wise Transformer for Efficient Hyperspectral Image Reconstruction</li>
<li>A Variational Bayesian Method for Similarity Learning in Non-Rigid Image Registration</li>
<li>Not Just Selection, But Exploration: Online Class-Incremental Continual Learning Via Dual View Consistency</li>
<li>Coupling Vision and Proprioception for Navigation of Legged Robots</li>
<li>Exploiting Rigidity Constraints for LiDAR Scene Flow Estimation</li>
<li>EMOCA: Emotion Driven Monocular Face Capture and Animation</li>
<li>Quarantine: Sparsity Can Uncover The Trojan Attack Trigger for Free</li>
<li>AlignQ: Alignment Quantization With ADMM-Based Correlation Preservation</li>
<li>Interactive Multi-Class Tiny-Object Detection</li>
<li>Learning From Pixel-Level Noisy Label: A New Perspective for Light Field Saliency Detection</li>
<li>Multi-View Depth Estimation By Fusing Single-View Depth Probability With Multi-View Geometry</li>
<li>Slimmable Domain Adaptation</li>
<li>High-Resolution Image Harmonization Via Collaborative Dual Transformations</li>
<li>MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation</li>
<li>Self-Supervised Neural Articulated Shape and Appearance Models</li>
<li>Topology Preserving Local Road Network Estimation From Single Onboard Camera Image</li>
<li>Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes</li>
<li>SwinTextSpotter: Scene Text Spotting Via Better Synergy Between Text Detection and Text Recognition</li>
<li>Deblur-NeRF: Neural Radiance Fields From Blurry Images</li>
<li>Whose Track Is It Anyway? Improving Robustness to Tracking Errors With Affinity-Based Trajectory Prediction</li>
<li>Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation</li>
<li>Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning</li>
<li>Blind Image Super-Resolution With Elaborate Degradation Modeling on Noise and Kernel</li>
<li>Faithful Extreme Rescaling Via Generative Prior Reciprocated Invertible Representations</li>
<li>Proto2Proto: Can You Recognize The Car, The Way I Do?</li>
<li>TVConv: Efficient Translation Variant Convolution for Layout-Aware Visual Processing</li>
<li>Dual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution</li>
<li>Habitat-Web: Learning Embodied Object-Search Strategies From Human Demonstrations at Scale</li>
<li>Simple But Effective: CLIP Embeddings for Embodied AI</li>
<li>NomMer: Nominate Synergistic Context in Vision Transformer for Visual Recognition</li>
<li>Collaborative Transformers for Grounded Situation Recognition</li>
<li>CPPF: Towards Robust Category-Level 9D Pose Estimation in The Wild</li>
<li>Continual Test-Time Domain Adaptation</li>
<li>Dynamic MLP for Fine-Grained Image Classification By Leveraging Geographical and Temporal Information</li>
<li>MuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-Based Visual Question Answering</li>
<li>Fair Contrastive Learning for Facial Attribute Classification</li>
<li>Directional Self-Supervised Learning for Heavy Image Augmentations</li>
<li>No-Reference Point Cloud Quality Assessment Via Domain Adaptation</li>
<li>Comprehending and Ordering Semantics for Image Captioning</li>
<li>A Large-Scale Comprehensive Dataset and Copy-Overlap Aware Evaluation Protocol for Segment-Level Video Copy Detection</li>
<li>Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification</li>
<li>HeadNeRF: A Real-Time NeRF-Based Parametric Head Model</li>
<li>Occlusion-Robust Face Alignment Using A Viewpoint-Invariant Hierarchical Network Architecture</li>
<li>IDR: Self-Supervised Image Denoising Via Iterative Data Refinement</li>
<li>MogFace: Towards A Deeper Appreciation on Face Detection</li>
<li>Learning Affinity From Attention: End-to-End Weakly-Supervised Semantic Segmentation With Transformers</li>
<li>CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation</li>
<li>FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos</li>
<li>Learning To Detect Mobile Objects From LiDAR Scans Without Labels</li>
<li>WildNet: Learning Domain Generalized Semantic Segmentation From The Wild</li>
<li>DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection</li>
<li>Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation</li>
<li>Generating Diverse 3D Reconstructions From A Single Occluded Face Image</li>
<li>Stand-Alone Inter-Frame Attention in Video Models</li>
<li>Large-Scale Pre-Training for Person Re-Identification With Noisy Labels</li>
<li>Semantic Segmentation By Early Region Proxy</li>
<li>LD-ConGR: A Large RGB-D Video Dataset for Long-Distance Continuous Gesture Recognition</li>
<li>HVH: Learning A Hybrid Neural Volumetric Representation for Dynamic Hair Performance Capture</li>
<li>Rethinking Visual Geo-Localization for Large-Scale Applications</li>
<li>The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy</li>
<li>ViM: Out-of-Distribution With Virtual-Logit Matching</li>
<li>Class-Aware Contrastive Semi-Supervised Learning</li>
<li>Ditto: Building Digital Twins of Articulated Objects From Interaction</li>
<li>Adaptive Early-Learning Correction for Segmentation From Noisy Annotations</li>
<li>Cross-Domain Correlation Distillation for Unsupervised Domain Adaptation in Nighttime Semantic Segmentation</li>
<li>RSTT: Real-Time Spatial Temporal Transformer for Space-Time Video Super-Resolution</li>
<li>Partial Class Activation Attention for Semantic Segmentation</li>
<li>Multi-Scale Memory-Based Video Deblurring</li>
<li>A Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching</li>
<li>Geometric Structure Preserving Warp for Natural Image Stitching</li>
<li>GOAL: Generating 4D Whole-Body Motion for Hand-Object Grasping</li>
<li>Conditional Prompt Learning for Vision-Language Models</li>
<li>Graph Sampling Based Deep Metric Learning for Generalizable Person Re-Identification</li>
<li>Undoing The Damage of Label Shift for Cross-Domain Semantic Segmentation</li>
<li>FisherMatch: Semi-Supervised Rotation Regression Via Entropy-Based Filtering</li>
<li>Affine Medical Image Registration With Coarse-To-Fine Vision Transformer</li>
<li>A Differentiable Two-Stage Alignment Scheme for Burst Image Reconstruction With Large Shift</li>
<li>Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes</li>
<li>Restormer: Efficient Transformer for High-Resolution Image Restoration</li>
<li>IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation</li>
<li>Large Loss Matters in Weakly Supervised Multi-Label Classification</li>
<li>Neural Inertial Localization</li>
<li>GraftNet: Towards Domain Generalized Stereo Matching With A Broad-Spectrum and Task-Oriented Feature</li>
<li>VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning</li>
<li>Catching Both Gray and Black Swans: Open-Set Supervised Anomaly Detection</li>
<li>MLSLT: Towards Multilingual Sign Language Translation</li>
<li>Towards An End-to-End Framework for Flow-Guided Video Inpainting</li>
<li>Contrastive Test-Time Adaptation</li>
<li>MotionAug: Augmentation With Physical Correction for Human Motion Prediction</li>
<li>Modeling Indirect Illumination for Inverse Rendering</li>
<li>TransWeather: Transformer-Based Restoration of Images Degraded By Adverse Weather Conditions</li>
<li>H2FA R-CNN: Holistic and Hierarchical Feature Alignment for Cross-Domain Weakly Supervised Object Detection</li>
<li>P3Depth: Monocular Depth Estimation With A Piecewise Planarity Prior</li>
<li>GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection</li>
<li>Simple Multi-Dataset Detection</li>
<li>Proactive Image Manipulation Detection</li>
<li>StyTr2: Image Style Transfer With Transformers</li>
<li>Global Matching With Overlapping Attention for Optical Flow Estimation</li>
<li>Language As Queries for Referring Video Object Segmentation</li>
<li>MViTv2: Improved Multiscale Vision Transformers for Classification and Detection</li>
<li>Audio-Visual Generalised Zero-Shot Learning With Cross-Modal Attention and Language</li>
<li>Rethinking Efficient Lane Detection Via Curve Modeling</li>
<li>Self-Supervised Arbitrary-Scale Point Clouds Upsampling Via Implicit Neural Representation</li>
<li>Co-Advise: Cross Inductive Bias Distillation</li>
<li>AdaMixer: A Fast-Converging Query-Based Object Detector</li>
<li>DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification</li>
<li>BEVT: BERT Pretraining of Video Transformers</li>
<li>Deep Generalized Unfolding Networks for Image Restoration</li>
<li>VISOLO: Grid-Based Space-Time Aggregation for Efficient Online Video Instance Segmentation</li>
<li>Deep Unlearning Via Randomized Conditionally Independent Hessians</li>
<li>Revisiting Skeleton-Based Action Recognition</li>
<li>Stereo Depth From Events Cameras: Concentrate and Focus on The Future</li>
<li>A Simple Data Mixing Prior for Improving Self-Supervised Learning</li>
<li>Knowledge Distillation As Efficient Pre-Training: Faster Convergence, Higher Data-Efficiency, and Better Transferability</li>
<li>BigDL 2.0: Seamless Scaling of AI Pipelines From Laptops to Distributed Cluster</li>
<li>Attentive Fine-Grained Structured Sparsity for Image Restoration</li>
<li>Learning Fair Classifiers With Partially Annotated Group Labels</li>
<li>NightLab: A Dual-Level Architecture With Hardness Detection for Segmentation at Night</li>
<li>Constrained Few-Shot Class-Incremental Learning</li>
<li>Threshold Matters in WSSS: Manipulating The Activation for The Robust and Accurate Segmentation Model Against Thresholds</li>
<li>TransMVSNet: Global Context-Aware Multi-View Stereo Network With Transformers</li>
<li>DPGEN: Differentially Private Generative Energy-Guided Network for Natural Image Synthesis</li>
<li>The Majority Can Help The Minority: Context-Rich Minority Oversampling for Long-Tailed Classification</li>
<li>IntentVizor: Towards Generic Query Guided Interactive Video Summarization</li>
<li>Shape-Invariant 3D Adversarial Point Clouds</li>
<li>Bootstrapping ViTs: Towards Liberating Vision Transformers From Pre-Training</li>
<li>PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents</li>
<li>Meta-Attention for ViT-Backed Continual Learning</li>
<li>DST: Dynamic Substitute Training for Data-Free Black-Box Attack</li>
<li>Unified Contrastive Learning in Image-Text-Label Space</li>
<li>Unsupervised Pre-Training for Temporal Action Localization Tasks</li>
<li>Look Outside The Room: Synthesizing A Consistent Long-Term 3D Scene Video From A Single Image</li>
<li>High-Fidelity Human Avatars From A Single RGB Camera</li>
<li>Multiview Transformers for Video Recognition</li>
<li>How Good Is Aesthetic Ability of A Fashion Model?</li>
<li>Deformation and Correspondence Aware Unsupervised Synthetic-to-Real Scene Flow Estimation for Point Clouds</li>
<li>Sequential Voting With Relational Box Fields for Active Object Detection</li>
<li>Semantic-Aware Auto-Encoders for Self-Supervised Representation Learning</li>
<li>Consistency Learning Via Decoding Path Augmentation for Transformers in Human Object Interaction Detection</li>
<li>Consistent Explanations By Contrastive Learning</li>
<li>Hierarchical Modular Network for Video Captioning</li>
<li>Depth Estimation By Combining Binocular Stereo and Monocular Structured-Light</li>
<li>Salient-to-Broad Transition for Video Person Re-Identification</li>
<li>DeeCap: Dynamic Early Exiting for Efficient Image Captioning</li>
<li>RepMLPNet: Hierarchical Vision MLP With Re-Parameterized Locality</li>
<li>DR.VIC: Decomposition and Reasoning for Video Individual Counting</li>
<li>ARCS: Accurate Rotation and Correspondence Search</li>
<li>Learning To Anticipate Future With Dynamic Context Removal</li>
<li>GCFSR: A Generative and Controllable Face Super Resolution Method Without Facial and GAN Priors</li>
<li>On The Integration of Self-Attention and Convolution</li>
<li>Domain Adaptation on Point Clouds Via Geometry-Aware Implicits</li>
<li>GroupViT: Semantic Segmentation Emerges From Text Supervision</li>
<li>DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation</li>
<li>BppAttack: Stealthy and Efficient Trojan Attacks Against Deep Neural Networks Via Image Quantization and Contrastive Adversarial Learning</li>
<li>Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation</li>
<li>Towards Better Plasticity-Stability Trade-Off in Incremental Learning: A Simple Linear Connector</li>
<li>Topology-Preserving Shape Reconstruction and Registration Via Neural Diffeomorphic Flow</li>
<li>Segment and Complete: Defending Object Detectors Against Adversarial Patch Attacks With Robust Patch Detection</li>
<li>MAXIM: Multi-Axis MLP for Image Processing</li>
<li>Learning Part Segmentation Through Unsupervised Domain Adaptation From Synthetic Vehicles</li>
<li>PSTR: End-to-End One-Step Person Search With Transformers</li>
<li>NFormer: Robust Person Re-Identification With Neighbor Transformer</li>
<li>Bridging Global Context Interactions for High-Fidelity Image Completion</li>
<li>SwinBERT: End-to-End Transformers With Sparse Attention for Video Captioning</li>
<li>Not All Tokens Are Equal: Human-Centric Visual Analysis Via Token Clustering Transformer</li>
<li>Temporally Efficient Vision Transformer for Video Instance Segmentation</li>
<li>The Devil Is in The Margin: Margin-Based Label Smoothing for Network Calibration</li>
<li>NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks</li>
<li>WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation</li>
<li>Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding</li>
<li>E2(GO)MOTION: Motion Augmented Event Stream for Egocentric Action Recognition</li>
<li>OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization</li>
<li>OnePose: One-Shot Object Pose Estimation Without CAD Models</li>
<li>Rethinking Minimal Sufficient Representation in Contrastive Learning</li>
<li>Scalable Penalized Regression for Noise Detection in Learning With Noisy Labels</li>
<li>Federated Class-Incremental Learning</li>
<li>Show, Deconfound and Tell: Image Captioning With Causal Inference</li>
<li>MobRecon: Mobile-Friendly Hand Mesh Reconstruction From Monocular Image</li>
<li>Parameter-Free Online Test-Time Adaptation</li>
<li>SIGMA: Semantic-Complete Graph Matching for Domain Adaptive Object Detection</li>
<li>No Pain, Big Gain: Classify Dynamic Point Cloud Sequences With Static Models By Fitting Feature-Level Space-Time Surfaces</li>
<li>HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for Snapshot Compressive Imaging</li>
<li>Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space</li>
<li>Learning To Estimate Robust 3D Human Mesh From In-the-Wild Crowded Scenes</li>
<li>Detecting Deepfakes With Self-Blended Images</li>
<li>Implicit Sample Extension for Unsupervised Person Re-Identification</li>
<li>Energy-Based Latent Aligner for Incremental Learning</li>
<li>Towards Semi-Supervised Deep Facial Expression Recognition With An Adaptive Confidence Margin</li>
<li>Group R-CNN for Weakly Semi-Supervised Object Detection With Points</li>
<li>Weakly-Supervised Action Transition Learning for Stochastic Human Motion Prediction</li>
<li>Hybrid Relation Guided Set Matching for Few-Shot Action Recognition</li>
<li>Cross-Patch Dense Contrastive Learning for Semi-Supervised Segmentation of Cellular Nuclei in Histopathologic Images</li>
<li>Generalized Binary Search Network for Highly-Efficient Multi-View Stereo</li>
<li>SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation</li>
<li>FlexIT: Towards Flexible Semantic Image Translation</li>
<li>CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow</li>
<li>BoxeR: Box-Attention for 2D and 3D Transformers</li>
<li>Neural Architecture Search With Representation Mutual Information</li>
<li>Can Neural Nets Learn The Same Model Twice? Investigating Reproducibility and Double Descent From The Decision Boundary Perspective</li>
<li>Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction</li>
<li>Multi-View Transformer for 3D Visual Grounding</li>
<li>Structured Sparse R-CNN for Direct Scene Graph Generation</li>
<li>BARC: Learning To Regress 3D Dog Shape From Images By Exploiting Breed Information</li>
<li>PCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models</li>
<li>Towards Understanding Adversarial Robustness of Optical Flow Networks</li>
<li>Lifelong Graph Learning</li>
<li>Hypergraph-Induced Semantic Tuplet Loss for Deep Metric Learning</li>
<li>Computing Wasserstein-p Distance Between Images With Linear Cost</li>
<li>Unsupervised Representation Learning for Binary Networks By Joint Classifier Learning</li>
<li>Large-Scale Video Panoptic Segmentation in The Wild: A Benchmark</li>
<li>GrainSpace: A Large-Scale Dataset for Fine-Grained and Domain-Adaptive Recognition of Cereal Grains</li>
<li>Learning Modal-Invariant and Temporal-Memory for Video-Based Visible-Infrared Person Re-Identification</li>
<li>MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning</li>
<li>Oriented RepPoints for Aerial Object Detection</li>
<li>Weakly Supervised Temporal Sentence Grounding With Gaussian-Based Contrastive Proposal Learning</li>
<li>Low-Resource Adaptation for Personalized Co-Speech Gesture Generation</li>
<li>Task-Specific Inconsistency Alignment for Domain Adaptive Object Detection</li>
<li>MS2DG-Net: Progressive Correspondence Learning Via Multiple Sparse Semantics Dynamic Graph</li>
<li>Learning To Listen: Modeling Non-Deterministic Dyadic Facial Motion</li>
<li>Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation From Monocular Video</li>
<li>MixFormer: End-to-End Tracking With Iterative Mixed Attention</li>
<li>Plenoxels: Radiance Fields Without Neural Networks</li>
<li>Selective-Supervised Contrastive Learning With Noisy Labels</li>
<li>SimT: Handling Open-Set Noise for Domain Adaptive Semantic Segmentation</li>
<li>Frequency-Driven Imperceptible Adversarial Attack on Semantic Similarity</li>
<li>Video Demoireing With Relation-Based Temporal Consistency</li>
<li>Industrial Style Transfer With Large-Scale Geometric Warping and Content Preservation</li>
<li>Modeling Image Composition for Complex Scene Generation</li>
<li>Decoupling Zero-Shot Semantic Segmentation</li>
<li>Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions</li>
<li>Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting The Adversarial Transferability</li>
<li>IFOR: Iterative Flow Minimization for Robotic Object Rearrangement</li>
<li>Zero Experience Required: Plug &amp; Play Modular Transfer Learning for Semantic Visual Navigation</li>
<li>TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation</li>
<li>The Wanderings of Odysseus in 3D Scenes</li>
<li>All-in-One Image Restoration for Unknown Corruption</li>
<li>PUMP: Pyramidal and Uniqueness Matching Priors for Unsupervised Learning of Local Descriptors</li>
<li>MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video</li>
<li>RCP: Recurrent Closest Point for Point Cloud</li>
<li>A Dual Weighting Label Assignment Scheme for Object Detection</li>
<li>Hyperbolic Vision Transformers: Combining Improvements in Metric Learning</li>
<li>Instance-Aware Dynamic Neural Network Quantization</li>
<li>Exploring Effective Data for Surrogate Training Towards Black-Box Attack</li>
<li>JRDB-Act: A Large-Scale Dataset for Spatio-Temporal Action, Social Group and Activity Detection</li>
<li>Investigating Top-k White-Box and Transferable Black-Box Attack</li>
<li>Decoupling and Recoupling Spatiotemporal Representation for RGB-D-Based Motion Recognition</li>
<li>A Self-Supervised Descriptor for Image Copy Detection</li>
<li>Negative-Aware Attention Framework for Image-Text Matching</li>
<li>An Image Patch Is A Wave: Phase-Aware Vision MLP</li>
<li>Shunted Self-Attention Via Multi-Scale Token Aggregation</li>
<li>Unified Multivariate Gaussian Mixture for Efficient Neural Image Compression</li>
<li>Recurrent Variational Network: A Deep Learning Inverse Problem Solver Applied to The Task of Accelerated MRI Reconstruction</li>
<li>Surpassing The Human Accuracy: Detecting Gallbladder Cancer From USG Images With Curriculum Learning</li>
<li>Appearance and Structure Aware Robust Deep Visual Graph Matching: Attack, Defense and Beyond</li>
<li>TrackFormer: Multi-Object Tracking With Transformers</li>
<li>3D Shape Reconstruction From 2D Images With Disentangled Attribute Flow</li>
<li>Feature Statistics Mixing Regularization for Generative Adversarial Networks</li>
<li>OpenTAL: Towards Open Set Temporal Action Localization</li>
<li>Self-Supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection</li>
<li>Ego4D: Around The World in 3,000 Hours of Egocentric Video</li>
<li>Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis</li>
<li>Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data</li>
<li>DAD-3DHeads: A Large-Scale Dense, Accurate and Diverse Dataset for 3D Head Alignment From A Single Image</li>
<li>Reconstructing Surfaces for Sparse Point Clouds With On-Surface Priors</li>
<li>VCLIMB: A Novel Video Class Incremental Learning Benchmark</li>
<li>Robust Equivariant Imaging: A Fully Unsupervised Framework for Learning To Image From Noisy and Partial Measurements</li>
<li>ST++: Make Self-Training Work Better for Semi-Supervised Semantic Segmentation</li>
<li>Interacting Attention Graph for Single Image Two-Hand Reconstruction</li>
<li>Rope3D: The Roadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task</li>
<li>Cross-Image Relational Knowledge Distillation for Semantic Segmentation</li>
<li>Towards Layer-Wise Image Vectorization</li>
<li>Scenic: A JAX Library for Computer Vision Research and Beyond</li>
<li>Real-Time Object Detection for Streaming Perception</li>
<li>VisualHow: Multimodal Problem Solving</li>
<li>Spatial Commonsense Graph for Object Localisation in Partial Scenes</li>
<li>OSSGAN: Open-Set Semi-Supervised Image Generation</li>
<li>Bi-Level Alignment for Cross-Domain Crowd Counting</li>
<li>ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation</li>
<li>Efficient Multi-View Stereo By Iterative Dynamic Cost Volume</li>
<li>TransEditor: Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing</li>
<li>Use All The Labels: A Hierarchical Multi-Label Contrastive Learning Framework</li>
<li>SGTR: End-to-End Scene Graph Generation With Transformer</li>
<li>Decoupled Knowledge Distillation</li>
<li>DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection</li>
<li>Reusing The Task-Specific Classifier As A Discriminator: Discriminator-Free Adversarial Domain Adaptation</li>
<li>Show Me What and Tell Me How: Video Synthesis Via Multimodal Conditioning</li>
<li>SIMBAR: Single Image-Based Scene Relighting for Effective Data Augmentation for Automated Driving Vision Tasks</li>
<li>Multi-Label Classification With Partial Annotations Using Class-Aware Selective Loss</li>
<li>CADTransformer: Panoptic Symbol Spotting Transformer for CAD Drawings</li>
<li>IntraQ: Learning Synthetic Images With Intra-Class Heterogeneity for Zero-Shot Network Quantization</li>
<li>I M Avatar: Implicit Morphable Head Avatars From Videos</li>
<li>Weakly-Supervised Metric Learning With Cross-Module Communications for The Classification of Anterior Chamber Angle Images</li>
<li>A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-Resolution</li>
<li>Multi-Modal Dynamic Graph Transformer for Visual Grounding</li>
<li>Geometric Transformer for Fast and Robust Point Cloud Registration</li>
<li>UMT: Unified Multi-Modal Transformers for Joint Video Moment Retrieval and Highlight Detection</li>
<li>Demystifying The Neural Tangent Kernel From A Practical Perspective: Can It Be Trusted for Neural Architecture Search Without Training?</li>
<li>The Devil Is in The Details: Window-Based Attention for Image Compression</li>
<li>DiLiGenT102: A Photometric Stereo Benchmark Dataset With Controlled Shape and Material Variation</li>
<li>PolyWorld: Polygonal Building Extraction With Graph Neural Networks in Satellite Images</li>
<li>Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation</li>
<li>Spatio-Temporal Relation Modeling for Few-Shot Action Recognition</li>
<li>Multi-Person Extreme Motion Prediction</li>
<li>B-DARTS: Beta-Decay Regularization for Differentiable Architecture Search</li>
<li>CMT: Convolutional Neural Networks Meet Vision Transformers</li>
<li>KNN Local Attention for Image Restoration</li>
<li>Predict, Prevent, and Evaluate: Disentangled Text-Driven Image Manipulation Empowered By Pre-Trained Vision-Language Model</li>
<li>TransMix: Attend To Mix for Vision Transformers</li>
<li>Inertia-Guided Flow Completion and Style Fusion for Video Inpainting</li>
<li>Long-Tailed Visual Recognition Via Gaussian Clouded Logit Adjustment</li>
<li>Image Animation With Perturbed Masks</li>
<li>Domain Generalization Via Shuffled Style Assembly for Face Anti-Spoofing</li>
<li>OcclusionFusion: Occlusion-Aware Motion Estimation for Real-Time Dynamic 3D Reconstruction</li>
<li>MonoScene: Monocular 3D Semantic Scene Completion</li>
<li>AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition</li>
<li>Continuous Scene Representations for Embodied AI</li>
<li>Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds</li>
<li>Non-Probability Sampling Network for Stochastic Human Trajectory Prediction</li>
<li>ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning</li>
<li>Human-Aware Object Placement for Visual Environment Reconstruction</li>
<li>X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval</li>
<li>RAMA: A Rapid Multicut Algorithm on GPU</li>
<li>Adversarial Parametric Pose Prior</li>
<li>Mask Transfiner for High-Quality Instance Segmentation</li>
<li>It Is Okay To Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning By Contrastive Data Collection</li>
<li>DiRA: Discriminative, Restorative, and Adversarial Learning for Self-Supervised Medical Image Analysis</li>
<li>Event-Based Video Reconstruction Via Potential-Assisted Spiking Neural Network</li>
<li>YouMVOS: An Actor-Centric Multi-Shot Video Object Segmentation Dataset</li>
<li>DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation</li>
<li>Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification</li>
<li>Self-Supervised Video Transformer</li>
<li>AutoRF: Learning 3D Object Radiance Fields From Single View Observations</li>
<li>Coopernaut: End-to-End Driving With Cooperative Perception for Networked Vehicles</li>
<li>TubeR: Tubelet Transformer for Video Action Detection</li>
<li>MUM: Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection</li>
<li>Learning Non-Target Knowledge for Few-Shot Semantic Segmentation</li>
<li>UKPGAN: A General Self-Supervised Keypoint Detector</li>
<li>Raw High-Definition Radar for Multi-Task Learning</li>
<li>Coarse-To-Fine Feature Mining for Video Semantic Segmentation</li>
<li>Compressing Models With Few Samples: Mimicking Then Replacing</li>
<li>PokeBNN: A Binary Pursuit of Lightweight Accuracy</li>
<li>Zoom in and Out: A Mixed-Scale Triplet Network for Camouflaged Object Detection</li>
<li>SOMSI: Spherical Novel View Synthesis With Soft Occlusion Multi-Sphere Images</li>
<li>EMScore: Evaluating Video Captioning Via Coarse-Grained and Fine-Grained Embedding Matching</li>
<li>PoseTriplet: Co-Evolving 3D Human Pose Estimation, Imitation, and Hallucination Under Self-Supervision</li>
<li>Group Contextualization for Video Recognition</li>
<li>Single-Domain Generalized Object Detection in Urban Scene Via Cyclic-Disentangled Self-Distillation</li>
<li>L2G: A Simple Local-to-Global Knowledge Transfer Framework for Weakly Supervised Semantic Segmentation</li>
<li>Self-Augmented Unpaired Image Dehazing Via Density and Depth Decomposition</li>
<li>Neural 3D Video Synthesis From Multi-View Video</li>
<li>SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation</li>
<li>Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search</li>
<li>HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening</li>
<li>Structure-Aware Flow Generation for Human Body Reshaping</li>
<li>Learning To Answer Questions in Dynamic Audio-Visual Scenarios</li>
<li>Synthetic Aperture Imaging With Events and Frames</li>
<li>MonoGround: Detecting Monocular 3D Objects From The Ground</li>
<li>Deep Visual Geo-Localization Benchmark</li>
<li>StyleGAN-V: A Continuous Video Generator With The Price, Image Quality and Perks of StyleGAN2</li>
<li>LISA: Learning Implicit Shape and Appearance of Hands</li>
<li>Iterative Deep Homography Estimation</li>
<li>Learned Queries for Efficient Local Attention</li>
<li>Colar: Effective and Efficient Online Action Detection By Consulting Exemplars</li>
<li>SoftGroup for 3D Instance Segmentation on Point Clouds</li>
<li>MVS2D: Efficient Multi-View Stereo Via Attention-Driven 2D Convolutions</li>
<li>Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance Segmentation Via Semantic Knowledge Transfer and Self-Refinement</li>
<li>Deep Constrained Least Squares for Blind Image Super-Resolution</li>
<li>EDTER: Edge Detection With Transformer</li>
<li>AirObject: A Temporally Evolving Graph Embedding for Object Identification</li>
<li>From Representation to Reasoning: Towards Both Evidence and Commonsense Reasoning for Video Question-Answering</li>
<li>Semantic-Aware Domain Generalized Segmentation</li>
<li>DanceTrack: Multi-Object Tracking in Uniform Appearance and Diverse Motion</li>
<li>UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection</li>
<li>AKB-48: A Real-World Articulated Object Knowledge Base</li>
<li>Stratified Transformer for 3D Point Cloud Segmentation</li>
<li>Aug-NeRF: Training Stronger Neural Radiance Fields With Triple-Level Physically-Grounded Augmentations</li>
<li>Semantic-Shape Adaptive Feature Modulation for Semantic Image Synthesis</li>
<li>Day-to-Night Image Synthesis for Training Nighttime Neural ISPs Literature ~Highlight: To address this problem, we propose a method that synthesizes nighttime images from daytime images.</li>
</ol>


<h2 class="relative group">References 
    <div id="references" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#references" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<ul>
<li><a href="https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/" target="_blank">https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/</a></li>
</ul>
<p><strong>Author</strong><br>
Dr Hari Thapliyaal<br>
dasarpai.com <br>
linkedin.com/in/harithapliyal</p>


        
        
      </div>

      <style>
 

</style><div class="td-author-box"><div class="td-author-box__avatar">
        <img src="/assets/images/myphotos/Profilephoto1.jpg" alt="Hari Thapliyaal's avatar" class="author-image" width="25%" >
      </div>
    <div class="td-author-box__links author-image"><b>Follow Me</b>
        <a href="https://join.slack.com/t/dasarpai/shared_invite/zt-2mg1j7ddw-0QYA9IAvFFRKw51ZBK6mkQ" target="_blank" rel="noopener" aria-label="Slack" title="Chat with other project users in #users">
            <i class="fab fa-slack" aria-hidden="true"></i>
        </a>
        <a href="https://groups.google.com/forum/#!forum/agones-discuss" target="_blank" rel="noopener" aria-label="User mailing list" title="Discussion and help from your fellow users">
            <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        <a href="https://twitter.com/dasarpai" target="_blank" rel="noopener" aria-label="Twitter" title="Follow us on Twitter to get the latest news!">
            <i class="fab fa-twitter" aria-hidden="true"></i>
        </a>
        <a href="https://www.youtube.com/playlist?list=PLhkWKwFGACw2dFpdmwxOyUCzlGP2-n7uF" target="_blank" rel="noopener" aria-label="Community Meetings" title="Live discussion of new features and issues, see the &lt;a href=&#34;https://github.com/googleforgames/agones/blob/main/CONTRIBUTING.md#community-meetings&#34;&gt;calendar&lt;/a&gt; or &lt;a href=&#34;https://groups.google.com/forum/#!forum/agones-discuss&#34;&gt;mailing list&lt;/a&gt; for details">
            <i class="fab fa-youtube" aria-hidden="true"></i>
        </a>
    </div>
  

    <div class="td-author-box__info">
    <h4 class="td-author-box__name">Hari Thapliyaal</h4><p class="td-author-box__bio">Dr. Hari Thapliyal is a seasoned professional and prolific blogger with a multifaceted background that spans the realms of Data Science, Project Management, and Advait-Vedanta Philosophy. Holding a Doctorate in AI/NLP from SSBM (Geneva, Switzerland), Hari has earned Master&#39;s degrees in Computers, Business Management, Data Science, and Economics, reflecting his dedication to continuous learning and a diverse skill set.

With over three decades of experience in management and leadership, Hari has proven expertise in training, consulting, and coaching within the technology sector. His extensive 16&#43; years in all phases of software product development are complemented by a decade-long focus on course design, training, coaching, and consulting in Project Management.

 In the dynamic field of Data Science, Hari stands out with more than three years of hands-on experience in software development, training course development, training, and mentoring professionals. His areas of specialization include Data Science, AI, Computer Vision, NLP, complex machine learning algorithms, statistical modeling, pattern identification, and extraction of valuable insights.

Hari&#39;s professional journey showcases his diverse experience in planning and executing multiple types of projects. He excels in driving stakeholders to identify and resolve business problems, consistently delivering excellent results. Beyond the professional sphere, Hari finds solace in long meditation, often seeking secluded places or immersing himself in the embrace of nature.</p></div>
  </div>
      <div class="td-comments">
      <h4 class="td-comments__title">Comments:</h4>
      <script src="https://giscus.app/client.js"
              data-repo="dasarpai/dasarpai-comments"
              data-repo-id="R_kgDOOGVFpA"
              data-category="General"
              data-category-id="DIC_kwDOOGVFpM4CnzHR"
              data-mapping="url"
              data-reactions-enabled="1"
              data-theme="light"
              data-strict="1"
              data-input-position="top"
              data-emit-metadata="1"
              data-lang="en"
              crossorigin="anonymous"
              async>
      </script>
    </div>
      

      
  
  <section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://dasarpai.com/dsblog/paperwithcode-resources/&amp;title=Paper%20with%20Code%20Resources"
      title="Share on LinkedIn"
      aria-label="Share on LinkedIn"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://twitter.com/intent/tweet/?url=https://dasarpai.com/dsblog/paperwithcode-resources/&amp;text=Paper%20with%20Code%20Resources"
      title="Tweet on Twitter"
      aria-label="Tweet on Twitter"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://api.whatsapp.com/send?text=https://dasarpai.com/dsblog/paperwithcode-resources/&amp;resubmit=true&amp;title=Paper%20with%20Code%20Resources"
      title="Share via WhatsApp"
      aria-label="Share via WhatsApp"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://t.me/share/url?url=https://dasarpai.com/dsblog/paperwithcode-resources/&amp;resubmit=true&amp;title=Paper%20with%20Code%20Resources"
      title="Share via Telegram"
      aria-label="Share via Telegram"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M248,8C111.033,8,0,119.033,0,256S111.033,504,248,504,496,392.967,496,256,384.967,8,248,8ZM362.952,176.66c-3.732,39.215-19.881,134.378-28.1,178.3-3.476,18.584-10.322,24.816-16.948,25.425-14.4,1.326-25.338-9.517-39.287-18.661-21.827-14.308-34.158-23.215-55.346-37.177-24.485-16.135-8.612-25,5.342-39.5,3.652-3.793,67.107-61.51,68.335-66.746.153-.655.3-3.1-1.154-4.384s-3.59-.849-5.135-.5q-3.283.746-104.608,69.142-14.845,10.194-26.894,9.934c-8.855-.191-25.888-5.006-38.551-9.123-15.531-5.048-27.875-7.717-26.8-16.291q.84-6.7,18.45-13.7,108.446-47.248,144.628-62.3c68.872-28.647,83.183-33.623,92.511-33.789,2.052-.034,6.639.474,9.61,2.885a10.452,10.452,0,0,1,3.53,6.716A43.765,43.765,0,0,1,362.952,176.66Z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://pinterest.com/pin/create/bookmarklet/?url=https://dasarpai.com/dsblog/paperwithcode-resources/&amp;description=Paper%20with%20Code%20Resources"
      title="Pin on Pinterest"
      aria-label="Pin on Pinterest"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M496 256c0 137-111 248-248 248-25.6 0-50.2-3.9-73.4-11.1 10.1-16.5 25.2-43.5 30.8-65 3-11.6 15.4-59 15.4-59 8.1 15.4 31.7 28.5 56.8 28.5 74.8 0 128.7-68.8 128.7-154.3 0-81.9-66.9-143.2-152.9-143.2-107 0-163.9 71.8-163.9 150.1 0 36.4 19.4 81.7 50.3 96.1 4.7 2.2 7.2 1.2 8.3-3.3.8-3.4 5-20.3 6.9-28.1.6-2.5.3-4.7-1.7-7.1-10.1-12.5-18.3-35.3-18.3-56.6 0-54.7 41.4-107.6 112-107.6 60.9 0 103.6 41.5 103.6 100.9 0 67.1-33.9 113.6-78 113.6-24.3 0-42.6-20.1-36.7-44.8 7-29.5 20.5-61.3 20.5-82.6 0-19-10.2-34.9-31.4-34.9-24.9 0-44.9 25.7-44.9 60.2 0 22 7.4 36.8 7.4 36.8s-24.5 103.8-29 123.2c-5 21.4-3 51.6-.9 71.2C65.4 450.9 0 361.1 0 256 0 119 111 8 248 8s248 111 248 248z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://www.facebook.com/sharer/sharer.php?u=https://dasarpai.com/dsblog/paperwithcode-resources/&amp;quote=Paper%20with%20Code%20Resources"
      title="Share on Facebook"
      aria-label="Share on Facebook"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="mailto:?body=https://dasarpai.com/dsblog/paperwithcode-resources/&amp;subject=Paper%20with%20Code%20Resources"
      title="Send via email"
      aria-label="Send via email"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1c-27.64 140.9 68.65 266.2 199.1 285.1c19.01 2.888 36.17-12.26 36.17-31.49l.0001-.6631c0-15.74-11.44-28.88-26.84-31.24c-84.35-12.98-149.2-86.13-149.2-174.2c0-102.9 88.61-185.5 193.4-175.4c91.54 8.869 158.6 91.25 158.6 183.2l0 16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98 .0036c-7.299 0-13.2 4.992-15.12 11.68c-24.85-12.15-54.24-16.38-86.06-5.106c-38.75 13.73-68.12 48.91-73.72 89.64c-9.483 69.01 43.81 128 110.9 128c26.44 0 50.43-9.544 69.59-24.88c24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3C495.1 107.1 361.2-9.332 207.8 20.73zM239.1 304.3c-26.47 0-48-21.56-48-48.05s21.53-48.05 48-48.05s48 21.56 48 48.05S266.5 304.3 239.1 304.3z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://bsky.app/intent/compose?text=Paper%20with%20Code%20Resources&#43;https://dasarpai.com/dsblog/paperwithcode-resources/"
      title="Post on Bluesky"
      aria-label="Post on Bluesky"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256,232.562c-21.183,-41.196 -78.868,-117.97 -132.503,-155.834c-51.378,-36.272 -70.978,-29.987 -83.828,-24.181c-14.872,6.72 -17.577,29.554 -17.577,42.988c0,13.433 7.365,110.138 12.169,126.281c15.873,53.336 72.376,71.358 124.413,65.574c2.66,-0.395 5.357,-0.759 8.089,-1.097c-2.68,0.429 -5.379,0.796 -8.089,1.097c-76.259,11.294 -143.984,39.085 -55.158,137.972c97.708,101.165 133.908,-21.692 152.484,-83.983c18.576,62.291 39.972,180.718 150.734,83.983c83.174,-83.983 22.851,-126.674 -53.408,-137.969c-2.71,-0.302 -5.409,-0.667 -8.089,-1.096c2.732,0.337 5.429,0.702 8.089,1.096c52.037,5.785 108.54,-12.239 124.413,-65.574c4.804,-16.142 12.169,-112.847 12.169,-126.281c-0,-13.434 -2.705,-36.267 -17.577,-42.988c-12.85,-5.806 -32.45,-12.09 -83.829,24.181c-53.634,37.864 -111.319,114.635 -132.502,155.831Z"/></svg>
  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://reddit.com/submit/?url=https://dasarpai.com/dsblog/paperwithcode-resources/&amp;resubmit=true&amp;title=Paper%20with%20Code%20Resources"
      title="Submit to Reddit"
      aria-label="Submit to Reddit"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"/></svg>

  </span>


    </a>
      
    
  </section>


    </div>

    
      
      
        
        
      

      <script>
        var oid = "views_dsblog\\2023-08-24-6091-Paperwithcode-Resources.md";
        var oid_likes = "likes_dsblog\\2023-08-24-6091-Paperwithcode-Resources.md";
      </script>
      
      <script type="text/javascript" src="/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js" integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q&#43;oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script>
    
  </section>

  <footer class="pt-8 print:hidden">
    
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="flex group mr-3" href="/dsblog/Comprehensive-Glossary-of-LLM/">
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Comprehensive Glossary of LLM, Deep Learning, NLP, and CV Terminology</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2023-08-21T00:00:00&#43;00:00">21 August 2023</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
            <a class="flex text-right group ml-3" href="/dsblog/select-ai-papers/">
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Important AI Paper List</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2023-08-22T00:00:00&#43;00:00">22 August 2023</time>
                  
                </span>
              </span>
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
            </a>
          
        </span>
      </div>
    </div>
  


    
  </footer>

  <div>
    


  
  
    <h2 class="mt-8 text-2xl font-extrabold mb-10">Related</h2>
    <section class="w-full grid gap-4 sm:grid-cols-2 md:grid-cols-3">
      
        

  <a href="/dsblog/select-ai-papers/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6090-rps-Important-AI-Paper-List.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/select-ai-papers/">Important AI Paper List</div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2023-08-22T00:00:00&#43;00:00">22 August 2023</time><span class="px-2 text-primary-500">&middot;</span><span>5247 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">25 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsresources/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsresources
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/llm/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    LLM
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/transformer/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Transformer
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/encoder/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Encoder
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/decoder/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Decoder
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/research-papers/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Research Papers
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-research/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Research
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/machine-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Machine Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/academic-resources/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Academic Resources
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-development/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Development
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/research-collection/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Research Collection
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         Important AI Paper List # Introduciton # In almost all citations it becomes very difficult to read …
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
        

  <a href="/dsblog/Comprehensive-Glossary-of-LLM/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6089-Comprehensive-Glossary-of-LLM.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/Comprehensive-Glossary-of-LLM/">Comprehensive Glossary of LLM, Deep Learning, NLP, and CV Terminology</div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2023-08-21T00:00:00&#43;00:00">21 August 2023</time><span class="px-2 text-primary-500">&middot;</span><span>3295 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">16 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/llm/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    LLM
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/nlp/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    NLP
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/computer-vision/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Computer Vision
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-terminology/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Terminology
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/machine-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Machine Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/technical-glossary/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Technical Glossary
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         Comprehensive Glossary of LLM # I am developing this Glossary slowly at my own pace. Content on …
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
        

  <a href="/dsblog/What-is-GAN-Architecture/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6069-What-is-GAN-Architecture.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/What-is-GAN-Architecture/">What is GAN Architecture?</div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2023-07-03T00:00:00&#43;00:00">3 July 2023</time><span class="px-2 text-primary-500">&middot;</span><span>937 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">5 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/gan/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    GAN
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/neural-networks/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Neural Networks
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/computer-vision/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Computer Vision
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/image-generation/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Image Generation
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/machine-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Machine Learning
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         What is GAN Architecture? # Generative Adversarial Networks (GANs) are a powerful class of neural …
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
        

  <a href="/dsblog/God-Fathers-of-AI/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6058-God-Fathers-of-AI.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/God-Fathers-of-AI/">God Fathers of AI</div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2023-05-05T00:00:00&#43;00:00">5 May 2023</time><span class="px-2 text-primary-500">&middot;</span><span>1221 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">6 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/artificial-intelligence/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Artificial Intelligence
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-history/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI History
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/computer-science/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Computer Science
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-pioneers/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Pioneers
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/machine-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Machine Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-research/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Research
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/technology-innovation/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Technology Innovation
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-development/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Development
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         God Fathers of AI # In other fields of studies or in religion, there is only one god or only one …
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
        

  <a href="/dsblog/What-is-GAN/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6043-gan.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/What-is-GAN/">What is GAN?</div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2023-01-17T00:00:00&#43;00:00">17 January 2023</time><span class="px-2 text-primary-500">&middot;</span><span>1016 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">5 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/generative-ai/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Generative AI
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/neural-networks/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Neural Networks
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/machine-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Machine Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/computer-vision/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Computer Vision
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/image-generation/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Image Generation
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-models/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Models
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/image-synthesis/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Image Synthesis
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/gan-architecture/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    GAN Architecture
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         What is GAN? # What is GAN (Generative Adversarial Network)? # Generative adversarial networks …
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
        

  <a href="/dsblog/what-is-computer-vision/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6018-What-is-Computer-Vision.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/what-is-computer-vision/">What is Computer Vision</div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2022-12-28T15:50:00&#43;05:30">28 December 2022</time><span class="px-2 text-primary-500">&middot;</span><span>2323 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">11 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/computer-vision/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Computer Vision
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/image-processing/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Image Processing
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/neural-networks/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Neural Networks
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/machine-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Machine Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-applications/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Applications
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         What is Computer vision? # Background # In the digital world, scientists are working hard to create …
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
    </section>
  

  </div>
</article>

      <div id="top-scroller" class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0">
  <a href="#the-top"
    class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top" title="Scroll to top">
    &uarr;
  </a>
</div>
    </main><article><section class="footer-wrapper">
  <footer class="td-footer container-fluid">
    <div class="row">
      
      <div class="col-md-2 mb-4 mb-md-0">
        <a href="https://dasarpai.com" target="_blank" rel="noopener">
          <img src="https://dasarpai.com/assets/images/site-logo.png" alt="dasarpAI" width="100" style="border-radius: 12px;">
        </a>
      </div>

      
      <div class="col-md-10">
        

        
        <div class="row"><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">Key Links</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/aboutme" class="text-muted">About Me</a></li><li class="mb-2"><a href="/dscourses" class="text-muted">My Data Science Courses/Services</a></li><li class="mb-2"><a href="/summary-of-al-ml-projects" class="text-muted">MyWork by Business Domain</a></li><li class="mb-2"><a href="/summary-of-my-technology-stacks" class="text-muted">MyWork by Tech Stack</a></li><li class="mb-2"><a href="/summary-of-management-projects" class="text-muted">MyWork in Project Management</a></li><li class="mb-2"><a href="/clients" class="text-muted">Clients</a></li><li class="mb-2"><a href="/testimonials" class="text-muted">Testimonial</a></li><li class="mb-2"><a href="/terms-of-service" class="text-muted">Terms &amp; Condition</a></li><li class="mb-2"><a href="/privacy" class="text-muted">Privacy Policy</a></li><li class="mb-2"><a href="/comment-policy" class="text-muted">Comment Policy</a></li></ul>
                  </div>
                </div><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">My Blogs</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/dsblog" class="text-muted">Data Science Blog</a></li><li class="mb-2"><a href="/booksumary" class="text-muted">Books/Interviews Blog</a></li><li class="mb-2"><a href="/news" class="text-muted">AI and Business News</a></li><li class="mb-2"><a href="/pmblog" class="text-muted">PMLOGY Blog</a></li><li class="mb-2"><a href="/pmbok6hi" class="text-muted">PMBOK6 Hindi Explorer</a></li><li class="mb-2"><a href="/wiaposts" class="text-muted">Wisdom in Awareness Blog</a></li><li class="mb-2"><a href="/samskrutyatra" class="text-muted">Samskrut Blog</a></li><li class="mb-2"><a href="/mychanting" class="text-muted">My Chantings</a></li><li class="mb-2"><a href="/quotations-blog" class="text-muted">WIA Quotes</a></li><li class="mb-2"><a href="/gk" class="text-muted">GK Blog</a></li></ul>
                  </div>
                </div><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">All Resources</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/datascience-tags#ds-resources" class="text-muted">DS Resources</a></li><li class="mb-2"><a href="https://aibenchmark-explorer.dasarpai.com" class="text-muted">AI Benchmark Explorer</a></li><li class="mb-2"><a href="/dsblog/ds-ai-ml-books" class="text-muted">Data Science-Books</a></li><li class="mb-2"><a href="/dsblog/data-science-cheatsheets" class="text-muted">Data Science/AI Cheatsheets</a></li><li class="mb-2"><a href="/dsblog/best-youtube-channels-for-ds" class="text-muted">Video Channels to Learn DS/AI</a></li><li class="mb-2"><a href="/dsblog/ds-ai-ml-interview-resources" class="text-muted">DS/AI Interview Questions</a></li><li class="mb-2"><a href="https://github.com/dasarpai/DAI-Datasets" class="text-muted">GitHub DAI-Datasets</a></li><li class="mb-2"><a href="/pmi-templates" class="text-muted">PMBOK6 Templates</a></li><li class="mb-2"><a href="/prince2-templates" class="text-muted">PRINCE2 Templates</a></li><li class="mb-2"><a href="/microsoft-pm-templates" class="text-muted">Microsoft PM Templates</a></li></ul>
                  </div>
                </div><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">Project Management</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/pmlogy-home" class="text-muted">PMLOGY Home</a></li><li class="mb-2"><a href="/pmblog" class="text-muted">PMLOGY Blog</a></li><li class="mb-2"><a href="/pmglossary" class="text-muted">PM Glossary</a></li><li class="mb-2"><a href="/pmlogy-tags" class="text-muted">PM Topics</a></li><li class="mb-2"><a href="/pmbok6-tags" class="text-muted">PMBOK6 Topics</a></li><li class="mb-2"><a href="/pmbok6-summary" class="text-muted">PMBOK6</a></li><li class="mb-2"><a href="/pmbok6" class="text-muted">PMBOK6 Explorer</a></li><li class="mb-2"><a href="/pmbok6hi-tags" class="text-muted">PMBOK6 Hindi Topics</a></li><li class="mb-2"><a href="/pmbok6hi-summary" class="text-muted">PMBoK6 Hindi</a></li><li class="mb-2"><a href="/pmbok6hi" class="text-muted">PMBOK6 Hindi Explorer</a></li></ul>
                  </div>
                </div></div>

        
        <div class="row"><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">Wisdom in Awareness</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/wia-home" class="text-muted">WIA Home</a></li><li class="mb-2"><a href="/wiaposts" class="text-muted">WIA Blog</a></li><li class="mb-2"><a href="/wia-tags" class="text-muted">WIA Topics</a></li><li class="mb-2"><a href="/quotations-blog" class="text-muted">WIA Quotes</a></li><li class="mb-2"><a href="/gk" class="text-muted">GK Blog</a></li><li class="mb-2"><a href="/gk-tags" class="text-muted">GK Topic</a></li></ul>
                  </div>
                </div><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">Samskrutyatra</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/samskrutyatra-home" class="text-muted">SamskrutYatra Home</a></li><li class="mb-2"><a href="/samskrutyatra" class="text-muted">Samskrut Blog</a></li><li class="mb-2"><a href="/samskrutyatra-tags" class="text-muted">Samskrut Topics</a></li><li class="mb-2"><a href="/mychanting" class="text-muted">My Vedic Chantings</a></li></ul>
                  </div>
                </div><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">My Gallery</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/gallary/slider-online-sessions1" class="text-muted">Online AI Classes 1</a></li><li class="mb-2"><a href="/gallary/slider-online-sessions2" class="text-muted">Online AI Classes 2</a></li><li class="mb-2"><a href="/gallary/slider-online-sessions3" class="text-muted">Online AI Classes 3</a></li><li class="mb-2"><a href="/gallary/slider-online-sessions4" class="text-muted">Online AI Classes 4</a></li><li class="mb-2"><a href="/gallary/slider-pm-selected-photos" class="text-muted">Management Classes</a></li><li class="mb-2"><a href="/gallary/slider-pm-workshops" class="text-muted">PM &amp; DS Workshop</a></li></ul>
                  </div>
                </div></div>
      </div>
    </div>

    
    <div class="row mt-4 pt-3 border-top">
      <div class="col-md-4 order-2 order-md-1">
        <ul class="td-footer__links-list">
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Slack" aria-label="Slack">
    <a target="_blank" rel="noopener" href="https://join.slack.com/t/dasarpai/shared_invite/zt-2mg1j7ddw-0QYA9IAvFFRKw51ZBK6mkQ" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="User mailing list" aria-label="User mailing list">
    <a target="_blank" rel="noopener" href="https://groups.google.com/forum/#!forum/agones-discuss" aria-label="User mailing list">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Twitter" aria-label="Twitter">
    <a target="_blank" rel="noopener" href="https://twitter.com/dasarpai" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Community Meetings" aria-label="Community Meetings">
    <a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLhkWKwFGACw2dFpdmwxOyUCzlGP2-n7uF" aria-label="Community Meetings">
      <i class="fab fa-youtube"></i>
    </a>
  </li>
  
</ul>

      </div>
      <div class="col-md-4 order-1 order-md-2 text-center mb-3 mb-md-0">
        
      </div>
      <div class="col-md-4 order-3 text-md-end">
        <ul class="td-footer__links-list">
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="GitHub" aria-label="GitHub">
    <a target="_blank" rel="noopener" href="https://github.com/dasarpai/dasarpai-agones" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Slack" aria-label="Slack">
    <a target="_blank" rel="noopener" href="https://join.slack.com/t/dasarpai/shared_invite/zt-2mg1j7ddw-0QYA9IAvFFRKw51ZBK6mkQ" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Community Meetings" aria-label="Community Meetings">
    <a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLhkWKwFGACw2dFpdmwxOyUCzlGP2-n7uF" aria-label="Community Meetings">
      <i class="fab fa-youtube"></i>
    </a>
  </li>
  
</ul>

      </div>
    </div>
  </footer>
</section>
</article>







<style>
.footer-wrapper {
   
  padding: 2rem 0;
  margin-top: 3rem;
}

.footer-menu .footer-title {
  font-size: 1rem;
  font-weight: 600;
  margin-bottom: 1rem;
  color: #333;
}

.footer-menu ul {
  padding-left: 0;
}

.footer-menu a {
  text-decoration: none;
  transition: color 0.2s;
}

.footer-menu a:hover {
  color: #007bff !important;  
}

@media (min-width: 768px) {
  .footer-menu {
    height: 100%;
  }
  .footer-menu > ul {
    display: flex;
    flex-direction: column;
    height: 100%;
  }
}
</style><div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="https://dasarpai.com/"
  style="z-index:500"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />

      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>


      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

  </div>
</body>

<script data-name="BMC-Widget" data-cfasync="false" src="https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js"
  data-id="harithapliyal" data-description="Support me on Buy me a coffee!" data-message=""
  data-color="#FFDD00" data-position="Right" data-x_margin="18" data-y_margin="18"></script>

</html>
