<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.147.0"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel="shortcut icon" href="../../favicons/favicon.ico?v=1"><link rel=apple-touch-icon href="../../favicons/apple-touch-icon-180x180.png?v=1" sizes=180x180><link rel=icon type=image/png href="../../favicons/favicon-16x16.png?v=1" sizes=16x16><link rel=icon type=image/png href="../../favicons/favicon-32x32.png?v=1" sizes=32x32><link rel=apple-touch-icon href="../../favicons/apple-touch-icon-180x180.png?v=1" sizes=180x180><title>Demystifying NVIDIA GPUs | Blowfish</title><meta property="og:url" content="https://dasarpai.github.io/dsblog/demystify-nvidia-gpus/">
<meta property="og:site_name" content="Blowfish"><meta property="og:title" content="Demystifying NVIDIA GPUs"><meta property="og:description" content="Demystifying NVIDIA GPUs Introduction NVIDIA has been in the GPU manufacturing business since 1993. They offer hundreds of different types of GPUs for various segments and purposes. For those not in the GPU infrastructure business, it can be confusing to understand even their naming conventions. In this article, I will do my best to help you understand the different types of NVIDIA GPUs and their naming conventions."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="dsblog"><meta property="article:published_time" content="2025-02-09T00:00:00+00:00"><meta property="article:modified_time" content="2025-02-09T00:00:00+00:00"><meta property="article:tag" content="NVIDIA"><meta property="article:tag" content="GPUs"><meta property="article:tag" content="Deep Learning"><meta itemprop=name content="Demystifying NVIDIA GPUs"><meta itemprop=description content="Demystifying NVIDIA GPUs Introduction NVIDIA has been in the GPU manufacturing business since 1993. They offer hundreds of different types of GPUs for various segments and purposes. For those not in the GPU infrastructure business, it can be confusing to understand even their naming conventions. In this article, I will do my best to help you understand the different types of NVIDIA GPUs and their naming conventions."><meta itemprop=datePublished content="2025-02-09T00:00:00+00:00"><meta itemprop=dateModified content="2025-02-09T00:00:00+00:00"><meta itemprop=wordCount content="1667"><meta itemprop=keywords content="Understanding NVIDIA GPU names,NVIDIA GPU naming conventions,NVIDIA GPU for deep learning,NVIDIA GPU for AI,NVIDIA GPU for machine learning,NVIDIA GPU for computer vision"><meta name=twitter:card content="summary"><meta name=twitter:title content="Demystifying NVIDIA GPUs"><meta name=twitter:description content="Demystifying NVIDIA GPUs Introduction NVIDIA has been in the GPU manufacturing business since 1993. They offer hundreds of different types of GPUs for various segments and purposes. For those not in the GPU infrastructure business, it can be confusing to understand even their naming conventions. In this article, I will do my best to help you understand the different types of NVIDIA GPUs and their naming conventions."><link rel=preload href=../../scss/main.min.8d5e9853aa86c416850fe7ccb39d048388bfe7fbefb7922f796f886c3c8084d8.css as=style integrity="sha256-jV6YU6qGxBaFD+fMs50Eg4i/5/vvt5IveW+IbDyAhNg=" crossorigin=anonymous><link href=../../scss/main.min.8d5e9853aa86c416850fe7ccb39d048388bfe7fbefb7922f796f886c3c8084d8.css rel=stylesheet integrity="sha256-jV6YU6qGxBaFD+fMs50Eg4i/5/vvt5IveW+IbDyAhNg=" crossorigin=anonymous><link rel=stylesheet type=text/css href=https://dasarpai.github.io/css/asciinema-player.css><script src=https://code.jquery.com/jquery-3.3.1.min.js integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin=anonymous></script><link rel=stylesheet href=../../css/custom.css><script src=../../js/lunr.js></script></head><body class=td-page><header><nav class="js-navbar-scroll navbar navbar-expand navbar-light nav-shadow flex-column flex-md-row td-navbar"><a id=agones-top class=navbar-brand href=../../><svg id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><rect x="198.8952" y="225.1043" style="fill:#5b7fc0" width="122.6266" height="13.8671"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zm7.993 21.8577c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><rect x="198.8952" y="170.69" style="fill:#d95140" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><rect x="199.3456" y="279.5436" style="fill:#56a55c" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><rect x="198.8952" y="333.6497" style="fill:#f1bc42" width="122.6266" height="13.8671"/></g></g></svg> <span class="text-uppercase fw-bold">Blowfish</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../template/about/><span>About</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=../../><span class=active>Data Science</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../template/docs/><span>Documentation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../template/docs/><span>Docs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../community/><span>Community</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../template/docs/shortcodes/><span>Short Codes</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../template/blog/><span>Blog</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://github.com/nunocoracao/blowfish><span></span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href>GitHub</a></li><li class="nav-item dropdown d-none d-lg-block"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Release</a><div class=dropdown-menu aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=https://development.agones.dev>Development</a>
<a class=dropdown-item href=https://agones.dev></a><a class=dropdown-item href=https://1-47-0.agones.dev>1.47.0</a>
<a class=dropdown-item href=https://1-46-0.agones.dev>1.46.0</a>
<a class=dropdown-item href=https://1-45-0.agones.dev>1.45.0</a>
<a class=dropdown-item href=https://1-44-0.agones.dev>1.44.0</a>
<a class=dropdown-item href=https://1-43-0.agones.dev>1.43.0</a>
<a class=dropdown-item href=https://1-42-0.agones.dev>1.42.0</a>
<a class=dropdown-item href=https://1-41-0.agones.dev>1.41.0</a>
<a class=dropdown-item href=https://1-40-0.agones.dev>1.40.0</a>
<a class=dropdown-item href=https://1-39-0.agones.dev>1.39.0</a>
<a class=dropdown-item href=https://1-38-0.agones.dev>1.38.0</a>
<a class=dropdown-item href=https://1-37-0.agones.dev>1.37.0</a>
<a class=dropdown-item href=https://1-36-0.agones.dev>1.36.0</a>
<a class=dropdown-item href=https://1-35-0.agones.dev>1.35.0</a>
<a class=dropdown-item href=https://1-34-0.agones.dev>1.34.0</a>
<a class=dropdown-item href=https://1-33-0.agones.dev>1.33.0</a>
<a class=dropdown-item href=https://1-32-0.agones.dev>1.32.0</a>
<a class=dropdown-item href=https://1-31-0.agones.dev>1.31.0</a></div></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><ul class=dropdown-menu><li><a class=dropdown-item href=../../it/>Italiano</a></li></ul></div></li></ul></div><div class="navbar-nav mx-lg-2 d-none d-lg-block"></div></nav></header><div class="container-fluid td-default td-outer"><main role=main class=td-main><div class=row><div class=col-md-2></div><div class=col-md-8><p><img src=../../assets/images/dspost/dsp6216-Demystify-NVIDIA-GPUs.jpg alt="Demystifying NVIDIA GPUs"></p><h1 id=demystifying-nvidia-gpus>Demystifying NVIDIA GPUs<a class=td-heading-self-link href=#demystifying-nvidia-gpus aria-label="Heading self-link"></a></h1><h2 id=introduction>Introduction<a class=td-heading-self-link href=#introduction aria-label="Heading self-link"></a></h2><p>NVIDIA has been in the GPU manufacturing business since 1993. They offer hundreds of different types of GPUs for various segments and purposes. For those not in the GPU infrastructure business, it can be confusing to understand even their naming conventions. In this article, I will do my best to help you understand the different types of NVIDIA GPUs and their naming conventions.</p><p>Any GPU can be identified by asking following questions.</p><ul><li>What architecture that GPU is using?</li><li>For what purpose that GPU is used?</li><li>What type of VRAM it has?</li><li>Whether it has ECC (Error Correction Code) memory?</li><li>What is the brand classification of the GPU?</li><li>Whether it has Ray Tracing support?</li><li>What generation of Tensor Cores it has?</li><li>How many CUDA Cores it has?</li><li>How much FP64 support it has?</li><li>Does that GPU has Multi-GPU support?</li><li>How much power that GPU consumes?</li></ul><h2 id=what-are-these-terms>What are these terms?<a class=td-heading-self-link href=#what-are-these-terms aria-label="Heading self-link"></a></h2><p>First let&rsquo;s understand these terms.</p><ol><li><p><strong>Architecture</strong>: The fundamental design and technology behind a GPU, determining its performance and capabilities. Example: NVIDIA&rsquo;s Ampere architecture powers the RTX 3000 series GPUs.</p></li><li><p><strong>Purpose</strong>: The primary application or use case for the GPU. Example: NVIDIA GeForce GPUs are designed for gaming, while Tesla GPUs are optimized for AI and data centers.</p></li><li><p><strong>VRAM Type</strong>: The type of memory used in the GPU to store graphical data, affecting speed and bandwidth. Example: GDDR6 is commonly used in gaming GPUs like the NVIDIA RTX 3080.</p></li><li><p><strong>ECC Memory</strong>: Error Correction Code memory, which detects and corrects data errors, crucial for reliability in professional workstations. Example: NVIDIA Quadro GPUs often include ECC memory.</p></li><li><p><strong>Brand Classification</strong>: The category or series of a GPU within its brand, indicating its target market. Example: NVIDIA GeForce (gaming), AMD Radeon (gaming), or NVIDIA Quadro (professional).</p></li><li><p><strong>Ray Tracing Support</strong>: A feature that enables realistic lighting, shadows, and reflections in real-time rendering. Example: NVIDIA RTX 2060 supports ray tracing.</p></li><li><p><strong>Tensor Core Generation</strong>: Specialized cores in a GPU designed for AI and machine learning tasks, with newer generations offering better performance. Example: NVIDIA Ampere GPUs feature 3rd-gen Tensor Cores.</p></li><li><p><strong>CUDA Cores</strong>: Parallel processing units in NVIDIA GPUs that handle multiple tasks simultaneously. Example: The NVIDIA RTX 3090 has 10,496 CUDA cores.</p></li><li><p><strong>FP64 Support</strong>: The GPU&rsquo;s ability to perform double-precision floating-point calculations, important for scientific computing. Example: NVIDIA A100 has strong FP64 performance.</p></li><li><p><strong>Multi-GPU Support</strong>: The ability to combine multiple GPUs for increased performance, often used in high-end setups. Example: NVIDIA SLI or AMD CrossFire technologies enable multi-GPU configurations.</p></li><li><p><strong>Power Consumption</strong>: The amount of electrical power a GPU requires, measured in watts (W). Example: The NVIDIA RTX 3080 has a power consumption of around 320W.</p></li></ol><h3 id=nvidia-gpu-classification--variables--values><strong>NVIDIA GPU Classification – Variables & Values</strong><a class=td-heading-self-link href=#nvidia-gpu-classification--variables--values aria-label="Heading self-link"></a></h3><table><thead><tr><th><strong>Variable</strong></th><th><strong>Possible Values</strong></th><th><strong>Description</strong></th></tr></thead><tbody><tr><td><strong>Architecture</strong></td><td><em>Kepler, Maxwell, Pascal, Volta, Turing, Ampere, Hopper, Ada Lovelace, Blackwell</em></td><td>Core design used in a GPU generation</td></tr><tr><td><strong>GPU Usage</strong></td><td><em>Consumer Gaming, AI Training, AI Inference, Data Center, Workstation, HPC (High-Performance Computing), Embedded Systems</em></td><td>Main purpose of the GPU</td></tr><tr><td><strong>Product Line</strong></td><td><em>GeForce GTX, GeForce RTX, Tesla, Quadro, TITAN, RTX Workstation, Jetson, A-Series, H-Series, B-Series</em></td><td>Brand classification based on usage</td></tr><tr><td><strong>VRAM Type</strong></td><td><em>GDDR5, GDDR6, GDDR6X, HBM2, HBM3, HBM3e</em></td><td>Type of memory used</td></tr><tr><td><strong>ECC Memory</strong></td><td><em>Yes, No</em></td><td>Error Correction Code (important for AI research & HPC)</td></tr><tr><td><strong>Tensor Cores</strong></td><td><em>None, 1st Gen, 2nd Gen, 3rd Gen, 4th Gen, 5th Gen</em></td><td>AI acceleration cores</td></tr><tr><td><strong>Ray Tracing (RTX)</strong></td><td><em>Yes, No</em></td><td>Hardware-accelerated ray tracing for graphics</td></tr><tr><td><strong>CUDA Cores</strong></td><td><em>Few (GTX Series), Many (RTX Series), Extreme (Data Center GPUs)</em></td><td>Parallel processing units for compute tasks</td></tr><tr><td><strong>FP64 (Double Precision)</strong></td><td><em>Low, Medium, High</em></td><td>Important for scientific calculations</td></tr><tr><td><strong>Multi-GPU Support</strong></td><td><em>No, NVLink, PCIe Scaling</em></td><td>Ability to connect multiple GPUs</td></tr><tr><td><strong>Power Consumption</strong></td><td><em>Low (&lt;100W), Medium (150-300W), High (350-450W), Extreme (600W+)</em></td><td>GPU power requirements</td></tr></tbody></table><hr><h3 id=example-entries-for-different-gpus><strong>Example Entries for Different GPUs</strong><a class=td-heading-self-link href=#example-entries-for-different-gpus aria-label="Heading self-link"></a></h3><h4 id=1-rtx-4090-high-end-gaming--ai><strong>1. RTX 4090 (High-End Gaming + AI)</strong><a class=td-heading-self-link href=#1-rtx-4090-high-end-gaming--ai aria-label="Heading self-link"></a></h4><table><thead><tr><th><strong>Variable</strong></th><th><strong>Value</strong></th></tr></thead><tbody><tr><td><strong>Architecture</strong></td><td>Ada Lovelace</td></tr><tr><td><strong>GPU Usage</strong></td><td>Consumer Gaming, AI Training, AI Inference</td></tr><tr><td><strong>Product Line</strong></td><td>GeForce RTX</td></tr><tr><td><strong>VRAM Type</strong></td><td>GDDR6X</td></tr><tr><td><strong>ECC Memory</strong></td><td>No</td></tr><tr><td><strong>Tensor Cores</strong></td><td>4th Gen</td></tr><tr><td><strong>Ray Tracing (RTX)</strong></td><td>Yes</td></tr><tr><td><strong>CUDA Cores</strong></td><td>Many</td></tr><tr><td><strong>FP64 (Double Precision)</strong></td><td>Low</td></tr><tr><td><strong>Multi-GPU Support</strong></td><td>No</td></tr><tr><td><strong>Power Consumption</strong></td><td>High (450W)</td></tr></tbody></table><hr><h4 id=2-tesla-k80-old-ai-compute-gpu><strong>2. Tesla K80 (Old AI Compute GPU)</strong><a class=td-heading-self-link href=#2-tesla-k80-old-ai-compute-gpu aria-label="Heading self-link"></a></h4><table><thead><tr><th><strong>Variable</strong></th><th><strong>Value</strong></th></tr></thead><tbody><tr><td><strong>Architecture</strong></td><td>Kepler</td></tr><tr><td><strong>GPU Usage</strong></td><td>AI Training, Data Center, HPC</td></tr><tr><td><strong>Product Line</strong></td><td>Tesla</td></tr><tr><td><strong>VRAM Type</strong></td><td>GDDR5</td></tr><tr><td><strong>ECC Memory</strong></td><td>Yes</td></tr><tr><td><strong>Tensor Cores</strong></td><td>None</td></tr><tr><td><strong>Ray Tracing (RTX)</strong></td><td>No</td></tr><tr><td><strong>CUDA Cores</strong></td><td>Medium</td></tr><tr><td><strong>FP64 (Double Precision)</strong></td><td>High</td></tr><tr><td><strong>Multi-GPU Support</strong></td><td>PCIe Scaling</td></tr><tr><td><strong>Power Consumption</strong></td><td>Medium (150-300W)</td></tr></tbody></table><hr><h4 id=3-h100-latest-ai-gpu-for-data-centers><strong>3. H100 (Latest AI GPU for Data Centers)</strong><a class=td-heading-self-link href=#3-h100-latest-ai-gpu-for-data-centers aria-label="Heading self-link"></a></h4><table><thead><tr><th><strong>Variable</strong></th><th><strong>Value</strong></th></tr></thead><tbody><tr><td><strong>Architecture</strong></td><td>Hopper</td></tr><tr><td><strong>GPU Usage</strong></td><td>AI Training, AI Inference, Data Center, HPC</td></tr><tr><td><strong>Product Line</strong></td><td>H-Series</td></tr><tr><td><strong>VRAM Type</strong></td><td>HBM3</td></tr><tr><td><strong>ECC Memory</strong></td><td>Yes</td></tr><tr><td><strong>Tensor Cores</strong></td><td>4th Gen</td></tr><tr><td><strong>Ray Tracing (RTX)</strong></td><td>No</td></tr><tr><td><strong>CUDA Cores</strong></td><td>Extreme</td></tr><tr><td><strong>FP64 (Double Precision)</strong></td><td>High</td></tr><tr><td><strong>Multi-GPU Support</strong></td><td>NVLink</td></tr><tr><td><strong>Power Consumption</strong></td><td>Extreme (600W+)</td></tr></tbody></table><h2 id=we-have-heard-words-like-tesla-kepler-and-gtx-what-are-they-and-how-they-are-related>We have heard words like Tesla, Kepler and GTX. What are they and how they are related?<a class=td-heading-self-link href=#we-have-heard-words-like-tesla-kepler-and-gtx-what-are-they-and-how-they-are-related aria-label="Heading self-link"></a></h2><h3 id=what-are-these-terms-1>What are these terms?<a class=td-heading-self-link href=#what-are-these-terms-1 aria-label="Heading self-link"></a></h3><ul><li><strong>Kepler</strong> is an <strong>architecture</strong> (2012–2014) used in multiple GPU series.</li><li><strong>GTX</strong> is a <strong>consumer gaming GPU lineup</strong> that included Kepler-based GPUs.</li><li><strong>Tesla</strong> is a <strong>professional & AI/HPC (High-Performance Computing) GPU lineup</strong>, which also used the Kepler architecture.</li></ul><h3 id=what-are-kepler-based-gpus>What are Kepler based GPUS?<a class=td-heading-self-link href=#what-are-kepler-based-gpus aria-label="Heading self-link"></a></h3><p>Kepler-based GPUs in Different NVIDIA Product Lines</p><table><thead><tr><th><strong>GPU Series</strong></th><th><strong>Kepler-Based Models</strong></th><th><strong>Purpose</strong></th></tr></thead><tbody><tr><td><strong>GTX (Gaming GPUs)</strong></td><td>GTX 780 Ti, GTX 780, GTX 770, GTX 760, GTX 750 Ti</td><td>High-performance gaming & general computing</td></tr><tr><td><strong>Tesla (Data Center GPUs)</strong></td><td>Tesla K40, Tesla K80, Tesla K20</td><td>AI, scientific computing, HPC workloads</td></tr><tr><td><strong>Quadro (Workstation GPUs)</strong></td><td>Quadro K6000, Quadro K5000</td><td>Professional 3D rendering, CAD, content creation</td></tr></tbody></table><hr><h3 id=key-differences-and-relationship-between-tesla-kepler-and-gtx>Key Differences and Relationship Between Tesla, Kepler, and GTX<a class=td-heading-self-link href=#key-differences-and-relationship-between-tesla-kepler-and-gtx aria-label="Heading self-link"></a></h3><table><thead><tr><th>Feature</th><th><strong>GTX (Gaming GPUs)</strong></th><th><strong>Tesla (AI/HPC GPUs)</strong></th></tr></thead><tbody><tr><td><strong>Target Audience</strong></td><td>Gamers, general users</td><td>AI researchers, scientific computing</td></tr><tr><td><strong>CUDA Cores</strong></td><td>Optimized for gaming</td><td>Optimized for AI & compute</td></tr><tr><td><strong>Double Precision (FP64)</strong></td><td>Limited</td><td>High precision for AI/HPC</td></tr><tr><td><strong>ECC Memory (Error Correction)</strong></td><td>No</td><td>Yes (important for research)</td></tr><tr><td><strong>Driver Optimization</strong></td><td>Gaming, DirectX, OpenGL</td><td>AI, deep learning, CUDA, HPC</td></tr><tr><td><strong>VRAM Type</strong></td><td>GDDR5</td><td>GDDR5, ECC support</td></tr></tbody></table><hr><h3 id=how-tesla--gtx-differ-in-ai-workloads>How Tesla & GTX Differ in AI Workloads<a class=td-heading-self-link href=#how-tesla--gtx-differ-in-ai-workloads aria-label="Heading self-link"></a></h3><ul><li><strong>GTX GPUs (e.g., GTX 780 Ti)</strong> can run AI models but are not optimized for deep learning or scientific accuracy.</li><li><strong>Tesla GPUs (e.g., Tesla K80)</strong> have <strong>higher FP64 performance, ECC memory, and better CUDA support</strong> for AI research.</li><li>Today, Tesla has been <strong>replaced by modern AI-focused GPUs like A100, H100, and Blackwell (B100, B200)</strong>.</li></ul><h3 id=why-does-this-matter-today>Why Does This Matter Today?<a class=td-heading-self-link href=#why-does-this-matter-today aria-label="Heading self-link"></a></h3><ul><li>If you&rsquo;re doing <strong>AI freelance work</strong>, modern <strong>RTX GPUs (4090, 4070, etc.)</strong> have replaced old Tesla/Kepler GPUs for deep learning.</li><li>If you&rsquo;re working with <strong>data center-level AI</strong>, then you’d look at modern <strong>A100, H100, or Blackwell GPUs</strong> instead of old Tesla cards.</li></ul><h2 id=what-are-different-gpu-architecture-from-nvidia>What are different GPU architecture from nvidia?<a class=td-heading-self-link href=#what-are-different-gpu-architecture-from-nvidia aria-label="Heading self-link"></a></h2><p>NVIDIA has released multiple GPU <strong>architectures</strong> over the years, each bringing improvements in performance, efficiency, and AI capabilities. Here&rsquo;s a breakdown of the major architectures:</p><h3 id=latest--current-architectures><strong>Latest & Current Architectures</strong><a class=td-heading-self-link href=#latest--current-architectures aria-label="Heading self-link"></a></h3><table><thead><tr><th>Architecture</th><th>Year</th><th>Notable GPUs</th><th>Key Features</th></tr></thead><tbody><tr><td><strong>Blackwell</strong></td><td>2024</td><td>B100, B200, RTX 50 Series (upcoming)</td><td>AI-focused, HBM3e memory, improved efficiency, NVLink 5.0</td></tr><tr><td><strong>Ada Lovelace</strong></td><td>2022</td><td>RTX 4090, 4080, 4070, 4060, 4050</td><td>4th-gen Tensor Cores, DLSS 3, better ray tracing</td></tr><tr><td><strong>Hopper</strong></td><td>2022</td><td>H100, H200</td><td>Data center AI GPUs, FP8 support, Transformer Engine</td></tr><tr><td><strong>Ampere</strong></td><td>2020</td><td>RTX 3090, 3080, A100, GA102</td><td>3rd-gen Tensor Cores, PCIe 4.0, AI optimizations</td></tr><tr><td><strong>Turing</strong></td><td>2018</td><td>RTX 2080 Ti, 2080, 2060, GTX 16 Series</td><td>First with RTX (Ray Tracing), DLSS 1.0</td></tr></tbody></table><h3 id=older-architectures-legacy--gaming-focused><strong>Older Architectures (Legacy & Gaming Focused)</strong><a class=td-heading-self-link href=#older-architectures-legacy--gaming-focused aria-label="Heading self-link"></a></h3><table><thead><tr><th>Architecture</th><th>Year</th><th>Notable GPUs</th><th>Key Features</th></tr></thead><tbody><tr><td><strong>Volta</strong></td><td>2017</td><td>Tesla V100, Titan V</td><td>First with Tensor Cores, HBM2 memory</td></tr><tr><td><strong>Pascal</strong></td><td>2016</td><td>GTX 1080 Ti, 1080, 1070, 1060</td><td>GDDR5X, power-efficient, great gaming performance</td></tr><tr><td><strong>Maxwell</strong></td><td>2014</td><td>GTX 980, 970, 960</td><td>Big power efficiency improvements</td></tr><tr><td><strong>Kepler</strong></td><td>2012</td><td>GTX 780 Ti, 780, 770</td><td>First with GPU Boost, CUDA advancements</td></tr><tr><td><strong>Fermi</strong></td><td>2010</td><td>GTX 580, 480, Tesla GPUs</td><td>Early CUDA support, power-hungry</td></tr></tbody></table><h3 id=specialized-architectures-for-ai--data-centers><strong>Specialized Architectures for AI & Data Centers</strong><a class=td-heading-self-link href=#specialized-architectures-for-ai--data-centers aria-label="Heading self-link"></a></h3><ul><li><strong>Tesla</strong> (Fermi, Kepler, Maxwell) – Early AI & HPC focus</li><li><strong>Pascal & Volta</strong> – Introduced deep learning accelerations</li><li><strong>Ampere, Hopper, Blackwell</strong> – Modern AI training GPUs</li></ul><h3 id=which-architecture-should-you-consider><strong>Which Architecture Should You Consider?</strong><a class=td-heading-self-link href=#which-architecture-should-you-consider aria-label="Heading self-link"></a></h3><ul><li>If you want <strong>gaming + AI workloads</strong>, go for <strong>Ada Lovelace (RTX 40)</strong> or wait for <strong>Blackwell (RTX 50)</strong>.</li><li>If you need <strong>AI research & LLM training</strong>, <strong>Hopper (H100) or Blackwell (B100, B200)</strong> are the best.</li><li>If you&rsquo;re using an <strong>RTX 4070</strong>, you already have <strong>Ada Lovelace</strong>, which is quite powerful for AI freelancing.</li></ul><h2 id=how-much-power-geforce-rtx-4070-consumes>How much power GeForce RTX 4070 consumes?<a class=td-heading-self-link href=#how-much-power-geforce-rtx-4070-consumes aria-label="Heading self-link"></a></h2><p>The power consumption of an <strong>RTX 4070</strong> in a day depends on <strong>usage, power draw, and duration</strong>. Let&rsquo;s break it down:</p><h3 id=rtx-4070-power-draw-approximate>RTX 4070 Power Draw (Approximate)<a class=td-heading-self-link href=#rtx-4070-power-draw-approximate aria-label="Heading self-link"></a></h3><table><thead><tr><th><strong>Usage Type</strong></th><th><strong>Power Consumption (Wattage, W)</strong></th></tr></thead><tbody><tr><td><strong>Idle / Low Usage</strong></td><td>~15-20W</td></tr><tr><td><strong>Web Browsing / Light Work</strong></td><td>~40-50W</td></tr><tr><td><strong>Gaming / AI Inference</strong></td><td>~150-180W</td></tr><tr><td><strong>AI Training / Full Load</strong></td><td>~200-220W</td></tr></tbody></table><h3 id=power-consumption-formula>Power Consumption Formula<a class=td-heading-self-link href=#power-consumption-formula aria-label="Heading self-link"></a></h3><p><strong>Energy Consumption (kWh) = (GPU Wattage × Hours Used) ÷ 1000</strong></p><p><strong>Example Scenarios (for 24 hours)</strong></p><table><thead><tr><th><strong>Usage Scenario</strong></th><th><strong>Hours Per Day</strong></th><th><strong>Wattage (W)</strong></th><th><strong>Energy Used (kWh)</strong></th><th><strong>Cost (at $0.15/kWh)</strong></th></tr></thead><tbody><tr><td><strong>Idle / Light Work</strong></td><td>24 hrs</td><td>20W</td><td>0.48 kWh</td><td>~$0.07</td></tr><tr><td><strong>Gaming (3 hrs) + Light Work (5 hrs)</strong></td><td>3 hrs (180W) + 5 hrs (50W)</td><td>~</td><td>~0.69 kWh</td><td>~$0.10</td></tr><tr><td><strong>AI Inference (8 hrs) + Light Work (8 hrs)</strong></td><td>8 hrs (180W) + 8 hrs (50W)</td><td>~</td><td>~1.84 kWh</td><td>~$0.28</td></tr><tr><td><strong>Full AI Training (12 hrs) + Idle (12 hrs)</strong></td><td>12 hrs (220W) + 12 hrs (20W)</td><td>~</td><td>~3.0 kWh</td><td>~$0.45</td></tr></tbody></table><p>Note: Cost of electricity is different in the differnt countries. It depends upon country, state of the country, provider, consumer type and how much they consume. In India, electricity is provided by various companies like Reliance, TATA, BPL, etc. and the price is different according to the company and the state. The rate of electricity in India varies between 12 - 13 cents per kilowatt-hour for industrial users, and roughly 8 - 9 cents per kilowatt-hour for residential users.</p><p>The average electric rate in the United States is 16.54 cents per kWh. Louisiana has the cheapest electric rate (on average) with customers paying 11.23 cents per kWh for electricity. Electricity rates in Hawaii are the highest with rates 42.10 cents per kWh for electricity.</p><h3 id=monthly--yearly-estimates-ai-workload>Monthly & Yearly Estimates (AI Workload)<a class=td-heading-self-link href=#monthly--yearly-estimates-ai-workload aria-label="Heading self-link"></a></h3><p>If you run <strong>AI workloads for 8 hours/day</strong> at ~180W:</p><ul><li><strong>Daily:</strong> ~1.44 kWh → <strong>$0.22/day</strong></li><li><strong>Monthly:</strong> ~43.2 kWh → <strong>$6.48/month</strong></li><li><strong>Yearly:</strong> ~525.6 kWh → <strong>$78.84/year</strong></li></ul><div class=category-section><h4 class=category-section__title>Categories:</h4><div class=category-badges><a href=../../categories/dsblog class=category-badge>dsblog</a></div></div><div class=td-tags><h4 class=td-tags__title>Tags:</h4><div class=category-badges><a href=../../tags/nvidia class=category-badge>NVIDIA</a><a href=../../tags/gpus class=category-badge>GPUs</a><a href=../../tags/deep-learning class=category-badge>Deep Learning</a></div></div><div class=td-author-box><div class=td-author-box__info><h4 class=td-author-box__name>Blowfish</h4><p class=td-author-box__bio>A powerful, lightweight theme for Hugo.</p><div class=td-author-box__links><a href target=_blank rel=noopener aria-label></a><a href target=_blank rel=noopener aria-label></a></div></div></div><div class=td-social-share><h4 class=td-social-share__title>Share this article:</h4><ul class=td-social-share__list><div class=social-share><a href="https://twitter.com/intent/tweet?text=Demystifying%20NVIDIA%20GPUs&url=https%3a%2f%2fdasarpai.github.io%2fdsblog%2fdemystify-nvidia-gpus%2f" target=_blank rel=noopener aria-label="Share on Twitter"><i class="fab fa-twitter"></i>
</a><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fdasarpai.github.io%2fdsblog%2fdemystify-nvidia-gpus%2f" target=_blank rel=noopener aria-label="Share on Facebook"><i class="fab fa-facebook"></i>
</a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fdasarpai.github.io%2fdsblog%2fdemystify-nvidia-gpus%2f&title=Demystifying%20NVIDIA%20GPUs" target=_blank rel=noopener aria-label="Share on LinkedIn"><i class="fab fa-linkedin"></i>
</a><a href="https://www.reddit.com/submit?url=https%3a%2f%2fdasarpai.github.io%2fdsblog%2fdemystify-nvidia-gpus%2f&title=Demystifying%20NVIDIA%20GPUs" target=_blank rel=noopener aria-label="Share on Reddit"><i class="fab fa-reddit"></i>
</a><a href="mailto:?subject=Demystifying%20NVIDIA%20GPUs&body=https%3a%2f%2fdasarpai.github.io%2fdsblog%2fdemystify-nvidia-gpus%2f" aria-label="Share via Email"><i class="fas fa-envelope"></i></a></div></ul></div><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><a class="td-pager__link td-pager__link--prev" href=../../dsblog/exploring-tokenization-and-embedding-in-nlp/ aria-label="Previous page"><div class=td-pager__meta><i class="fa-solid fa-angle-left"></i>
<span class=td-pager__meta-label><b>Previous:</b></span>
<span class=td-pager__meta-title>Exploring Tokenization and Embedding in NLP</span></div></a><a class="td-pager__link td-pager__link--next" href=../../dsblog/exploring-the-energy-demand-and-supply-of-india/ aria-label="Next page"><div class=td-pager__meta><span class=td-pager__meta-label><b>Next:</b></span>
<span class=td-pager__meta-title>Exploring the Energy Demand and Supply of India</span>
<i class="fa-solid fa-angle-right"></i></div></a></ul></div><div class=col-md-2></div></div></main><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class=col-2><a href=https://dasarpai.com target=_blank rel=noopener><img src=https://dasarpai.github.io/assets/images/site-logo.png alt=dasarpAI width=100 style=border-radius:12px></a></div><div class=col-8><div class=row></div><div class=row></div></div><div class=col-2></div><div class="td-footer__left col-6 col-sm-4 order-sm-1"></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"></div></div></div></footer></div><script src=../../js/main.min.4e728f6d1777a74bef81c238fd7b573f42f1848a910503e07f877f49f1f442cb.js integrity="sha256-TnKPbRd3p0vvgcI4/XtXP0LxhIqRBQPgf4d/SfH0Qss=" crossorigin=anonymous></script><script defer src=../../js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=../../js/tabpane-persist.js></script><script src=https://dasarpai.github.io/js/asciinema-player.js></script><script>(function(){var e=document.querySelector("#td-section-nav");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></body></html>