<!doctype html><html itemscope itemtype=http://schema.org/WebPage lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.147.0"><meta name=ROBOTS content="NOINDEX, NOFOLLOW"><link rel="shortcut icon" href="../../favicons/favicon.ico?v=1"><link rel=apple-touch-icon href="../../favicons/apple-touch-icon-180x180.png?v=1" sizes=180x180><link rel=icon type=image/png href="../../favicons/favicon-16x16.png?v=1" sizes=16x16><link rel=icon type=image/png href="../../favicons/favicon-32x32.png?v=1" sizes=32x32><link rel=apple-touch-icon href="../../favicons/apple-touch-icon-180x180.png?v=1" sizes=180x180><title>AWS SageMaker Jumpstart Models | Blowfish</title><meta property="og:url" content="https://dasarpai.github.io/dsblog/AWS-SageMaker-Jumpstart-Models/">
<meta property="og:site_name" content="Blowfish"><meta property="og:title" content="AWS SageMaker Jumpstart Models"><meta property="og:description" content="AWS SageMaker Jumpstart Models As of 17-Jul-23, AWS Sagemaker has 463 models in its Model Zoo. They call these models as Jumstart Models. What are the capabilities of these models, who are the developer of these models, where these models are hosted in given in the table below."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="dsblog"><meta property="article:published_time" content="2023-07-18T00:00:00+00:00"><meta property="article:modified_time" content="2023-07-18T00:00:00+00:00"><meta property="article:tag" content="Python"><meta property="article:tag" content="Programming"><meta itemprop=name content="AWS SageMaker Jumpstart Models"><meta itemprop=description content="AWS SageMaker Jumpstart Models As of 17-Jul-23, AWS Sagemaker has 463 models in its Model Zoo. They call these models as Jumstart Models. What are the capabilities of these models, who are the developer of these models, where these models are hosted in given in the table below."><meta itemprop=datePublished content="2023-07-18T00:00:00+00:00"><meta itemprop=dateModified content="2023-07-18T00:00:00+00:00"><meta itemprop=wordCount content="7796"><meta itemprop=keywords content="AWS SageMaker,Jumpstart Models,Machine Learning,AI Models,Model Zoo,Text Generation,Text to Image"><meta name=twitter:card content="summary"><meta name=twitter:title content="AWS SageMaker Jumpstart Models"><meta name=twitter:description content="AWS SageMaker Jumpstart Models As of 17-Jul-23, AWS Sagemaker has 463 models in its Model Zoo. They call these models as Jumstart Models. What are the capabilities of these models, who are the developer of these models, where these models are hosted in given in the table below."><link rel=preload href=../../scss/main.min.8d5e9853aa86c416850fe7ccb39d048388bfe7fbefb7922f796f886c3c8084d8.css as=style integrity="sha256-jV6YU6qGxBaFD+fMs50Eg4i/5/vvt5IveW+IbDyAhNg=" crossorigin=anonymous><link href=../../scss/main.min.8d5e9853aa86c416850fe7ccb39d048388bfe7fbefb7922f796f886c3c8084d8.css rel=stylesheet integrity="sha256-jV6YU6qGxBaFD+fMs50Eg4i/5/vvt5IveW+IbDyAhNg=" crossorigin=anonymous><link rel=stylesheet type=text/css href=https://dasarpai.github.io/css/asciinema-player.css><script src=https://code.jquery.com/jquery-3.3.1.min.js integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin=anonymous></script><link rel=stylesheet href=../../css/custom.css><script src=../../js/lunr.js></script></head><body class=td-page><header><nav class="js-navbar-scroll navbar navbar-expand navbar-light nav-shadow flex-column flex-md-row td-navbar"><a id=agones-top class=navbar-brand href=../../><svg id="Layer_1" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><rect x="198.8952" y="225.1043" style="fill:#5b7fc0" width="122.6266" height="13.8671"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zm7.993 21.8577c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><rect x="198.8952" y="170.69" style="fill:#d95140" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><rect x="199.3456" y="279.5436" style="fill:#56a55c" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><rect x="198.8952" y="333.6497" style="fill:#f1bc42" width="122.6266" height="13.8671"/></g></g></svg> <span class="text-uppercase fw-bold">Blowfish</span></a><div class="td-navbar-nav-scroll ms-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../template/about/><span>About</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=../../><span class=active>Data Science</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../template/docs/><span>Documentation</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../template/docs/><span>Docs</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../community/><span>Community</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../template/docs/shortcodes/><span>Short Codes</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=../../template/blog/><span>Blog</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=https://github.com/nunocoracao/blowfish><span></span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href>GitHub</a></li><li class="nav-item dropdown d-none d-lg-block"><a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>Release</a><div class=dropdown-menu aria-labelledby=navbarDropdownMenuLink><a class=dropdown-item href=https://development.agones.dev>Development</a>
<a class=dropdown-item href=https://agones.dev></a><a class=dropdown-item href=https://1-47-0.agones.dev>1.47.0</a>
<a class=dropdown-item href=https://1-46-0.agones.dev>1.46.0</a>
<a class=dropdown-item href=https://1-45-0.agones.dev>1.45.0</a>
<a class=dropdown-item href=https://1-44-0.agones.dev>1.44.0</a>
<a class=dropdown-item href=https://1-43-0.agones.dev>1.43.0</a>
<a class=dropdown-item href=https://1-42-0.agones.dev>1.42.0</a>
<a class=dropdown-item href=https://1-41-0.agones.dev>1.41.0</a>
<a class=dropdown-item href=https://1-40-0.agones.dev>1.40.0</a>
<a class=dropdown-item href=https://1-39-0.agones.dev>1.39.0</a>
<a class=dropdown-item href=https://1-38-0.agones.dev>1.38.0</a>
<a class=dropdown-item href=https://1-37-0.agones.dev>1.37.0</a>
<a class=dropdown-item href=https://1-36-0.agones.dev>1.36.0</a>
<a class=dropdown-item href=https://1-35-0.agones.dev>1.35.0</a>
<a class=dropdown-item href=https://1-34-0.agones.dev>1.34.0</a>
<a class=dropdown-item href=https://1-33-0.agones.dev>1.33.0</a>
<a class=dropdown-item href=https://1-32-0.agones.dev>1.32.0</a>
<a class=dropdown-item href=https://1-31-0.agones.dev>1.31.0</a></div></li><li class="nav-item dropdown d-none d-lg-block"><div class=dropdown><a class="nav-link dropdown-toggle" href=# role=button data-bs-toggle=dropdown aria-haspopup=true aria-expanded=false>English</a><ul class=dropdown-menu><li><a class=dropdown-item href=../../it/>Italiano</a></li></ul></div></li></ul></div><div class="navbar-nav mx-lg-2 d-none d-lg-block"></div></nav></header><div class="container-fluid td-default td-outer"><main role=main class=td-main><div class=row><div class=col-md-2></div><div class=col-md-8><p><img src=../../assets/images/dspost/dsp6076-AWS-SageMaker-Jumpstart-Models.jpg alt="AWS SageMaker Jumpstart Models"></p><h1 id=aws-sagemaker-jumpstart-models>AWS SageMaker Jumpstart Models<a class=td-heading-self-link href=#aws-sagemaker-jumpstart-models aria-label="Heading self-link"></a></h1><p>As of 17-Jul-23, AWS Sagemaker has 463 models in its Model Zoo. They call these models as Jumstart Models. What are the capabilities of these models, who are the developer of these models, where these models are hosted in given in the table below.</p><table><thead><tr><th>SNo.</th><th>Task Type</th><th>Company</th><th>Model Description</th><th>Model ID</th></tr></thead><tbody><tr><td>1.</td><td>Text Generation</td><td>Huggingface</td><td>Falcon-40B-Instruct is a 40B parameters causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize It is ready-to-use chat/instruct model based on Falcon 40B</td><td>Model draft: false</td></tr><tr><td>id: huggingface-textgeneration-falcon-40b-instruct-bf16</td><td></td><td></td><td></td><td></td></tr><tr><td>2.</td><td>Text Generation</td><td>Huggingface</td><td>This is a Text Generation model built upon a Transformer model from Hugging Face</td><td>Model draft: false</td></tr><tr><td>id: huggingface-textgeneration-open-llama</td><td></td><td></td><td></td><td></td></tr><tr><td>3.</td><td>Text to Image</td><td>StabilityAI</td><td>Extend beyond just text-to-image prompting. Stable Diffusion XL offers several ways to modify the images: Inpainting - edit inside the image, Outpainting - extend the image outside of the original image, Image-to-image - prompt a new image using a sourced image.</td><td></td></tr><tr><td>4.</td><td>Text Generation</td><td>Cohere</td><td>Generative model that responds well with instruction-like prompts. This model provides businesses and enterprises with best quality, performance and accuracy in all generative tasks. And with our intuitive SDK, unlocking the full potential of LLMs for your applications has never been easier.</td><td></td></tr><tr><td>5.</td><td>Text Generation</td><td>AI21 Labs</td><td>Jurassic-2 Ultra is optimized to follow natural language instructions and context, so there is no need to provide it with any examples.</td><td></td></tr><tr><td>6.</td><td>Text Generation</td><td>AI21 Labs</td><td></td><td></td></tr><tr><td>7.</td><td>Text Generation</td><td>AI21 Labs</td><td>Condense lengthy texts into short, easy-to-read bites that remain factually consistent with the source. No prompting needed – simply input the text that needs to be summarized. The model is specifically trained to generate summaries that capture the essence and key ideas of the original text.</td><td></td></tr><tr><td>8.</td><td>Text Generation</td><td>AI21 Labs</td><td>Get the AI21 Paraphrase model, the top-of-the-line paraphrasing engine, and deploy it in your private environment. The model aims to generate 10 alternative suggestions with every activation. It may return fewer suggestions when rewriting very short texts for which it cannot produce as many as 10 sensible paraphrases.</td><td></td></tr><tr><td>9.</td><td>Text Generation</td><td>AI21 Labs</td><td>Jurassic-2 Mid is optimized to follow natural language instructions and context, so there is no need to provide it with any examples. Pre-trained language model trained by AI21 Labs on a corpus of web text including natural language and computer programs with recent data - updated to mid 2022. This model has a 8192 token context window (i.e. the length of the prompt + completion should be at most 8192 tokens).</td><td></td></tr><tr><td>10.</td><td>Text Generation</td><td>AI21 Labs</td><td>Detects and suggests corrections for Grammar, Spelling, Punctuation mistakes, as well as word misuse, and accidental repetition or omission.</td><td></td></tr><tr><td>11.</td><td>Text to Image</td><td>StabilityAI</td><td>Extend beyond just text-to-image prompting. Stable Diffusion XL offers several ways to modify the images: Inpainting - edit inside the image, Outpainting - extend the image outside of the original image, Image-to-image - prompt a new image using a sourced image.</td><td></td></tr><tr><td>12.</td><td>Text to Image</td><td>Stabilityai</td><td>This is a text-to-image model from Stability AI and downloaded from HuggingFace It takes a textual description as input and returns a generated image from the description</td><td>Model draft: false</td></tr><tr><td>id: model-txt2img-stabilityai-stable-diffusion-v2-1-base</td><td></td><td></td><td></td><td></td></tr><tr><td>13.</td><td></td><td>Huggingface</td><td>This is a Text2Text Generation model built upon a T5 model from Hugging Face The deployed model can be used for running inference on any input text</td><td>Model draft: false</td></tr><tr><td>id: huggingface-text2text-flan-t5-xl</td><td></td><td></td><td></td><td></td></tr><tr><td>14.</td><td></td><td>Huggingface</td><td>This is a Text Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts next words in the sequence</td><td>Model draft: false</td></tr><tr><td>id: huggingface-textgeneration1-gpt-j-6b</td><td></td><td></td><td></td><td></td></tr><tr><td>15.</td><td></td><td>Huggingface</td><td>This is a Text2Text Generation model built upon a T5 model from Hugging Face The deployed model can be used for running inference on any input text</td><td>Model draft: false</td></tr><tr><td>id: huggingface-text2text-flan-ul2-bf16</td><td></td><td></td><td></td><td></td></tr><tr><td>16.</td><td>Text Generation</td><td>Pytorch</td><td>AlexaTM 20B is a multitask, multilingual, large-scale sequence-to-sequence (seq2seq) model, trained on a mixture of Common Crawl (mC4) and Wikipedia data across 12 languages, using denoising and Causal Language Modeling (CLM) tasks</td><td>Model draft: false</td></tr><tr><td>id: pytorch-textgeneration1-alexa20b</td><td></td><td></td><td></td><td></td></tr><tr><td>17.</td><td>Text Generation</td><td>Huggingface</td><td>This is a Text Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts next words in the sequence</td><td>Model draft: false</td></tr><tr><td>id: huggingface-textgeneration-bloom-1b7</td><td></td><td></td><td></td><td></td></tr><tr><td>18.</td><td>Image Classification</td><td>Tensorflow</td><td>This is an Image Classification model from TensorFlow Hub It takes an image as input and classifies the image to one of the 1001 classes</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v2-100-224-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>19.</td><td>Object Detection</td><td>Tensorflow</td><td>This is an object detection model from Tensorflow It takes an image as input and returns bounding boxes for the objects in the image</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-resnet50-v1-fpn-640x640-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>20.</td><td>Object Detection</td><td>Pytorch</td><td>This is an object detection model from PyTorch Hub It takes an image as input and returns bounding boxes for the objects in the image</td><td>Model draft: false</td></tr><tr><td>id: pytorch-od1-fasterrcnn-resnet50-fpn</td><td></td><td></td><td></td><td></td></tr><tr><td>21.</td><td>Text Classification</td><td>Tensorflow</td><td>This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub It takes a text string as input and classifies the input text as either a positive or negative movie review</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-bert-en-uncased-L-12-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>22.</td><td>Question Answering</td><td>Huggingface</td><td>This is an Extractive Question Answering model built on a Transformer model from Hugging Face It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-distilbert-base-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>23.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>This is Zero Shot Text Classification model built on a Transformer model from Hugging Face It can classify sentences in English language It takes a sequence and a list of candidate labels as inputs and predicts score that the sequence is associated with the particular label</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-facebook-bart-large-mnli</td><td></td><td></td><td></td><td></td></tr><tr><td>24.</td><td>Semantic Segmentation</td><td>Mxnet</td><td>This is an Semantic Segmentation model from Gluon CV It takes an image as input and returns class label for each pixel in the image</td><td>Model draft: false</td></tr><tr><td>id: mxnet-semseg-fcn-resnet101-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>25.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>This is a Sentence Pair Classification model built upon a Text Embedding model from Hugging Face It takes a pair of sentences as input and classifies the input pair to &rsquo;entailment&rsquo; or &rsquo;no-entailment'</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-distilbert-base-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>26.</td><td>Named Entity Recognition</td><td>Huggingface</td><td>This is a Named Entity Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts named entities in the input text</td><td>Model draft: false</td></tr><tr><td>id: huggingface-ner-distilbert-base-cased-finetuned-conll03-english</td><td></td><td></td><td></td><td></td></tr><tr><td>27.</td><td>Text Summarization</td><td>Huggingface</td><td>This is a Text Summarization model built upon a Transformer model from Hugging Face It takes a text string as input and returns a summary of the text</td><td>Model draft: false</td></tr><tr><td>id: huggingface-summarization-distilbart-xsum-1-1</td><td></td><td></td><td></td><td></td></tr><tr><td>28.</td><td>Machine Translation</td><td>Huggingface</td><td>This is a Machine Translation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts its translation</td><td>Model draft: false</td></tr><tr><td>id: huggingface-translation-t5-small</td><td></td><td></td><td></td><td></td></tr><tr><td>29.</td><td>Text Embedding</td><td>Tensorflow</td><td>This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-2-H-128-A-2-2</td><td></td><td></td><td></td><td></td></tr><tr><td>30.</td><td>Text Embedding</td><td>Mxnet</td><td>This is a Text Embedding model from GluonNLP pre-trained on the decade (2010-2019) of S&amp;P 500 10-K/10-Q reports It takes a text string as input and outputs an embedding vector For pre-training, the entire text of the 10K/Q filing was used, not just the MD&amp;A (Management Discussion and Analysis) section, so as to ensure that a broader context of financial language is captured Embeddings from the pre-trained modelare then used for fine-tuning specific classifiers</td><td>Model draft: false</td></tr><tr><td>id: mxnet-tcembedding-robertafin-base-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>31.</td><td>Sentence Pair Classification</td><td>Tensorflow</td><td>This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub It takes a pair of sentences as input and classifies the input pair to &rsquo;entailment&rsquo; or &rsquo;no-entailment'</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-spc-bert-en-uncased-L-12-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>32.</td><td>Instance Segmentation</td><td>Mxnet</td><td>This is an Instance Segmentation model from Gluon CV It detects and delineates each distinct object in the image</td><td>Model draft: false</td></tr><tr><td>id: mxnet-is-mask-rcnn-fpn-resnet101-v1d-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>33.</td><td>Image Embedding</td><td>Tensorflow</td><td>This is an Image Feature Vector model from TensorFlow Hub It takes an image as input and returns a feature vector (embedding) of the image</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v2-100-224-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>34.</td><td>Image Classification</td><td>Pytorch</td><td>This is an Image Classification model from PyTorch Hub It takes an image as input and classifies the image to one of the 1000 classes</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-mobilenet-v2</td><td></td><td></td><td></td><td></td></tr><tr><td>35.</td><td>Object Detection</td><td>Mxnet</td><td>This is an object detection model from Gluon CV It takes an image as input and returns bounding boxes for the objects in the image</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-ssd-512-mobilenet1-0-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>36.</td><td>Object Detection</td><td>Tensorflow</td><td>This is an object detection model from TensorFlow Hub It takes an image as input and returns bounding boxes for the objects in the image</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-ssd-mobilenet-v2-fpnlite-320x320-1</td><td></td><td></td><td></td><td></td></tr><tr><td>37.</td><td>Object Detection</td><td>Pytorch</td><td>This is an object detection model from PyTorch Hub It takes an image as input and returns bounding boxes for the objects in the image</td><td>Model draft: false</td></tr><tr><td>id: pytorch-od-nvidia-ssd</td><td></td><td></td><td></td><td></td></tr><tr><td>38.</td><td>Image Classification</td><td>Tensorflow</td><td>This is an Image Classification model from TensorFlow Hub It takes an image as input and classifies the image to one of the 1001 classes</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v2-075-224-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>39.</td><td>Image Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v2-050-224-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>40.</td><td>Image Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v2-035-224-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>41.</td><td>Image Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v2-140-224-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>42.</td><td>Image Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v2-130-224-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>43.</td><td>Object Detection</td><td>Pytorch</td><td>This is an object detection model from PyTorch Hub It takes an image as input and returns bounding boxes for the objects in the image</td><td>Model draft: false</td></tr><tr><td>id: pytorch-od1-fasterrcnn-mobilenet-v3-large-320-fpn</td><td></td><td></td><td></td><td></td></tr><tr><td>44.</td><td>Object Detection</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-od1-fasterrcnn-mobilenet-v3-large-fpn</td><td></td><td></td><td></td><td></td></tr><tr><td>45.</td><td>Semantic Segmentation</td><td>Mxnet</td><td>This is an Semantic Segmentation model from Gluon CV It takes an image as input and returns class label for each pixel in the image</td><td>Model draft: false</td></tr><tr><td>id: mxnet-semseg-fcn-resnet101-voc</td><td></td><td></td><td></td><td></td></tr><tr><td>46.</td><td>Semantic Segmentation</td><td>Mxnet</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: mxnet-semseg-fcn-resnet101-ade</td><td></td><td></td><td></td><td></td></tr><tr><td>47.</td><td>Instance Segmentation</td><td>Mxnet</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: mxnet-semseg-fcn-resnet50-ade</td><td></td><td></td><td></td><td></td></tr><tr><td>48.</td><td>Image Classification</td><td>Pytorch</td><td>This is an Image Classification model from PyTorch Hub It takes an image as input and classifies the image to one of the 1000 classes</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-resnet18</td><td></td><td></td><td></td><td></td></tr><tr><td>49.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-resnet34</td><td></td><td></td><td></td><td></td></tr><tr><td>50.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-resnet50</td><td></td><td></td><td></td><td></td></tr><tr><td>51.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-resnet101</td><td></td><td></td><td></td><td></td></tr><tr><td>52.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-resnet152</td><td></td><td></td><td></td><td></td></tr><tr><td>53.</td><td>Object Detection</td><td>Mxnet</td><td>This is an object detection model from Gluon CV It takes an image as input and returns bounding boxes for the objects in the image</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-ssd-512-mobilenet1-0-voc</td><td></td><td></td><td></td><td></td></tr><tr><td>54.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-ssd-512-resnet50-v1-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>55.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-ssd-512-resnet50-v1-voc</td><td></td><td></td><td></td><td></td></tr><tr><td>56.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-ssd-300-vgg16-atrous-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>57.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-ssd-300-vgg16-atrous-voc</td><td></td><td></td><td></td><td></td></tr><tr><td>58.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-efficientdet-d0-512x512-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>59.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-efficientdet-d1-640x640-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>60.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-efficientdet-d2-768x768-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>61.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-efficientdet-d3-896x896-coco17-tpu-32</td><td></td><td></td><td></td><td></td></tr><tr><td>62.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-mobilenet-v1-fpn-640x640-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>63.</td><td>Instance Segmentation</td><td>Mxnet</td><td>This is an Instance Segmentation model from Gluon CV It detects and delineates each distinct object in the image</td><td>Model draft: false</td></tr><tr><td>id: mxnet-is-mask-rcnn-fpn-resnet50-v1b-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>64.</td><td>Instance Segmentation</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-is-mask-rcnn-fpn-resnet18-v1b-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>65.</td><td></td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-is-mask-rcnn-resnet18-v1b-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>66.</td><td>Image Embedding</td><td>Tensorflow</td><td>This is an Image Feature Vector model from TensorFlow Hub It takes an image as input and returns a feature vector (embedding) of the image</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v2-075-224-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>67.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v2-050-224-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>68.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v2-035-224-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>69.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v2-140-224-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>70.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v2-130-224-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>71.</td><td>Object Detection</td><td>Tensorflow</td><td>This is an object detection model from TensorFlow Hub It takes an image as input and returns bounding boxes for the objects in the image</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-ssd-mobilenet-v2-fpnlite-640x640-1</td><td></td><td></td><td></td><td></td></tr><tr><td>72.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-ssd-mobilenet-v2-2</td><td></td><td></td><td></td><td></td></tr><tr><td>73.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-ssd-mobilenet-v1-fpn-640x640-1</td><td></td><td></td><td></td><td></td></tr><tr><td>74.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-faster-rcnn-resnet50-v1-640x640-1</td><td></td><td></td><td></td><td></td></tr><tr><td>75.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-faster-rcnn-resnet50-v1-800x1333-1</td><td></td><td></td><td></td><td></td></tr><tr><td>76.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>This is Zero Shot Text Classification model built on a Transformer model from Hugging Face It can classify sentences in English language It takes a sequence and a list of candidate labels as inputs and predicts score that the sequence is associated with the particular label</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-narsil-deberta-large-mnli-zero-cls</td><td></td><td></td><td></td><td></td></tr><tr><td>77.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-moritzlaurer-deberta-v3-large-mnli-fever-anli-ling-wanli</td><td></td><td></td><td></td><td></td></tr><tr><td>78.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-cross-encoder-nli-distilroberta-base</td><td></td><td></td><td></td><td></td></tr><tr><td>79.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-recognai-bert-base-spanish-wwm-cased-xnli</td><td></td><td></td><td></td><td></td></tr><tr><td>80.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-moritzlaurer-mdeberta-v3-base-xnli-multilingual-nli-2mil7</td><td></td><td></td><td></td><td></td></tr><tr><td>81.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-cross-encoder-nli-roberta-base</td><td></td><td></td><td></td><td></td></tr><tr><td>82.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-cross-encoder-nli-deberta-base</td><td></td><td></td><td></td><td></td></tr><tr><td>83.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-cross-encoder-nli-minilm2-l6-h768</td><td></td><td></td><td></td><td></td></tr><tr><td>84.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-recognai-zeroshot-selectra-medium</td><td></td><td></td><td></td><td></td></tr><tr><td>85.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-navteca-bart-large-mnli</td><td></td><td></td><td></td><td></td></tr><tr><td>86.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-jiva-xlm-roberta-large-it-mnli</td><td></td><td></td><td></td><td></td></tr><tr><td>87.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-digitalepidemiologylab-covid-twitter-bert-v2-mnli</td><td></td><td></td><td></td><td></td></tr><tr><td>88.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-recognai-zeroshot-selectra-small</td><td></td><td></td><td></td><td></td></tr><tr><td>89.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-snli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>90.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-bert-base-turkish-cased-allnli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>91.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-bert-base-turkish-cased-snli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>92.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-bert-base-multilingual-cased-allnli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>93.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-narsil-bart-large-mnli-opti</td><td></td><td></td><td></td><td></td></tr><tr><td>94.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-allnli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>95.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-lighteternal-nli-xlm-r-greek</td><td></td><td></td><td></td><td></td></tr><tr><td>96.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-allnli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>97.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-bert-base-multilingual-cased-multinli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>98.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-eleldar-theme-classification</td><td></td><td></td><td></td><td></td></tr><tr><td>99.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-bert-base-turkish-cased-multinli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>100.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-bert-base-multilingual-cased-snli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>101.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-multinli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>102.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-multinli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>103.</td><td>Zero-Shot Text Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-snli-tr</td><td></td><td></td><td></td><td></td></tr><tr><td>104.</td><td>Image Classification</td><td>Tensorflow</td><td>This is an Image Classification model from TensorFlow Hub It takes an image as input and classifies the image to one of the 1001 classes</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-tf2-preview-mobilenet-v2-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>105.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-inception-v3-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>106.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-inception-v2-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>107.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-inception-v1-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>108.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-tf2-preview-inception-v3-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>109.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-inception-resnet-v2-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>110.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-resnet-v2-50-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>111.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-resnet-v2-101-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>112.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-resnet-v2-152-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>113.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-resnet-v1-50-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>114.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-resnet-v1-101-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>115.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-resnet-v1-152-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>116.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-resnet-50-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>117.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-b0-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>118.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-b1-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>119.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-b2-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>120.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-b3-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>121.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-b4-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>122.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-b5-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>123.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-b6-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>124.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-b7-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>125.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-lite0-classification-2</td><td></td><td></td><td></td><td></td></tr><tr><td>126.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-lite1-classification-2</td><td></td><td></td><td></td><td></td></tr><tr><td>127.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-lite2-classification-2</td><td></td><td></td><td></td><td></td></tr><tr><td>128.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-lite3-classification-2</td><td></td><td></td><td></td><td></td></tr><tr><td>129.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-efficientnet-lite4-classification-2</td><td></td><td></td><td></td><td></td></tr><tr><td>130.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-100-224-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>131.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-100-192-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>132.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-100-160-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>133.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-100-128-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>134.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-075-224-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>135.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-075-192-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>136.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-075-160-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>137.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-075-128-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>138.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-050-224-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>139.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-050-192-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>140.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-050-160-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>141.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-050-128-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>142.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-025-224-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>143.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-025-192-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>144.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-025-160-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>145.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-imagenet-mobilenet-v1-025-128-classification-4</td><td></td><td></td><td></td><td></td></tr><tr><td>146.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-s-r50x1-ilsvrc2012-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>147.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-s-r50x3-ilsvrc2012-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>148.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-s-r101x1-ilsvrc2012-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>149.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-s-r101x3-ilsvrc2012-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>150.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-m-r50x1-ilsvrc2012-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>151.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-m-r50x3-ilsvrc2012-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>152.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-m-r101x1-ilsvrc2012-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>153.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-m-r101x3-ilsvrc2012-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>154.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-m-r50x1-imagenet21k-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>155.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-m-r50x3-imagenet21k-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>156.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-m-r101x1-imagenet21k-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>157.</td><td>Image Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-ic-bit-m-r101x3-imagenet21k-classification-1</td><td></td><td></td><td></td><td></td></tr><tr><td>158.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-alexnet</td><td></td><td></td><td></td><td></td></tr><tr><td>159.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-densenet121</td><td></td><td></td><td></td><td></td></tr><tr><td>160.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-densenet169</td><td></td><td></td><td></td><td></td></tr><tr><td>161.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-densenet201</td><td></td><td></td><td></td><td></td></tr><tr><td>162.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-densenet161</td><td></td><td></td><td></td><td></td></tr><tr><td>163.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-resnext50-32x4d</td><td></td><td></td><td></td><td></td></tr><tr><td>164.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-resnext101-32x8d</td><td></td><td></td><td></td><td></td></tr><tr><td>165.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-shufflenet-v2-x1-0</td><td></td><td></td><td></td><td></td></tr><tr><td>166.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-squeezenet1-0</td><td></td><td></td><td></td><td></td></tr><tr><td>167.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-squeezenet1-1</td><td></td><td></td><td></td><td></td></tr><tr><td>168.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-vgg11</td><td></td><td></td><td></td><td></td></tr><tr><td>169.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-vgg11-bn</td><td></td><td></td><td></td><td></td></tr><tr><td>170.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-vgg13</td><td></td><td></td><td></td><td></td></tr><tr><td>171.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-vgg13-bn</td><td></td><td></td><td></td><td></td></tr><tr><td>172.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-vgg16</td><td></td><td></td><td></td><td></td></tr><tr><td>173.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-vgg16-bn</td><td></td><td></td><td></td><td></td></tr><tr><td>174.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-vgg19</td><td></td><td></td><td></td><td></td></tr><tr><td>175.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-vgg19-bn</td><td></td><td></td><td></td><td></td></tr><tr><td>176.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-wide-resnet50-2</td><td></td><td></td><td></td><td></td></tr><tr><td>177.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-wide-resnet101-2</td><td></td><td></td><td></td><td></td></tr><tr><td>178.</td><td>Image Classification</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-ic-googlenet</td><td></td><td></td><td></td><td></td></tr><tr><td>179.</td><td>Object Detection</td><td>Mxnet</td><td>This is an object detection model from Gluon CV It takes an image as input and returns bounding boxes for the objects in the image</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-ssd-512-vgg16-atrous-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>180.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-ssd-512-vgg16-atrous-voc</td><td></td><td></td><td></td><td></td></tr><tr><td>181.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-yolo3-darknet53-voc</td><td></td><td></td><td></td><td></td></tr><tr><td>182.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-yolo3-mobilenet1-0-voc</td><td></td><td></td><td></td><td></td></tr><tr><td>183.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-yolo3-darknet53-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>184.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-yolo3-mobilenet1-0-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>185.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-faster-rcnn-resnet50-v1b-voc</td><td></td><td></td><td></td><td></td></tr><tr><td>186.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-faster-rcnn-resnet50-v1b-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>187.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-faster-rcnn-resnet101-v1d-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>188.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-faster-rcnn-fpn-resnet50-v1b-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>189.</td><td>Object Detection</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-od-faster-rcnn-fpn-resnet101-v1d-coco</td><td></td><td></td><td></td><td></td></tr><tr><td>190.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-mobilenet-v2-fpnlite-320x320-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>191.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-mobilenet-v2-fpnlite-640x640-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>192.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-resnet50-v1-fpn-1024x1024-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>193.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-resnet101-v1-fpn-640x640-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>194.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-resnet101-v1-fpn-1024x1024-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>195.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-resnet152-v1-fpn-640x640-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>196.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od1-ssd-resnet152-v1-fpn-1024x1024-coco17-tpu-8</td><td></td><td></td><td></td><td></td></tr><tr><td>197.</td><td>Image Embedding</td><td>Tensorflow</td><td>This is an Image Feature Vector model from TensorFlow Hub It takes an image as input and returns a feature vector (embedding) of the image</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-inception-v3-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>198.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-inception-v2-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>199.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-inception-v1-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>200.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-tf2-preview-inception-v3-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>201.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-tf2-preview-mobilenet-v2-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>202.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-resnet-v2-50-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>203.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-resnet-v2-101-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>204.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-resnet-v2-152-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>205.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-resnet-v1-50-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>206.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-resnet-v1-101-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>207.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-resnet-v1-152-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>208.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-resnet-50-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>209.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-efficientnet-b0-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>210.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-efficientnet-b1-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>211.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-efficientnet-b2-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>212.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-efficientnet-b3-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>213.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-efficientnet-b6-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>214.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-efficientnet-lite0-featurevector-2</td><td></td><td></td><td></td><td></td></tr><tr><td>215.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-efficientnet-lite1-featurevector-2</td><td></td><td></td><td></td><td></td></tr><tr><td>216.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-efficientnet-lite2-featurevector-2</td><td></td><td></td><td></td><td></td></tr><tr><td>217.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-efficientnet-lite3-featurevector-2</td><td></td><td></td><td></td><td></td></tr><tr><td>218.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-efficientnet-lite4-featurevector-2</td><td></td><td></td><td></td><td></td></tr><tr><td>219.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-100-224-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>220.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-100-192-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>221.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-100-160-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>222.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-100-128-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>223.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-075-224-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>224.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-075-192-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>225.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-075-160-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>226.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-075-128-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>227.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-050-224-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>228.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-050-192-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>229.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-050-160-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>230.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-050-128-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>231.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-025-224-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>232.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-025-192-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>233.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-025-160-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>234.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-imagenet-mobilenet-v1-025-128-featurevector-4</td><td></td><td></td><td></td><td></td></tr><tr><td>235.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-bit-s-r50x1-ilsvrc2012-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>236.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-bit-s-r50x3-ilsvrc2012-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>237.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-bit-s-r101x1-ilsvrc2012-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>238.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-bit-s-r101x3-ilsvrc2012-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>239.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-bit-m-r50x1-ilsvrc2012-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>240.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-bit-m-r50x3-imagenet21k-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>241.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-bit-m-r101x1-ilsvrc2012-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>242.</td><td>Image Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-icembedding-bit-m-r101x3-imagenet21k-featurevector-1</td><td></td><td></td><td></td><td></td></tr><tr><td>243.</td><td>Object Detection</td><td>Tensorflow</td><td>This is an object detection model from TensorFlow Hub It takes an image as input and returns bounding boxes for the objects in the image</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-faster-rcnn-resnet50-v1-1024x1024-1</td><td></td><td></td><td></td><td></td></tr><tr><td>244.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-faster-rcnn-resnet101-v1-640x640-1</td><td></td><td></td><td></td><td></td></tr><tr><td>245.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-faster-rcnn-resnet101-v1-800x1333-1</td><td></td><td></td><td></td><td></td></tr><tr><td>246.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-faster-rcnn-resnet101-v1-1024x1024-1</td><td></td><td></td><td></td><td></td></tr><tr><td>247.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-faster-rcnn-resnet152-v1-640x640-1</td><td></td><td></td><td></td><td></td></tr><tr><td>248.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-faster-rcnn-resnet152-v1-800x1333-1</td><td></td><td></td><td></td><td></td></tr><tr><td>249.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-faster-rcnn-resnet152-v1-1024x1024-1</td><td></td><td></td><td></td><td></td></tr><tr><td>250.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-faster-rcnn-inception-resnet-v2-640x640-1</td><td></td><td></td><td></td><td></td></tr><tr><td>251.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-faster-rcnn-inception-resnet-v2-1024x1024-1</td><td></td><td></td><td></td><td></td></tr><tr><td>252.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-efficientdet-d0-1</td><td></td><td></td><td></td><td></td></tr><tr><td>253.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-efficientdet-d1-1</td><td></td><td></td><td></td><td></td></tr><tr><td>254.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-efficientdet-d2-1</td><td></td><td></td><td></td><td></td></tr><tr><td>255.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-efficientdet-d3-1</td><td></td><td></td><td></td><td></td></tr><tr><td>256.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-efficientdet-d4-1</td><td></td><td></td><td></td><td></td></tr><tr><td>257.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-efficientdet-d5-1</td><td></td><td></td><td></td><td></td></tr><tr><td>258.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-retinanet-resnet50-v1-fpn-640x640-1</td><td></td><td></td><td></td><td></td></tr><tr><td>259.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-retinanet-resnet50-v1-fpn-1024x1024-1</td><td></td><td></td><td></td><td></td></tr><tr><td>260.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-retinanet-resnet101-v1-fpn-640x640-1</td><td></td><td></td><td></td><td></td></tr><tr><td>261.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-retinanet-resnet101-v1-fpn-1024x1024-1</td><td></td><td></td><td></td><td></td></tr><tr><td>262.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-retinanet-resnet152-v1-fpn-640x640-1</td><td></td><td></td><td></td><td></td></tr><tr><td>263.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-retinanet-resnet152-v1-fpn-1024x1024-1</td><td></td><td></td><td></td><td></td></tr><tr><td>264.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-centernet-hourglass-512x512-1</td><td></td><td></td><td></td><td></td></tr><tr><td>265.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-centernet-hourglass-512x512-kpts-1</td><td></td><td></td><td></td><td></td></tr><tr><td>266.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-centernet-hourglass-1024x1024-1</td><td></td><td></td><td></td><td></td></tr><tr><td>267.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-centernet-hourglass-1024x1024-kpts-1</td><td></td><td></td><td></td><td></td></tr><tr><td>268.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-centernet-resnet50v1-fpn-512x512-1</td><td></td><td></td><td></td><td></td></tr><tr><td>269.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-centernet-resnet50v1-fpn-512x512-kpts-1</td><td></td><td></td><td></td><td></td></tr><tr><td>270.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-centernet-resnet50v2-512x512-1</td><td></td><td></td><td></td><td></td></tr><tr><td>271.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-centernet-resnet50v2-512x512-kpts-1</td><td></td><td></td><td></td><td></td></tr><tr><td>272.</td><td>Object Detection</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-od-centernet-resnet101v1-fpn-512x512-1</td><td></td><td></td><td></td><td></td></tr><tr><td>273.</td><td>Text Classification</td><td>Tensorflow</td><td>This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub It takes a text string as input and classifies the input text as either a positive or negative movie review</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-bert-en-cased-L-12-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>274.</td><td>Text Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-bert-multi-cased-L-12-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>275.</td><td>Text Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-128-A-2</td><td></td><td></td><td></td><td></td></tr><tr><td>276.</td><td>Text Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-256-A-4</td><td></td><td></td><td></td><td></td></tr><tr><td>277.</td><td>Text Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-512-A-8</td><td></td><td></td><td></td><td></td></tr><tr><td>278.</td><td>Question Answering</td><td>Huggingface</td><td>This is an Extractive Question Answering model built on a Transformer model from Hugging Face It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-distilbert-base-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>279.</td><td>Question Answering</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-distilbert-base-multilingual-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>280.</td><td>Question Answering</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-bert-base-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>281.</td><td>Question Answering</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-bert-base-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>282.</td><td>Question Answering</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-bert-base-multilingual-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>283.</td><td>Sentence Pair Classification</td><td>Tensorflow</td><td>This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub It takes a pair of sentences as input and classifies the input pair to &rsquo;entailment&rsquo; or &rsquo;no-entailment'</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-spc-bert-en-cased-L-12-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>284.</td><td>Sentence Pair Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-spc-bert-multi-cased-L-12-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>285.</td><td>Sentence Pair Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-spc-bert-en-uncased-L-24-H-1024-A-16-2</td><td></td><td></td><td></td><td></td></tr><tr><td>286.</td><td>Sentence Pair Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-spc-electra-small-1</td><td></td><td></td><td></td><td></td></tr><tr><td>287.</td><td>Sentence Pair Classification</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-spc-electra-base-1</td><td></td><td></td><td></td><td></td></tr><tr><td>288.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-distilbert-base-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>289.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-distilbert-base-multilingual-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>290.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-bert-base-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>291.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-bert-base-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>292.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-bert-base-multilingual-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>293.</td><td>Named Entity Recognition</td><td>Huggingface</td><td>This is a Named Entity Generation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts named entities in the input text</td><td>Model draft: false</td></tr><tr><td>id: huggingface-ner-distilbert-base-uncased-finetuned-conll03-english</td><td></td><td></td><td></td><td></td></tr><tr><td>294.</td><td>Text Generation</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-textgeneration-bloom-1b1</td><td></td><td></td><td></td><td></td></tr><tr><td>295.</td><td>Text Generation</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-textgeneration-bloom-560m</td><td></td><td></td><td></td><td></td></tr><tr><td>296.</td><td>Text Generation</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-textgeneration-gpt2</td><td></td><td></td><td></td><td></td></tr><tr><td>297.</td><td>Text Generation</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-textgeneration-distilgpt2</td><td></td><td></td><td></td><td></td></tr><tr><td>298.</td><td>Text Summarization</td><td>Huggingface</td><td>This is a Text Summarization model built upon a Transformer model from Hugging Face It takes a text string as input and returns a summary of the text</td><td>Model draft: false</td></tr><tr><td>id: huggingface-summarization-bert-small2bert-small-finetuned-cnn-daily-mail-summarization</td><td></td><td></td><td></td><td></td></tr><tr><td>299.</td><td>Text Summarization</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-summarization-distilbart-cnn-6-6</td><td></td><td></td><td></td><td></td></tr><tr><td>300.</td><td>Text Summarization</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-summarization-distilbart-xsum-12-3</td><td></td><td></td><td></td><td></td></tr><tr><td>301.</td><td>Text Summarization</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-summarization-distilbart-cnn-12-6</td><td></td><td></td><td></td><td></td></tr><tr><td>302.</td><td>Text Summarization</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-summarization-bart-large-cnn-samsum</td><td></td><td></td><td></td><td></td></tr><tr><td>303.</td><td>Machine Translation</td><td>Huggingface</td><td>This is a Machine Translation model built upon a Transformer model from Hugging Face It takes a text string as input and predicts its translation</td><td>Model draft: false</td></tr><tr><td>id: huggingface-translation-t5-base</td><td></td><td></td><td></td><td></td></tr><tr><td>304.</td><td>Machine Translation</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-translation-t5-large</td><td></td><td></td><td></td><td></td></tr><tr><td>305.</td><td>Machine Translation</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-translation-opus-mt-en-es</td><td></td><td></td><td></td><td></td></tr><tr><td>306.</td><td>Machine Translation</td><td>Huggingface</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: huggingface-translation-opus-mt-en-vi</td><td></td><td></td><td></td><td></td></tr><tr><td>307.</td><td>Text Embedding</td><td>Tensorflow</td><td>This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-2-H-256-A-4</td><td></td><td></td><td></td><td></td></tr><tr><td>308.</td><td>Text Embedding</td><td>Tensorflow</td><td>same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-2-H-512-A-8-2</td><td></td><td></td><td></td><td></td></tr><tr><td>309.</td><td>Text Embedding</td><td>Tensorflow</td><td>same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-2-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>310.</td><td>Text to Image</td><td>Stabilityai</td><td>This is a text-to-image model from Stability AI and downloaded from HuggingFace It takes a textual description as input and returns a generated image from the description</td><td>Model draft: false</td></tr><tr><td>id: model-txt2img-stabilityai-stable-diffusion-v2</td><td></td><td></td><td></td><td></td></tr><tr><td>311.</td><td>Text Embedding</td><td>Tensorflow</td><td>This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-4-H-128-A-2-2</td><td></td><td></td><td></td><td></td></tr><tr><td>312.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-4-H-256-A-4-2</td><td></td><td></td><td></td><td></td></tr><tr><td>313.</td><td>Text Embedding</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-tcembedding-robertafin-base-wiki-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>314.</td><td>Text Embedding</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-tcembedding-robertafin-large-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>315.</td><td>Text Embedding</td><td>Mxnet</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: mxnet-tcembedding-robertafin-large-wiki-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>316.</td><td>Text Classification</td><td>Tensorflow</td><td>This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub It takes a text string as input and classifies the input text as either a positive or negative movie review</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-768-A-12</td><td></td><td></td><td></td><td></td></tr><tr><td>317.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-128-A-2</td><td></td><td></td><td></td><td></td></tr><tr><td>318.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-256-A-4</td><td></td><td></td><td></td><td></td></tr><tr><td>319.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-512-A-8</td><td></td><td></td><td></td><td></td></tr><tr><td>320.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-768-A-12</td><td></td><td></td><td></td><td></td></tr><tr><td>321.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-128-A-2</td><td></td><td></td><td></td><td></td></tr><tr><td>322.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-256-A-4</td><td></td><td></td><td></td><td></td></tr><tr><td>323.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-512-A-8</td><td></td><td></td><td></td><td></td></tr><tr><td>324.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-768-A-12</td><td></td><td></td><td></td><td></td></tr><tr><td>325.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-128-A-2</td><td></td><td></td><td></td><td></td></tr><tr><td>326.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-256-A-4</td><td></td><td></td><td></td><td></td></tr><tr><td>327.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-512-A-8</td><td></td><td></td><td></td><td></td></tr><tr><td>328.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-768-A-12</td><td></td><td></td><td></td><td></td></tr><tr><td>329.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-128-A-2</td><td></td><td></td><td></td><td></td></tr><tr><td>330.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-256-A-4</td><td></td><td></td><td></td><td></td></tr><tr><td>331.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-512-A-8</td><td></td><td></td><td></td><td></td></tr><tr><td>332.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-768-A-12</td><td></td><td></td><td></td><td></td></tr><tr><td>333.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-128-A-2</td><td></td><td></td><td></td><td></td></tr><tr><td>334.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-256-A-4</td><td></td><td></td><td></td><td></td></tr><tr><td>335.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-512-A-8</td><td></td><td></td><td></td><td></td></tr><tr><td>336.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-768-A-12</td><td></td><td></td><td></td><td></td></tr><tr><td>337.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-bert-en-uncased-L-24-H-1024-A-16-2</td><td></td><td></td><td></td><td></td></tr><tr><td>338.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-bert-en-cased-L-24-H-1024-A-16-2</td><td></td><td></td><td></td><td></td></tr><tr><td>339.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-bert-en-wwm-uncased-L-24-H-1024-A-16-2</td><td></td><td></td><td></td><td></td></tr><tr><td>340.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-bert-en-wwm-cased-L-24-H-1024-A-16-2</td><td></td><td></td><td></td><td></td></tr><tr><td>341.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-albert-en-base</td><td></td><td></td><td></td><td></td></tr><tr><td>342.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-electra-small-1</td><td></td><td></td><td></td><td></td></tr><tr><td>343.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-electra-base-1</td><td></td><td></td><td></td><td></td></tr><tr><td>344.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-experts-bert-wiki-books-1</td><td></td><td></td><td></td><td></td></tr><tr><td>345.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-experts-bert-pubmed-1</td><td></td><td></td><td></td><td></td></tr><tr><td>346.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-talking-heads-base</td><td></td><td></td><td></td><td></td></tr><tr><td>347.</td><td>Text Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tc-talking-heads-large</td><td></td><td></td><td></td><td></td></tr><tr><td>348.</td><td>Question Answering</td><td>Huggingface</td><td>This is an Extractive Question Answering model built on a Transformer model from Hugging Face It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-bert-base-multilingual-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>349.</td><td>Question Answering</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-bert-large-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>350.</td><td>Question Answering</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-bert-large-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>351.</td><td>Question Answering</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-bert-large-uncased-whole-word-masking</td><td></td><td></td><td></td><td></td></tr><tr><td>352.</td><td>Question Answering</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-bert-large-cased-whole-word-masking</td><td></td><td></td><td></td><td></td></tr><tr><td>353.</td><td>Question Answering</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-distilroberta-base</td><td></td><td></td><td></td><td></td></tr><tr><td>354.</td><td>Question Answering</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-roberta-base</td><td></td><td></td><td></td><td></td></tr><tr><td>355.</td><td>Question Answering</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-roberta-base-openai-detector</td><td></td><td></td><td></td><td></td></tr><tr><td>356.</td><td>Question Answering</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-eqa-roberta-large</td><td></td><td></td><td></td><td></td></tr><tr><td>357.</td><td>Sentence Pair Classification</td><td>Tensorflow</td><td>This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub It takes a pair of sentences as input and classifies the input pair to &rsquo;entailment&rsquo; or &rsquo;no-entailment'</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-spc-bert-en-wwm-uncased-L-24-H-1024-A-16-2</td><td></td><td></td><td></td><td></td></tr><tr><td>358.</td><td>Sentence Pair Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-spc-bert-en-wwm-cased-L-24-H-1024-A-16-2</td><td></td><td></td><td></td><td></td></tr><tr><td>359.</td><td>Sentence Pair Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-spc-experts-bert-wiki-books-1</td><td></td><td></td><td></td><td></td></tr><tr><td>360.</td><td>Sentence Pair Classification</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-spc-experts-bert-pubmed-1</td><td></td><td></td><td></td><td></td></tr><tr><td>361.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-bert-base-multilingual-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>362.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-bert-large-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>363.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-bert-large-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>364.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-bert-large-uncased-whole-word-masking</td><td></td><td></td><td></td><td></td></tr><tr><td>365.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-bert-large-cased-whole-word-masking</td><td></td><td></td><td></td><td></td></tr><tr><td>366.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-distilroberta-base</td><td></td><td></td><td></td><td></td></tr><tr><td>367.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-roberta-base</td><td></td><td></td><td></td><td></td></tr><tr><td>368.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-roberta-base-openai-detector</td><td></td><td></td><td></td><td></td></tr><tr><td>369.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-roberta-large</td><td></td><td></td><td></td><td></td></tr><tr><td>370.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-roberta-large-openai-detector</td><td></td><td></td><td></td><td></td></tr><tr><td>371.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-xlm-mlm-ende-1024</td><td></td><td></td><td></td><td></td></tr><tr><td>372.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-xlm-mlm-enro-1024</td><td></td><td></td><td></td><td></td></tr><tr><td>373.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-xlm-mlm-xnli15-1024</td><td></td><td></td><td></td><td></td></tr><tr><td>374.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-xlm-mlm-tlm-xnli15-1024</td><td></td><td></td><td></td><td></td></tr><tr><td>375.</td><td>Sentence Pair Classification</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-spc-xlm-clm-ende-1024</td><td></td><td></td><td></td><td></td></tr><tr><td>376.</td><td>Text Summarization</td><td>Huggingface</td><td>This is a Text Summarization model built upon a Transformer model from Hugging Face It takes a text string as input and returns a summary of the text</td><td>Model draft: false</td></tr><tr><td>id: huggingface-summarization-bigbird-pegasus-large-arxiv</td><td></td><td></td><td></td><td></td></tr><tr><td>377.</td><td>Text Summarization</td><td>Huggingface</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: huggingface-summarization-bigbird-pegasus-large-pubmed</td><td></td><td></td><td></td><td></td></tr><tr><td>378.</td><td>Text Embedding</td><td>Tensorflow</td><td>This is a Text Embedding model from TensorFlow Hub It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-4-H-512-A-8-2</td><td></td><td></td><td></td><td></td></tr><tr><td>379.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-4-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>380.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-6-H-128-A-2-2</td><td></td><td></td><td></td><td></td></tr><tr><td>381.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-6-H-256-A-4</td><td></td><td></td><td></td><td></td></tr><tr><td>382.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-6-H-512-A-8-2</td><td></td><td></td><td></td><td></td></tr><tr><td>383.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-6-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>384.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-8-H-256-A-4-2</td><td></td><td></td><td></td><td></td></tr><tr><td>385.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-8-H-512-A-8-2</td><td></td><td></td><td></td><td></td></tr><tr><td>386.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-8-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>387.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-10-H-128-A-2-2</td><td></td><td></td><td></td><td></td></tr><tr><td>388.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-10-H-256-A-4-2</td><td></td><td></td><td></td><td></td></tr><tr><td>389.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-10-H-512-A-8-2</td><td></td><td></td><td></td><td></td></tr><tr><td>390.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-10-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>391.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-12-H-128-A-2-2</td><td></td><td></td><td></td><td></td></tr><tr><td>392.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-12-H-256-A-4</td><td></td><td></td><td></td><td></td></tr><tr><td>393.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-12-H-512-A-8-2</td><td></td><td></td><td></td><td></td></tr><tr><td>394.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-2</td><td></td><td></td><td></td><td></td></tr><tr><td>395.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-4</td><td></td><td></td><td></td><td></td></tr><tr><td>396.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-wiki-books-sst2</td><td></td><td></td><td></td><td></td></tr><tr><td>397.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-bert-wiki-books-mnli-2</td><td></td><td></td><td></td><td></td></tr><tr><td>398.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-large-1</td><td></td><td></td><td></td><td></td></tr><tr><td>399.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-base-1</td><td></td><td></td><td></td><td></td></tr><tr><td>400.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-talkheads-ggelu-bert-en-base-2</td><td></td><td></td><td></td><td></td></tr><tr><td>401.</td><td>Text Embedding</td><td>Tensorflow</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-tcembedding-talkheads-ggelu-bert-en-large-2</td><td></td><td></td><td></td><td></td></tr><tr><td>402.</td><td>Tabular Classification</td><td></td><td>This is the LightGBM algorithm for tabular classification task LightGBM is a gradient boosting framework that uses tree based learning algorithms</td><td>Model draft: false</td></tr><tr><td>id: lightgbm-classification-model</td><td></td><td></td><td></td><td></td></tr><tr><td>403.</td><td>Tabular Classification</td><td>Catboost</td><td>This is the CatBoost algorithm for tabular classification task CatBoost is a machine learning algorithm that uses gradient boosting on decision trees</td><td>Model draft: false</td></tr><tr><td>id: catboost-classification-model</td><td></td><td></td><td></td><td></td></tr><tr><td>404.</td><td>Tabular Classification</td><td></td><td>This is the AutoGluon-Tabular algorithm for tabular classification task AutoGluon-Tabular is an open-source AutoML framework that trains highly accurate machine learning models on an unprocessed tabular dataset Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers</td><td>Model draft: false</td></tr><tr><td>id: autogluon-classification-ensemble</td><td></td><td></td><td></td><td></td></tr><tr><td>405.</td><td>Tabular Classification</td><td></td><td>This is the TabTransformer algorithm for tabular classification task TabTransformer is a deep tabular data modeling architecture that built upon self-attention based Transformers</td><td>Model draft: false</td></tr><tr><td>id: pytorch-tabtransformerclassification-model</td><td></td><td></td><td></td><td></td></tr><tr><td>406.</td><td>Tabular Classification</td><td>Sklearn</td><td>This is the scikit-learn linear algorithm for tabular classification task Linear Classification is a linear approach to classify data into labels (targets) based on a linear combination of its input features (predictors)</td><td>Model draft: false</td></tr><tr><td>id: sklearn-classification-linear</td><td></td><td></td><td></td><td></td></tr><tr><td>407.</td><td>Tabular Classification</td><td>Xgboost</td><td>This is the XGBoost algorithm for tabular classification task XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable It implements machine learning algorithms under the Gradient Boosting framework</td><td>Model draft: false</td></tr><tr><td>id: xgboost-classification-model</td><td></td><td></td><td></td><td></td></tr><tr><td>408.</td><td>Tabular Regression</td><td></td><td>This is the LightGBM algorithm for tabular regression task LightGBM is a gradient boosting framework that uses tree based learning algorithms</td><td>Model draft: false</td></tr><tr><td>id: lightgbm-regression-model</td><td></td><td></td><td></td><td></td></tr><tr><td>409.</td><td>Tabular Regression</td><td>Catboost</td><td>This is the CatBoost algorithm for tabular regression task CatBoost is a machine learning algorithm that uses gradient boosting on decision trees</td><td>Model draft: false</td></tr><tr><td>id: catboost-regression-model</td><td></td><td></td><td></td><td></td></tr><tr><td>410.</td><td>Tabular Regression</td><td></td><td>This is the AutoGluon-Tabular algorithm for tabular regression task AutoGluon-Tabular is an open-source AutoML framework that trains highly accurate machine learning models on an unprocessed tabular dataset Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers</td><td>Model draft: false</td></tr><tr><td>id: autogluon-regression-ensemble</td><td></td><td></td><td></td><td></td></tr><tr><td>411.</td><td>Tabular Regression</td><td></td><td>This is the TabTransformer algorithm for tabular regression task TabTransformer is a deep tabular data modeling architecture that built upon self-attention based Transformers</td><td>Model draft: false</td></tr><tr><td>id: pytorch-tabtransformerregression-model</td><td></td><td></td><td></td><td></td></tr><tr><td>412.</td><td>Tabular Regression</td><td>Sklearn</td><td>This is the scikit-learn linear algorithm for tabular regression task Linear Regression is a linear approach for modelling the relationship between a scalar response and one or more explanatory variables</td><td>Model draft: false</td></tr><tr><td>id: sklearn-regression-linear</td><td></td><td></td><td></td><td></td></tr><tr><td>413.</td><td>Tabular Regression</td><td>Xgboost</td><td>This is the XGBoost algorithm for tabular regression task XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable It implements machine learning algorithms under the Gradient Boosting framework</td><td>Model draft: false</td></tr><tr><td>id: xgboost-regression-model</td><td></td><td></td><td></td><td></td></tr><tr><td>414.</td><td>Question Answering</td><td>Pytorch</td><td>This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-distilbert-base-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>415.</td><td>Question Answering</td><td>Pytorch</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-bert-large-uncased-whole-word-masking</td><td></td><td></td><td></td><td></td></tr><tr><td>416.</td><td>Question Answering</td><td>Pytorch</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-bert-large-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>417.</td><td>Question Answering</td><td>Pytorch</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-bert-large-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>418.</td><td>Question Answering</td><td>Pytorch</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-roberta-base</td><td></td><td></td><td></td><td></td></tr><tr><td>419.</td><td>Question Answering</td><td>Pytorch</td><td>Same as above</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-distilbert-base-multilingual-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>420.</td><td>Object detection</td><td>SageMaker</td><td>Identify birds species in a scene using a SageMaker object detection model.</td><td></td></tr><tr><td>421.</td><td>Question Answering</td><td>Pytorch</td><td>This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-distilroberta-base</td><td></td><td></td><td></td><td></td></tr><tr><td>422.</td><td>Audio Embedding</td><td>Tensorflow</td><td>This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-audioembedding-trill-distilled-3</td><td></td><td></td><td></td><td></td></tr><tr><td>423.</td><td>Question Answering</td><td>Pytorch</td><td>This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-roberta-large-openai-detector</td><td></td><td></td><td></td><td></td></tr><tr><td>424.</td><td>Object detection</td><td>SageMaker</td><td>Identify defective regions in product images either by training an object detection model from scratch or fine-tuning pretrained SageMaker models.</td><td></td></tr><tr><td>425.</td><td>Audio Embedding</td><td>Tensorflow</td><td>This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-audioembedding-trillsson2-1</td><td></td><td></td><td></td><td></td></tr><tr><td>426.</td><td>Tabular classification</td><td>SageMaker</td><td>Automatically detect potentially fraudulent activity in transactions using SageMaker XGBoost with the over-sampling technique Synthetic Minority Over-sampling (SMOTE).</td><td></td></tr><tr><td>427.</td><td>Feature importance using shap</td><td>SageMaker</td><td></td><td></td></tr><tr><td>428.</td><td>Question Answering</td><td>Pytorch</td><td>This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-distilbert-base-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>429.</td><td>Graph neural network classification</td><td>SageMaker</td><td>Detect fraud in financial transactions by training a graph convolutional network with the deep graph library and a SageMaker XGBoost model.</td><td></td></tr><tr><td>430.</td><td>Tabular classification</td><td>SageMaker</td><td>Classify financial payments based on transaction information using SageMaker XGBoost. Use this solution template as an intermediate step in fraud detection, personalization, or anomaly detection.</td><td></td></tr><tr><td>431.</td><td>Tabular classification</td><td>SageMaker</td><td>Identify unhappy mobile phone customers using SageMaker XGBoost.</td><td></td></tr><tr><td>432.</td><td>Question Answering</td><td>Pytorch</td><td>This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-bert-base-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>433.</td><td>RL</td><td>SageMaker</td><td>Distributed reinforcement learning starter kit for NeurIPS 2020 Procgen Reinforcement learning challenge.</td><td></td></tr><tr><td>434.</td><td>Question Answering</td><td>Pytorch</td><td>This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-bert-large-cased-whole-word-masking-finetuned-squad</td><td></td><td></td><td></td><td></td></tr><tr><td>435.</td><td>Tabular classification</td><td>SageMaker</td><td></td><td></td></tr><tr><td>436.</td><td>RL</td><td>SageMaker</td><td></td><td></td></tr><tr><td>437.</td><td>Entity resolution</td><td>SageMaker</td><td></td><td></td></tr><tr><td>438.</td><td>Tabular classification</td><td>SageMaker</td><td></td><td></td></tr><tr><td>439.</td><td>Tabular and text classification</td><td>SageMaker</td><td></td><td></td></tr><tr><td>440.</td><td>Text classification</td><td>SageMaker</td><td>Anonymize text to better preserve user privacy in sentiment classification.</td><td></td></tr><tr><td>441.</td><td>Tabular, image, and text classification.</td><td>SageMaker</td><td></td><td></td></tr><tr><td>442.</td><td>Tabular classification</td><td>SageMaker</td><td></td><td></td></tr><tr><td>443.</td><td>Text to Image</td><td>Stabilityai</td><td>This is a text-to-image model from Stability AI and downloaded from HuggingFace It takes a textual description as input and returns a generated image from the description</td><td>Model draft: false</td></tr><tr><td>id: model-txt2img-stabilityai-stable-diffusion-v2-fp16</td><td></td><td></td><td></td><td></td></tr><tr><td>444.</td><td>Text to Image</td><td>Stabilityai</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: model-txt2img-stabilityai-stable-diffusion-v1-4-fp16</td><td></td><td></td><td></td><td></td></tr><tr><td>445.</td><td>ext to Image</td><td>Stabilityai</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: model-txt2img-stabilityai-stable-diffusion-v1-4</td><td></td><td></td><td></td><td></td></tr><tr><td>446.</td><td>Question Answering</td><td>Pytorch</td><td>This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-bert-base-multilingual-cased</td><td></td><td></td><td></td><td></td></tr><tr><td>447.</td><td>Question Answering</td><td>Pytorch</td><td>This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-roberta-large</td><td></td><td></td><td></td><td></td></tr><tr><td>448.</td><td>Audio Embedding</td><td>Tensorflow</td><td>This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-audioembedding-frill-1</td><td></td><td></td><td></td><td></td></tr><tr><td>449.</td><td>Audio Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-audioembedding-trillsson3-1</td><td></td><td></td><td></td><td></td></tr><tr><td>450.</td><td>Audio Embedding</td><td>Tensorflow</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-audioembedding-trill-3</td><td></td><td></td><td></td><td></td></tr><tr><td>451.</td><td>Tabular and text classification</td><td>SageMaker</td><td></td><td></td></tr><tr><td>452.</td><td>Question Answering</td><td>Pytorch</td><td>This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-roberta-base-openai-detector</td><td></td><td></td><td></td><td></td></tr><tr><td>453.</td><td>Question Answering</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-bert-large-cased-whole-word-masking</td><td></td><td></td><td></td><td></td></tr><tr><td>454.</td><td>Time series</td><td>SageMaker</td><td>Demand forecasting for multivariate time series data using three state-of-the-art time series forecasting algorithms: LSTNet, Prophet, and SageMaker DeepAR.</td><td></td></tr><tr><td>455.</td><td>Question Answering</td><td>Pytorch</td><td>This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-bert-large-uncased-whole-word-masking-finetuned-squad</td><td></td><td></td><td></td><td></td></tr><tr><td>456.</td><td>Question Answering</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-bert-base-multilingual-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>457.</td><td>Question Answering</td><td>Pytorch</td><td>Same</td><td>Model draft: false</td></tr><tr><td>id: pytorch-eqa-bert-base-uncased</td><td></td><td></td><td></td><td></td></tr><tr><td>458.</td><td>Audio Embedding</td><td>Tensorflow</td><td>This is an audio embedding model from Tensorflow Hub It takes a wav (audio file format) file as input and outputs an embedding vector</td><td>Model draft: false</td></tr><tr><td>id: tensorflow-audioembedding-trillsson1-1</td><td></td><td></td><td></td><td></td></tr><tr><td>459.</td><td>Object detection</td><td>SageMaker</td><td></td><td></td></tr><tr><td>460.</td><td>Causal inference</td><td>SageMaker</td><td>Generate a counterfactual analysis of corn response to nitrogen. This solution learns the crop phenology cycle in its entirety using multi-spectral satellite imagery and ground-level observations.</td><td></td></tr><tr><td>461.</td><td>Price optimization</td><td>SageMaker</td><td>Estimate price elasticity using Double Machine Learning (ML) for causal inference and the Prophet forecasting procedure. Use these estimates to optimize daily prices.</td><td></td></tr><tr><td>462.</td><td>Tabular and text classification</td><td>SageMaker</td><td></td><td></td></tr><tr><td>463.</td><td>Upscaling</td><td>Stabilityai</td><td>This is a upscaling model from Stability AI downloaded from HuggingFace with FP16 precision Given a low resolution image and a textual prompt, it generates a higher resolution image with size up to four times the original image size</td><td>Model draft: false</td></tr><tr><td>id: model-upscaling-stabilityai-stable-diffusion-x4-upscaler-fp16</td><td></td><td></td><td></td><td></td></tr></tbody></table><h2 id=references>References<a class=td-heading-self-link href=#references aria-label="Heading self-link"></a></h2><ul><li><a href=https://aws.amazon.com/sagemaker/jumpstart/getting-started/>https://aws.amazon.com/sagemaker/jumpstart/getting-started/</a></li></ul><p><strong>Author</strong><br>Dr. Hari Thapliyaal<br>dasarpai.com<br>linkedin.com/in/harithapliyal</p><div class=category-section><h4 class=category-section__title>Categories:</h4><div class=category-badges><a href=../../categories/dsblog class=category-badge>dsblog</a></div></div><div class=td-tags><h4 class=td-tags__title>Tags:</h4><div class=category-badges><a href=../../tags/python class=category-badge>Python</a><a href=../../tags/programming class=category-badge>Programming</a></div></div><div class=td-author-box><div class=td-author-box__info><h4 class=td-author-box__name>Blowfish</h4><p class=td-author-box__bio>A powerful, lightweight theme for Hugo.</p><div class=td-author-box__links><a href target=_blank rel=noopener aria-label></a><a href target=_blank rel=noopener aria-label></a></div></div></div><div class=td-social-share><h4 class=td-social-share__title>Share this article:</h4><ul class=td-social-share__list><div class=social-share><a href="https://twitter.com/intent/tweet?text=AWS%20SageMaker%20Jumpstart%20Models&url=https%3a%2f%2fdasarpai.github.io%2fdsblog%2fAWS-SageMaker-Jumpstart-Models%2f" target=_blank rel=noopener aria-label="Share on Twitter"><i class="fab fa-twitter"></i>
</a><a href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fdasarpai.github.io%2fdsblog%2fAWS-SageMaker-Jumpstart-Models%2f" target=_blank rel=noopener aria-label="Share on Facebook"><i class="fab fa-facebook"></i>
</a><a href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fdasarpai.github.io%2fdsblog%2fAWS-SageMaker-Jumpstart-Models%2f&title=AWS%20SageMaker%20Jumpstart%20Models" target=_blank rel=noopener aria-label="Share on LinkedIn"><i class="fab fa-linkedin"></i>
</a><a href="https://www.reddit.com/submit?url=https%3a%2f%2fdasarpai.github.io%2fdsblog%2fAWS-SageMaker-Jumpstart-Models%2f&title=AWS%20SageMaker%20Jumpstart%20Models" target=_blank rel=noopener aria-label="Share on Reddit"><i class="fab fa-reddit"></i>
</a><a href="mailto:?subject=AWS%20SageMaker%20Jumpstart%20Models&body=https%3a%2f%2fdasarpai.github.io%2fdsblog%2fAWS-SageMaker-Jumpstart-Models%2f" aria-label="Share via Email"><i class="fas fa-envelope"></i></a></div></ul></div><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><a class="td-pager__link td-pager__link--prev" href=../../dsblog/Embedding-with-FastText/ aria-label="Previous page"><div class=td-pager__meta><i class="fa-solid fa-angle-left"></i>
<span class=td-pager__meta-label><b>Previous:</b></span>
<span class=td-pager__meta-title>Embedding with FastText</span></div></a><a class="td-pager__link td-pager__link--next" href=../../dsblog/Introduction-to-ML-Model-deployment/ aria-label="Next page"><div class=td-pager__meta><span class=td-pager__meta-label><b>Next:</b></span>
<span class=td-pager__meta-title>Introduction to ML Model Deployment</span>
<i class="fa-solid fa-angle-right"></i></div></a></ul></div><div class=col-md-2></div></div></main><footer class="td-footer row d-print-none"><div class=container-fluid><div class="row mx-md-2"><div class=col-2><a href=https://dasarpai.com target=_blank rel=noopener><img src=https://dasarpai.github.io/assets/images/site-logo.png alt=dasarpAI width=100 style=border-radius:12px></a></div><div class=col-8><div class=row></div><div class=row></div></div><div class=col-2></div><div class="td-footer__left col-6 col-sm-4 order-sm-1"></div><div class="td-footer__right col-6 col-sm-4 order-sm-3"></div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2"></div></div></div></footer></div><script src=../../js/main.min.4e728f6d1777a74bef81c238fd7b573f42f1848a910503e07f877f49f1f442cb.js integrity="sha256-TnKPbRd3p0vvgcI4/XtXP0LxhIqRBQPgf4d/SfH0Qss=" crossorigin=anonymous></script><script defer src=../../js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js integrity="sha256-c0eKfUgHaYrtfjVesj+YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin=anonymous></script><script src=../../js/tabpane-persist.js></script><script src=https://dasarpai.github.io/js/asciinema-player.js></script><script>(function(){var e=document.querySelector("#td-section-nav");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></body></html>