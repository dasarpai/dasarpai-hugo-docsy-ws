<!DOCTYPE html>
<html lang="en" dir="ltr" class="scroll-smooth" data-default-appearance="dark"
  data-auto-appearance="true"><head>
  <meta charset="utf-8" />
  
  <meta http-equiv="content-language" content="en" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title>Understanding Contextual Embedding in Transformers &middot; </title>
  <meta name="title" content="Understanding Contextual Embedding in Transformers &middot; " />
  
  
  <meta name="keywords" content="Transformers, Embeddings, Deep Learning, " />
  
  
  <link rel="canonical" href="https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/" />
  
  
  
  
  
  
  
  
  
  
  
  
  <link type="text/css" rel="stylesheet" href="/css/main.bundle.min.d335c1c6fee4163b424b4aa7d14752445031097c25817767a55d8a7db1621ca481e0287c82b86b87ea9c9a649f872dd80f066f485f3a8695959a63d7f01643d1.css"
    integrity="sha512-0zXBxv7kFjtCS0qn0UdSRFAxCXwlgXdnpV2KfbFiHKSB4Ch8grhrh&#43;qcmmSfhy3YDwZvSF86hpWVmmPX8BZD0Q==" />
  
  
  <script type="text/javascript" src="/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js"
    integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj&#43;e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script>
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  <script defer type="text/javascript" id="script-bundle" src="/js/main.bundle.min.d216f70fb590d5fe69353ea31ace5a1c496a6ac5dd460871bf068a266962b270837f78a38bc9975746955acc580b40b63a33b8197693cd73c8f86a3589442db9.js"
    integrity="sha512-0hb3D7WQ1f5pNT6jGs5aHElqasXdRghxvwaKJmlisnCDf3iji8mXV0aVWsxYC0C2OjO4GXaTzXPI&#43;Go1iUQtuQ==" data-copy="Copy" data-copied="Copied"></script>
  
  
  
  <script src="/lib/zoom/zoom.min.f592a181a15d2a5b042daa7f746c3721acf9063f8b6acd175d989129865a37d400ae0e85b640f9ad42cd98d1f8ad30931718cf8811abdcc5fcb264400d1a2b0c.js" integrity="sha512-9ZKhgaFdKlsELap/dGw3Iaz5Bj&#43;Las0XXZiRKYZaN9QArg6FtkD5rULNmNH4rTCTFxjPiBGr3MX8smRADRorDA=="></script>
  
  
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="manifest" href="/site.webmanifest" />
  
  
  
  <meta name="google-site-verification" content="google926354b0a3e2593e.html" />
  
  
  
  
  
  
  <meta property="og:url" content="https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/">
  <meta property="og:title" content="Understanding Contextual Embedding in Transformers">
  <meta property="og:description" content="Introduction # Embedding can be confusing for many people, and contextual embedding performed by transformers can be even more perplexing. Even after gaining an understanding, many questions remain. In this article, we aim to address the following questions.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="dsblog">
    <meta property="article:published_time" content="2025-01-30T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-01-30T00:00:00+00:00">
    <meta property="article:tag" content="Transformers">
    <meta property="article:tag" content="Embeddings">
    <meta property="article:tag" content="Deep Learning">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Understanding Contextual Embedding in Transformers">
  <meta name="twitter:description" content="Introduction # Embedding can be confusing for many people, and contextual embedding performed by transformers can be even more perplexing. Even after gaining an understanding, many questions remain. In this article, we aim to address the following questions.">

  
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

<script>
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$']],     
        displayMath: [['$$', '$$']]   
      }
    };
</script>  
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>




  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Data Science Blog",
    "name": "Understanding Contextual Embedding in Transformers",
    "headline": "Understanding Contextual Embedding in Transformers",
    
    "abstract": "\u003cp\u003e\n    \u003cfigure\u003e\n      \u003cimg class=\u0022my-0 rounded-md\u0022 loading=\u0022lazy\u0022 src=\u0022\/assets\/images\/dspost\/dsp6214-Understanding-Contextual-Embedding-in-Transformer.jpg\u0022 alt=\u0022Understanding Contextual Embedding in Transformers\u0022 \/\u003e\n      \n    \u003c\/figure\u003e\n\u003c\/p\u003e\n\n\n\u003ch2 class=\u0022relative group\u0022\u003eIntroduction \n    \u003cdiv id=\u0022introduction\u0022 class=\u0022anchor\u0022\u003e\u003c\/div\u003e\n    \n    \u003cspan\n        class=\u0022absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100\u0022\u003e\n        \u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022\n            style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#introduction\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\n    \u003c\/span\u003e        \n    \n\u003c\/h2\u003e\n\u003cp\u003eEmbedding can be confusing for many people, and contextual embedding performed by transformers can be even more perplexing. Even after gaining an understanding, many questions remain. In this article, we aim to address the following questions.\u003c\/p\u003e",
    "inLanguage": "en",
    "url" : "https:\/\/dasarpai.com\/dsblog\/understanding-contextual-embedding-in-transformers\/",
    "author" : {
      "@type": "Person",
      "name": "Hari Thapliyaal"
    },
    "copyrightYear": "2025",
    "dateCreated": "2025-01-30T00:00:00\u002b00:00",
    "datePublished": "2025-01-30T00:00:00\u002b00:00",
    
    "dateModified": "2025-01-30T00:00:00\u002b00:00",
    
    "keywords": ["Contextual Embedding in Transformers","How Transformers Handle Context","What is Fixed Embedding","How Contextural Embedding is Generated","What will be the output size of attention formula softmax","What is meaning of a LLM has context length of 2 million tokens","How many attention layers we keep in transformer like gpt4"],
    
    "mainEntityOfPage": "true",
    "wordCount": "1921"
  }]
  </script>


  
  
  <meta name="author" content="Hari Thapliyaal" />
  
  
  

<script src="/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js" integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj&#43;KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script>






















  
  

<script async src="https://www.googletagmanager.com/gtag/js?id=G-PEDMYR1V0K"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PEDMYR1V0K');
</script>



  
  
  <meta name="theme-color"/>
  
  

  <link
  rel="stylesheet"
  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css"
/>

</head>
<body
  class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600">
  <div id="the-top" class="absolute flex self-center">
    <a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
      href="#main-content"><span
        class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>Skip to main content</a>
  </div>
  
  
  <div class="min-h-[148px]"></div>
<div class="fixed inset-x-0 pl-[24px] pr-[24px]" style="z-index:100">
  <div id="menu-blur" class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div>
  <div class="relative max-w-[64rem] ml-auto mr-auto">
    <div style="padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px"
    class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3">
    
    <div class="flex flex-1 items-center justify-between">
        <nav class="flex space-x-3">

            
            <a href="/" class="text-base font-medium text-gray-500 hover:text-gray-900"></a>
            

        </nav>
        <nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12">

            
            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Home
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/aboutme"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            About Me
          </p>
        </a>
        
        <a href="/clients"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Clients
          </p>
        </a>
        
        <a href="/dscourses"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            DS/AI Courses/Services
          </p>
        </a>
        
        <a href="/corpus-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            History Corpus
          </p>
        </a>
        
        <a href="/management"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PM Courses/Services
          </p>
        </a>
        
        <a href="/project-index-page"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Project/Work Catalog
          </p>
        </a>
        
        <a href="/publications-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Publications
          </p>
        </a>
        
        <a href="/testimonials"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Testimonial
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Data Science
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/news"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            AI and Business News
          </p>
        </a>
        
        <a href="/dsblog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Data Science Blog
          </p>
        </a>
        
        <a href="/dsblog/data-science-cheatsheets"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Data Science Cheatsheets
          </p>
        </a>
        
        <a href="/datascience-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Data Science Topics
          </p>
        </a>
        
        <a href="/dsblog/ds-ai-ml-books"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Data Science-Books
          </p>
        </a>
        
        <a href="/dsblog/ds-ai-ml-interview-resources"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            DS Interview Questions
          </p>
        </a>
        
        <a href="/datascience-resources"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            DS Resources
          </p>
        </a>
        
        <a href="/dsblog/best-youtube-channels-for-ds"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Video Channels to Learn DS
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Project Management
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/pmglossary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PM Glossary
          </p>
        </a>
        
        <a href=""  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PM Resources
          </p>
        </a>
        
        <a href="/pmlogy-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PM Topics
          </p>
        </a>
        
        <a href="/pmbok6-summary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PMBOK6
          </p>
        </a>
        
        <a href="/pmbok6"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PMBOK6 Explorer
          </p>
        </a>
        
        <a href="/pmbok6-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PMBOK6 Topics
          </p>
        </a>
        
        <a href="/pmblog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PMLOGY Blog
          </p>
        </a>
        
        <a href="/pmlogy-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PMLOGY Home
          </p>
        </a>
        
        <a href=""  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Project Management Hindi
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      SpiritualDrops
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/booksummary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Book Summary
          </p>
        </a>
        
        <a href="/gk"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            GK Blog
          </p>
        </a>
        
        <a href="/gk-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            GK Topic
          </p>
        </a>
        
        <a href="/wiaposts"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            WIA Blog
          </p>
        </a>
        
        <a href="/wia-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            WIA Home
          </p>
        </a>
        
        <a href="/quotations-blog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            WIA Quotes
          </p>
        </a>
        
        <a href="/wia-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            WIA Topics
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  href="/gallary"   class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Gallery
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/gallary/slider-pm-selected-photos"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Management Classes
          </p>
        </a>
        
        <a href="/gallary/slider-online-sessions1"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Online AI Classes 1
          </p>
        </a>
        
        <a href="/gallary/slider-online-sessions2"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Online AI Classes 2
          </p>
        </a>
        
        <a href="/gallary/slider-online-sessions3"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Online AI Classes 3
          </p>
        </a>
        
        <a href="/gallary/slider-online-sessions4"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Online AI Classes 4
          </p>
        </a>
        
        <a href="/gallary/slider-pm-workshops"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            PM &amp; DS Workshop Photos
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Samskrut
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/mychanting"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            My Vedic Chantings
          </p>
        </a>
        
        <a href="/samskrutyatra"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Samskrut Blog
          </p>
        </a>
        
        <a href="/samskrutyatra-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Samskrut Topics
          </p>
        </a>
        
        <a href="/samskrutyatra-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            SamskrutYatra Home
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
            

            


            
            <button id="search-button" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            


            
            
            <div
                class=" flex items-center">
                <button id="appearance-switcher" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400">
                    <div class="flex items-center justify-center dark:hidden">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                    </div>
                    <div class="items-center justify-center hidden dark:flex">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                    </div>
                </button>
            </div>
            

        </nav>
        <div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12">

            <span></span>

            


            
            <button id="search-button-mobile" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            

            
            
            <button id="appearance-switcher-mobile" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400 ltr:mr-1 rtl:ml-1">
                <div class="flex items-center justify-center dark:hidden">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                </div>
                <div class="items-center justify-center hidden dark:flex">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                </div>
            </button>
            

        </div>
    </div>
    <div class="-my-2 md:hidden">

        <label id="menu-button" class="block">
            
            <div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400">
                

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>

  </span>


            </div>
            <div id="menu-wrapper" style="padding-top:5px;"
                class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50">
                <ul
                    class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl">

                    <li id="menu-close-button">
                        <span
                            class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>

</span>
                    </li>

                    

                     
  <li class="mt-1">
    <a href="" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Home
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/aboutme"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            About Me
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/clients"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Clients
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dscourses"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            DS/AI Courses/Services
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/corpus-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            History Corpus
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/management"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PM Courses/Services
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/project-index-page"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Project/Work Catalog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/publications-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Publications
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/testimonials"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Testimonial
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a href="" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Data Science
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/news"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            AI and Business News
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dsblog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Data Science Blog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dsblog/data-science-cheatsheets"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Data Science Cheatsheets
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/datascience-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Data Science Topics
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dsblog/ds-ai-ml-books"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Data Science-Books
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dsblog/ds-ai-ml-interview-resources"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            DS Interview Questions
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/datascience-resources"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            DS Resources
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/dsblog/best-youtube-channels-for-ds"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Video Channels to Learn DS
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a href="" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Project Management
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/pmglossary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PM Glossary
        </p>
    </a>
</li>

<li class="mt-1">
    <a href=""  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PM Resources
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmlogy-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PM Topics
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmbok6-summary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PMBOK6
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmbok6"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PMBOK6 Explorer
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmbok6-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PMBOK6 Topics
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmblog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PMLOGY Blog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/pmlogy-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PMLOGY Home
        </p>
    </a>
</li>

<li class="mt-1">
    <a href=""  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Project Management Hindi
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a href="" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            SpiritualDrops
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/booksummary"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Book Summary
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gk"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            GK Blog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gk-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            GK Topic
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/wiaposts"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            WIA Blog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/wia-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            WIA Home
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/quotations-blog"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            WIA Quotes
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/wia-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            WIA Topics
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a href="/gallary" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Gallery
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-pm-selected-photos"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Management Classes
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-online-sessions1"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Online AI Classes 1
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-online-sessions2"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Online AI Classes 2
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-online-sessions3"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Online AI Classes 3
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-online-sessions4"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Online AI Classes 4
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/gallary/slider-pm-workshops"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            PM &amp; DS Workshop Photos
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a href="" class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Samskrut
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/mychanting"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            My Vedic Chantings
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/samskrutyatra"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Samskrut Blog
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/samskrutyatra-tags"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Samskrut Topics
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/samskrutyatra-home"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            SamskrutYatra Home
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                </ul>
                
                

            </div>
        </label>
    </div>
</div>




<script>
    (function () {
        var $mainmenu = $('.main-menu');
        var path = window.location.pathname;
        $mainmenu.find('a[href="' + path + '"]').each(function (i, e) {
            $(e).children('p').addClass('active');
        });
    })();
</script>


  </div>
</div>
<script>
  window.addEventListener('scroll', function (e) {
    var scroll = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop || 0;
    var background_blur = document.getElementById('menu-blur');
    background_blur.style.opacity = (scroll / 300);
  });
</script>

  
  <div class="relative flex flex-col grow">
    <main id="main-content" class="grow">
      


<style>
  .article-content img {
    width: 100%;
    max-width: 100vw;
    height: auto;
    object-fit: contain;
    margin-left: 50%;
    transform: translateX(-50%);
  }
  @media (max-width: 768px) {
    .article-content img {
      width: 100%;
      margin-left: 0;
      transform: none;
    }
  }
</style>

<article>
  

  <header id="single_header" class="mt-5">
    
      <ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden">
  
  
    
  
    
  
  <li class="hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/"
      >dasarpAI</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="inline">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/dsblog/"
      >Data Science Blog</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/dsblog/understanding-contextual-embedding-in-transformers/"
      >Understanding Contextual Embedding in Transformers</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

</ol>


    

    <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
      Understanding Contextual Embedding in Transformers
    </h1>

    <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
      





  
  







  





  



  











  



<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2025-01-30T00:00:00&#43;00:00">30 January 2025</time><span class="px-2 text-primary-500">&middot;</span><span>1921 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">10 mins</span><span class="px-2 text-primary-500">&middot;</span>


<script type="text/javascript" src="/js/zen-mode.min.eea5245cf9244ecbdf2c150d1c8833226c1541cadf6e98f63a7c9192b1a3676df2c3ec603b14f4cfaaa53971fd9d8955640c0f405bf3de2b43ee7a5fb29ae721.js" integrity="sha512-7qUkXPkkTsvfLBUNHIgzImwVQcrfbpj2OnyRkrGjZ23yw&#43;xgOxT0z6qlOXH9nYlVZAwPQFvz3itD7npfsprnIQ=="></script>

<span class="mb-[2px]">
    <span id="zen-mode-button"
          class="text-lg hover:text-primary-500"
          title="Enable zen mode"
          data-title-i18n-disable="Enable zen mode"
          data-title-i18n-enable="Disable zen mode">
        <span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="50px" height="50px">
    <path fill="currentColor" d="M 12.980469 4 C 9.1204688 4 5.9804688 7.14 5.9804688 11 L 6 26 L 9.9804688 26 L 9.9804688 11 C 9.9804688 9.35 11.320469 8 12.980469 8 L 40.019531 8 C 41.679531 8 43.019531 9.35 43.019531 11 L 43.019531 39 C 43.019531 40.65 41.679531 42 40.019531 42 L 29 42 C 29 43.54 28.420938 44.94 27.460938 46 L 40.019531 46 C 43.879531 46 47.019531 42.86 47.019531 39 L 47.019531 11 C 47.019531 7.14 43.879531 4 40.019531 4 L 12.980469 4 z M 7 28 C 4.794 28 3 29.794 3 32 L 3 42 C 3 44.206 4.794 46 7 46 L 23 46 C 25.206 46 27 44.206 27 42 L 27 32 C 27 29.794 25.206 28 23 28 L 7 28 z M 7 32 L 23 32 L 23.001953 42 L 7 42 L 7 32 z"/>
</svg>
  </span>

</span>
    </span>
</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/transformers/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Transformers
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/embeddings/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Embeddings
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  
  
  
</div>




    </div>

    

    
    

    

    
      

      

      
    
  </header>

  <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
    
    
    

    
      <div class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8">
        <div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]">
          
            <h4>On This Page</h4>
<details open id="TOCView"
  class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block">
  <summary
    class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    Table of Contents
  </summary>
  <div
    class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#what-is-embedding">What is Embedding?</a></li>
    <li><a href="#what-is-fixed-embedding">What is Fixed Embedding?</a></li>
    <li><a href="#how-transformers-handle-context">How Transformers Handle Context</a></li>
    <li><a href="#how-this-token-bank-and-corresponding-embedding-is-stored-in-embedding-database">How this token &lsquo;bank&rsquo; and corresponding embedding is stored in embedding database?</a></li>
    <li><a href="#how-contextural-embedding-is-generated">How contextural embedding is generated?</a></li>
    <li><a href="#what-will-be-the-output-size-of-attention-formula-softmax">What will be the output size of attention formula softmax?</a></li>
    <li><a href="#what-is-meaning-of-a-llm-has-context-length-of-2-million-tokens">What is meaning of a LLM has context length of 2 million tokens?</a></li>
    <li><a href="#how-many-attention-layers-we-keep-in-transformer-like-gpt4">How many attention layers we keep in transformer like gpt4?</a></li>
    <li><a href="#what-is-the-meaning-of-96-attention-layers-are-they-attention-head-count">What is the meaning of 96 attention layers, are they attention head count?</a></li>
  </ul>
</nav>
  </div>
</details>
<details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden">
  <summary
    class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    Table of Contents
  </summary>
  <div
    class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction">Introduction</a></li>
    <li><a href="#what-is-embedding">What is Embedding?</a></li>
    <li><a href="#what-is-fixed-embedding">What is Fixed Embedding?</a></li>
    <li><a href="#how-transformers-handle-context">How Transformers Handle Context</a></li>
    <li><a href="#how-this-token-bank-and-corresponding-embedding-is-stored-in-embedding-database">How this token &lsquo;bank&rsquo; and corresponding embedding is stored in embedding database?</a></li>
    <li><a href="#how-contextural-embedding-is-generated">How contextural embedding is generated?</a></li>
    <li><a href="#what-will-be-the-output-size-of-attention-formula-softmax">What will be the output size of attention formula softmax?</a></li>
    <li><a href="#what-is-meaning-of-a-llm-has-context-length-of-2-million-tokens">What is meaning of a LLM has context length of 2 million tokens?</a></li>
    <li><a href="#how-many-attention-layers-we-keep-in-transformer-like-gpt4">How many attention layers we keep in transformer like gpt4?</a></li>
    <li><a href="#what-is-the-meaning-of-96-attention-layers-are-they-attention-head-count">What is the meaning of 96 attention layers, are they attention head count?</a></li>
  </ul>
</nav>
  </div>
</details>

<script>

  var margin = 200;
  var marginError = 50;

  (function () {
    var $window = $(window);
    var $toc = $('#TOCView');
    var tocHeight = $toc.height();

    function onResize() {
      var windowAndMarginHeight = $window.height() - margin;
      if(tocHeight >= windowAndMarginHeight) {
        $toc.css("overflow-y", "scroll")
        $toc.css("max-height", (windowAndMarginHeight + marginError) + "px")
      } else {
        $toc.css("overflow-y", "hidden")
        $toc.css("max-height", "9999999px")
      }
    }

    $window.on('resize', onResize);
    $(document).ready(onResize);
  })();



  (function () {
    var $toc = $('#TableOfContents');
    if ($toc.length > 0) {
      var $window = $(window);

      function onScroll() {
        var currentScroll = $window.scrollTop();
        var h = $('.anchor');
        var id = "";
        h.each(function (i, e) {
          e = $(e);
          if (e.offset().top - $(window).height()/3 <= currentScroll) {
            id = decodeURIComponent(e.attr('id'));
          }
        });
        var active = $toc.find('a.active');      
        if (active.length == 1 && active.eq(0).attr('href') == '#' + id) return true;

        active.each(function (i, e) {
          
            $(e).removeClass('active');
          
        });
        $toc.find('a[href="#' + id + '"]').addClass('active')
        $toc.find('a[href="#' + id + '"]').parentsUntil('#TableOfContents').each(function (i, e) {
          $(e).children('a').parents('ul').show();          
        });
      }

      $window.on('scroll', onScroll);
      $(document).ready(function () {
        
        onScroll();
      });
    }
  })();


</script>

          
          
          
        </div>
      </div>
    

    <div class="min-w-0 min-h-0 max-w-fit">
      


      <div class="article-content mb-20">
        <p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="/assets/images/dspost/dsp6214-Understanding-Contextual-Embedding-in-Transformer.jpg" alt="Understanding Contextual Embedding in Transformers" />
      
    </figure>
</p>


<h2 class="relative group">Introduction 
    <div id="introduction" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#introduction" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>Embedding can be confusing for many people, and contextual embedding performed by transformers can be even more perplexing. Even after gaining an understanding, many questions remain. In this article, we aim to address the following questions.</p>
<ul>
<li>What is Embedding?</li>
<li>What is Fixed Embedding?</li>
<li>How Transformers Handle Context</li>
<li>How this token &lsquo;bank&rsquo; and corresponding embedding is stored in embedding database?</li>
<li>How contextural embedding is generated?</li>
<li>What will be the output size of attention formula softmax?</li>
<li>What is meaning of a LLM has context length of 2 million tokens?</li>
<li>How many attention layers we keep in transformer like gpt4?</li>
<li>What is the meaning of 96 attention layers, are they attention head count?</li>
</ul>


<h2 class="relative group">What is Embedding? 
    <div id="what-is-embedding" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#what-is-embedding" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>An embedding is a way to represent discrete data (like words or tokens) as continuous vectors of numbers.</p>
<p>for example</p>
<pre tabindex="0"><code>&#34;cat&#34;  [0.2, -0.5, 0.1, 0.8, ...]  # e.g., 100 dimensions vector
&#34;dog&#34;  [0.3, -0.4, 0.2, 0.7, ...]
</code></pre><p>Each dimension potentially represents some feature, they may be Masculinity/femininity, Animate/inanimate, Abstract/concrete etc.</p>
<p>Embedding helps</p>
<ul>
<li>convert discrete symbols into a numbers which can be processed by neural networks.</li>
<li>These numbers can also capture the relationships between words and in sementic operations like Queen = King - Man + Woman.</li>
<li>Reduce dimensionality (compared to one-hot encoding)</li>
</ul>


<h2 class="relative group">What is Fixed Embedding? 
    <div id="what-is-fixed-embedding" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#what-is-fixed-embedding" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>A word &ldquo;bank&rdquo; can have multiple meaning linking to finance, dependence or river. In LLM when we do the tokenization in all case the token for this word will be same. But, what about embedding when &lsquo;bank&rsquo; word appears in different contexts</p>
<p><strong>Word Embeddings vs. Contextual Embeddings</strong></p>
<p>In traditional word embeddings (like Word2Vec or GloVe):</p>
<ul>
<li>Each word has a single, static embedding vector</li>
<li>&ldquo;bank&rdquo; would have the same embedding regardless of context</li>
<li>This is a limitation, as it can&rsquo;t distinguish between financial bank vs. river bank</li>
</ul>
<p>In contextual embedding (transormer models like BERT, GPT):</p>
<ul>
<li>Words get contextual embeddings that change based on surrounding text</li>
<li>&ldquo;bank&rdquo; gets different embedding representations depending on its usage</li>
<li>The model learns to create distinct representations for different meanings</li>
</ul>


<h2 class="relative group">How Transformers Handle Context 
    <div id="how-transformers-handle-context" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#how-transformers-handle-context" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>Let&rsquo;s look at examples:</p>
<pre tabindex="0"><code>&#34;I went to the bank to deposit money&#34;
&#34;The river bank was muddy&#34;
</code></pre><p>In these sentences:</p>
<ul>
<li>The initial token embeddings are combined with positional encodings</li>
<li>Each self-attention layer considers the relationships between &ldquo;bank&rdquo; and other words</li>
<li>Words like &ldquo;deposit,&rdquo; &ldquo;money,&rdquo; &ldquo;river,&rdquo; and &ldquo;muddy&rdquo; influence how &ldquo;bank&rdquo; is represented</li>
<li>The resulting contextual embeddings for &ldquo;bank&rdquo; will be different in each case</li>
</ul>
<p>Step 1. Initial Embedding:</p>
<ul>
<li>The word &ldquo;bank&rdquo; is first tokenized</li>
<li>It gets a base embedding from the embedding layer (typically there are different models for this work, these models are called embedding models)</li>
</ul>
<p>Step 2. Contextual Processing:</p>
<ul>
<li>Self-attention mechanisms look at surrounding words</li>
<li>Each attention head can focus on different aspects of meaning</li>
<li>Multiple transformer layers progressively refine the representation</li>
</ul>
<p>Step 3. Final Representation:</p>
<ul>
<li>The final embedding captures the specific meaning in that context</li>
<li>The financial &ldquo;bank&rdquo; embedding will be closer to other financial terms</li>
<li>The geographical &ldquo;bank&rdquo; embedding will be closer to other geographical terms</li>
</ul>
<p>Real-world Example</p>
<p>Consider these vectors (simplified for illustration):</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># Hypothetical embedding dimensions</span>
</span></span><span class="line"><span class="cl"><span class="n">bank</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>  <span class="c1"># if this is financal bank then it will be close to the words like &#34;money&#34;, &#34;deposit&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">bank</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="o">...</span><span class="p">]</span>  <span class="c1"># if this is related to river then it will be close to words like &#34;water&#34;, swimming,&#34;river&#34;, &#34;shore&#34;</span>
</span></span></code></pre></div><p>The transformer model automatically generates these different representations based on context, allowing it to:</p>
<ul>
<li>Understand the appropriate meaning</li>
<li>Make relevant predictions</li>
<li>Handle ambiguity effectively</li>
</ul>
<p>This is why transformers are so powerful at handling polysemy - they don&rsquo;t just look up static word meanings but dynamically construct meanings based on context, much like humans do.</p>


<h2 class="relative group">How this token &lsquo;bank&rsquo; and corresponding embedding is stored in embedding database? 
    <div id="how-this-token-bank-and-corresponding-embedding-is-stored-in-embedding-database" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#how-this-token-bank-and-corresponding-embedding-is-stored-in-embedding-database" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p><strong>1. Token Storage (Vocabulary)</strong></p>
<ul>
<li>The tokenizer maintains a fixed vocabulary mapping</li>
<li>&ldquo;bank&rdquo; as a token is stored in a vocabulary dictionary/lookup table</li>
<li>Each token has a unique integer ID</li>
<li>Example vocabulary entry:</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">vocab</span> <span class="o">=</span> <span class="p">{</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;bank&#34;</span><span class="p">:</span> <span class="mi">2847</span><span class="p">,</span>  <span class="c1"># unique ID</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;bank&#34;</span><span class="p">:</span> <span class="s2">&#34;bank&#34;</span><span class="p">,</span>  <span class="c1"># actual token (might include special chars for word boundaries. Plus actual token need not be a complete word, for example you will not time one token for a word &#34;simultaneously&#34;)</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div><p><strong>2. Embedding Storage:</strong></p>
<ul>
<li>The embedding layer is implemented as a matrix/lookup table</li>
<li>Dimensions: (vocab_size  embedding_dim)</li>
<li>Each row corresponds to a token&rsquo;s base embedding vector</li>
<li>Example structure:</li>
</ul>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># For token &#34;bank&#34; with ID 2847:</span>
</span></span><span class="line"><span class="cl"><span class="n">base_embedding</span> <span class="o">=</span> <span class="n">embedding_matrix</span><span class="p">[</span><span class="mi">2847</span><span class="p">]</span>  <span class="c1"># Gets base embedding vector</span>
</span></span></code></pre></div><p>Key Points:</p>
<ul>
<li>There is only ONE base embedding vector per token</li>
<li>The contextual embeddings are generated on-the-fly during processing</li>
<li>The model doesn&rsquo;t store different embeddings for different meanings</li>
<li>The context-specific meanings emerge from the transformer layers</li>
</ul>
<p><strong>3. What&rsquo;s Actually Stored:</strong></p>
<pre tabindex="0"><code>Token Storage:
&#34;bank&#34; -&gt; 2847 (ID)

Embedding Matrix:
Row 2847: [0.1, 0.3, -0.2, ...] (base embedding vector)
</code></pre><p><strong>4. During Processing:</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="c1"># When processing &#34;financial bank&#34;:</span>
</span></span><span class="line"><span class="cl"><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&#34;I went to the bank to deposit money&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">base_embeddings</span> <span class="o">=</span> <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">input_ids</span><span class="p">]</span>  <span class="c1"># Look up base embeddings</span>
</span></span><span class="line"><span class="cl"><span class="n">contextual_embeddings</span> <span class="o">=</span> <span class="n">transformer_layers</span><span class="p">(</span><span class="n">base_embeddings</span><span class="p">)</span>  <span class="c1"># Generate context-specific embeddings</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># When processing &#34;river bank&#34;:</span>
</span></span><span class="line"><span class="cl"><span class="n">input_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">&#34;The river bank was muddy&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">base_embeddings</span> <span class="o">=</span> <span class="n">embedding_matrix</span><span class="p">[</span><span class="n">input_ids</span><span class="p">]</span>  <span class="c1"># Same base embeddings</span>
</span></span><span class="line"><span class="cl"><span class="n">contextual_embeddings</span> <span class="o">=</span> <span class="n">transformer_layers</span><span class="p">(</span><span class="n">base_embeddings</span><span class="p">)</span>  <span class="c1"># Different context-specific embeddings</span>
</span></span></code></pre></div><p>The different meanings of &ldquo;bank&rdquo; emerge from:</p>
<ul>
<li>The transformer&rsquo;s attention mechanisms</li>
<li>Layer-by-layer contextual processing</li>
<li>Interaction with surrounding tokens</li>
</ul>
<p>Important Note:</p>
<ul>
<li>The model doesn&rsquo;t explicitly store different embeddings for different meanings</li>
<li>It learns to transform the base embedding based on context</li>
<li>This makes the system more efficient and flexible</li>
<li>The meaning disambiguation happens dynamically during processing</li>
</ul>
<p>Token &ldquo;bank&rdquo;  Base Embedding  Transformer Layers  Contextual Embedding

(considers surrounding context)</p>
<p><strong>5. Post Processing</strong></p>
<ul>
<li>The contextual embeddings are used temporarily for the current task</li>
<li>They exist only during processing (encoding/decoding)</li>
<li>After the task is complete, only the results are kept, not the intermediate contextual embeddings</li>
</ul>


<h2 class="relative group">How contextural embedding is generated? 
    <div id="how-contextural-embedding-is-generated" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#how-contextural-embedding-is-generated" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>To generate that contextual embedding we take help of that formula of Query (Q), Key (K), and Value (V) given in &ldquo;Attention is all you need&rdquo; paper?</p>
<p><strong>1. For each token&rsquo;s base embedding, the model creates:</strong></p>
<pre tabindex="0"><code>Q = W_q  base_embedding  (Query)
K = W_k  base_embedding  (Key)
V = W_v  base_embedding  (Value)
</code></pre><p><strong>2. The attention formula then is:</strong></p>
<pre tabindex="0"><code>Attention(Q, K, V) = softmax(QK^T/d_k)V
</code></pre><p>Where:</p>
<ul>
<li>QK^T computes compatibility scores between tokens</li>
<li>d_k is the scaling factor to prevent vanishing gradients</li>
<li>softmax creates attention weights</li>
<li>Final multiplication with V produces the contextual representation</li>
</ul>
<p><strong>3. Example for &ldquo;bank&rdquo;:</strong></p>
<ul>
<li>
<p>When processing &ldquo;bank&rdquo; in &ldquo;river bank&rdquo;:</p>
<ul>
<li>Q for &ldquo;bank&rdquo; will attend more strongly to &ldquo;river&rdquo;</li>
<li>The resulting contextual embedding shifts toward geographical meaning</li>
</ul>
</li>
<li>
<p>When processing &ldquo;bank&rdquo; in &ldquo;deposit money at the bank&rdquo;:</p>
<ul>
<li>Q for &ldquo;bank&rdquo; will attend more strongly to &ldquo;deposit&rdquo;, &ldquo;money&rdquo;</li>
<li>The resulting contextual embedding shifts toward financial meaning</li>
</ul>
</li>
</ul>
<p><strong>4. Multi-head attention:</strong></p>
<ul>
<li>Multiple sets of Q, K, V transformations</li>
<li>Each head can focus on different aspects of context</li>
<li>Results are concatenated and linearly transformed</li>
</ul>
<p>This mechanism allows the model to dynamically weigh different aspects of context when creating the contextual embeddings for each token.</p>


<h2 class="relative group">What will be the output size of attention formula softmax? 
    <div id="what-will-be-the-output-size-of-attention-formula-softmax" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#what-will-be-the-output-size-of-attention-formula-softmax" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>If d_k=1024 and based embedding is 1024 then in that what will be the output size of attention formula softmax?</p>
<ol>
<li>Initial dimensions:</li>
</ol>
<ul>
<li>Base embedding dimension = 1024</li>
<li>d_k = 1024</li>
<li>Let&rsquo;s say we have a sequence length of n tokens</li>
</ul>
<ol start="2">
<li>Creating Q, K, V matrices:</li>
</ol>
<ul>
<li>Q: (n  d_k) = (n  1024)</li>
<li>K: (n  d_k) = (n  1024)</li>
<li>V: (n  d_k) = (n  1024)</li>
</ul>
<ol start="3">
<li>In the attention formula:</li>
</ol>
<pre tabindex="0"><code>QK^T/d_k
</code></pre><ul>
<li>Q: (n  1024)</li>
<li>K^T: (1024  n)</li>
<li>QK^T results in: (n  n) matrix</li>
<li>This represents attention scores between every token pair. There are n token and it is nxn correlation matrix.</li>
</ul>
<ol start="4">
<li>After softmax:</li>
</ol>
<ul>
<li>Input: (n  n) matrix</li>
<li>Output: (n  n) matrix of attention weights</li>
<li>Each row sums to 1</li>
</ul>
<ol start="5">
<li>Final multiplication with V:</li>
</ol>
<pre tabindex="0"><code>softmax(QK^T/d_k)V
</code></pre><ul>
<li>Attention weights: (n  n)</li>
<li>V: (n  1024)</li>
<li>Result: (n  1024)</li>
</ul>
<p>So the softmax actually operates on an (n  n) attention matrix. The 1024 dimension (d_k) is used for the intermediate calculation but doesn&rsquo;t determine the final attention matrix size. The attention matrix size depends on the sequence length n (how many tokens are in your input).</p>
<p>For example, if you&rsquo;re processing 5 tokens:</p>
<ul>
<li>Attention matrix would be 55</li>
<li>Each token can attend to all other tokens</li>
<li>Final output preserves the sequence length and embedding dimension: 51024</li>
</ul>


<h2 class="relative group">What is meaning of a LLM has context length of 2 million tokens? 
    <div id="what-is-meaning-of-a-llm-has-context-length-of-2-million-tokens" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#what-is-meaning-of-a-llm-has-context-length-of-2-million-tokens" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>In the case of LLM like gemini where they say context length is 2 million tokens, in that case this n is 2 millions?</p>
<p>Yes, theoretically in that case n would be 2 million, which reveals one of the biggest challenges in transformer architecture - the quadratic complexity problem.</p>
<p>Let&rsquo;s break down what this means:</p>
<ol>
<li>Memory Requirements:</li>
</ol>
<ul>
<li>For 2M tokens, attention matrix is 2M  2M</li>
<li>That&rsquo;s 4 trillion (4  10^12) elements</li>
<li>Even with float16 precision, this needs ~8TB of memory just for one attention layer</li>
</ul>
<ol start="2">
<li>Computational Complexity:</li>
</ol>
<ul>
<li>Computing QK^T is O(n)</li>
<li>For n = 2M, that&rsquo;s 4 trillion operations per attention layer</li>
<li>Multiple this by number of heads and layers</li>
</ul>
<p>This is why models like Gemini likely use optimization techniques to handle such long contexts:</p>
<ol>
<li>Sparse Attention:</li>
</ol>
<ul>
<li>Not all tokens attend to all other tokens</li>
<li>Use patterns like local attention, sliding windows</li>
<li>Reduces from O(n) to O(n log n) or even O(n)</li>
</ul>
<ol start="2">
<li>Memory-efficient techniques:</li>
</ol>
<ul>
<li>Flash Attention</li>
<li>Sparse or linear transformers</li>
<li>State space models</li>
<li>Rotary position embeddings</li>
</ul>
<ol start="3">
<li>Attention Patterns like:</li>
</ol>
<ul>
<li>Sliding window attention</li>
<li>Dilated attention</li>
<li>Hierarchical attention</li>
</ul>
<p>Without these optimizations, the original transformer attention mechanism would be computationally infeasible for such long contexts.</p>


<h2 class="relative group">How many attention layers we keep in transformer like gpt4? 
    <div id="how-many-attention-layers-we-keep-in-transformer-like-gpt4" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#how-many-attention-layers-we-keep-in-transformer-like-gpt4" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>The exact architecture details of GPT-4 aren&rsquo;t public, but we can discuss what&rsquo;s known about transformer architectures in general and earlier models:</p>
<ol>
<li>Typical Structure:</li>
</ol>
<ul>
<li>Multiple transformer blocks/layers (anywhere from 12 to hundreds)</li>
<li>Each block contains:
<ul>
<li>Multi-head attention layer</li>
<li>Feed-forward neural network</li>
<li>Layer normalization</li>
<li>Residual connections</li>
</ul>
</li>
</ul>
<ol start="2">
<li>Known Examples:</li>
</ol>
<ul>
<li>GPT-3 (175B parameter model):
<ul>
<li>96 attention layers</li>
<li>96 heads per layer</li>
</ul>
</li>
<li>GPT-2:
<ul>
<li>Large variant: 48 layers</li>
<li>Medium: 24 layers</li>
<li>Small: 12 layers</li>
</ul>
</li>
</ul>
<ol start="3">
<li>General Pattern:</li>
</ol>
<ul>
<li>Larger models tend to have more layers</li>
<li>Common to use powers of 2 for layer counts</li>
<li>Often balanced with number of attention heads</li>
<li>More layers = deeper understanding but more compute</li>
</ul>
<ol start="4">
<li>Trade-offs:</li>
</ol>
<ul>
<li>More layers = better performance but:
<ul>
<li>Higher computational cost</li>
<li>More memory usage</li>
<li>Longer inference time</li>
<li>Risk of vanishing gradients</li>
</ul>
</li>
</ul>


<h2 class="relative group">What is the meaning of 96 attention layers, are they attention head count? 
    <div id="what-is-the-meaning-of-96-attention-layers-are-they-attention-head-count" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#what-is-the-meaning-of-96-attention-layers-are-they-attention-head-count" aria-label="Anchor">#</a>
    </span>        
    
</h2>
<p>N</p>
<ol>
<li>Layer vs Head Count:</li>
</ol>
<ul>
<li>Number of layers and heads are independent parameters</li>
<li>A model with 96 layers might have 12, 20, or 96 heads per layer</li>
<li>The head count doesn&rsquo;t need to match layer count</li>
</ul>
<ol start="2">
<li>Example Configurations:</li>
</ol>
<pre tabindex="0"><code>GPT-3:
- 96 layers
- 96 attention heads per layer

BERT-base:
- 12 layers
- 12 attention heads per layer

BERT-large:
- 24 layers
- 16 attention heads per layer
</code></pre><ol start="3">
<li>Each Layer&rsquo;s Structure:</li>
</ol>
<pre tabindex="0"><code>Transformer Layer

 Multi-Head Attention (e.g., 12 heads)
    Head 1: (Q1,K1,V1)
    Head 2: (Q2,K2,V2)
    ... up to Head 12

 Feed Forward Network
 Layer Normalization
</code></pre><ol start="4">
<li>Process Flow:</li>
</ol>
<ul>
<li>Input  Layer 1 (12 heads)  Layer 2 (12 heads)  &hellip;  Layer 96 (12 heads)</li>
<li>Each head in a layer processes the same input differently</li>
<li>Results from all heads are concatenated and projected</li>
</ul>
<p><strong>The number of heads is more about parallel processing of different attention patterns, while the number of layers is about depth of processing.</strong></p>


        
        
      </div>

      <style>
 

</style><div class="td-author-box"><div class="td-author-box__avatar">
        <img src="/assets/images/myphotos/Profilephoto1.jpg" alt="Hari Thapliyaal's avatar" class="author-image" width="25%" >
      </div>
    <div class="td-author-box__links author-image"><b>Follow Me</b>
        <a href="https://join.slack.com/t/dasarpai/shared_invite/zt-2mg1j7ddw-0QYA9IAvFFRKw51ZBK6mkQ" target="_blank" rel="noopener" aria-label="Slack" title="Chat with other project users in #users">
            <i class="fab fa-slack" aria-hidden="true"></i>
        </a>
        <a href="https://groups.google.com/forum/#!forum/agones-discuss" target="_blank" rel="noopener" aria-label="User mailing list" title="Discussion and help from your fellow users">
            <i class="fa fa-envelope" aria-hidden="true"></i>
        </a>
        <a href="https://twitter.com/dasarpai" target="_blank" rel="noopener" aria-label="Twitter" title="Follow us on Twitter to get the latest news!">
            <i class="fab fa-twitter" aria-hidden="true"></i>
        </a>
        <a href="https://www.youtube.com/playlist?list=PLhkWKwFGACw2dFpdmwxOyUCzlGP2-n7uF" target="_blank" rel="noopener" aria-label="Community Meetings" title="Live discussion of new features and issues, see the &lt;a href=&#34;https://github.com/googleforgames/agones/blob/main/CONTRIBUTING.md#community-meetings&#34;&gt;calendar&lt;/a&gt; or &lt;a href=&#34;https://groups.google.com/forum/#!forum/agones-discuss&#34;&gt;mailing list&lt;/a&gt; for details">
            <i class="fab fa-youtube" aria-hidden="true"></i>
        </a>
    </div>
  

    <div class="td-author-box__info">
    <h4 class="td-author-box__name">Hari Thapliyaal</h4><p class="td-author-box__bio">Dr. Hari Thapliyal is a seasoned professional and prolific blogger with a multifaceted background that spans the realms of Data Science, Project Management, and Advait-Vedanta Philosophy. Holding a Doctorate in AI/NLP from SSBM (Geneva, Switzerland), Hari has earned Master&#39;s degrees in Computers, Business Management, Data Science, and Economics, reflecting his dedication to continuous learning and a diverse skill set.

With over three decades of experience in management and leadership, Hari has proven expertise in training, consulting, and coaching within the technology sector. His extensive 16&#43; years in all phases of software product development are complemented by a decade-long focus on course design, training, coaching, and consulting in Project Management.

 In the dynamic field of Data Science, Hari stands out with more than three years of hands-on experience in software development, training course development, training, and mentoring professionals. His areas of specialization include Data Science, AI, Computer Vision, NLP, complex machine learning algorithms, statistical modeling, pattern identification, and extraction of valuable insights.

Hari&#39;s professional journey showcases his diverse experience in planning and executing multiple types of projects. He excels in driving stakeholders to identify and resolve business problems, consistently delivering excellent results. Beyond the professional sphere, Hari finds solace in long meditation, often seeking secluded places or immersing himself in the embrace of nature.</p></div>
  </div>
      <div class="td-comments">
      <h4 class="td-comments__title">Comments:</h4>
      <script src="https://giscus.app/client.js"
              data-repo="dasarpai/dasarpai-comments"
              data-repo-id="R_kgDOOGVFpA"
              data-category="General"
              data-category-id="DIC_kwDOOGVFpM4CnzHR"
              data-mapping="url"
              data-reactions-enabled="1"
              data-theme="light"
              data-strict="1"
              data-input-position="top"
              data-emit-metadata="1"
              data-lang="en"
              crossorigin="anonymous"
              async>
      </script>
    </div>
      

      
  
  <section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/&amp;title=Understanding%20Contextual%20Embedding%20in%20Transformers"
      title="Share on LinkedIn"
      aria-label="Share on LinkedIn"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://twitter.com/intent/tweet/?url=https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/&amp;text=Understanding%20Contextual%20Embedding%20in%20Transformers"
      title="Tweet on Twitter"
      aria-label="Tweet on Twitter"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://api.whatsapp.com/send?text=https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/&amp;resubmit=true&amp;title=Understanding%20Contextual%20Embedding%20in%20Transformers"
      title="Share via WhatsApp"
      aria-label="Share via WhatsApp"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://t.me/share/url?url=https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/&amp;resubmit=true&amp;title=Understanding%20Contextual%20Embedding%20in%20Transformers"
      title="Share via Telegram"
      aria-label="Share via Telegram"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M248,8C111.033,8,0,119.033,0,256S111.033,504,248,504,496,392.967,496,256,384.967,8,248,8ZM362.952,176.66c-3.732,39.215-19.881,134.378-28.1,178.3-3.476,18.584-10.322,24.816-16.948,25.425-14.4,1.326-25.338-9.517-39.287-18.661-21.827-14.308-34.158-23.215-55.346-37.177-24.485-16.135-8.612-25,5.342-39.5,3.652-3.793,67.107-61.51,68.335-66.746.153-.655.3-3.1-1.154-4.384s-3.59-.849-5.135-.5q-3.283.746-104.608,69.142-14.845,10.194-26.894,9.934c-8.855-.191-25.888-5.006-38.551-9.123-15.531-5.048-27.875-7.717-26.8-16.291q.84-6.7,18.45-13.7,108.446-47.248,144.628-62.3c68.872-28.647,83.183-33.623,92.511-33.789,2.052-.034,6.639.474,9.61,2.885a10.452,10.452,0,0,1,3.53,6.716A43.765,43.765,0,0,1,362.952,176.66Z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://pinterest.com/pin/create/bookmarklet/?url=https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/&amp;description=Understanding%20Contextual%20Embedding%20in%20Transformers"
      title="Pin on Pinterest"
      aria-label="Pin on Pinterest"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M496 256c0 137-111 248-248 248-25.6 0-50.2-3.9-73.4-11.1 10.1-16.5 25.2-43.5 30.8-65 3-11.6 15.4-59 15.4-59 8.1 15.4 31.7 28.5 56.8 28.5 74.8 0 128.7-68.8 128.7-154.3 0-81.9-66.9-143.2-152.9-143.2-107 0-163.9 71.8-163.9 150.1 0 36.4 19.4 81.7 50.3 96.1 4.7 2.2 7.2 1.2 8.3-3.3.8-3.4 5-20.3 6.9-28.1.6-2.5.3-4.7-1.7-7.1-10.1-12.5-18.3-35.3-18.3-56.6 0-54.7 41.4-107.6 112-107.6 60.9 0 103.6 41.5 103.6 100.9 0 67.1-33.9 113.6-78 113.6-24.3 0-42.6-20.1-36.7-44.8 7-29.5 20.5-61.3 20.5-82.6 0-19-10.2-34.9-31.4-34.9-24.9 0-44.9 25.7-44.9 60.2 0 22 7.4 36.8 7.4 36.8s-24.5 103.8-29 123.2c-5 21.4-3 51.6-.9 71.2C65.4 450.9 0 361.1 0 256 0 119 111 8 248 8s248 111 248 248z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://www.facebook.com/sharer/sharer.php?u=https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/&amp;quote=Understanding%20Contextual%20Embedding%20in%20Transformers"
      title="Share on Facebook"
      aria-label="Share on Facebook"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="mailto:?body=https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/&amp;subject=Understanding%20Contextual%20Embedding%20in%20Transformers"
      title="Send via email"
      aria-label="Send via email"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1c-27.64 140.9 68.65 266.2 199.1 285.1c19.01 2.888 36.17-12.26 36.17-31.49l.0001-.6631c0-15.74-11.44-28.88-26.84-31.24c-84.35-12.98-149.2-86.13-149.2-174.2c0-102.9 88.61-185.5 193.4-175.4c91.54 8.869 158.6 91.25 158.6 183.2l0 16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98 .0036c-7.299 0-13.2 4.992-15.12 11.68c-24.85-12.15-54.24-16.38-86.06-5.106c-38.75 13.73-68.12 48.91-73.72 89.64c-9.483 69.01 43.81 128 110.9 128c26.44 0 50.43-9.544 69.59-24.88c24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3C495.1 107.1 361.2-9.332 207.8 20.73zM239.1 304.3c-26.47 0-48-21.56-48-48.05s21.53-48.05 48-48.05s48 21.56 48 48.05S266.5 304.3 239.1 304.3z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://bsky.app/intent/compose?text=Understanding%20Contextual%20Embedding%20in%20Transformers&#43;https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/"
      title="Post on Bluesky"
      aria-label="Post on Bluesky"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256,232.562c-21.183,-41.196 -78.868,-117.97 -132.503,-155.834c-51.378,-36.272 -70.978,-29.987 -83.828,-24.181c-14.872,6.72 -17.577,29.554 -17.577,42.988c0,13.433 7.365,110.138 12.169,126.281c15.873,53.336 72.376,71.358 124.413,65.574c2.66,-0.395 5.357,-0.759 8.089,-1.097c-2.68,0.429 -5.379,0.796 -8.089,1.097c-76.259,11.294 -143.984,39.085 -55.158,137.972c97.708,101.165 133.908,-21.692 152.484,-83.983c18.576,62.291 39.972,180.718 150.734,83.983c83.174,-83.983 22.851,-126.674 -53.408,-137.969c-2.71,-0.302 -5.409,-0.667 -8.089,-1.096c2.732,0.337 5.429,0.702 8.089,1.096c52.037,5.785 108.54,-12.239 124.413,-65.574c4.804,-16.142 12.169,-112.847 12.169,-126.281c-0,-13.434 -2.705,-36.267 -17.577,-42.988c-12.85,-5.806 -32.45,-12.09 -83.829,24.181c-53.634,37.864 -111.319,114.635 -132.502,155.831Z"/></svg>
  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://reddit.com/submit/?url=https://dasarpai.com/dsblog/understanding-contextual-embedding-in-transformers/&amp;resubmit=true&amp;title=Understanding%20Contextual%20Embedding%20in%20Transformers"
      title="Submit to Reddit"
      aria-label="Submit to Reddit"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"/></svg>

  </span>


    </a>
      
    
  </section>


    </div>

    
      
      
        
        
      

      <script>
        var oid = "views_dsblog\\2025-01-30-6214-Understanding-Contextual-Embedding-in-Transformers.md";
        var oid_likes = "likes_dsblog\\2025-01-30-6214-Understanding-Contextual-Embedding-in-Transformers.md";
      </script>
      
      <script type="text/javascript" src="/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js" integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q&#43;oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script>
    
  </section>

  <footer class="pt-8 print:hidden">
    
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="flex group mr-3" href="/dsblog/understanding-working-of-cnn/">
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Understanding the Working of CNN</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2025-01-29T00:00:00&#43;00:00">29 January 2025</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
            <a class="flex text-right group ml-3" href="/dsblog/exploring-tokenization-and-embedding-in-nlp/">
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Exploring Tokenization and Embedding in NLP</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2025-01-31T00:00:00&#43;00:00">31 January 2025</time>
                  
                </span>
              </span>
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
            </a>
          
        </span>
      </div>
    </div>
  


    
  </footer>

  <div>
    


  
  
    <h2 class="mt-8 text-2xl font-extrabold mb-10">Related</h2>
    <section class="w-full grid gap-4 sm:grid-cols-2 md:grid-cols-3">
      
        

  <a href="/dsblog/transformers-demystified-a-step-by-step-guide/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6113-transformers-demystified-a-step-by-step-guide.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/transformers-demystified-a-step-by-step-guide/">Transformers Demystified A Step-by-Step Guide</div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2024-07-25T00:00:00&#43;00:00">25 July 2024</time><span class="px-2 text-primary-500">&middot;</span><span>7312 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">35 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/transformers/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Transformers
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/natural-language-processing/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Natural Language Processing
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/neural-networks/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Neural Networks
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/machine-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Machine Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-architecture/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Architecture
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/attention-mechanism/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Attention Mechanism
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         Transformers Demystified A Step-by-Step Guide # All modern Transformers are based on a paper 
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
        

  <a href="/dsblog/Understanding-LLM-GAN-and-Transformers/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6127-Understanding-LLM-GAN-and-Transformers.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/Understanding-LLM-GAN-and-Transformers/">Understanding LLM GAN and Transformers</div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2024-07-26T00:00:00&#43;00:00">26 July 2024</time><span class="px-2 text-primary-500">&middot;</span><span>2064 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">10 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/large-language-models/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Large Language Models
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/gans/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    GANs
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/transformers/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Transformers
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-architecture/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Architecture
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/neural-networks/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Neural Networks
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/machine-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Machine Learning
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         Understanding LLM, GAN and Transformers # LLM Layers # Large Language Models (LLMs) are typically 
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
        

  <a href="/dsblog/understanding-working-of-cnn/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6213-Understanding-Working-of-CNN.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/understanding-working-of-cnn/">Understanding the Working of CNN</div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2025-01-29T00:00:00&#43;00:00">29 January 2025</time><span class="px-2 text-primary-500">&middot;</span><span>3769 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">18 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/cnn/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    CNN
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         Understanding the Working of CNN # In this article, we aim to delve deeper into the working of 
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
        

  <a href="/dsblog/AI-Imperialism/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6191-AI-Imperialism.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/AI-Imperialism/">AI Imperialism: Western Dominance and the Future of Global Technology </div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2024-12-16T00:00:00&#43;00:00">16 December 2024</time><span class="px-2 text-primary-500">&middot;</span><span>3392 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">16 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/nlp/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    NLP
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/transformers/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Transformers
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/attention/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Attention
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/imperialism/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Imperialism
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         AI Imperialism: Western Dominance and the Future of Global Technology # In the rapidly evolving 
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
        

  <a href="/dsblog/Types-of-LLM/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6171-Types-of-LLM.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/Types-of-LLM/">Types of Large Language Models (LLM)</div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2024-10-24T00:00:00&#43;00:00">24 October 2024</time><span class="px-2 text-primary-500">&middot;</span><span>1071 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">6 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/large-language-models/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Large Language Models
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/artificial-intelligence/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Artificial Intelligence
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/natural-language-processing/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Natural Language Processing
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/machine-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Machine Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-models/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Models
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/language-ai/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Language AI
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/text-generation/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Text Generation
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ai-technology/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    AI Technology
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         Introduction: # The world of Generative AI (GenAI) is expanding at an astonishing rate, with new 
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
        

  <a href="/dsblog/ML-Model-Development-Framework/" class="min-w-full">

  <div class="min-h-full border border-neutral-200 dark:border-neutral-700 border-2 rounded overflow-hidden shadow-2xl relative">

    
      
        
      
      <div class="w-full thumbnail_card_related nozoom" style="background-image:url(/assets/images/dspost/dsp6096-ML-Model-Development-Framework.jpg);"></div>
      
    

    <div class="px-6 py-4">

      
      <div class="font-bold text-xl text-neutral-800 decoration-primary-500 hover:underline hover:underline-offset-2 dark:text-neutral"
        href="/dsblog/ML-Model-Development-Framework/">ML Model Development Framework</div>
      

      <div class="text-sm text-neutral-500 dark:text-neutral-400">
        











  





  



  













<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="2023-09-02T00:00:00&#43;00:00">2 September 2023</time><span class="px-2 text-primary-500">&middot;</span><span>296 words</span><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">2 mins</span>
  

  
  
</div>





<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/categories/dsblog/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Dsblog
  </span>
</span>
  </span>
  
  
  
  
  
  
  
  
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/ml-development/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    ML Development
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/model-framework/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Model Framework
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/deep-learning/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Deep Learning
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/model-architecture/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Model Architecture
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/mlops/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    MLOps
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/software-engineering/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Software Engineering
  </span>
</span>
  </span>
  
  <span style="margin-top:0.5rem" class="mr-2" onclick="window.open(&#34;/tags/best-practices/&#34;,'_self');return false;">
    <span class="flex" style="cursor: pointer;">
  <span class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400">
    Best Practices
  </span>
</span>
  </span>
  
  
  
  
</div>




      </div>

      
      
      <div class="py-1 prose dark:prose-invert">
         ML Model Development Framework &amp; Model Repositories # Introduction # There are hundreds of 
      </div>
      
    </div>
    <div class="px-6 pt-4 pb-2">

    </div>
  </div>
</a>

      
    </section>
  

  </div>
</article>

      <div id="top-scroller" class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0">
  <a href="#the-top"
    class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="Scroll to top" title="Scroll to top">
    &uarr;
  </a>
</div>
    </main><article><section class="footer-wrapper">
  <footer class="td-footer container-fluid">
    <div class="row">
      
      <div class="col-md-2 mb-4 mb-md-0">
        <a href="https://dasarpai.com" target="_blank" rel="noopener">
          <img src="https://dasarpai.com/assets/images/site-logo.png" alt="dasarpAI" width="100" style="border-radius: 12px;">
        </a>
      </div>

      
      <div class="col-md-10">
        

        
        <div class="row"><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">Key Links</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/aboutme" class="text-muted">About Me</a></li><li class="mb-2"><a href="/dscourses" class="text-muted">My Data Science Courses/Services</a></li><li class="mb-2"><a href="/summary-of-al-ml-projects" class="text-muted">MyWork by Business Domain</a></li><li class="mb-2"><a href="/summary-of-my-technology-stacks" class="text-muted">MyWork by Tech Stack</a></li><li class="mb-2"><a href="/summary-of-management-projects" class="text-muted">MyWork in Project Management</a></li><li class="mb-2"><a href="/clients" class="text-muted">Clients</a></li><li class="mb-2"><a href="/testimonials" class="text-muted">Testimonial</a></li><li class="mb-2"><a href="/terms-of-service" class="text-muted">Terms &amp; Condition</a></li><li class="mb-2"><a href="/privacy" class="text-muted">Privacy Policy</a></li><li class="mb-2"><a href="/comment-policy" class="text-muted">Comment Policy</a></li></ul>
                  </div>
                </div><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">My Blogs</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/dsblog" class="text-muted">Data Science Blog</a></li><li class="mb-2"><a href="/booksumary" class="text-muted">Books/Interviews Blog</a></li><li class="mb-2"><a href="/news" class="text-muted">AI and Business News</a></li><li class="mb-2"><a href="/pmblog" class="text-muted">PMLOGY Blog</a></li><li class="mb-2"><a href="/pmbok6hi" class="text-muted">PMBOK6 Hindi Explorer</a></li><li class="mb-2"><a href="/wiaposts" class="text-muted">Wisdom in Awareness Blog</a></li><li class="mb-2"><a href="/samskrutyatra" class="text-muted">Samskrut Blog</a></li><li class="mb-2"><a href="/mychanting" class="text-muted">My Chantings</a></li><li class="mb-2"><a href="/quotations-blog" class="text-muted">WIA Quotes</a></li><li class="mb-2"><a href="/gk" class="text-muted">GK Blog</a></li></ul>
                  </div>
                </div><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">All Resources</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/datascience-tags#ds-resources" class="text-muted">DS Resources</a></li><li class="mb-2"><a href="https://aibenchmark-explorer.dasarpai.com" class="text-muted">AI Benchmark Explorer</a></li><li class="mb-2"><a href="/dsblog/ds-ai-ml-books" class="text-muted">Data Science-Books</a></li><li class="mb-2"><a href="/dsblog/data-science-cheatsheets" class="text-muted">Data Science/AI Cheatsheets</a></li><li class="mb-2"><a href="/dsblog/best-youtube-channels-for-ds" class="text-muted">Video Channels to Learn DS/AI</a></li><li class="mb-2"><a href="/dsblog/ds-ai-ml-interview-resources" class="text-muted">DS/AI Interview Questions</a></li><li class="mb-2"><a href="https://github.com/dasarpai/DAI-Datasets" class="text-muted">GitHub DAI-Datasets</a></li><li class="mb-2"><a href="/pmi-templates" class="text-muted">PMBOK6 Templates</a></li><li class="mb-2"><a href="/prince2-templates" class="text-muted">PRINCE2 Templates</a></li><li class="mb-2"><a href="/microsoft-pm-templates" class="text-muted">Microsoft PM Templates</a></li></ul>
                  </div>
                </div><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">Project Management</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/pmlogy-home" class="text-muted">PMLOGY Home</a></li><li class="mb-2"><a href="/pmblog" class="text-muted">PMLOGY Blog</a></li><li class="mb-2"><a href="/pmglossary" class="text-muted">PM Glossary</a></li><li class="mb-2"><a href="/pmlogy-tags" class="text-muted">PM Topics</a></li><li class="mb-2"><a href="/pmbok6-tags" class="text-muted">PMBOK6 Topics</a></li><li class="mb-2"><a href="/pmbok6-summary" class="text-muted">PMBOK6</a></li><li class="mb-2"><a href="/pmbok6" class="text-muted">PMBOK6 Explorer</a></li><li class="mb-2"><a href="/pmbok6hi-tags" class="text-muted">PMBOK6 Hindi Topics</a></li><li class="mb-2"><a href="/pmbok6hi-summary" class="text-muted">PMBoK6 Hindi</a></li><li class="mb-2"><a href="/pmbok6hi" class="text-muted">PMBOK6 Hindi Explorer</a></li></ul>
                  </div>
                </div></div>

        
        <div class="row"><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">Wisdom in Awareness</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/wia-home" class="text-muted">WIA Home</a></li><li class="mb-2"><a href="/wiaposts" class="text-muted">WIA Blog</a></li><li class="mb-2"><a href="/wia-tags" class="text-muted">WIA Topics</a></li><li class="mb-2"><a href="/quotations-blog" class="text-muted">WIA Quotes</a></li><li class="mb-2"><a href="/gk" class="text-muted">GK Blog</a></li><li class="mb-2"><a href="/gk-tags" class="text-muted">GK Topic</a></li></ul>
                  </div>
                </div><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">Samskrutyatra</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/samskrutyatra-home" class="text-muted">SamskrutYatra Home</a></li><li class="mb-2"><a href="/samskrutyatra" class="text-muted">Samskrut Blog</a></li><li class="mb-2"><a href="/samskrutyatra-tags" class="text-muted">Samskrut Topics</a></li><li class="mb-2"><a href="/mychanting" class="text-muted">My Vedic Chantings</a></li></ul>
                  </div>
                </div><div class="col-md-3 mb-4">
                  <div class="footer-menu">
                    <h5 class="footer-title">My Gallery</h5>
                    <ul class="list-unstyled"><li class="mb-2"><a href="/gallary/slider-online-sessions1" class="text-muted">Online AI Classes 1</a></li><li class="mb-2"><a href="/gallary/slider-online-sessions2" class="text-muted">Online AI Classes 2</a></li><li class="mb-2"><a href="/gallary/slider-online-sessions3" class="text-muted">Online AI Classes 3</a></li><li class="mb-2"><a href="/gallary/slider-online-sessions4" class="text-muted">Online AI Classes 4</a></li><li class="mb-2"><a href="/gallary/slider-pm-selected-photos" class="text-muted">Management Classes</a></li><li class="mb-2"><a href="/gallary/slider-pm-workshops" class="text-muted">PM &amp; DS Workshop</a></li></ul>
                  </div>
                </div></div>
      </div>
    </div>

    
    <div class="row mt-4 pt-3 border-top">
      <div class="col-md-4 order-2 order-md-1">
        <ul class="td-footer__links-list">
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Slack" aria-label="Slack">
    <a target="_blank" rel="noopener" href="https://join.slack.com/t/dasarpai/shared_invite/zt-2mg1j7ddw-0QYA9IAvFFRKw51ZBK6mkQ" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="User mailing list" aria-label="User mailing list">
    <a target="_blank" rel="noopener" href="https://groups.google.com/forum/#!forum/agones-discuss" aria-label="User mailing list">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Twitter" aria-label="Twitter">
    <a target="_blank" rel="noopener" href="https://twitter.com/dasarpai" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Community Meetings" aria-label="Community Meetings">
    <a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLhkWKwFGACw2dFpdmwxOyUCzlGP2-n7uF" aria-label="Community Meetings">
      <i class="fab fa-youtube"></i>
    </a>
  </li>
  
</ul>

      </div>
      <div class="col-md-4 order-1 order-md-2 text-center mb-3 mb-md-0">
        
      </div>
      <div class="col-md-4 order-3 text-md-end">
        <ul class="td-footer__links-list">
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="GitHub" aria-label="GitHub">
    <a target="_blank" rel="noopener" href="https://github.com/dasarpai/dasarpai-agones" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Slack" aria-label="Slack">
    <a target="_blank" rel="noopener" href="https://join.slack.com/t/dasarpai/shared_invite/zt-2mg1j7ddw-0QYA9IAvFFRKw51ZBK6mkQ" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Community Meetings" aria-label="Community Meetings">
    <a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLhkWKwFGACw2dFpdmwxOyUCzlGP2-n7uF" aria-label="Community Meetings">
      <i class="fab fa-youtube"></i>
    </a>
  </li>
  
</ul>

      </div>
    </div>
  </footer>
</section>
</article>







<style>
.footer-wrapper {
   
  padding: 2rem 0;
  margin-top: 3rem;
}

.footer-menu .footer-title {
  font-size: 1rem;
  font-weight: 600;
  margin-bottom: 1rem;
  color: #333;
}

.footer-menu ul {
  padding-left: 0;
}

.footer-menu a {
  text-decoration: none;
  transition: color 0.2s;
}

.footer-menu a:hover {
  color: #007bff !important;  
}

@media (min-width: 768px) {
  .footer-menu {
    height: 100%;
  }
  .footer-menu > ul {
    display: flex;
    flex-direction: column;
    height: 100%;
  }
}
</style><div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="https://dasarpai.com/"
  style="z-index:500"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="Search"
          tabindex="0"
        />

      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="Close (Esc)"
      >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>


      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

  </div>
</body>

<script data-name="BMC-Widget" data-cfasync="false" src="https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js"
  data-id="harithapliyal" data-description="Support me on Buy me a coffee!" data-message=""
  data-color="#FFDD00" data-position="Right" data-x_margin="18" data-y_margin="18"></script>

</html>
